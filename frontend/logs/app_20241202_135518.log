2024-12-02 13:55:18,178 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:55:18,181 [INFO] app1.py:1402 - Starting Flask application
2024-12-02 13:55:18,181 [INFO] app1.py:1405 - Starting with Waitress server on http://127.0.0.1:4585
2024-12-02 13:55:27,478 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 13:55:27,663 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 13:55:27,777 [INFO] app1.py:1240 - Audio stream started
2024-12-02 13:55:29,692 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 13:55:29,692 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ab1b9da6c60478fa7fdff5b66df9a00, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:30,094 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 13:55:30,095 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=04f1a1baa974431e840f2ae1931ab5a6, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:30,402 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 13:55:30,403 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ec44dc8a77b540fc9191282d9aa2467f, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:32,003 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing are you
2024-12-02 13:55:32,004 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dd75092544824623a0b3e22ff3a8c6b9, text="hello what are you doing are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:32,300 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing are you listening
2024-12-02 13:55:32,301 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c2fe489a0284cba91f090be8c178fc8, text="hello what are you doing are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:32,701 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing are you listening me
2024-12-02 13:55:32,701 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0ee57bdb466a40e1815f74026df44e63, text="hello what are you doing are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:33,276 [INFO] app1.py:1205 - Speech recognized: Hello. What are you doing? Are you listening me?
2024-12-02 13:55:33,276 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b7aabaa9da62424f81faf09d0c099edd, text="Hello. What are you doing? Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:55:35,005 [DEBUG] app1.py:1214 - Speech recognizing: yeah OK
2024-12-02 13:55:35,005 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=357e282cf7044b6c87bf11a2d2427196, text="yeah OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:35,842 [INFO] app1.py:1205 - Speech recognized: Yeah, OK.
2024-12-02 13:55:35,842 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7901b5944a3c47e58231ceb9ec633c57, text="Yeah, OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:55:40,631 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:55:40,632 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:55:40,632 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 13:55:40,635 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 13:55:40,635 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 13:55:40,636 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing are you (is_final: False)
2024-12-02 13:55:40,637 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing are you listening (is_final: False)
2024-12-02 13:55:40,639 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing are you listening me (is_final: False)
2024-12-02 13:55:40,641 [DEBUG] app1.py:1104 - Sending transcription: Hello. What are you doing? Are you listening me? (is_final: True)
2024-12-02 13:55:40,642 [DEBUG] app1.py:1104 - Sending transcription: yeah OK (is_final: False)
2024-12-02 13:55:40,663 [DEBUG] app1.py:1104 - Sending transcription: Yeah, OK. (is_final: True)
2024-12-02 13:55:42,732 [DEBUG] app1.py:1214 - Speech recognizing: yeah OK
2024-12-02 13:55:42,733 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=01c0ae17985b4b1d89d6220999231919, text="yeah OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:42,735 [DEBUG] app1.py:1104 - Sending transcription: yeah OK (is_final: False)
2024-12-02 13:55:43,309 [INFO] app1.py:1205 - Speech recognized: Yeah, OK.
2024-12-02 13:55:43,310 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=932f2650f05d456e9c512891cb6a5147, text="Yeah, OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:55:43,311 [DEBUG] app1.py:1104 - Sending transcription: Yeah, OK. (is_final: True)
2024-12-02 13:55:45,004 [DEBUG] app1.py:1214 - Speech recognizing: yeah OK
2024-12-02 13:55:45,005 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce3864ce8ff54e41ae23fd1f70d68385, text="yeah OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:45,006 [DEBUG] app1.py:1104 - Sending transcription: yeah OK (is_final: False)
2024-12-02 13:55:46,824 [INFO] app1.py:1205 - Speech recognized: Yeah, OK.
2024-12-02 13:55:46,825 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e3efeb540c874806995b5a167d1f08ee, text="Yeah, OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:55:46,825 [DEBUG] app1.py:1104 - Sending transcription: Yeah, OK. (is_final: True)
2024-12-02 13:55:47,959 [DEBUG] app1.py:1214 - Speech recognizing: yeah
2024-12-02 13:55:47,960 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0f617357d45748698ac25328e1a0efc7, text="yeah", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:47,961 [DEBUG] app1.py:1104 - Sending transcription: yeah (is_final: False)
2024-12-02 13:55:48,182 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:55:48,566 [DEBUG] app1.py:1214 - Speech recognizing: yeah OK
2024-12-02 13:55:48,566 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7c9a7be46f1641189be8cc4dd7d23aaa, text="yeah OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:55:48,566 [DEBUG] app1.py:1104 - Sending transcription: yeah OK (is_final: False)
2024-12-02 13:55:50,429 [INFO] app1.py:1205 - Speech recognized: Yeah, OK.
2024-12-02 13:55:50,430 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e9f49a11451f40f5afe41cac4bcd2862, text="Yeah, OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:55:50,431 [DEBUG] app1.py:1104 - Sending transcription: Yeah, OK. (is_final: True)
2024-12-02 13:56:10,632 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:56:10,634 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa04b33710134f129d85fdf3203fc0f8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:56:10,637 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:56:13,030 [DEBUG] app1.py:1214 - Speech recognizing: lime salmon
2024-12-02 13:56:13,031 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ccb30e0312ba4d6ba778a54e61f816fa, text="lime salmon", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:13,033 [DEBUG] app1.py:1104 - Sending transcription: lime salmon (is_final: False)
2024-12-02 13:56:13,340 [DEBUG] app1.py:1214 - Speech recognizing: live salman
2024-12-02 13:56:13,341 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c2adb267324b47549ac75c431c50a480, text="live salman", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:13,342 [DEBUG] app1.py:1104 - Sending transcription: live salman (is_final: False)
2024-12-02 13:56:13,757 [DEBUG] app1.py:1214 - Speech recognizing: live salman khan
2024-12-02 13:56:13,758 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=df01eb4850fb45018c3d213acd0e274a, text="live salman khan", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:13,760 [DEBUG] app1.py:1104 - Sending transcription: live salman khan (is_final: False)
2024-12-02 13:56:14,331 [DEBUG] app1.py:1214 - Speech recognizing: live salman khurshid
2024-12-02 13:56:14,332 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=451eba944c994f38b9d3900d67425a19, text="live salman khurshid", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:14,333 [DEBUG] app1.py:1104 - Sending transcription: live salman khurshid (is_final: False)
2024-12-02 13:56:14,737 [DEBUG] app1.py:1214 - Speech recognizing: live salman khan did a piece of
2024-12-02 13:56:14,738 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5bdae8181dc84c3b8722df0beb4e9d7a, text="live salman khan did a piece of", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:14,739 [DEBUG] app1.py:1104 - Sending transcription: live salman khan did a piece of (is_final: False)
2024-12-02 13:56:14,926 [DEBUG] app1.py:1214 - Speech recognizing: live salman khan did a piece of life salman
2024-12-02 13:56:14,927 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5f47a5f43f0e4577ad8ca49ed60e2880, text="live salman khan did a piece of life salman", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:14,928 [DEBUG] app1.py:1104 - Sending transcription: live salman khan did a piece of life salman (is_final: False)
2024-12-02 13:56:15,329 [DEBUG] app1.py:1214 - Speech recognizing: live salman khan did a piece of life salman khan
2024-12-02 13:56:15,331 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=84f7c1143ef84e86be705f155bde535c, text="live salman khan did a piece of life salman khan", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:15,333 [DEBUG] app1.py:1104 - Sending transcription: live salman khan did a piece of life salman khan (is_final: False)
2024-12-02 13:56:16,201 [INFO] app1.py:1205 - Speech recognized: Live Salman Khurshid.
2024-12-02 13:56:16,202 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=62fc823a0399415598cdd40f80c46e16, text="Live Salman Khurshid.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:56:16,203 [DEBUG] app1.py:1104 - Sending transcription: Live Salman Khurshid. (is_final: True)
2024-12-02 13:56:18,003 [DEBUG] app1.py:1214 - Speech recognizing: live
2024-12-02 13:56:18,003 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ec1c06fe750b47389ff3fc6969a779eb, text="live", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:18,004 [DEBUG] app1.py:1104 - Sending transcription: live (is_final: False)
2024-12-02 13:56:18,183 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:56:18,298 [DEBUG] app1.py:1214 - Speech recognizing: live salman kosher
2024-12-02 13:56:18,300 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=582c376da44a48609ba2d6f472f4d54e, text="live salman kosher", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:18,300 [DEBUG] app1.py:1104 - Sending transcription: live salman kosher (is_final: False)
2024-12-02 13:56:18,499 [DEBUG] app1.py:1214 - Speech recognizing: live salmon kosher
2024-12-02 13:56:18,500 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f15fb766eb464181a38d329220b377c3, text="live salmon kosher", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:56:18,500 [DEBUG] app1.py:1104 - Sending transcription: live salmon kosher (is_final: False)
2024-12-02 13:56:36,348 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:56:36,349 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2f8a976bf8dd44488d83109b88e42d44, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:56:36,350 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:56:48,184 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:56:51,521 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:56:51,522 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fde57747cc67453db29b3d63db68d2a6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:56:51,524 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:57:01,019 [DEBUG] app1.py:1214 - Speech recognizing: mmm
2024-12-02 13:57:01,020 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fcbf0f9fe8714b5c924e2a49ecd9e4f4, text="mmm", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:01,021 [DEBUG] app1.py:1104 - Sending transcription: mmm (is_final: False)
2024-12-02 13:57:02,931 [INFO] app1.py:1205 - Speech recognized: MMM.
2024-12-02 13:57:02,932 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e2f87d42a6914d40845f594dbaf6e54a, text="MMM.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:02,933 [DEBUG] app1.py:1104 - Sending transcription: MMM. (is_final: True)
2024-12-02 13:57:06,824 [DEBUG] app1.py:1214 - Speech recognizing: mmm
2024-12-02 13:57:06,825 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=171a4d44953f4658b4b3ac7814004fde, text="mmm", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:06,826 [DEBUG] app1.py:1104 - Sending transcription: mmm (is_final: False)
2024-12-02 13:57:06,841 [INFO] app1.py:1205 - Speech recognized: MMM.
2024-12-02 13:57:06,841 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9ca749c733254569b065d8aefc99729e, text="MMM.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:06,842 [DEBUG] app1.py:1104 - Sending transcription: MMM. (is_final: True)
2024-12-02 13:57:09,620 [DEBUG] app1.py:1214 - Speech recognizing: what are you
2024-12-02 13:57:09,621 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c4eeaf35f2c94692a89e3b445253a596, text="what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:09,621 [DEBUG] app1.py:1104 - Sending transcription: what are you (is_final: False)
2024-12-02 13:57:09,826 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 13:57:09,827 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=028c6bf0e23a4ed8b7d37f98d6deb20f, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:09,828 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 13:57:10,756 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 13:57:10,769 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9ddb92e597b14dd89cfee416efe86f0a, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:10,770 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 13:57:12,203 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 13:57:12,203 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=43ddafacb70d4338848a351fa7f2d160, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:12,204 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 13:57:12,764 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 13:57:12,764 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6299e715a87049008cf8f80c7b63ee23, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:12,765 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 13:57:15,015 [DEBUG] app1.py:1214 - Speech recognizing: what do you do
2024-12-02 13:57:15,016 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8a5591fd78c24820b55c6b7566444456, text="what do you do", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:15,017 [DEBUG] app1.py:1104 - Sending transcription: what do you do (is_final: False)
2024-12-02 13:57:15,606 [DEBUG] app1.py:1214 - Speech recognizing: what do you do i'm free
2024-12-02 13:57:15,606 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bfad0b418d674144a893d6ca4eaf6c7a, text="what do you do i'm free", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:15,607 [DEBUG] app1.py:1104 - Sending transcription: what do you do i'm free (is_final: False)
2024-12-02 13:57:16,242 [INFO] app1.py:1205 - Speech recognized: What do you do? I'm free.
2024-12-02 13:57:16,243 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=894c866122bd4088b5ecc963ef9b59f5, text="What do you do? I'm free.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:16,243 [DEBUG] app1.py:1104 - Sending transcription: What do you do? I'm free. (is_final: True)
2024-12-02 13:57:17,337 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 13:57:17,338 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3cfc9fde26724f5496f5be282ea997d3, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:17,339 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 13:57:17,614 [DEBUG] app1.py:1214 - Speech recognizing: what do you do
2024-12-02 13:57:17,615 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=29c7d348b32d4b6fb04d1504edcb5bd8, text="what do you do", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:17,616 [DEBUG] app1.py:1104 - Sending transcription: what do you do (is_final: False)
2024-12-02 13:57:18,186 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:57:19,200 [DEBUG] app1.py:1214 - Speech recognizing: what do you do i'm
2024-12-02 13:57:19,201 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3cae90f2efde4552ae3c4e49f4970deb, text="what do you do i'm", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:19,201 [DEBUG] app1.py:1104 - Sending transcription: what do you do i'm (is_final: False)
2024-12-02 13:57:19,514 [DEBUG] app1.py:1214 - Speech recognizing: what do you do i'm free
2024-12-02 13:57:19,515 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f8446b4d37df4ef58290b3cbb4fc2e84, text="what do you do i'm free", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:19,516 [DEBUG] app1.py:1104 - Sending transcription: what do you do i'm free (is_final: False)
2024-12-02 13:57:20,057 [INFO] app1.py:1205 - Speech recognized: What do you do when I'm free?
2024-12-02 13:57:20,059 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3bd2ffd16c8b4d75a2e93e2685bfffd3, text="What do you do when I'm free?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:20,059 [DEBUG] app1.py:1104 - Sending transcription: What do you do when I'm free? (is_final: True)
2024-12-02 13:57:21,816 [DEBUG] app1.py:1214 - Speech recognizing: how do you do
2024-12-02 13:57:21,817 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c264ccde8d9c44a99b3ac0f6747682a2, text="how do you do", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:21,818 [DEBUG] app1.py:1104 - Sending transcription: how do you do (is_final: False)
2024-12-02 13:57:22,234 [DEBUG] app1.py:1214 - Speech recognizing: what do you do when i
2024-12-02 13:57:22,235 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f3aaf0d22d2143feb4164cb18bdc53f7, text="what do you do when i", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:22,236 [DEBUG] app1.py:1104 - Sending transcription: what do you do when i (is_final: False)
2024-12-02 13:57:22,716 [DEBUG] app1.py:1214 - Speech recognizing: what do you do when i'm free
2024-12-02 13:57:22,718 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eecdc084bd0f4635836e95ceeca59665, text="what do you do when i'm free", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:22,719 [DEBUG] app1.py:1104 - Sending transcription: what do you do when i'm free (is_final: False)
2024-12-02 13:57:23,378 [INFO] app1.py:1205 - Speech recognized: What do you do when I'm free?
2024-12-02 13:57:23,379 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=22fbf2a624ea447f92828b8217ad0492, text="What do you do when I'm free?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:23,379 [DEBUG] app1.py:1104 - Sending transcription: What do you do when I'm free? (is_final: True)
2024-12-02 13:57:28,865 [DEBUG] app1.py:1214 - Speech recognizing: what do you store
2024-12-02 13:57:28,866 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=525982d54c594f82b665067ea9ed7609, text="what do you store", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:28,868 [DEBUG] app1.py:1104 - Sending transcription: what do you store (is_final: False)
2024-12-02 13:57:28,870 [INFO] app1.py:1205 - Speech recognized: What do you store?
2024-12-02 13:57:28,871 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bb791e075e76445db60f214b17d8dd2d, text="What do you store?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:28,871 [DEBUG] app1.py:1104 - Sending transcription: What do you store? (is_final: True)
2024-12-02 13:57:30,038 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 13:57:30,040 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eb66408be901442ca6428c865101e564, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:30,040 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 13:57:30,241 [DEBUG] app1.py:1214 - Speech recognizing: what do
2024-12-02 13:57:30,242 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=62e6ff5a318a4105b1eebc1fdc571542, text="what do", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:30,242 [DEBUG] app1.py:1104 - Sending transcription: what do (is_final: False)
2024-12-02 13:57:30,535 [DEBUG] app1.py:1214 - Speech recognizing: what do you
2024-12-02 13:57:30,536 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ed5b90f51224e6abf9f85af3a2820fe, text="what do you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:30,537 [DEBUG] app1.py:1104 - Sending transcription: what do you (is_final: False)
2024-12-02 13:57:30,834 [DEBUG] app1.py:1214 - Speech recognizing: what do you store
2024-12-02 13:57:30,834 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9e74dd334fc4f4886af1af3495f7689, text="what do you store", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:30,835 [DEBUG] app1.py:1104 - Sending transcription: what do you store (is_final: False)
2024-12-02 13:57:32,435 [DEBUG] app1.py:1214 - Speech recognizing: what do you store store
2024-12-02 13:57:32,436 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e2fb715b08044b89a04aa3cd20c42ba7, text="what do you store store", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:32,437 [DEBUG] app1.py:1104 - Sending transcription: what do you store store (is_final: False)
2024-12-02 13:57:32,765 [INFO] app1.py:1205 - Speech recognized: What do you store store?
2024-12-02 13:57:32,766 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e41a22e7e7384e15a10134c04cc13e0f, text="What do you store store?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:32,767 [DEBUG] app1.py:1104 - Sending transcription: What do you store store? (is_final: True)
2024-12-02 13:57:34,238 [DEBUG] app1.py:1214 - Speech recognizing: what do
2024-12-02 13:57:34,239 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2d3511ede97445e99fa25494b1c9c95e, text="what do", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:34,239 [DEBUG] app1.py:1104 - Sending transcription: what do (is_final: False)
2024-12-02 13:57:34,411 [DEBUG] app1.py:1214 - Speech recognizing: what do you
2024-12-02 13:57:34,412 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=02e73690f34447ab9d5891b294f24c42, text="what do you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:34,412 [DEBUG] app1.py:1104 - Sending transcription: what do you (is_final: False)
2024-12-02 13:57:35,120 [DEBUG] app1.py:1214 - Speech recognizing: what do you store store
2024-12-02 13:57:35,121 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=64c71f7070d84019b2a4700065f34a6b, text="what do you store store", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:57:35,122 [DEBUG] app1.py:1104 - Sending transcription: what do you store store (is_final: False)
2024-12-02 13:57:38,841 [INFO] app1.py:1205 - Speech recognized: What do you store store?
2024-12-02 13:57:38,842 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dab014c0c5524bed84d736a62a932eb3, text="What do you store store?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:38,843 [DEBUG] app1.py:1104 - Sending transcription: What do you store store? (is_final: True)
2024-12-02 13:57:48,187 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:57:54,209 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:57:54,209 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c0d0d5c30d094223909582277f08bbe1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:57:54,210 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:58:06,539 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 13:58:06,540 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=96ba128af0144c608886354b71ef0269, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:58:13,227 [DEBUG] app1.py:1214 - Speech recognizing: hi hi
2024-12-02 13:58:13,228 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7278b9c31c9147fea5f7cbdd7634b085, text="hi hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:58:14,125 [DEBUG] app1.py:1214 - Speech recognizing: hi hi what
2024-12-02 13:58:14,125 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ecaa3b57df944880a25523ed0df62a2b, text="hi hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:58:14,433 [DEBUG] app1.py:1214 - Speech recognizing: hi hi what are you
2024-12-02 13:58:14,433 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d107171027fe412ca81fb102a365da29, text="hi hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:58:14,528 [DEBUG] app1.py:1214 - Speech recognizing: hi hi what are you doing
2024-12-02 13:58:14,529 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bce21439c0d04c7b9da068ed6dc68528, text="hi hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:58:15,323 [INFO] app1.py:1205 - Speech recognized: Hi. Hi. What are you doing?
2024-12-02 13:58:15,324 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c934b887b45a495cbc8ffaf3adb202f0, text="Hi. Hi. What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:58:15,901 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:58:15,901 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:58:15,902 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 13:58:15,903 [DEBUG] app1.py:1104 - Sending transcription: hi hi (is_final: False)
2024-12-02 13:58:15,904 [DEBUG] app1.py:1104 - Sending transcription: hi hi what (is_final: False)
2024-12-02 13:58:15,905 [DEBUG] app1.py:1104 - Sending transcription: hi hi what are you (is_final: False)
2024-12-02 13:58:15,905 [DEBUG] app1.py:1104 - Sending transcription: hi hi what are you doing (is_final: False)
2024-12-02 13:58:15,906 [DEBUG] app1.py:1104 - Sending transcription: Hi. Hi. What are you doing? (is_final: True)
2024-12-02 13:58:17,529 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:58:17,531 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=836ef2fac33742bc84970cd8a2fb627a, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:58:17,532 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:58:18,190 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:58:18,430 [DEBUG] app1.py:1214 - Speech recognizing: hi home
2024-12-02 13:58:18,431 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d6cebc625a274be7806515d32e28e3a8, text="hi home", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:58:18,433 [DEBUG] app1.py:1104 - Sending transcription: hi home (is_final: False)
2024-12-02 13:58:18,834 [INFO] app1.py:1205 - Speech recognized: Hi home.
2024-12-02 13:58:18,836 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2a6642a0ff1049c4b391d78734476008, text="Hi home.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:58:18,837 [DEBUG] app1.py:1104 - Sending transcription: Hi home. (is_final: True)
2024-12-02 13:58:20,821 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 13:58:20,821 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a02f046cc41547c1bc751a65a744bdb8, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:58:20,822 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 13:58:38,680 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:58:38,681 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=383ebf1724e24d3695bcaf0c5b418442, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:58:38,683 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:58:48,193 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:58:53,811 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:58:53,812 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c4dc5ec75f884ab58134ba87af8ea6ba, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:58:53,812 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:59:08,887 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:59:08,888 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5d0a6f3a1f4f4b90b589dec7145c1e3a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:59:08,888 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:59:18,195 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:59:21,723 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:59:21,723 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=20cfa44bba8d44b3b685af034ea4b03b, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:59:22,126 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:59:22,126 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=12cb59cbf9a64de9abb726dba39c5356, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:59:23,633 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing hi
2024-12-02 13:59:23,634 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c9b349bdc6ee4a5fb42f26574c8d21fd, text="hi what are you doing hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:59:24,020 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing hi are you
2024-12-02 13:59:24,020 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=10534552255e48148c9cc42d58a85e20, text="hi what are you doing hi are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:59:24,336 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing hi are you listening
2024-12-02 13:59:24,337 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ead58c4c75064e0db6e065aa36f4a754, text="hi what are you doing hi are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:59:24,723 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing hi are you listening me
2024-12-02 13:59:24,724 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=11cd4170095d4f97b290d501f7bf5f11, text="hi what are you doing hi are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:59:24,955 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing? Hi, are you listening me?
2024-12-02 13:59:24,956 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f0709213f6c2441ead9d6ca25c7d595c, text="Hi, what are you doing? Hi, are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:59:43,249 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:59:43,250 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6476191c035145de8b3dbcd7c201f995, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:59:48,196 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:00:00,185 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:00:00,186 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6b4b716d310b47e1bee6f9823211a2b3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:00:15,190 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:00:15,191 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fc4b20fa6a934a4b951adfa9e3969a6f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:00:18,197 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:00:30,180 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:00:30,181 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7e8899fdb29447718d4c604ce14decb6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:00:45,277 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:00:45,278 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=93916e16593f4fd4938e77794f8b2771, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:00:48,198 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:01:00,288 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:01:00,290 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e8bd01a3ec0e42ec8ca6f37253da3f4b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:01:15,288 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:01:15,289 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=58291c6c6df243d7bfb91510450862c5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:01:18,200 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:01:30,279 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:01:30,281 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ffae516e0b0c4b9f881083e82d050730, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:01:34,835 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:01:34,836 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8a4425051d5747408e00452a73fdab78, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:01:48,201 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:01:50,615 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:01:50,616 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=075824f04a4b4c9f8dcb2086b46c7332, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:02:10,110 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:02:10,111 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=84277ccba5354c6ba83cbd9ae1c91cb2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:02:18,204 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:02:24,632 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:02:24,634 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=19d8c23a6f5c44ad9c6522923c3306e9, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:02:44,579 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:02:44,580 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=894520eadf2c4fbfb4d4645a70959c72, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:02:48,206 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:02:59,644 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:02:59,645 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=572893ff8f0940789c482a2b4449346f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:03:14,733 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:03:14,734 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=45a2082214844e4aaf00948c9ac83e9e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:03:18,208 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:03:29,675 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:03:29,677 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d5afb737fd9c47d6a83378814df2b4c1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:03:44,739 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:03:44,739 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b849e218fa5d47e9ad5bb57264f4e67f, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:03:48,209 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:04:04,678 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:04:04,680 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e622e124a3c241e58bc20f0893e5c751, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:04:18,211 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:04:19,775 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:04:19,776 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=089063f54cb44596a95a589bac0fef0c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:04:34,779 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:04:34,780 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1665d79ab8574baabbef5330242c7104, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:04:48,212 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:04:49,779 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:04:49,779 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8761b984fa2248f8977dc5e6390e2c18, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:05:04,880 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:05:04,881 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=609072888a064b8a800b65e2241904d8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:05:18,215 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:05:19,889 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:05:19,890 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=863ea88f01b4474b83609d33fd006d64, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:05:33,508 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:05:33,509 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=731fd62e6a974c83873c6a396bdd6850, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:05:48,216 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:05:51,954 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:05:51,956 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=522dd564d4474b42abed148d76611180, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:06:08,478 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:06:08,479 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=db8c5995ea8f430cac5b2f3c7007febb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:06:18,218 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:06:23,477 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:06:23,478 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d2c226b42bf3493b9e64d77d12ed64c5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:06:35,921 [INFO] app1.py:1205 - Speech recognized: The.
2024-12-02 14:06:35,923 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6173b29f8beb43a4a9d4665092dbe593, text="The.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:06:48,220 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:06:56,024 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:06:56,025 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=76be36daeba147e3b791b0e75fcded0b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:07:10,906 [INFO] app1.py:1205 - Speech recognized: Hey, Cortana.
2024-12-02 14:07:10,907 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b758fb2f475f4123b343b69bf8a5d7d5, text="Hey, Cortana.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:07:18,222 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:07:31,039 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:07:31,040 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f6442d3194984c9f8468685d5a01ec5c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:07:37,138 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:07:37,139 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa39fb7ed67a41d29ab9e83bbf949e83, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:07:48,224 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:07:56,978 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:07:56,979 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b308761df20549508890a906e1c68e14, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:08:11,045 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:08:11,046 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3d7a6ed2b8114e8db85b4e0ec7fb7a84, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:08:18,226 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:08:30,873 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:08:30,873 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a6dc5cbe766247808e23757178ae3cd6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:08:36,126 [INFO] app1.py:1205 - Speech recognized: The.
2024-12-02 14:08:36,126 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b3bd182db0f94663a9638256af4a5950, text="The.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:08:45,307 [INFO] app1.py:1205 - Speech recognized: It's.
2024-12-02 14:08:45,308 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=246fb524a69542f28826cae9dcdf3997, text="It's.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:08:48,228 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:09:05,363 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:09:05,364 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1ed3b68bb26341fdafcd9e524602e011, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:09:18,230 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:09:20,375 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:09:20,375 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=12dac280fdb94d4280d0f548531b66fb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:09:35,378 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:09:35,379 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=61f38ccb847c4080b3b0cd4c358ff2e0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:09:48,232 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:09:50,479 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:09:50,480 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=85a631bca3f54ebf97e4863ad20cba67, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:10:05,479 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:10:05,480 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b76e7ce5b75545979b644b0d91ef97d2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:10:18,234 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:10:20,487 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:10:20,489 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1defdaba40134d1aa31278586ce5b52c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:10:35,477 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:10:35,478 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=66b9f58598b44e8980a10e59543328c8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:10:48,236 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:10:50,488 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:10:50,489 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0c5434727e9d460e97ee345337f02436, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:11:05,478 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:11:05,480 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=235221812c4f460c879b74ccfce88b99, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:11:18,238 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:11:20,563 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:11:20,565 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a966607c885e4883bbb70cfd95328608, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:11:35,474 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:11:35,475 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4348eb44b324449d8269c8ad2eded8f6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:11:48,239 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:11:50,476 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:11:50,477 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b722d6849b5e455484afca154798c8fe, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:12:05,488 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:12:05,489 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=db5f30064b6b4e4ba9512d661bdc72e5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:12:18,241 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:12:20,831 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:12:20,832 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fa73bd2cda1c4dee9af34940520a599d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:12:35,791 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:12:35,792 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bbd8c18efb384e9391a13a8b6d15578c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:12:48,243 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:12:50,777 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:12:50,779 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7cfde1ade30c4dcca06a4724b5b13998, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:13:05,787 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:13:05,787 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c9492db665cd492cbba2def25d93f0b3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:13:18,245 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:13:20,878 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:13:20,879 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9090e656923a4d188e8ee283bf29c0ed, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:13:35,899 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:13:35,900 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2aa501f24ec641f38530b6f0f7c88393, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:13:48,247 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:13:50,885 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:13:50,887 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=18e34074441d484dadfe893daa2c1f9c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:14:05,876 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:14:05,877 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fbd4e914c3424119994258889b30cf49, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:14:18,249 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:14:20,876 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:14:20,877 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=de796c3c54984efab0576417b5136f9f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:14:35,877 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:14:35,879 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=51b67522eb614ae493f8af163d5795bf, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:14:48,250 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:14:50,878 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:14:50,880 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2ab43b8f8a66416a87aa9b5766e8c52f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:15:05,893 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:15:05,894 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3f9f75246d4a4ff89f8c34a380e9827a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:15:18,252 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:15:20,899 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:15:20,900 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=40c15f5291e848fca2f9ba4b5c7bb380, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:15:35,872 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:15:35,873 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d66d97cd827543769e05f14357109f89, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:15:48,254 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:15:50,886 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:15:50,887 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1131d595f2df44c2af5c884c47b4bcf1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:16:05,999 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:16:06,001 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a6809a7cd80e4970aed415b1edb120f7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:16:18,256 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:16:21,129 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:16:21,131 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ae0d38e12eed4bb793a01bfe04da411b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:16:36,186 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:16:36,187 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=674d817444484eadae1dac1d2ee2902d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:16:48,258 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:16:51,172 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:16:51,174 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3b2d13ca28784b879e95d22516cb025e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:17:06,206 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:17:06,208 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e3a3549883e34f30aeee15bbdaa832e4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:17:18,259 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:17:21,287 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:17:21,288 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=141960f20da5457ea54c00f6d961af87, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:17:36,277 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:17:36,278 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=09a06b69b0314e2b874bf68ded2d73a7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:17:48,261 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:17:51,276 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:17:51,293 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=26f514b5880d467e9d4a98fda4d146f2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:18:06,270 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:18:06,271 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cbbdbcbeedbd4c93b2b02e129af38b96, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:18:18,264 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:18:21,396 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:18:21,397 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2752f4ae125649bcbd391141a7a7216e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:18:36,377 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:18:36,378 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f6e1f99e91b54662a7ec9af858e88195, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:18:48,266 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:18:51,377 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:18:51,378 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a2d45c6a81bd457d8ed72be71c8f0f77, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:19:06,384 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:19:06,385 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=69767bcd3ad449f48b3f332862dc24d6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:19:18,267 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:19:21,376 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:19:21,377 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=53853a03d0e54672acc10af264d9049e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:19:36,371 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:19:36,373 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f65bdce95daf429182db7d56b0ccfb92, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:19:48,269 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:19:51,371 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:19:51,372 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7f39204f7dd2468f82dbb2c28ea7a392, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:20:06,390 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:20:06,391 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa42183c95e04125a11157527ed332a4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:20:18,271 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:20:21,470 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:20:21,471 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8e33c6f2a87c49419851aa42d16384dd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:20:36,486 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:20:36,487 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c0a364222a9849aaa3406088889a387f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:20:48,273 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:20:51,475 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:20:51,476 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8dec148bfe454640a3a933d39e1392f0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:21:06,476 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:21:06,477 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=94ae3d706f1341c8a0a165d15eccd37a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:21:18,275 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:21:21,476 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:21:21,477 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=34199c314c1c45b4afd4b1ec6f6acf95, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:21:36,477 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:21:36,478 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=81248be0a0e44cc18ec1c49ea4432818, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:21:48,276 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:21:51,470 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:21:51,471 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2ee47bb961a64da8a1f8dd4f3e4d0d02, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:22:06,502 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:22:06,503 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=96d66ccc178e4c98ab25695f4c24b2c3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:22:18,278 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:22:21,476 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:22:21,477 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=845f343c06d24da58e9f8668fe65e95f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:22:36,474 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:22:36,475 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=87e1f76dc29f44119a7b58204d4317e5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:22:48,280 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:22:51,571 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:22:51,573 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a5c250dd49304c2eae5997df8141fdb3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:23:06,575 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:23:06,576 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa0b885f64a94368abceac870c29810e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:23:18,282 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:23:21,598 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:23:21,598 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=83e2df631b084e6fabe3e4d21da4c9dd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:23:36,570 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:23:36,571 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ea3cf37ff45c4a6b9ecd053402911aba, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:23:48,284 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:23:51,574 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:23:51,576 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=05f02607eb8c472abc6f2f07e0709b8c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:23:56,756 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:23:56,757 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3fa9c14fa2dc4f5d92e3bdbf2bfd8003, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:24:16,785 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:24:16,787 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3b4313fbf36447298ff3049d487becae, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:24:18,286 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:24:31,774 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:24:31,775 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a2aa87cfb0e34c69bba4db4b839b482c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:24:46,885 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:24:46,886 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7e403148e1584ae1be025d16bc9f0eeb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:24:48,288 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:25:01,868 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:25:01,869 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=821d8392dd5946158db98d1010381611, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:25:16,883 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:25:16,883 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d367651d1529468b9d1012af98a263a7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:25:18,290 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:25:31,875 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:25:31,876 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aec3af75b8be4b63be7f8d460efb66c5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:25:46,875 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:25:46,877 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6e638c9ab3c946b59d5210ba989e6a70, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:25:48,292 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:26:01,876 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:26:01,877 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=acfa631e25544034b2bf67caa739e77c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:26:16,873 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:26:16,874 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8a62bff70c9c455f9e81225f95238fec, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:26:18,294 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:26:31,873 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:26:31,874 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=85fcec3d6c314c03bd1423e8993a5808, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:26:46,875 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:26:46,876 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=235cc74dafac4991b92ab6e98c49e5c7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:26:48,295 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:27:01,881 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:27:01,882 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7e23ecec43fe48bdacb0c4bbd1f42f74, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:27:16,984 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:27:16,985 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c00de5a733424633a81c79a3f095bea3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:27:18,297 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:27:31,975 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:27:31,976 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e995105bfb2348ceb45c1ebc7add0b85, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:27:46,975 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:27:46,976 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7ed39afa3546453fba70fabb7689cacf, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:27:48,299 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:28:01,976 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:28:01,977 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9f9d2cb63eff41b79b039181e5de6b95, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:28:16,971 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:28:16,973 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1fc5351aa3c047d5b12b8d59c6be6be7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:28:18,301 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:28:31,969 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:28:31,970 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=96276ca59e4d4bf19c502488b61162df, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:28:46,974 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:28:46,975 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8058133f1c2b419687d584127d01eff9, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:28:48,303 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:29:01,968 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:29:01,970 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=171934df5efd49baa9d3db067c552e74, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:29:16,974 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:29:16,975 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=02da592be25146ce9d8967c984a5095e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:29:18,304 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:29:32,073 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:29:32,074 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=79ff3308dda44f079459556e9209b1d3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:29:47,066 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:29:47,067 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8c54babd0bff487881219747aa8de0ce, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:29:48,306 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:30:02,091 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:30:02,092 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3f0861383cdd4758a53abaef2fe69fe6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:30:17,234 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:30:17,236 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=56e2b7c2c577438eb2a9ec6737acfb2b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:30:18,308 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:30:32,274 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:30:32,275 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6b7078d9bc224944803a823775832d30, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:30:47,275 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:30:47,276 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0b0eea223adb49cf837038e6f76d82fb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:30:48,309 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:31:02,271 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:31:02,272 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=29f56e5d02304502bafabc20bd0bfe29, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:31:17,269 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:31:17,270 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9321568eb709428dbf5ad45370cb098a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:31:18,310 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:31:32,274 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:31:32,275 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=39008615afb94daea83a9e2f90a01248, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:31:47,272 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:31:47,272 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7a418aeb1f314692b2f633880f680e9d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:31:48,310 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:31:57,814 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:31:57,815 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=99a5265e742c480982a674babe056a98, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:32:14,401 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:32:14,402 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=615606a2120747d09413699f8d7b1806, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:32:18,312 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:32:33,041 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:32:33,043 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a3ed6b589b0f4249bd4f8f5ee78efdb6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:32:47,974 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:32:47,975 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e142e9b938b74d759e8e2ac4a886ba70, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:32:48,314 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:33:02,993 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:33:02,994 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a4bf49d99b22409a96d596cb6edc70df, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:33:17,968 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:33:17,969 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1d03415d2a1a4b81b796c34d26583997, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:33:18,315 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:33:32,970 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:33:32,972 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ab68735803d54eae9090a99ff64ba3c8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:33:47,973 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:33:47,974 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=315b3d3718d941e48b5a89a68fa7ff74, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:33:48,317 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:34:02,968 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:34:02,970 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ee539f9e74e14db480599050905878b1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:34:18,121 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:34:18,122 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1163079bbc494a61ae965cfbc9dedfd5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:34:18,319 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:34:33,175 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:34:33,176 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e207a139920c4b9c817a4be95dd4f798, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:34:48,181 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:34:48,181 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ae0cf641af2a4cb9ba4b76d2e081010b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:34:48,321 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:35:03,170 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:35:03,171 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=047d707e47ea4d749ebc1965f6273676, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:35:18,173 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:35:18,174 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7df86f2c58234a7b950f7728d68a5f29, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:35:18,323 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:35:33,173 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:35:33,174 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=133527eb164b4cd4b0ee0336a323efa1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:35:48,173 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:35:48,174 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=34ad8e442741498c8c99e76ce846646c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:35:48,325 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:36:03,169 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:36:03,170 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aba249e5c59947d8956938e07e1515e1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:36:18,170 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:36:18,171 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=20e1aa765cb740af866acb66eb1c2d4f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:36:18,327 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:36:33,174 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:36:33,175 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8172a3c3746945c39a9f0c1710415274, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:36:48,269 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:36:48,270 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=748cfae999a14bd583642def57986bf1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:36:48,328 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:37:03,267 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:37:03,268 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c1c4371c68de4829bcefc7bc255ca96d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:37:18,270 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:37:18,270 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2830c24ce10d405dbd55689c3948f4c3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:37:18,330 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:37:33,288 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:37:33,290 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=067fbbddc641411489743ec71fb94617, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:37:48,273 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:37:48,274 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d63f9c5ac26a40ca9e4231da17de4126, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:37:48,332 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:38:03,269 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:38:03,270 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e9db9264ad2a4c42a86da0e4965038ff, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:38:18,268 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:38:18,269 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d614870673ef464799fdb5a9975fdd45, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:38:18,333 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:38:33,523 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:38:33,525 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b6fd63e3bd974f3eb11c4151d7620ce5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:38:48,335 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:38:48,472 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:38:48,473 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0aae106f9a03449b8655c106f3d47c24, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:38:53,142 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:38:53,142 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f52f541058ed499e970f09630b40a76d, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:39:13,172 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:39:13,173 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6aafcc60783641d58cf8688fae464081, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:39:18,337 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:39:28,272 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:39:28,273 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=af5d3af026b34dbc9463ab2247634b84, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:39:43,271 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:39:43,273 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8368fa2994e64bd58955aabb06030fa2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:39:48,339 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:39:58,266 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:39:58,268 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=27a2c02874ff464bbf14aac8a9602861, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:40:13,267 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:40:13,268 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=083e138d08ab41a6ae79331d552d4965, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:40:18,341 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:40:28,601 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:40:28,603 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bd755f78f4e047c1bee08286f08b5a11, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:40:43,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:40:43,571 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a69246da42be463a8dd1a35b7a546b5a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:40:48,342 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:40:58,797 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:40:58,798 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=034197a290fa42c49a4c819ab5645630, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:41:13,766 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:41:13,767 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ad5f5b52989b416aaddf95e86d3aeac5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:41:17,622 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 14:41:17,623 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d7983036049e463dac95321a0a2655a5, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:41:18,344 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:41:37,669 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:41:37,670 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=094f36d6421d4bd6b9b0f019ca6e8199, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:41:48,346 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:41:52,937 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:41:52,939 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1d8322dcdca84ba6a8ac32e589936c27, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:42:00,531 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:42:00,532 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c0fcd3dc1e7b4bd68cdb41b55cea334c, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:42:18,348 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:42:18,524 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 14:42:18,526 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=18e88766f7714a549dc5a75e10550ee6, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:42:38,472 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:42:38,473 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8aa03842d2e54e40a621a29ad997767e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:42:48,350 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:42:53,572 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:42:53,573 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=05ed9f013db240a7b03cf54a9e36491d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:43:08,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:43:08,569 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5368f92d2e4148e29caa66110a01fef5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:43:18,352 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:43:23,572 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:43:23,573 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d89da8caf6bd4f4e857750468876084e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:43:37,697 [INFO] app1.py:1205 - Speech recognized: It's.
2024-12-02 14:43:37,698 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b2f5626efddf4a0ead6f6baf88e072c8, text="It's.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:43:48,354 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:43:57,671 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:43:57,672 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5549f50018d7495498469163aeedb794, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:44:12,765 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:44:12,766 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6c202f9276eb4ba08b488e571ce7d278, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:44:18,356 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:44:27,772 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:44:27,773 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=167a94731c444322ab1af2b823db1900, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:44:42,779 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:44:42,780 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6c61a0d328d6470a9655ac2369f9ad4a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:44:48,358 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:44:57,770 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:44:57,772 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1744a793371a452dacb41a557cde3af6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:45:12,766 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:45:12,767 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e6ebfc3c0b0c436c93122b2b30781a7d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:45:18,360 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:45:27,791 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:45:27,792 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1d4953f327ff4a35b9e9a3a1ac1f4cdd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:45:42,770 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:45:42,771 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2fcd70c4a5b542fbb27418cbe0d8b9c1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:45:48,362 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:45:57,778 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:45:57,779 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da782ce92592411c818279f4d7c3aee2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:46:12,765 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:46:12,765 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2882bf13f8d64448a17f6526be01d8c4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:46:18,364 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:46:22,538 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 14:46:22,539 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d94713797b274251ab816b7969433aec, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:46:42,371 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:46:42,373 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b3924b828d334d25a0a084aee09f561d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:46:48,366 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:46:57,469 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:46:57,470 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5618147b568644b2b4a6b3dfb6a47d43, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:47:12,482 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:47:12,483 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=09079aeee8bd419fa1bd14ca4d768655, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:47:18,368 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:47:27,469 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:47:27,470 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c0f8b3482caf47cca5684115329f8eb3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:47:42,470 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:47:42,471 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7078e7f7d7f74ea28ae538d2ac694216, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:47:48,369 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:47:57,567 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:47:57,568 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6340b70f158b463b8e8a0afae4ee923b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:48:12,589 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:48:12,590 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ecc6fdb71eab484d8ab61e0c95c17846, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:48:18,371 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:48:27,570 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:48:27,571 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3e05b7728034480a991f60ae58bf463b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:48:42,563 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:48:42,564 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ec66f075db744ca38875e74369fc78e9, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:48:48,373 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:48:57,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:48:57,570 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4deda0d5364b47caa4a1b49ff586565b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:49:12,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:49:12,570 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6d84ebcf592649bba5d00fa7cae6b396, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:49:18,375 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:49:27,570 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:49:27,572 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=33cd23d55103439490a5239be4183e65, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:49:42,576 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:49:42,577 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ee5bec75d57d483eb8ffd41dd95bff01, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:49:48,377 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:49:57,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:49:57,570 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=99f472261e0b483a999145a6ca04a9e9, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:50:12,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:50:12,571 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b44eae3c90a347559e7b90fc71559387, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:50:18,379 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:50:27,669 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:50:27,672 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6ee4df9f90c9433eb27b5a14b16b39a7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:50:42,666 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:50:42,667 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9ba84ce6140e4127ad1b48e4c367446e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:50:48,381 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:50:57,670 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:50:57,671 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e9707b3736254a329d9d770254387bd0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:51:12,827 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:51:12,828 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5ed51660a7664b13a2b4d92c36ef9ece, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:51:18,383 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:51:28,015 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:51:28,016 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cb5d246f4601486da78171f88a4ccb8a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:51:32,142 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 14:51:32,144 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0074d850b8a643fba836a64d0cf80633, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:51:38,332 [DEBUG] app1.py:1214 - Speech recognizing: change
2024-12-02 14:51:38,333 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d2b5cb11942e4d36b63ffc736484564b, text="change", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:51:38,440 [DEBUG] app1.py:1214 - Speech recognizing: change your mother
2024-12-02 14:51:38,441 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d2c34819f414de0a30b775caa8cd15a, text="change your mother", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:51:39,046 [INFO] app1.py:1205 - Speech recognized: Change your mother.
2024-12-02 14:51:39,047 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1156d828c5224f54942a466d263460e3, text="Change your mother.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:51:48,385 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:51:59,071 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:51:59,072 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6035a1f4d0e14cadb7d159ad476523f7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:52:14,250 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:52:14,251 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=17ea5cb368f74b46897171deeded6238, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:52:18,386 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:52:26,027 [DEBUG] app1.py:1214 - Speech recognizing: nepali
2024-12-02 14:52:26,029 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2f0c26cd9e364b9a8022ca92e1ed8b60, text="nepali", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:52:26,337 [DEBUG] app1.py:1214 - Speech recognizing: nepali equilibrium
2024-12-02 14:52:26,338 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=05198371f9b44681844ccd72b7ecfa21, text="nepali equilibrium", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:52:27,532 [DEBUG] app1.py:1214 - Speech recognizing: nepali equilibrium ap
2024-12-02 14:52:27,534 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=95255c5064ce440a8bcc0f7cd62b1876, text="nepali equilibrium ap", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:52:27,625 [DEBUG] app1.py:1214 - Speech recognizing: nepali equilibrium apartment
2024-12-02 14:52:27,626 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=85a31a2ef4ad4a95bcc86955fe2ae87f, text="nepali equilibrium apartment", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:52:28,929 [DEBUG] app1.py:1214 - Speech recognizing: nepali equilibrium apartment kurai
2024-12-02 14:52:28,930 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=60dae206cb4b49f7a1969fadb2dcf6a5, text="nepali equilibrium apartment kurai", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:52:29,827 [DEBUG] app1.py:1214 - Speech recognizing: nepali equilibrium apartment kuraji
2024-12-02 14:52:29,828 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c9f5848328b14608894fda9555e23eac, text="nepali equilibrium apartment kuraji", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:52:30,183 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:52:30,185 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f6393cf44cc44055b430d2d6aa3ecffd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:52:45,480 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:52:45,482 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f4d10f1939164b9b919e0b9cbd677642, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:52:48,388 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:53:00,384 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:53:00,385 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9084a106c2c4421d9563df50bc5daae1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:53:15,368 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:53:15,369 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=37b0748c208e4049a142ce89d6d1175d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:53:18,390 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:53:30,364 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:53:30,365 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=344ec800257647f5a88501a534e4c60f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:53:45,738 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:53:45,739 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=90db33bd3ade462baa3ac5b6d2015733, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:53:48,392 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:54:00,668 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:54:00,670 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=853fb241a5e94f0eb090a4e95527a59f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:54:15,900 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:54:15,901 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3e5f0ec1c3294c3093b4ac8b2b8a83a2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:54:18,394 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:54:30,869 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:54:30,870 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8788fc4c99584fea85340105f5ee69d0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:54:45,869 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:54:45,871 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fa40b66cc6c14e929c0b609ff60fdbd4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:54:48,396 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:55:00,853 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:55:00,854 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=61e0508562b542c18598215ee7e9b05c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:55:15,862 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:55:15,863 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2da7d73b4b5e49c8aab6c200195ff01f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:55:18,397 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:55:30,868 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:55:30,869 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6b059624ccae41a0a2630a433e7de537, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:55:45,969 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:55:45,971 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a421c5becb2b47a989cfc21ad7c58fe9, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:55:48,399 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:56:00,977 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:56:00,978 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=82b9104866bc4eb0bedb98398a895f9e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:56:15,969 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:56:15,970 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3fdbb44679744d22989e471b8b3661e6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:56:18,400 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:56:30,967 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:56:30,969 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b4d894de22504c21a3628179094de2cc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:56:45,968 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:56:45,969 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e417ce0b2c844f95a91ad327645d528b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:56:48,402 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:57:00,963 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:57:00,964 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d77be203b4df4a6f870c9ee59086ba22, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:57:15,969 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:57:15,970 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=91753b6f668b4a14891dd3b3196e20cd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:57:18,404 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:57:30,967 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:57:30,969 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bcf66906fa874452a4685286fdf28fb7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:57:45,968 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:57:45,969 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=92b1fcf1d4cb4f399137bd3d6d66e943, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:57:48,406 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:58:00,992 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:58:00,994 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f4196f9eab084c3d83670b16206c9c06, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:58:16,068 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:58:16,069 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f5ed0d079d68465a97e89fda9b30ff8e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:58:18,407 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:58:31,305 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:58:31,306 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f4cdc4fd2ad342648e99c9ab6f3e5c0c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:58:46,619 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:58:46,620 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=872cd6d185a240c9bb2766704eb757ff, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:58:48,409 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:59:01,614 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:59:01,615 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b7b7fe2e749046b58c051d92c526719d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:59:16,568 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 14:59:16,569 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4bf35af8180d40bb90255b9af73c454a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:59:18,411 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:59:30,616 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 14:59:30,617 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f55e6572361f439384782210826623a8, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 14:59:48,016 [DEBUG] app1.py:1214 - Speech recognizing: gmail
2024-12-02 14:59:48,017 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=abd4cd0b574344d8ac7df753ec771fba, text="gmail", reason=ResultReason.RecognizingSpeech)
2024-12-02 14:59:48,413 [INFO] app1.py:898 - Active clients: []
2024-12-02 14:59:49,832 [INFO] app1.py:1205 - Speech recognized: Gmail.
2024-12-02 14:59:49,833 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e1019c9daa7d48d5be80634882f84fc9, text="Gmail.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:00:05,219 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:00:05,221 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1081757b76b94621a74b2b78a4af605f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:00:08,912 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 15:00:08,913 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dbe6f7619045435b907505adad82280a, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:00:18,414 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:00:24,964 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:00:24,964 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=32ab566234b146cba11a04b4dc3c338f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:00:39,965 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:00:39,966 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=481d8ec8d5c44268ab06510e59422a2d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:00:48,416 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:00:54,976 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:00:54,978 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=59f30fdf1a5a4d87a870afdd55bcb52c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:01:09,967 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:01:09,968 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=397d8372d9b84517b7de6ee3b579ee64, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:01:18,418 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:01:24,974 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:01:24,975 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a8b5049c6d614a0ab8e59c68b8e60600, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:01:40,333 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:01:40,333 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7dfce1e0b6244dfea1cba2b5fbabf852, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:01:48,419 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:01:55,267 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:01:55,268 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1d48d5c797724f98ac05a391e1a6e238, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:02:10,267 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:02:10,268 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=61c392fbcdee47f6a88b2cb9e43ca962, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:02:18,421 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:02:25,515 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:02:25,516 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a183d941cba7495abd06cd4f6355c505, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:02:40,462 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:02:40,463 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6f88310ccbbf463a80fe2bc3dbb28451, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:02:48,423 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:02:55,564 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:02:55,565 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a312455e735d4111a1538a3fdaba1412, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:03:10,700 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:03:10,701 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1c73bde6d1c64fccbe170752c239a993, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:03:14,884 [DEBUG] app1.py:1214 - Speech recognizing: anya chad
2024-12-02 15:03:14,885 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=320bc6aeeb1c427f8fbac242d11a6aa9, text="anya chad", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:15,082 [DEBUG] app1.py:1214 - Speech recognizing: anya chajarat
2024-12-02 15:03:15,083 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ef3eeedc4e454d68b1e86bf39f827b0c, text="anya chajarat", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:15,906 [INFO] app1.py:1205 - Speech recognized: Anya Chadha.
2024-12-02 15:03:15,907 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c959bbba087647288db12fdfc3da9d1a, text="Anya Chadha.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:03:18,425 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:03:32,004 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:03:32,005 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1783784a037d43c7bcbd8729ace98370, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:03:40,025 [DEBUG] app1.py:1214 - Speech recognizing: how do you
2024-12-02 15:03:40,027 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2749495a8ad14c91863d5d2117ebf643, text="how do you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:48,427 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:03:50,642 [DEBUG] app1.py:1214 - Speech recognizing: yeh bhi kabhi bahu thi
2024-12-02 15:03:50,642 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fcbcb663e12c48598dc6dd9722b504d0, text="yeh bhi kabhi bahu thi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:50,938 [DEBUG] app1.py:1214 - Speech recognizing: NCERT
2024-12-02 15:03:50,939 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f2d56254ae3f436899beb7888f32ee11, text="NCERT", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:52,529 [DEBUG] app1.py:1214 - Speech recognizing: kymta khak
2024-12-02 15:03:52,529 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9859b13d7f814b94b3ea741d1029b961, text="kymta khak", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:52,730 [DEBUG] app1.py:1214 - Speech recognizing: kymta khaki
2024-12-02 15:03:52,731 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=616e7060b2bd4eec868c62afd90a687c, text="kymta khaki", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:53,134 [DEBUG] app1.py:1214 - Speech recognizing: kymta khaki video
2024-12-02 15:03:53,135 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b6d6c7a12e54f01b6bd2553a9dbf03f, text="kymta khaki video", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:53,739 [INFO] app1.py:1205 - Speech recognized: Kymta Khaki video.
2024-12-02 15:03:53,741 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e453601f4de84c53a29dc06524108c6a, text="Kymta Khaki video.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:03:56,786 [DEBUG] app1.py:1214 - Speech recognizing: take
2024-12-02 15:03:56,787 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6629157063a4473a96a202a752374492, text="take", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:57,189 [DEBUG] app1.py:1214 - Speech recognizing: 8:00
2024-12-02 15:03:57,191 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9f058f9761364e979d9923ef9841402d, text="8:00", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:03:57,735 [INFO] app1.py:1205 - Speech recognized: 8:00 today.
2024-12-02 15:03:57,736 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6648b71bc6924b31808a7ecb59822014, text="8:00 today.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:04:10,283 [DEBUG] app1.py:1214 - Speech recognizing: SC
2024-12-02 15:04:10,284 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=81da711eff994f7ba781a1a0cb33edf0, text="SC", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:04:17,921 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:04:17,922 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=33f8b1a3000e4ef995417a15d2ced180, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:04:18,429 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:04:32,589 [DEBUG] app1.py:1214 - Speech recognizing: blinked
2024-12-02 15:04:32,591 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=36a61bb68b4545caac614d0b59d18f23, text="blinked", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:04:34,288 [DEBUG] app1.py:1214 - Speech recognizing: blinked blinked
2024-12-02 15:04:34,289 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8261833877904b5eb1c6fa092b44b01c, text="blinked blinked", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:04:34,832 [INFO] app1.py:1205 - Speech recognized: Blinked.
2024-12-02 15:04:34,833 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=45d4accb49aa4690947caf647e8c34b3, text="Blinked.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:04:40,410 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 15:04:40,411 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=901c4e1a3f3f4cc7a8b4bed83a7a0a30, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:04:41,917 [INFO] app1.py:1205 - Speech recognized: Hey, Cortana.
2024-12-02 15:04:41,918 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e7cea43b21c9403589ebcba65d8ebab8, text="Hey, Cortana.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:04:48,431 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:05:00,487 [DEBUG] app1.py:1214 - Speech recognizing: Y
2024-12-02 15:05:00,489 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=faa7d6dbb6bb44eaadd838b955423ccf, text="Y", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:05:01,090 [DEBUG] app1.py:1214 - Speech recognizing: Y or
2024-12-02 15:05:01,091 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=59171207dbe14c46b7d8db7291559c34, text="Y or", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:05:01,199 [DEBUG] app1.py:1214 - Speech recognizing: Y or menu
2024-12-02 15:05:01,200 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c87d4a12ae24905835c1d276a15951e, text="Y or menu", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:05:01,495 [DEBUG] app1.py:1214 - Speech recognizing: Y or menu of the
2024-12-02 15:05:01,495 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9364fab602914b41972a0a2ff87076a3, text="Y or menu of the", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:05:01,587 [DEBUG] app1.py:1214 - Speech recognizing: Y or menu of the meeting
2024-12-02 15:05:01,587 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f9750b1bf3b6457ab14f940a2c19ac9c, text="Y or menu of the meeting", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:05:02,196 [DEBUG] app1.py:1214 - Speech recognizing: Y or menu of the meeting can you talk
2024-12-02 15:05:02,198 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5b864931a3b54d67acc41b433b77abaa, text="Y or menu of the meeting can you talk", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:05:03,314 [INFO] app1.py:1205 - Speech recognized: Y or menu of the meeting. Can you talk?
2024-12-02 15:05:03,315 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4be6a5e3af50420c8c37b33dfadcaec2, text="Y or menu of the meeting. Can you talk?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:05:18,433 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:05:23,495 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:05:23,497 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f254b2815a584fd7aa15860789734394, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:05:33,717 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 15:05:33,719 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9999c4ea08d49bda3003fc030e6b9c0, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:05:38,423 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:05:38,424 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ca6c17e882384015943e697e4c420a14, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:05:48,435 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:05:53,413 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:05:53,415 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=51f066f5dae4481698096eecd79421ef, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:06:08,466 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:06:08,467 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1b689844bbc643339af1afc8ab6c8cc7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:06:18,436 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:06:23,505 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:06:23,506 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=847baac4016a4b249b52bff449664178, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:06:31,437 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 15:06:31,439 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3cf0b53b958344a693740321f3d25f8f, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:06:48,438 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:06:51,538 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:06:51,538 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=98f0f559daa141c6980e8de4b4e219e8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:07:06,834 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:07:06,835 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aaf6956cc1ef42afb097835883b78ea4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:07:17,063 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 15:07:17,064 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bb4d798388d24c4a8f0a5bf488ec30d6, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:07:18,441 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:07:27,339 [DEBUG] app1.py:1214 - Speech recognizing: BJPS makar sankranti
2024-12-02 15:07:27,340 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=877a008a668446c68f3ebb1a950a75ba, text="BJPS makar sankranti", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:07:28,427 [INFO] app1.py:1205 - Speech recognized: BJPS, Makar Sankranti.
2024-12-02 15:07:28,428 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=106852e0843044cb997fa28387fc1e0b, text="BJPS, Makar Sankranti.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:07:48,443 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:07:48,525 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:07:48,525 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9595b049787c4114be37c36b64146e05, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:07:59,517 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 15:07:59,518 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7f08738a182d4c04a200fe4f86a7f7f4, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:08:18,444 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:08:19,615 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:08:19,615 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1ea8f2bd8f7e49a69ca7d8821a9e0de4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:08:34,817 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:08:34,818 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8b52666e9c73443cb8a2c01388add85b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:08:44,352 [INFO] app1.py:1205 - Speech recognized: BJP.
2024-12-02 15:08:44,354 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e21ae5fba78b4e25bd67212d4864cfc1, text="BJP.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:08:48,446 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:09:03,297 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:09:03,299 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d3747d9fecaa47bb8c6018a74bbd2e35, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:09:18,448 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:09:19,828 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:09:19,830 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5073aaacc9af4538bb17efd50d6e4925, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:09:35,108 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:09:35,109 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6e498d51ae6943119430fdd33c1acc31, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:09:41,940 [INFO] app1.py:1205 - Speech recognized: I I.
2024-12-02 15:09:41,942 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8079b25c5b5b4a3f941ec99b32b11e67, text="I I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:09:48,450 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:10:02,051 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:10:02,052 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=18715de3fedf405fbca8a45ef32f56ef, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:10:17,194 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:10:17,196 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c863ca2595de41a3b721d3af8c8b054a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:10:18,451 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:10:32,520 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:10:32,522 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=97a5f6c112ce480d990505802ff6a7b3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:10:47,466 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:10:47,467 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=18bc71582a68498d9b7178898c8de443, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:10:48,453 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:11:02,801 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:11:02,802 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a0df87c16e4443718f8e7c9fdd2e4063, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:11:18,016 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:11:18,018 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0d02c5e0f6f44d668312156422a74115, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:11:18,454 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:11:21,299 [DEBUG] app1.py:1214 - Speech recognizing: G7
2024-12-02 15:11:21,300 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c07057a605b42fdae76263b2224f788, text="G7", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:21,502 [DEBUG] app1.py:1214 - Speech recognizing: G7C
2024-12-02 15:11:21,507 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3619fbb966b741df830bdcfd8a4def23, text="G7C", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:21,828 [INFO] app1.py:1205 - Speech recognized: G 76 photos.
2024-12-02 15:11:21,829 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f6240c50018347169886b3508fe75fc9, text="G 76 photos.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:11:25,711 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor
2024-12-02 15:11:25,713 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ab2287006796466d95a896804f059fb7, text="janhvi kapoor", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:26,004 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor recording
2024-12-02 15:11:26,005 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d6f96124f68d42d0958c474d1d3b70b0, text="janhvi kapoor recording", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:26,406 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor
2024-12-02 15:11:26,407 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3915a056611b4eed8bcc4e88eb17b6f8, text="janhvi kapoor", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:27,605 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor ach
2024-12-02 15:11:27,607 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=04dfe3b785e246299c5afc583afbe419, text="janhvi kapoor ach", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:27,714 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor achi
2024-12-02 15:11:27,715 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1f4e57c6e11b4149b53ad6d72bf3e886, text="janhvi kapoor achi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:27,917 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor achi will be feeling
2024-12-02 15:11:27,917 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d3e79cc466e74dea83fbd90a50f6addc, text="janhvi kapoor achi will be feeling", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:28,505 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor achi will be feeling i
2024-12-02 15:11:28,506 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ba571553afeb4e37a3530e3471da3470, text="janhvi kapoor achi will be feeling i", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:28,905 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor feeling i
2024-12-02 15:11:28,906 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c4bc86f45929429e908d5c6515155c1b, text="janhvi kapoor feeling i", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:30,533 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor achi will be feeling i hello
2024-12-02 15:11:30,535 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=882a1b458b7e4e3ab45801249869e7d1, text="janhvi kapoor achi will be feeling i hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:30,810 [DEBUG] app1.py:1214 - Speech recognizing: janhvi kapoor feeling i hello
2024-12-02 15:11:30,811 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3d9df3274ac2498e94c599c1772afeea, text="janhvi kapoor feeling i hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:32,744 [INFO] app1.py:1205 - Speech recognized: Janhvi Kapoor feeling I hello.
2024-12-02 15:11:32,744 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8def5f2b6664407a8655c573f4f96ce7, text="Janhvi Kapoor feeling I hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:11:34,710 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 15:11:34,711 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2072a14537f14ab699554fe505678ceb, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:34,910 [DEBUG] app1.py:1214 - Speech recognizing: hello what are
2024-12-02 15:11:34,912 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=49e3ffb827c6401f9d52765e737d60ff, text="hello what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:35,015 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:11:35,017 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d1989429f8f44386b5e597ef45f5db74, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:36,509 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing is
2024-12-02 15:11:36,511 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=411ad16e46e941acbb2473f4c5afeffa, text="hello what are you doing is", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:37,814 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing is is
2024-12-02 15:11:37,815 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8f0e6f1aedbb43d1acce2c14431c061a, text="hello what are you doing is is", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:38,108 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing is is any
2024-12-02 15:11:38,109 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e6accac41eec47ee8fbe376e0fc5374d, text="hello what are you doing is is any", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:38,216 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing is is anything
2024-12-02 15:11:38,217 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=73b150647d2a4a0e8ea0f4962b3d1350, text="hello what are you doing is is anything", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:38,513 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing is is anything happening
2024-12-02 15:11:38,515 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4329e88b96854599ba12a7f9a6b064de, text="hello what are you doing is is anything happening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:38,807 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing is is anything happening with you
2024-12-02 15:11:38,810 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=79aa5956d943449b83626c8f232588b5, text="hello what are you doing is is anything happening with you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:39,743 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing? Is is anything happening with you?
2024-12-02 15:11:39,745 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=26162f3945364ca1a6c8e408921d19d2, text="Hello, what are you doing? Is is anything happening with you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:11:43,005 [DEBUG] app1.py:1214 - Speech recognizing: no
2024-12-02 15:11:43,006 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9029e084e47e494e85445038292219e7, text="no", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:46,297 [DEBUG] app1.py:1214 - Speech recognizing: candidate
2024-12-02 15:11:46,298 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f5fb866357f84769b187eacd1d73a5ab, text="candidate", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:46,605 [DEBUG] app1.py:1214 - Speech recognizing: can you tell
2024-12-02 15:11:46,606 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f4bd98f50108418782a47a9cb0538ae7, text="can you tell", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:46,698 [DEBUG] app1.py:1214 - Speech recognizing: candidate
2024-12-02 15:11:46,699 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=31fcf7253c994c998bab5968bf35d07e, text="candidate", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:46,994 [DEBUG] app1.py:1214 - Speech recognizing: calcutta flight
2024-12-02 15:11:46,994 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=57c373107aea46b1941f939f3dd24715, text="calcutta flight", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:11:47,336 [INFO] app1.py:1205 - Speech recognized: Can you tell me?
2024-12-02 15:11:47,337 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c43b400af02145e79c2fcf20b6b41a36, text="Can you tell me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:11:48,455 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:12:05,846 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:12:05,847 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=948cc2c5143843bda3112cff8c807acb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:12:18,456 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:12:22,263 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:12:22,264 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=25808a1432a14031b21d47229050653d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:12:37,283 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:12:37,283 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=05cd080c4d9547a59f3706d8e9bdb36d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:12:48,457 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:12:52,258 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:12:52,259 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6d0b6308aae7417696f824e3f9ceffb0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:07,263 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:13:07,264 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=84b3e61ea78e4112a1c719757c50ebb1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:09,097 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:13:09,098 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:13:09,098 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:13:09,099 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:13:09,099 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing hi (is_final: False)
2024-12-02 15:13:09,100 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing hi are you (is_final: False)
2024-12-02 15:13:09,100 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing hi are you listening (is_final: False)
2024-12-02 15:13:09,103 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing hi are you listening me (is_final: False)
2024-12-02 15:13:09,104 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? Hi, are you listening me? (is_final: True)
2024-12-02 15:13:09,106 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,106 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,109 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,110 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,114 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,114 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,117 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,118 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,124 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,126 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,129 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,131 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,152 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,166 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,169 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,179 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,181 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,197 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,202 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,209 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,216 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,219 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,226 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,227 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,228 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,232 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,235 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,235 [DEBUG] app1.py:1104 - Sending transcription: The. (is_final: True)
2024-12-02 15:13:09,243 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,248 [DEBUG] app1.py:1104 - Sending transcription: Hey, Cortana. (is_final: True)
2024-12-02 15:13:09,249 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,251 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,260 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,277 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,282 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,296 [DEBUG] app1.py:1104 - Sending transcription: The. (is_final: True)
2024-12-02 15:13:09,299 [DEBUG] app1.py:1104 - Sending transcription: It's. (is_final: True)
2024-12-02 15:13:09,315 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,331 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,345 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,346 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,347 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,347 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,352 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,359 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,361 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,362 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,367 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,369 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,376 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,377 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,379 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,380 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,382 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,383 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,386 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,392 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,394 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,394 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,396 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,397 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,398 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,403 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,412 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,415 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,415 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,417 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,425 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,428 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,429 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,433 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,433 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,434 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,434 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,435 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,435 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,481 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,518 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,523 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,525 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,527 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,542 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,545 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,546 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,547 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,548 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,549 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,549 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,561 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,575 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,575 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,576 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,583 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,584 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,585 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,585 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,586 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,590 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,592 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,593 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,595 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,595 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,598 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,602 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,604 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,629 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,632 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,633 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,635 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,636 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,637 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,642 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,643 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,648 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,648 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,649 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,652 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,657 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,658 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,659 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,659 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,661 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,662 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,663 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,664 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,666 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,667 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,668 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,674 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,675 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,676 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,678 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,679 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,679 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,682 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,686 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,691 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,692 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,692 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,695 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,697 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,698 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,698 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,708 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,709 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,711 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,711 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,712 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,712 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,714 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,715 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,716 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,716 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,719 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,720 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,724 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,726 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,727 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,728 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,729 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,729 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,732 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,733 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,737 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,744 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,745 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,745 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,746 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:13:09,749 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,751 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,751 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,761 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:13:09,768 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,782 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,782 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,784 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,785 [DEBUG] app1.py:1104 - Sending transcription: It's. (is_final: True)
2024-12-02 15:13:09,792 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,799 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,800 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,808 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,812 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,815 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,819 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,826 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,827 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,828 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,829 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:13:09,831 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,837 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,843 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,848 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,853 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,860 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,863 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,864 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,869 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,874 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,877 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,877 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,879 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,884 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,885 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,886 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,887 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,891 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,892 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,893 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,893 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 15:13:09,894 [DEBUG] app1.py:1104 - Sending transcription: change (is_final: False)
2024-12-02 15:13:09,899 [DEBUG] app1.py:1104 - Sending transcription: change your mother (is_final: False)
2024-12-02 15:13:09,900 [DEBUG] app1.py:1104 - Sending transcription: Change your mother. (is_final: True)
2024-12-02 15:13:09,901 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,902 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,909 [DEBUG] app1.py:1104 - Sending transcription: nepali (is_final: False)
2024-12-02 15:13:09,916 [DEBUG] app1.py:1104 - Sending transcription: nepali equilibrium (is_final: False)
2024-12-02 15:13:09,919 [DEBUG] app1.py:1104 - Sending transcription: nepali equilibrium ap (is_final: False)
2024-12-02 15:13:09,931 [DEBUG] app1.py:1104 - Sending transcription: nepali equilibrium apartment (is_final: False)
2024-12-02 15:13:09,935 [DEBUG] app1.py:1104 - Sending transcription: nepali equilibrium apartment kurai (is_final: False)
2024-12-02 15:13:09,948 [DEBUG] app1.py:1104 - Sending transcription: nepali equilibrium apartment kuraji (is_final: False)
2024-12-02 15:13:09,961 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,963 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,964 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,965 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,966 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,967 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,968 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,969 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,969 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,974 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,977 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,979 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:09,998 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,028 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,030 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,035 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,048 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,053 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,062 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,064 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,068 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,069 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,077 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,077 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,078 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,078 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,079 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,081 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,082 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:13:10,083 [DEBUG] app1.py:1104 - Sending transcription: gmail (is_final: False)
2024-12-02 15:13:10,085 [DEBUG] app1.py:1104 - Sending transcription: Gmail. (is_final: True)
2024-12-02 15:13:10,086 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,092 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 15:13:10,103 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,111 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,113 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,113 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,187 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,196 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,197 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,200 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,202 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,202 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,203 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,209 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,214 [DEBUG] app1.py:1104 - Sending transcription: anya chad (is_final: False)
2024-12-02 15:13:10,217 [DEBUG] app1.py:1104 - Sending transcription: anya chajarat (is_final: False)
2024-12-02 15:13:10,219 [DEBUG] app1.py:1104 - Sending transcription: Anya Chadha. (is_final: True)
2024-12-02 15:13:10,220 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,225 [DEBUG] app1.py:1104 - Sending transcription: how do you (is_final: False)
2024-12-02 15:13:10,229 [DEBUG] app1.py:1104 - Sending transcription: yeh bhi kabhi bahu thi (is_final: False)
2024-12-02 15:13:10,230 [DEBUG] app1.py:1104 - Sending transcription: NCERT (is_final: False)
2024-12-02 15:13:10,232 [DEBUG] app1.py:1104 - Sending transcription: kymta khak (is_final: False)
2024-12-02 15:13:10,233 [DEBUG] app1.py:1104 - Sending transcription: kymta khaki (is_final: False)
2024-12-02 15:13:10,233 [DEBUG] app1.py:1104 - Sending transcription: kymta khaki video (is_final: False)
2024-12-02 15:13:10,235 [DEBUG] app1.py:1104 - Sending transcription: Kymta Khaki video. (is_final: True)
2024-12-02 15:13:10,235 [DEBUG] app1.py:1104 - Sending transcription: take (is_final: False)
2024-12-02 15:13:10,236 [DEBUG] app1.py:1104 - Sending transcription: 8:00 (is_final: False)
2024-12-02 15:13:10,236 [DEBUG] app1.py:1104 - Sending transcription: 8:00 today. (is_final: True)
2024-12-02 15:13:10,241 [DEBUG] app1.py:1104 - Sending transcription: SC (is_final: False)
2024-12-02 15:13:10,247 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,247 [DEBUG] app1.py:1104 - Sending transcription: blinked (is_final: False)
2024-12-02 15:13:10,249 [DEBUG] app1.py:1104 - Sending transcription: blinked blinked (is_final: False)
2024-12-02 15:13:10,249 [DEBUG] app1.py:1104 - Sending transcription: Blinked. (is_final: True)
2024-12-02 15:13:10,250 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 15:13:10,250 [DEBUG] app1.py:1104 - Sending transcription: Hey, Cortana. (is_final: True)
2024-12-02 15:13:10,251 [DEBUG] app1.py:1104 - Sending transcription: Y (is_final: False)
2024-12-02 15:13:10,251 [DEBUG] app1.py:1104 - Sending transcription: Y or (is_final: False)
2024-12-02 15:13:10,252 [DEBUG] app1.py:1104 - Sending transcription: Y or menu (is_final: False)
2024-12-02 15:13:10,252 [DEBUG] app1.py:1104 - Sending transcription: Y or menu of the (is_final: False)
2024-12-02 15:13:10,255 [DEBUG] app1.py:1104 - Sending transcription: Y or menu of the meeting (is_final: False)
2024-12-02 15:13:10,256 [DEBUG] app1.py:1104 - Sending transcription: Y or menu of the meeting can you talk (is_final: False)
2024-12-02 15:13:10,258 [DEBUG] app1.py:1104 - Sending transcription: Y or menu of the meeting. Can you talk? (is_final: True)
2024-12-02 15:13:10,259 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,260 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 15:13:10,262 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,263 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,263 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,263 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,265 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:13:10,265 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,266 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,266 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:13:10,266 [DEBUG] app1.py:1104 - Sending transcription: BJPS makar sankranti (is_final: False)
2024-12-02 15:13:10,267 [DEBUG] app1.py:1104 - Sending transcription: BJPS, Makar Sankranti. (is_final: True)
2024-12-02 15:13:10,267 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,269 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:13:10,270 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,270 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,270 [DEBUG] app1.py:1104 - Sending transcription: BJP. (is_final: True)
2024-12-02 15:13:10,274 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,275 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,275 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,277 [DEBUG] app1.py:1104 - Sending transcription: I I. (is_final: True)
2024-12-02 15:13:10,277 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,277 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,278 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,279 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,279 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,281 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,281 [DEBUG] app1.py:1104 - Sending transcription: G7 (is_final: False)
2024-12-02 15:13:10,282 [DEBUG] app1.py:1104 - Sending transcription: G7C (is_final: False)
2024-12-02 15:13:10,282 [DEBUG] app1.py:1104 - Sending transcription: G 76 photos. (is_final: True)
2024-12-02 15:13:10,282 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor (is_final: False)
2024-12-02 15:13:10,283 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor recording (is_final: False)
2024-12-02 15:13:10,283 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor (is_final: False)
2024-12-02 15:13:10,284 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor ach (is_final: False)
2024-12-02 15:13:10,285 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor achi (is_final: False)
2024-12-02 15:13:10,285 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor achi will be feeling (is_final: False)
2024-12-02 15:13:10,287 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor achi will be feeling i (is_final: False)
2024-12-02 15:13:10,291 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor feeling i (is_final: False)
2024-12-02 15:13:10,292 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor achi will be feeling i hello (is_final: False)
2024-12-02 15:13:10,293 [DEBUG] app1.py:1104 - Sending transcription: janhvi kapoor feeling i hello (is_final: False)
2024-12-02 15:13:10,295 [DEBUG] app1.py:1104 - Sending transcription: Janhvi Kapoor feeling I hello. (is_final: True)
2024-12-02 15:13:10,295 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 15:13:10,296 [DEBUG] app1.py:1104 - Sending transcription: hello what are (is_final: False)
2024-12-02 15:13:10,296 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:13:10,296 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing is (is_final: False)
2024-12-02 15:13:10,297 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing is is (is_final: False)
2024-12-02 15:13:10,297 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing is is any (is_final: False)
2024-12-02 15:13:10,298 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing is is anything (is_final: False)
2024-12-02 15:13:10,298 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing is is anything happening (is_final: False)
2024-12-02 15:13:10,298 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing is is anything happening with you (is_final: False)
2024-12-02 15:13:10,300 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? Is is anything happening with you? (is_final: True)
2024-12-02 15:13:10,301 [DEBUG] app1.py:1104 - Sending transcription: no (is_final: False)
2024-12-02 15:13:10,302 [DEBUG] app1.py:1104 - Sending transcription: candidate (is_final: False)
2024-12-02 15:13:10,302 [DEBUG] app1.py:1104 - Sending transcription: can you tell (is_final: False)
2024-12-02 15:13:10,303 [DEBUG] app1.py:1104 - Sending transcription: candidate (is_final: False)
2024-12-02 15:13:10,303 [DEBUG] app1.py:1104 - Sending transcription: calcutta flight (is_final: False)
2024-12-02 15:13:10,305 [DEBUG] app1.py:1104 - Sending transcription: Can you tell me? (is_final: True)
2024-12-02 15:13:10,307 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,308 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,308 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,309 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:10,309 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:13:12,093 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:13:12,094 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=11acd656a03b4fbabf5e98b6cf758e51, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:12,095 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:13:13,004 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:13:13,004 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d72b3c41e18b4377925c8db7732e693b, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:13,005 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:13:13,599 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:13:13,599 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=07a4798bcc0b4800a24ad1134ea146f1, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:13,600 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:13:14,001 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:13:14,002 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da724109eec74a3d8b73f98978f06c5f, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:14,003 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:13:15,992 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:13:15,992 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d947d8e19734c2e88da329dd987c3b5, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:15,993 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:13:16,212 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 15:13:16,214 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2d3dad95a9a840d1965a60be5cbab807, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:16,215 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 15:13:16,693 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:13:16,694 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cc7478ea40c147f2905673581c72f343, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:16,696 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:13:17,513 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:13:17,514 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0ef1496170214e0eb9d549d20b7e23c8, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:17,514 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:13:18,459 [INFO] app1.py:898 - Active clients: []
2024-12-02 15:13:20,398 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 15:13:20,398 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=050d4160558a461fb45cb55fa320635e, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:20,399 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 15:13:20,788 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 15:13:20,789 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=da5f348e609d4846ba0ec74f12bc30c8, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:20,790 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 15:13:21,608 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:13:21,608 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3bd8c245c6824a8fa2cef823c0b0e766, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:21,609 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:13:22,881 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:13:22,882 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=520219d89b6941509894f86f9461efb0, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:22,882 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:13:24,112 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 15:13:24,114 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=51ddc316dd4b45c3a0329471107da633, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:24,115 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 15:13:25,479 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 15:13:25,480 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e1766b21ee3540ce955d596937a2bd1c, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:25,480 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 15:13:25,873 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:13:25,873 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1135f70a9b6d4f1d8cea8ac1b09e92ad, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:25,875 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:13:27,112 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 15:13:27,113 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c26e2f33f0274ea998a442593d81e4ef, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:27,115 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 15:13:28,787 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:13:28,787 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e41ce5dbed5d4abfb4e4faf22d1860fa, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:28,789 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:13:29,017 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 15:13:29,017 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3c836e79f10e41b19ef572fdb44e639f, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:29,018 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 15:13:30,387 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:13:30,387 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e82678dd9322498384903a542ad26ede, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:30,388 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:13:31,287 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 15:13:31,305 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a4b2ceb39ee9470e8c6283afb206ac2f, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:31,306 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 15:13:32,701 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:13:32,701 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c708c4070aef452fa28025b0d1d753e9, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:32,702 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:13:34,506 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 15:13:34,507 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2e77a2273981426f80997fd20a53c996, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:34,509 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 15:13:35,604 [DEBUG] app1.py:1214 - Speech recognizing: are
2024-12-02 15:13:35,605 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7d40d92bf3f04422a33a2ad41fbf9e4d, text="are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:35,607 [DEBUG] app1.py:1104 - Sending transcription: are (is_final: False)
2024-12-02 15:13:35,805 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:13:35,806 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=57a27802b51342f1af0e0578a81dc147, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:35,808 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:13:37,709 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 15:13:37,711 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fc0e11b91722472fb29fe7068c34c43f, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:37,713 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 15:13:42,000 [DEBUG] app1.py:1214 - Speech recognizing: to me
2024-12-02 15:13:42,000 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=30f3d6f968c64aec92a0f213abf2856e, text="to me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:42,003 [DEBUG] app1.py:1104 - Sending transcription: to me (is_final: False)
2024-12-02 15:13:42,309 [INFO] app1.py:1205 - Speech recognized: To.
2024-12-02 15:13:42,310 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b4a611d5f6134e4584e6c9dfb286b48e, text="To.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:42,310 [DEBUG] app1.py:1104 - Sending transcription: To. (is_final: True)
2024-12-02 15:13:42,773 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:13:42,996 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:13:47,941 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:13:47,961 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:13:47,968 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:13:47,968 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:13:47,969 [INFO] app1.py:1131 - Creating new client connection: 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:13:48,016 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:13:48,104 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:13:48,460 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543']
2024-12-02 15:13:51,002 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:13:51,003 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aa1d566c50824d6ba88975b93b97d949, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:51,004 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:13:51,050 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:51,050 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:51,052 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:51,186 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:13:51,186 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2ae9fc7837eb42798df367e6e4bcc3f6, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:51,189 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:13:51,194 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:51,195 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:13:51,195 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 15:13:51,196 [DEBUG] app1.py:1056 - Checking cache with key: hi.:pt
2024-12-02 15:13:51,196 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:13:51,197 [INFO] app1.py:933 - Starting translation request - Text: 'hi.', Target language: pt
2024-12-02 15:13:51,200 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:13:51,201 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:13:51,201 [DEBUG] app1.py:964 - Request body: [{'text': 'hi.'}]
2024-12-02 15:13:52,455 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:13:52,458 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Oi.', 'to': 'pt'}]}]
2024-12-02 15:13:52,459 [DEBUG] app1.py:974 - Extracted translation: Oi.
2024-12-02 15:13:52,460 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi.' -> Translation: 'Oi.' (pt)
2024-12-02 15:13:52,463 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: Oi.
2024-12-02 15:13:52,464 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:13:52,464 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'Oi.'}
2024-12-02 15:13:53,178 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:13:53,179 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=37d95dc5f27f48f288db4ea1cda69a52, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:53,181 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:13:53,186 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:53,187 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:53,188 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:54,170 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 15:13:54,170 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=105655e85dc64e2487fcdf373bce317b, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:54,172 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 15:13:54,176 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:54,176 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello how are you', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:54,177 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:55,075 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you what are you
2024-12-02 15:13:55,076 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3a2c9c25187346d68476c14f9743bde3, text="hello how are you what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:55,078 [DEBUG] app1.py:1104 - Sending transcription: hello how are you what are you (is_final: False)
2024-12-02 15:13:55,085 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:55,087 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello how are you what are you', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:55,090 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:55,383 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you what are you doing
2024-12-02 15:13:55,384 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5e94f9cfdc6c4f5b94feb346fc5bab55, text="hello how are you what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:55,385 [DEBUG] app1.py:1104 - Sending transcription: hello how are you what are you doing (is_final: False)
2024-12-02 15:13:55,392 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:55,393 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello how are you what are you doing', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:55,393 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:56,079 [INFO] app1.py:1205 - Speech recognized: Hello, how are you? What are you doing?
2024-12-02 15:13:56,080 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=811b19d0bdf54d8c90964dc41adca505, text="Hello, how are you? What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:56,081 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? What are you doing? (is_final: True)
2024-12-02 15:13:56,088 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:56,088 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello, how are you? What are you doing?', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:13:56,089 [DEBUG] app1.py:1042 - Normalized text: 'hello, how are you? what are you doing?'
2024-12-02 15:13:56,089 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 4.892981290817261s
2024-12-02 15:13:56,090 [DEBUG] app1.py:1056 - Checking cache with key: hello, how are you? what are you doing?:pt
2024-12-02 15:13:56,090 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:13:56,091 [INFO] app1.py:933 - Starting translation request - Text: 'hello, how are you? what are you doing?', Target language: pt
2024-12-02 15:13:56,092 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:13:56,092 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:13:56,093 [DEBUG] app1.py:964 - Request body: [{'text': 'hello, how are you? what are you doing?'}]
2024-12-02 15:13:56,607 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:13:56,608 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Ol, tudo bem? O que  que est a fazer?', 'to': 'pt'}]}]
2024-12-02 15:13:56,608 [DEBUG] app1.py:974 - Extracted translation: Ol, tudo bem? O que  que est a fazer?
2024-12-02 15:13:56,609 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello, how are you? what are you doing?' -> Translation: 'Ol, tudo bem? O que  que est a fazer?' (pt)
2024-12-02 15:13:56,611 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: Ol, tudo bem? O que  que est a fazer?
2024-12-02 15:13:56,611 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:13:56,611 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'Ol, tudo bem? O que  que est a fazer?'}
2024-12-02 15:13:58,157 [DEBUG] app1.py:1214 - Speech recognizing: nurse feature
2024-12-02 15:13:58,157 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=170414d3365b498f8b8e47e1e663f45e, text="nurse feature", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:58,158 [DEBUG] app1.py:1104 - Sending transcription: nurse feature (is_final: False)
2024-12-02 15:13:58,161 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:58,162 [DEBUG] app1.py:1031 - Received translation request - Text: 'nurse feature', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:58,162 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:58,468 [DEBUG] app1.py:1214 - Speech recognizing: nurse feature on cherry lodge
2024-12-02 15:13:58,469 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=05aa9d3af6e1423180fbad6070a19aa6, text="nurse feature on cherry lodge", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:58,471 [DEBUG] app1.py:1104 - Sending transcription: nurse feature on cherry lodge (is_final: False)
2024-12-02 15:13:58,475 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:58,476 [DEBUG] app1.py:1031 - Received translation request - Text: 'nurse feature on cherry lodge', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:58,476 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:59,056 [DEBUG] app1.py:1214 - Speech recognizing: nurse feature on cherry loddha
2024-12-02 15:13:59,057 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=deab191828684bfb922cc603139ebe2f, text="nurse feature on cherry loddha", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:13:59,057 [DEBUG] app1.py:1104 - Sending transcription: nurse feature on cherry loddha (is_final: False)
2024-12-02 15:13:59,061 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:59,062 [DEBUG] app1.py:1031 - Received translation request - Text: 'nurse feature on cherry loddha', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:13:59,062 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:13:59,086 [INFO] app1.py:1205 - Speech recognized: Nurse feature on Cherry Lodge.
2024-12-02 15:13:59,086 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d7b31587cbae48f6beeaac2728e34af3, text="Nurse feature on Cherry Lodge.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:13:59,087 [DEBUG] app1.py:1104 - Sending transcription: Nurse feature on Cherry Lodge. (is_final: True)
2024-12-02 15:13:59,093 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:13:59,093 [DEBUG] app1.py:1031 - Received translation request - Text: 'Nurse feature on Cherry Lodge.', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:13:59,093 [DEBUG] app1.py:1042 - Normalized text: 'nurse feature on cherry lodge.'
2024-12-02 15:13:59,094 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 3.0053374767303467s
2024-12-02 15:13:59,095 [DEBUG] app1.py:1056 - Checking cache with key: nurse feature on cherry lodge.:pt
2024-12-02 15:13:59,095 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:13:59,096 [INFO] app1.py:933 - Starting translation request - Text: 'nurse feature on cherry lodge.', Target language: pt
2024-12-02 15:13:59,096 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:13:59,097 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:13:59,097 [DEBUG] app1.py:964 - Request body: [{'text': 'nurse feature on cherry lodge.'}]
2024-12-02 15:13:59,618 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:13:59,620 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Recurso de enfermeira em Cherry Lodge.', 'to': 'pt'}]}]
2024-12-02 15:13:59,621 [DEBUG] app1.py:974 - Extracted translation: Recurso de enfermeira em Cherry Lodge.
2024-12-02 15:13:59,622 [INFO] app1.py:975 - Translation completed successfully - Original: 'nurse feature on cherry lodge.' -> Translation: 'Recurso de enfermeira em Cherry Lodge.' (pt)
2024-12-02 15:13:59,623 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: Recurso de enfermeira em Cherry Lodge.
2024-12-02 15:13:59,623 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:13:59,623 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'Recurso de enfermeira em Cherry Lodge.'}
2024-12-02 15:14:01,072 [DEBUG] app1.py:1214 - Speech recognizing: hi there
2024-12-02 15:14:01,073 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bba424e48d384054af48d124a7a948fd, text="hi there", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:14:01,074 [DEBUG] app1.py:1104 - Sending transcription: hi there (is_final: False)
2024-12-02 15:14:01,079 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:14:01,080 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi there', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:14:01,081 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:14:01,552 [INFO] app1.py:1205 - Speech recognized: Hi there.
2024-12-02 15:14:01,552 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8a0cc2bc42b54873a38e5c06f1e98073, text="Hi there.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:14:01,552 [DEBUG] app1.py:1104 - Sending transcription: Hi there. (is_final: True)
2024-12-02 15:14:01,558 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:14:01,558 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi there.', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:14:01,562 [DEBUG] app1.py:1042 - Normalized text: 'hi there.'
2024-12-02 15:14:01,565 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 2.4708075523376465s
2024-12-02 15:14:01,565 [DEBUG] app1.py:1056 - Checking cache with key: hi there.:pt
2024-12-02 15:14:01,566 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:14:01,566 [INFO] app1.py:933 - Starting translation request - Text: 'hi there.', Target language: pt
2024-12-02 15:14:01,566 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:14:01,568 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:14:01,568 [DEBUG] app1.py:964 - Request body: [{'text': 'hi there.'}]
2024-12-02 15:14:02,802 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:14:02,803 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Oi.', 'to': 'pt'}]}]
2024-12-02 15:14:02,804 [DEBUG] app1.py:974 - Extracted translation: Oi.
2024-12-02 15:14:02,804 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi there.' -> Translation: 'Oi.' (pt)
2024-12-02 15:14:02,805 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: Oi.
2024-12-02 15:14:02,806 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:14:02,806 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'Oi.'}
2024-12-02 15:14:06,786 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 15:14:06,786 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=41af4b629164455baadc0ae4f2aceb01, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:14:06,786 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:14:06,792 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:14:06,793 [DEBUG] app1.py:1031 - Received translation request - Text: 'I.', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:14:06,797 [DEBUG] app1.py:1042 - Normalized text: 'i.'
2024-12-02 15:14:06,797 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 5.231339931488037s
2024-12-02 15:14:06,798 [DEBUG] app1.py:1056 - Checking cache with key: i.:pt
2024-12-02 15:14:06,798 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:14:06,799 [INFO] app1.py:933 - Starting translation request - Text: 'i.', Target language: pt
2024-12-02 15:14:06,801 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:14:06,802 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:14:06,802 [DEBUG] app1.py:964 - Request body: [{'text': 'i.'}]
2024-12-02 15:14:08,011 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:14:08,012 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.86}, 'translations': [{'text': 'eu.', 'to': 'pt'}]}]
2024-12-02 15:14:08,012 [DEBUG] app1.py:974 - Extracted translation: eu.
2024-12-02 15:14:08,013 [INFO] app1.py:975 - Translation completed successfully - Original: 'i.' -> Translation: 'eu.' (pt)
2024-12-02 15:14:08,013 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: eu.
2024-12-02 15:14:08,014 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:14:08,014 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'eu.'}
2024-12-02 15:14:18,462 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543']
2024-12-02 15:14:23,417 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 15:14:23,418 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5579f7bc596844c086e51756625f380f, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:14:23,419 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:14:23,426 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:14:23,427 [DEBUG] app1.py:1031 - Received translation request - Text: 'I.', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:14:23,428 [DEBUG] app1.py:1042 - Normalized text: 'i.'
2024-12-02 15:14:23,428 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 16.631229400634766s
2024-12-02 15:14:23,429 [DEBUG] app1.py:1056 - Checking cache with key: i.:pt
2024-12-02 15:14:23,429 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:14:23,429 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: eu.
2024-12-02 15:14:23,431 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:14:23,433 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'eu.'}
2024-12-02 15:14:43,330 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:14:43,331 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d25d80ea55154eecb9c50d2a86eb70b7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:14:43,333 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:14:48,463 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543']
2024-12-02 15:14:53,736 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:14:56,663 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:14:57,667 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:14:58,433 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:14:58,434 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=71ce2c2a7aa146049479d841c2280782, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:14:58,435 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:15:00,651 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:01,653 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:04,656 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:05,661 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:08,657 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:09,663 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:12,657 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:13,420 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:15:13,420 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=50314af41db449a8868af5715910b988, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:15:13,421 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:15:13,666 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:16,652 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:17,658 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:18,465 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543']
2024-12-02 15:15:20,660 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:21,667 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:24,655 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:25,659 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:28,649 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:28,757 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:15:28,758 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=11d70150c1e54588b53278a8423c4bbc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:15:28,759 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:15:29,662 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:32,663 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:33,665 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:36,653 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:37,661 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:40,135 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:41,144 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:43,160 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:43,883 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:15:43,884 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c7ba07f518174a19a8fe508861cd301f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:15:43,884 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:15:44,161 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:46,177 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:47,181 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:48,467 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543']
2024-12-02 15:15:49,201 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:50,207 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:52,228 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:53,237 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:55,251 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:56,259 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:15:58,266 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:15:58,806 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:15:58,807 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=07845e3f114d44a8b75a4cdff6d6a2a0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:15:58,809 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:15:59,269 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:16:01,279 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:16:02,286 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:16:04,653 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:16:05,661 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:16:08,665 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:16:09,667 [WARNING] app1.py:1148 - Client 295d61aa-6936-467c-bb1d-8b07951a8543 connection timed out
2024-12-02 15:16:10,354 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:16:10,355 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6f90a80eb80d4c30b51f2c2747c67c4f, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:10,355 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:16:10,363 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:10,364 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:16:10,364 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:11,051 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:16:11,052 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=44f3751ee8aa4a1fa922bc1fd2ea02f3, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:11,053 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:16:11,058 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:11,058 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you doing', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:16:11,060 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:11,476 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:16:11,477 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2d5650f7a81c45018d437a1bbecf3925, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:16:11,477 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:16:11,481 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:11,481 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, what are you doing?', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:16:11,481 [DEBUG] app1.py:1042 - Normalized text: 'hi, what are you doing?'
2024-12-02 15:16:11,482 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 108.0543565750122s
2024-12-02 15:16:11,482 [DEBUG] app1.py:1056 - Checking cache with key: hi, what are you doing?:pt
2024-12-02 15:16:11,483 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:16:11,483 [INFO] app1.py:933 - Starting translation request - Text: 'hi, what are you doing?', Target language: pt
2024-12-02 15:16:11,483 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:16:11,484 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:16:11,484 [DEBUG] app1.py:964 - Request body: [{'text': 'hi, what are you doing?'}]
2024-12-02 15:16:11,792 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:16:11,793 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'Oi, o que voc est fazendo?', 'to': 'pt'}]}]
2024-12-02 15:16:11,794 [DEBUG] app1.py:974 - Extracted translation: Oi, o que voc est fazendo?
2024-12-02 15:16:11,795 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi, what are you doing?' -> Translation: 'Oi, o que voc est fazendo?' (pt)
2024-12-02 15:16:11,796 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: Oi, o que voc est fazendo?
2024-12-02 15:16:11,797 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:16:12,654 [INFO] app1.py:1121 - New translation stream connection for client: 295d61aa-6936-467c-bb1d-8b07951a8543, language: pt
2024-12-02 15:16:12,655 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'Oi, o que voc est fazendo?'}
2024-12-02 15:16:13,166 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:16:13,169 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=20e614814b6247f4b1cf450de1829464, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:13,170 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:16:13,176 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:13,176 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:16:13,178 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:13,451 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 15:16:13,452 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=680bc1f8be1b4e1d95da5bf8b5d9dc9e, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:16:13,453 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 15:16:13,459 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:13,460 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:16:13,460 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 15:16:13,460 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 1.9783728122711182s
2024-12-02 15:16:13,462 [DEBUG] app1.py:1056 - Checking cache with key: hello.:pt
2024-12-02 15:16:13,462 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:16:13,462 [INFO] app1.py:933 - Starting translation request - Text: 'hello.', Target language: pt
2024-12-02 15:16:13,462 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:16:13,464 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:16:13,465 [DEBUG] app1.py:964 - Request body: [{'text': 'hello.'}]
2024-12-02 15:16:13,723 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:16:13,725 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Ol.', 'to': 'pt'}]}]
2024-12-02 15:16:13,726 [DEBUG] app1.py:974 - Extracted translation: Ol.
2024-12-02 15:16:13,727 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello.' -> Translation: 'Ol.' (pt)
2024-12-02 15:16:13,729 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: Ol.
2024-12-02 15:16:13,730 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:16:13,730 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'Ol.'}
2024-12-02 15:16:17,245 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:16:17,247 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0f740877f33e49ad9becba197935769e, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:17,248 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:16:17,258 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:17,258 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: False
2024-12-02 15:16:17,259 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:17,493 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:16:17,495 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b7640e4e4fec44be893f131e60eb196e, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:16:17,496 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:16:17,502 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:17,502 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: pt, Client: 295d61aa-6936-467c-bb1d-8b07951a8543, Final: True
2024-12-02 15:16:17,503 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 15:16:17,503 [DEBUG] app1.py:1048 - Time since last translation for 295d61aa-6936-467c-bb1d-8b07951a8543:pt: 4.0429041385650635s
2024-12-02 15:16:17,503 [DEBUG] app1.py:1056 - Checking cache with key: hi.:pt
2024-12-02 15:16:17,503 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:16:17,505 [DEBUG] app1.py:918 - Sending translation to client 295d61aa-6936-467c-bb1d-8b07951a8543: Oi.
2024-12-02 15:16:17,505 [DEBUG] app1.py:925 - Translation sent successfully to client 295d61aa-6936-467c-bb1d-8b07951a8543
2024-12-02 15:16:17,505 [DEBUG] app1.py:1144 - Sending message to client 295d61aa-6936-467c-bb1d-8b07951a8543: {'type': 'final', 'translation': 'Oi.'}
2024-12-02 15:16:18,468 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543']
2024-12-02 15:16:27,150 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:16:27,298 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:16:32,688 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:16:32,704 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:16:32,705 [INFO] app1.py:1121 - New translation stream connection for client: dfff3259-8802-40bf-b5af-a30fb9321a5d, language: es
2024-12-02 15:16:32,731 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:16:32,733 [INFO] app1.py:1131 - Creating new client connection: dfff3259-8802-40bf-b5af-a30fb9321a5d
2024-12-02 15:16:32,783 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:16:32,876 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:16:36,920 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:16:36,920 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9f05f6a23c2d4046813d3c11cbd56089, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:36,920 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:16:36,928 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:36,928 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:36,929 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:37,462 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 15:16:37,462 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=92dfe7a9af404b49a4eaade22c0f4ce0, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:16:37,462 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 15:16:37,466 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:37,467 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: True
2024-12-02 15:16:37,467 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 15:16:37,468 [DEBUG] app1.py:1056 - Checking cache with key: hello.:es
2024-12-02 15:16:37,468 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:16:37,468 [INFO] app1.py:933 - Starting translation request - Text: 'hello.', Target language: es
2024-12-02 15:16:37,469 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:16:37,469 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:16:37,469 [DEBUG] app1.py:964 - Request body: [{'text': 'hello.'}]
2024-12-02 15:16:38,057 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:16:38,058 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola.', 'to': 'es'}]}]
2024-12-02 15:16:38,059 [DEBUG] app1.py:974 - Extracted translation: Hola.
2024-12-02 15:16:38,061 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello.' -> Translation: 'Hola.' (es)
2024-12-02 15:16:38,061 [DEBUG] app1.py:918 - Sending translation to client dfff3259-8802-40bf-b5af-a30fb9321a5d: Hola.
2024-12-02 15:16:38,062 [DEBUG] app1.py:925 - Translation sent successfully to client dfff3259-8802-40bf-b5af-a30fb9321a5d
2024-12-02 15:16:38,062 [DEBUG] app1.py:1144 - Sending message to client dfff3259-8802-40bf-b5af-a30fb9321a5d: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 15:16:43,514 [DEBUG] app1.py:1214 - Speech recognizing: hi hi
2024-12-02 15:16:43,515 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=427b68356bbb4df7a4d9a5abd24240e7, text="hi hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:43,517 [DEBUG] app1.py:1104 - Sending transcription: hi hi (is_final: False)
2024-12-02 15:16:43,524 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:43,525 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi hi', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:43,525 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:43,731 [INFO] app1.py:1205 - Speech recognized: Hi. Hi.
2024-12-02 15:16:43,733 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf580da4b8924d958483660b97a8dd00, text="Hi. Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:16:43,734 [DEBUG] app1.py:1104 - Sending transcription: Hi. Hi. (is_final: True)
2024-12-02 15:16:43,740 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:43,740 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi. Hi.', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: True
2024-12-02 15:16:43,741 [DEBUG] app1.py:1042 - Normalized text: 'hi. hi.'
2024-12-02 15:16:43,742 [DEBUG] app1.py:1048 - Time since last translation for dfff3259-8802-40bf-b5af-a30fb9321a5d:es: 6.273868560791016s
2024-12-02 15:16:43,742 [DEBUG] app1.py:1056 - Checking cache with key: hi. hi.:es
2024-12-02 15:16:43,743 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:16:43,743 [INFO] app1.py:933 - Starting translation request - Text: 'hi. hi.', Target language: es
2024-12-02 15:16:43,745 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:16:43,745 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:16:43,745 [DEBUG] app1.py:964 - Request body: [{'text': 'hi. hi.'}]
2024-12-02 15:16:44,266 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:16:44,266 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'es', 'score': 0.43}, 'translations': [{'text': 'hi. hi.', 'to': 'es'}]}]
2024-12-02 15:16:44,268 [DEBUG] app1.py:974 - Extracted translation: hi. hi.
2024-12-02 15:16:44,269 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi. hi.' -> Translation: 'hi. hi.' (es)
2024-12-02 15:16:44,270 [DEBUG] app1.py:918 - Sending translation to client dfff3259-8802-40bf-b5af-a30fb9321a5d: hi. hi.
2024-12-02 15:16:44,271 [DEBUG] app1.py:925 - Translation sent successfully to client dfff3259-8802-40bf-b5af-a30fb9321a5d
2024-12-02 15:16:44,272 [DEBUG] app1.py:1144 - Sending message to client dfff3259-8802-40bf-b5af-a30fb9321a5d: {'type': 'final', 'translation': 'hi. hi.'}
2024-12-02 15:16:45,510 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:16:45,511 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0271f7880b7f4e7ab493808245648938, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:45,512 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:16:45,516 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:45,517 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:45,518 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:45,710 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 15:16:45,711 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dbd697c4b0f544248176275a2b52af07, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:45,712 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 15:16:45,719 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:45,720 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello what', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:45,721 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:46,112 [DEBUG] app1.py:1214 - Speech recognizing: hello what are
2024-12-02 15:16:46,112 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=75d9548ea0cf44e2ad27e373b0f38272, text="hello what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:46,113 [DEBUG] app1.py:1104 - Sending transcription: hello what are (is_final: False)
2024-12-02 15:16:46,119 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:46,119 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello what are', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:46,120 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:46,407 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:16:46,408 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3e432eff559240e0943ecc409aa6f731, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:46,409 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:16:46,414 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:46,414 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello what are you doing', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:46,415 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:46,655 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:16:46,656 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e899d5c8e43e4bc69cf393982197d9f6, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:16:46,657 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:16:46,661 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:46,662 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello, what are you doing?', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: True
2024-12-02 15:16:46,662 [DEBUG] app1.py:1042 - Normalized text: 'hello, what are you doing?'
2024-12-02 15:16:46,664 [DEBUG] app1.py:1048 - Time since last translation for dfff3259-8802-40bf-b5af-a30fb9321a5d:es: 2.9199182987213135s
2024-12-02 15:16:46,664 [DEBUG] app1.py:1056 - Checking cache with key: hello, what are you doing?:es
2024-12-02 15:16:46,664 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:16:46,664 [INFO] app1.py:933 - Starting translation request - Text: 'hello, what are you doing?', Target language: es
2024-12-02 15:16:46,666 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:16:46,666 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:16:46,666 [DEBUG] app1.py:964 - Request body: [{'text': 'hello, what are you doing?'}]
2024-12-02 15:16:46,971 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:16:46,973 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola, qu ests haciendo?', 'to': 'es'}]}]
2024-12-02 15:16:46,974 [DEBUG] app1.py:974 - Extracted translation: Hola, qu ests haciendo?
2024-12-02 15:16:46,976 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello, what are you doing?' -> Translation: 'Hola, qu ests haciendo?' (es)
2024-12-02 15:16:46,977 [DEBUG] app1.py:918 - Sending translation to client dfff3259-8802-40bf-b5af-a30fb9321a5d: Hola, qu ests haciendo?
2024-12-02 15:16:46,978 [DEBUG] app1.py:925 - Translation sent successfully to client dfff3259-8802-40bf-b5af-a30fb9321a5d
2024-12-02 15:16:46,978 [DEBUG] app1.py:1144 - Sending message to client dfff3259-8802-40bf-b5af-a30fb9321a5d: {'type': 'final', 'translation': 'Hola, qu ests haciendo?'}
2024-12-02 15:16:48,433 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 15:16:48,434 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ea1edf72a34463d89e8b47756412b2e, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:48,436 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 15:16:48,443 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:48,447 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:48,448 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:48,471 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:16:48,721 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:16:48,722 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b58fd4f340de4515aa0d89767fb1d85d, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:16:48,723 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:16:48,752 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:48,753 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: False
2024-12-02 15:16:48,754 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:16:49,325 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:16:49,325 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2d5b3d22db564359ba2f9f793a1735a3, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:16:49,326 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:16:49,331 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:16:49,332 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening me?', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: True
2024-12-02 15:16:49,332 [DEBUG] app1.py:1042 - Normalized text: 'are you listening me?'
2024-12-02 15:16:49,334 [DEBUG] app1.py:1048 - Time since last translation for dfff3259-8802-40bf-b5af-a30fb9321a5d:es: 2.6713204383850098s
2024-12-02 15:16:49,335 [DEBUG] app1.py:1056 - Checking cache with key: are you listening me?:es
2024-12-02 15:16:49,335 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:16:49,335 [INFO] app1.py:933 - Starting translation request - Text: 'are you listening me?', Target language: es
2024-12-02 15:16:49,335 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:16:49,336 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:16:49,336 [DEBUG] app1.py:964 - Request body: [{'text': 'are you listening me?'}]
2024-12-02 15:16:49,861 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:16:49,862 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Me ests escuchando?', 'to': 'es'}]}]
2024-12-02 15:16:49,862 [DEBUG] app1.py:974 - Extracted translation: Me ests escuchando?
2024-12-02 15:16:49,863 [INFO] app1.py:975 - Translation completed successfully - Original: 'are you listening me?' -> Translation: 'Me ests escuchando?' (es)
2024-12-02 15:16:49,865 [DEBUG] app1.py:918 - Sending translation to client dfff3259-8802-40bf-b5af-a30fb9321a5d: Me ests escuchando?
2024-12-02 15:16:49,865 [DEBUG] app1.py:925 - Translation sent successfully to client dfff3259-8802-40bf-b5af-a30fb9321a5d
2024-12-02 15:16:49,866 [DEBUG] app1.py:1144 - Sending message to client dfff3259-8802-40bf-b5af-a30fb9321a5d: {'type': 'final', 'translation': 'Me ests escuchando?'}
2024-12-02 15:17:04,652 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:17:04,653 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9b9fde0094104dd98ebbe9d5df9834c6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:04,654 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:17:18,473 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:17:20,188 [WARNING] app1.py:1148 - Client dfff3259-8802-40bf-b5af-a30fb9321a5d connection timed out
2024-12-02 15:17:20,768 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 15:17:20,769 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=12906d7c25144cdcaa4fb2c7e07c29b8, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:20,770 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:17:20,781 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:17:20,783 [DEBUG] app1.py:1031 - Received translation request - Text: 'I.', Target: es, Client: dfff3259-8802-40bf-b5af-a30fb9321a5d, Final: True
2024-12-02 15:17:20,784 [DEBUG] app1.py:1042 - Normalized text: 'i.'
2024-12-02 15:17:20,784 [DEBUG] app1.py:1048 - Time since last translation for dfff3259-8802-40bf-b5af-a30fb9321a5d:es: 31.450773000717163s
2024-12-02 15:17:20,786 [DEBUG] app1.py:1056 - Checking cache with key: i.:es
2024-12-02 15:17:20,786 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:17:20,787 [INFO] app1.py:933 - Starting translation request - Text: 'i.', Target language: es
2024-12-02 15:17:20,787 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:17:20,788 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:17:20,788 [DEBUG] app1.py:964 - Request body: [{'text': 'i.'}]
2024-12-02 15:17:21,338 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:17:21,339 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.86}, 'translations': [{'text': 'Yo.', 'to': 'es'}]}]
2024-12-02 15:17:21,341 [DEBUG] app1.py:974 - Extracted translation: Yo.
2024-12-02 15:17:21,342 [INFO] app1.py:975 - Translation completed successfully - Original: 'i.' -> Translation: 'Yo.' (es)
2024-12-02 15:17:21,344 [DEBUG] app1.py:918 - Sending translation to client dfff3259-8802-40bf-b5af-a30fb9321a5d: Yo.
2024-12-02 15:17:21,344 [DEBUG] app1.py:925 - Translation sent successfully to client dfff3259-8802-40bf-b5af-a30fb9321a5d
2024-12-02 15:17:22,648 [INFO] app1.py:1121 - New translation stream connection for client: dfff3259-8802-40bf-b5af-a30fb9321a5d, language: es
2024-12-02 15:17:22,650 [DEBUG] app1.py:1144 - Sending message to client dfff3259-8802-40bf-b5af-a30fb9321a5d: {'type': 'final', 'translation': 'Yo.'}
2024-12-02 15:17:34,088 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:17:34,094 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:17:40,817 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:17:40,818 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0f2e9321201e480986596ef1360251e3, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:40,819 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:17:41,109 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 15:17:41,110 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=84afb120686f4c5398f32b6ba36e0e9d, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:41,111 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 15:17:41,418 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:17:41,419 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1ad5016e74cd427b88710f40eeed2a97, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:41,420 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:17:42,122 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:17:42,123 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=292b231d999a4437b975f9ac65e25fb8, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:42,124 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:17:43,631 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:17:43,634 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=da5114fc6cb94e51ac0b187b5d63be0b, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:43,634 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:17:45,443 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:17:45,444 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c1f1cdf58faa45dc81f07c8545ea65a0, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:45,445 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:17:46,422 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:17:46,423 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4eca01b0106548a9b9a93f3882aa36a1, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:46,423 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:17:47,622 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:17:47,623 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e40b680375784bb4af9e988bb377d971, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:47,623 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:17:48,475 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:17:49,034 [INFO] app1.py:1205 - Speech recognized: Hello. What are you doing? ****.
2024-12-02 15:17:49,036 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8ef11e0d682d4910ac03e7ae7921ddfe, text="Hello. What are you doing? ****.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:49,036 [DEBUG] app1.py:1104 - Sending transcription: Hello. What are you doing? ****. (is_final: True)
2024-12-02 15:17:50,873 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:17:50,874 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6d060c1d600149e8b0f94a84074ba390, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:50,875 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:17:51,710 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 15:17:51,711 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0daf830c7f6a470eb473dfa001d187c7, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:51,711 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 15:17:51,770 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you
2024-12-02 15:17:51,771 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c327ee746504cadbf724f1b51708d31, text="hello what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:51,772 [DEBUG] app1.py:1104 - Sending transcription: hello what are you (is_final: False)
2024-12-02 15:17:51,974 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:17:51,975 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2e1c54de56a24f439857518767dfa5ce, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:51,977 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:17:52,440 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:17:52,441 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=77803e0970d246a3a5286a323a16d2d5, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:52,442 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:17:53,626 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:17:53,626 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ed30bdac20e3420d833ddf531c2ca63d, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:53,627 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:17:54,435 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you
2024-12-02 15:17:54,436 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f276238f7b8f4aa982523a4097b93959, text="hello what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:54,437 [DEBUG] app1.py:1104 - Sending transcription: hello what are you (is_final: False)
2024-12-02 15:17:54,733 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:17:54,734 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f3c53f80769b4d80b93774f0826f9409, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:54,735 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:17:55,433 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:17:55,434 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1089199573ea4340bec9615f1d6a1d3d, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:55,435 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:17:56,821 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:17:56,822 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2b2e4c8f455e4b4697192e803020fd8c, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:56,823 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:17:57,721 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:17:57,721 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c7130f71f3e5425eb314547d85e98195, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:17:57,723 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:17:58,639 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:17:58,640 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5f838b16571e414ba78b99aaa094ffdd, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:17:58,642 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:18:00,614 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:18:00,615 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4ad44298375a410197fb671acfc52b3a, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:00,616 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:18:01,216 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:18:01,216 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7ddbfafeb259401c9b91c9027ea3096f, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:01,218 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:18:01,544 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:18:01,545 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=11adf2b3deed4cb581f62054a39e7024, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:18:01,547 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:18:03,517 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:18:03,518 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0e95c755a1b8492f87038929a058fc88, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:03,518 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:18:03,719 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 15:18:03,720 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b08a4ad7a63c4d969331f2173db57f53, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:03,721 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 15:18:03,812 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you
2024-12-02 15:18:03,814 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cf307878ce8e4b928e547f844ab66fea, text="hello what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:03,815 [DEBUG] app1.py:1104 - Sending transcription: hello what are you (is_final: False)
2024-12-02 15:18:04,233 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:18:04,234 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cc35535d34fb4afbba0316ebe1e84227, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:04,235 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:18:06,022 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:18:06,023 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=69b39ef3ea284e6eb5a6f63b1f61cb07, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:18:06,024 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:18:07,015 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:18:07,016 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d35019717575476db9859e8ab86d0966, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:07,018 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:18:08,326 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:18:08,327 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc3fd4fc6cc74da68b9b6d117c202b1a, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:08,329 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:18:09,131 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:18:09,132 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=38093faf91844e64a7bacec4cd8e80db, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:18:09,138 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:18:10,233 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:18:10,234 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bc221242f7e840ea986ec639d0abca24, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:10,235 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:18:11,057 [DEBUG] app1.py:1214 - Speech recognizing: hello what are
2024-12-02 15:18:11,058 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aa5276731dd0432c8544f7f413b7ca5e, text="hello what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:11,058 [DEBUG] app1.py:1104 - Sending transcription: hello what are (is_final: False)
2024-12-02 15:18:11,136 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you
2024-12-02 15:18:11,136 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9608349b8347489e82acb3046c1c5fda, text="hello what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:11,137 [DEBUG] app1.py:1104 - Sending transcription: hello what are you (is_final: False)
2024-12-02 15:18:11,435 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:18:11,436 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=048266d8c8a24a0fb7fc728cec715581, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:11,436 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:18:12,326 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:18:12,327 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=19d738589dcf41beb4cce83ff23581af, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:18:12,328 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:18:14,311 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:18:14,312 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5d4264b9394240f6b13038051ae5bf94, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:14,312 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:18:14,909 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:18:14,922 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7e58ff76c34d4e58ae71c6500e9faded, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:18:14,924 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:18:18,477 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:18:32,207 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:18:32,209 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c043b711c3f144bd986c55e2175b4629, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:18:32,210 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:18:47,293 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:18:47,294 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=91231e8826ac4261ad10bdc1ddb6ea49, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:18:47,295 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:18:48,479 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:19:02,300 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:19:02,302 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b1c83f2dae6b4b3b81c4d89d6067db71, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:19:02,303 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:19:17,437 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:19:17,438 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dc2b0bdde4414c789889f2a97b96da1a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:19:17,439 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:19:18,481 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:19:22,422 [DEBUG] app1.py:1214 - Speech recognizing: we are
2024-12-02 15:19:22,423 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=15c36272bea44999a7a7907759c7f19d, text="we are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:19:22,425 [DEBUG] app1.py:1104 - Sending transcription: we are (is_final: False)
2024-12-02 15:19:22,827 [DEBUG] app1.py:1214 - Speech recognizing: we are we are
2024-12-02 15:19:22,828 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e35f33de1a9a4655ba2d94d9f2f4422e, text="we are we are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:19:22,829 [DEBUG] app1.py:1104 - Sending transcription: we are we are (is_final: False)
2024-12-02 15:19:23,231 [INFO] app1.py:1205 - Speech recognized: We are. We are.
2024-12-02 15:19:23,231 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e85548fe9e914d82998b82cdcf648583, text="We are. We are.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:19:23,233 [DEBUG] app1.py:1104 - Sending transcription: We are. We are. (is_final: True)
2024-12-02 15:19:33,440 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 15:19:33,441 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ee652a7256146b8a5dd370c8ae5080d, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:19:33,442 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 15:19:33,737 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 15:19:33,738 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=56031e4500cc442491afd10f877e7dbb, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:19:33,739 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 15:19:34,344 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:19:34,345 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4d736100a6ac49e3bd154f00b845b112, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:19:34,346 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:19:38,016 [DEBUG] app1.py:1214 - Speech recognizing: no
2024-12-02 15:19:38,017 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=40c2c0dba0b7497c99d3a1138230ee66, text="no", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:19:38,019 [DEBUG] app1.py:1104 - Sending transcription: no (is_final: False)
2024-12-02 15:19:38,671 [INFO] app1.py:1205 - Speech recognized: Are you listening? No.
2024-12-02 15:19:38,672 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=156a189143f44014a8b5a41017bc2de3, text="Are you listening? No.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:19:38,673 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? No. (is_final: True)
2024-12-02 15:19:48,482 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:19:58,846 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:19:58,846 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6e955fb4e59c472da4cc5952745a1e04, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:19:58,847 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:20:14,026 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:20:14,027 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7cda51e302c5460aae065ef1a6b85dd5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:20:14,027 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:20:18,484 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:20:29,240 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:20:29,240 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ee8ba67350b14f0f8143adce14853dde, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:20:29,242 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:20:44,440 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:20:44,441 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d10540a25e6f40aba1ec01883582bec4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:20:44,442 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:20:48,486 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:20:48,999 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:20:49,215 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:20:49,215 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=643fb6d347af411c853c97d450e58d75, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:20:49,216 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:20:49,216 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:21:18,487 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:21:48,489 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:22:18,490 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:22:48,493 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:23:18,494 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:23:19,457 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:23:19,618 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:23:19,716 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:23:35,083 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:23:35,084 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4f1ab70eed934832be022ab4e417ca90, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:23:43,117 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 15:23:43,118 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5d3eabb9c67e4ce3be1c5471a16f1805, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:23:48,496 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:24:03,299 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:24:03,300 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a8466247f5844b99b2700f74d314a103, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:24:10,568 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:24:10,569 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=abd47a8c9389400cbc7dff170c97c160, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:24:11,768 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 15:24:11,769 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=db63abe92f0c4e05ad4836048f16f1e7, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:24:12,465 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:24:12,465 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=00bff5e153fb4d6f8aa965e974821c42, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:24:14,265 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 15:24:14,266 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ec186e64c0b048eda8a8cca14c422a52, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:24:16,082 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:24:16,082 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=db45747eb937415ba18df2810f12a7c0, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:24:16,970 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:24:16,971 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cf02c4c0bb7549a49c572d96baddf827, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:24:18,499 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:24:21,078 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:24:21,079 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1deff517767a4378ac2a6d1bf5399c42, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:24:21,268 [DEBUG] app1.py:1214 - Speech recognizing: hi what are
2024-12-02 15:24:21,269 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c0f346a5aa804d16b25097cae701cd01, text="hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:24:21,669 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:24:21,669 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d3ff7e6b966a4ebe878b5b5a2d486770, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:24:22,293 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:24:22,293 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f963b28cc25b4f26bd0c29fa5f5a3a4b, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:24:40,087 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:24:40,088 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9c24fa3bb74845e9bae9003f24547ba4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:24:48,501 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:24:57,234 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:24:57,235 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=38bbc069b337491686c15e139c17146c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:25:12,686 [DEBUG] app1.py:1214 - Speech recognizing: uh in the driveway
2024-12-02 15:25:12,686 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0d7d180523c64c5a9d5777bb6aa668d2, text="uh in the driveway", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:14,137 [INFO] app1.py:1205 - Speech recognized: In the driveway.
2024-12-02 15:25:14,139 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7e8d4e0680b94d46b6cb086aa7b97327, text="In the driveway.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:25:18,503 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:25:18,777 [DEBUG] app1.py:1214 - Speech recognizing: anthony will stop
2024-12-02 15:25:18,778 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a680643cb97f49088f77bb9621717aea, text="anthony will stop", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:19,186 [DEBUG] app1.py:1214 - Speech recognizing: ankhi must talk about
2024-12-02 15:25:19,187 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4af89cba9c6a4bea98a08c693ee0266c, text="ankhi must talk about", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:19,381 [DEBUG] app1.py:1214 - Speech recognizing: ankhi must talk about the naan jihad
2024-12-02 15:25:19,382 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=258f50165d4247248cc597972e9fa2f4, text="ankhi must talk about the naan jihad", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:19,772 [DEBUG] app1.py:1214 - Speech recognizing: ankhi must talk about the naan jihad takkun
2024-12-02 15:25:19,773 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2948c3261c48448684373be978ab838f, text="ankhi must talk about the naan jihad takkun", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:20,083 [DEBUG] app1.py:1214 - Speech recognizing: ankhi must talk about the naan jihad takkunu
2024-12-02 15:25:20,084 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=435720acaf3645f99c8aefe33ccf0095, text="ankhi must talk about the naan jihad takkunu", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:20,235 [INFO] app1.py:1205 - Speech recognized: Anthony must talk about the Naan Jihad Takkunu in Lt.
2024-12-02 15:25:20,235 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=473533228bdf464c9da6a9932f0b7064, text="Anthony must talk about the Naan Jihad Takkunu in Lt.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:25:36,815 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:25:36,816 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5d260e5011ab4099bd4a05b90f1ae3e5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:25:48,504 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:25:53,183 [DEBUG] app1.py:1214 - Speech recognizing: play savitri
2024-12-02 15:25:53,184 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2fd9d356346b4f00854345d1459096b9, text="play savitri", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:53,778 [DEBUG] app1.py:1214 - Speech recognizing: play savitri chaar second
2024-12-02 15:25:53,779 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=43565704d9e54da4b565fcc7c22441a4, text="play savitri chaar second", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:54,184 [DEBUG] app1.py:1214 - Speech recognizing: play savitri char secondary
2024-12-02 15:25:54,185 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=869c104630ee4190a2d2409b3957fc40, text="play savitri char secondary", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:25:54,898 [INFO] app1.py:1205 - Speech recognized: Play Savitri Char secondary.
2024-12-02 15:25:54,899 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f1bad1521c0a4549956681d95d6a1343, text="Play Savitri Char secondary.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:26:12,385 [INFO] app1.py:1205 - Speech recognized: My translator does that.
2024-12-02 15:26:12,386 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=950dab4c2f9b4febb7db46c5e1214e42, text="My translator does that.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:26:14,158 [DEBUG] app1.py:1214 - Speech recognizing: new transmitter
2024-12-02 15:26:14,159 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=30975960d19545818b6e60f2577aa02e, text="new transmitter", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:15,090 [INFO] app1.py:1205 - Speech recognized: New transmitter used.
2024-12-02 15:26:15,091 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c7a84d93474b4eb584575c8455cf01ed, text="New transmitter used.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:26:18,506 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:26:18,658 [DEBUG] app1.py:1214 - Speech recognizing: who dresses
2024-12-02 15:26:18,659 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=16601ba9ae374e3c9462ed5572435566, text="who dresses", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:23,466 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 15:26:23,466 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d8cb5b50f6ef4f84894ce846d655cda8, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:24,108 [INFO] app1.py:1205 - Speech recognized: Hey, Cortana.
2024-12-02 15:26:24,109 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1898cc84eb5f45cf93d7d3acd32974ca, text="Hey, Cortana.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:26:26,870 [DEBUG] app1.py:1214 - Speech recognizing: deepika padukone
2024-12-02 15:26:26,871 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=deab1e0fa2bd443f84bb626d4ea00676, text="deepika padukone", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:27,798 [INFO] app1.py:1205 - Speech recognized: Deepika Padukone.
2024-12-02 15:26:27,799 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b85c97fb6a354f2aab142422a26c4ab8, text="Deepika Padukone.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:26:29,761 [DEBUG] app1.py:1214 - Speech recognizing: 4
2024-12-02 15:26:29,762 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5fc35b20c3c4491c9e22a6128b0412e3, text="4", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:30,162 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor
2024-12-02 15:26:30,164 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8bbac32b5aaa4b22bcbbd63ff0a86267, text="4 BHK builder floor", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:31,376 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor 1
2024-12-02 15:26:31,377 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d7a1ea70b3ca4cb49483a843d4554aa8, text="4 BHK builder floor 1", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:32,960 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor 1000
2024-12-02 15:26:32,961 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a79aed775de74857a6e3c8cda9e16145, text="4 BHK builder floor 1000", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:33,665 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor 1000 SQFT for rent
2024-12-02 15:26:33,666 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=208d4815639b40a6a8d924b4b1e75f4b, text="4 BHK builder floor 1000 SQFT for rent", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:33,961 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor 1000
2024-12-02 15:26:33,962 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8c6bb7ea3b3441c6ac1edd7a37023a62, text="4 BHK builder floor 1000", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:34,164 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor 1000 SQFT for rent in
2024-12-02 15:26:34,166 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3e41ab270112464ba2ab18f9e554a322, text="4 BHK builder floor 1000 SQFT for rent in", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:34,662 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor 1000
2024-12-02 15:26:34,663 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0c8b2f041d614be4983633a1bc250f47, text="4 BHK builder floor 1000", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:35,971 [DEBUG] app1.py:1214 - Speech recognizing: 4 BHK builder floor 100
2024-12-02 15:26:35,972 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3ea3a302c27946d6898a1cd14ca9c5fd, text="4 BHK builder floor 100", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:26:37,804 [INFO] app1.py:1205 - Speech recognized: 4 BHK Builder Floor 100.
2024-12-02 15:26:37,805 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3d33bd92e28e4285b83c206bb6c87a4d, text="4 BHK Builder Floor 100.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:26:48,508 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:26:57,974 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:26:57,975 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=07b93614c8d0474b99f6eafa40e6d2fa, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:08,275 [INFO] app1.py:1205 - Speech recognized: I think it's.
2024-12-02 15:27:08,275 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=924fe6fae14d45c2a71a1c7bdd248846, text="I think it's.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:11,588 [DEBUG] app1.py:1214 - Speech recognizing: jallikattu
2024-12-02 15:27:11,588 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dd235d3c36b94cc98f5c4730f6662a4a, text="jallikattu", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:12,184 [INFO] app1.py:1205 - Speech recognized: Jallikattu.
2024-12-02 15:27:12,184 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eb8d80192fd8482f90a6e9f5c9ad9c62, text="Jallikattu.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:15,481 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:27:15,482 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=07d8a5ddb8fe44fd9a536ea2d5303846, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:15,776 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:27:15,778 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fa5ac9639f084d60a20178db8f204ed8, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:16,072 [DEBUG] app1.py:1214 - Speech recognizing: hi what are
2024-12-02 15:27:16,073 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9153ed1fa9094787aefb325e15ff6235, text="hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:16,180 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:27:16,183 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ec13ff6bbe84aa0a13704966ed701de, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:16,679 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:27:16,679 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5d54816118964b1e98bfeb63042f5d91, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:17,445 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:27:17,445 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:27:17,445 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:27:17,446 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:27:17,448 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:27:17,449 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:27:17,457 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 15:27:17,458 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:27:17,459 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 15:27:17,460 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:27:17,461 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:27:17,474 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:27:17,475 [DEBUG] app1.py:1104 - Sending transcription: hi what are (is_final: False)
2024-12-02 15:27:17,476 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:27:17,477 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:27:17,479 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:27:17,491 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:27:17,492 [DEBUG] app1.py:1104 - Sending transcription: uh in the driveway (is_final: False)
2024-12-02 15:27:17,495 [DEBUG] app1.py:1104 - Sending transcription: In the driveway. (is_final: True)
2024-12-02 15:27:17,496 [DEBUG] app1.py:1104 - Sending transcription: anthony will stop (is_final: False)
2024-12-02 15:27:17,504 [DEBUG] app1.py:1104 - Sending transcription: ankhi must talk about (is_final: False)
2024-12-02 15:27:17,507 [DEBUG] app1.py:1104 - Sending transcription: ankhi must talk about the naan jihad (is_final: False)
2024-12-02 15:27:17,508 [DEBUG] app1.py:1104 - Sending transcription: ankhi must talk about the naan jihad takkun (is_final: False)
2024-12-02 15:27:17,511 [DEBUG] app1.py:1104 - Sending transcription: ankhi must talk about the naan jihad takkunu (is_final: False)
2024-12-02 15:27:17,524 [DEBUG] app1.py:1104 - Sending transcription: Anthony must talk about the Naan Jihad Takkunu in Lt. (is_final: True)
2024-12-02 15:27:17,526 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:27:17,526 [DEBUG] app1.py:1104 - Sending transcription: play savitri (is_final: False)
2024-12-02 15:27:17,537 [DEBUG] app1.py:1104 - Sending transcription: play savitri chaar second (is_final: False)
2024-12-02 15:27:17,539 [DEBUG] app1.py:1104 - Sending transcription: play savitri char secondary (is_final: False)
2024-12-02 15:27:17,539 [DEBUG] app1.py:1104 - Sending transcription: Play Savitri Char secondary. (is_final: True)
2024-12-02 15:27:17,540 [DEBUG] app1.py:1104 - Sending transcription: My translator does that. (is_final: True)
2024-12-02 15:27:17,540 [DEBUG] app1.py:1104 - Sending transcription: new transmitter (is_final: False)
2024-12-02 15:27:17,541 [DEBUG] app1.py:1104 - Sending transcription: New transmitter used. (is_final: True)
2024-12-02 15:27:17,541 [DEBUG] app1.py:1104 - Sending transcription: who dresses (is_final: False)
2024-12-02 15:27:17,543 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 15:27:17,544 [DEBUG] app1.py:1104 - Sending transcription: Hey, Cortana. (is_final: True)
2024-12-02 15:27:17,545 [DEBUG] app1.py:1104 - Sending transcription: deepika padukone (is_final: False)
2024-12-02 15:27:17,555 [DEBUG] app1.py:1104 - Sending transcription: Deepika Padukone. (is_final: True)
2024-12-02 15:27:17,557 [DEBUG] app1.py:1104 - Sending transcription: 4 (is_final: False)
2024-12-02 15:27:17,560 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor (is_final: False)
2024-12-02 15:27:17,561 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor 1 (is_final: False)
2024-12-02 15:27:17,562 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor 1000 (is_final: False)
2024-12-02 15:27:17,566 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor 1000 SQFT for rent (is_final: False)
2024-12-02 15:27:17,567 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor 1000 (is_final: False)
2024-12-02 15:27:17,569 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor 1000 SQFT for rent in (is_final: False)
2024-12-02 15:27:17,570 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor 1000 (is_final: False)
2024-12-02 15:27:17,571 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK builder floor 100 (is_final: False)
2024-12-02 15:27:17,571 [DEBUG] app1.py:1104 - Sending transcription: 4 BHK Builder Floor 100. (is_final: True)
2024-12-02 15:27:17,571 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:27:17,573 [DEBUG] app1.py:1104 - Sending transcription: I think it's. (is_final: True)
2024-12-02 15:27:17,573 [DEBUG] app1.py:1104 - Sending transcription: jallikattu (is_final: False)
2024-12-02 15:27:17,574 [DEBUG] app1.py:1104 - Sending transcription: Jallikattu. (is_final: True)
2024-12-02 15:27:17,574 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:27:17,576 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:27:17,576 [DEBUG] app1.py:1104 - Sending transcription: hi what are (is_final: False)
2024-12-02 15:27:17,577 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:27:17,577 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:27:18,509 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d']
2024-12-02 15:27:25,274 [DEBUG] app1.py:1214 - Speech recognizing: bowling
2024-12-02 15:27:25,276 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=52654ffdb8524244958e566575b259df, text="bowling", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:25,276 [DEBUG] app1.py:1104 - Sending transcription: bowling (is_final: False)
2024-12-02 15:27:25,868 [DEBUG] app1.py:1214 - Speech recognizing: bowling alley
2024-12-02 15:27:25,868 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=31bb624c52114a4f98279c4aa4cee14a, text="bowling alley", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:25,974 [INFO] app1.py:1205 - Speech recognized: Bowling alley.
2024-12-02 15:27:25,975 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9e2746ef15154b0bb18c1a5c646f4a81, text="Bowling alley.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:26,598 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:27:26,599 [INFO] app1.py:1121 - New translation stream connection for client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, language: es
2024-12-02 15:27:26,599 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:27:26,599 [INFO] app1.py:1131 - Creating new client connection: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc
2024-12-02 15:27:26,599 [DEBUG] app1.py:1104 - Sending transcription: bowling alley (is_final: False)
2024-12-02 15:27:26,600 [DEBUG] app1.py:1104 - Sending transcription: Bowling alley. (is_final: True)
2024-12-02 15:27:26,617 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:26,617 [DEBUG] app1.py:1031 - Received translation request - Text: 'Bowling alley.', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: True
2024-12-02 15:27:26,617 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:26,618 [DEBUG] app1.py:1042 - Normalized text: 'bowling alley.'
2024-12-02 15:27:26,618 [DEBUG] app1.py:1031 - Received translation request - Text: 'bowling alley', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:26,620 [DEBUG] app1.py:1056 - Checking cache with key: bowling alley.:es
2024-12-02 15:27:26,620 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:26,621 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:27:26,622 [INFO] app1.py:933 - Starting translation request - Text: 'bowling alley.', Target language: es
2024-12-02 15:27:26,624 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:27:26,625 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:27:26,625 [DEBUG] app1.py:964 - Request body: [{'text': 'bowling alley.'}]
2024-12-02 15:27:27,142 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:27:27,144 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'bolera.', 'to': 'es'}]}]
2024-12-02 15:27:27,145 [DEBUG] app1.py:974 - Extracted translation: bolera.
2024-12-02 15:27:27,145 [INFO] app1.py:975 - Translation completed successfully - Original: 'bowling alley.' -> Translation: 'bolera.' (es)
2024-12-02 15:27:27,146 [DEBUG] app1.py:918 - Sending translation to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: bolera.
2024-12-02 15:27:27,146 [DEBUG] app1.py:925 - Translation sent successfully to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc
2024-12-02 15:27:27,147 [DEBUG] app1.py:1144 - Sending message to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: {'type': 'final', 'translation': 'bolera.'}
2024-12-02 15:27:27,213 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'bolera.', Language: es
2024-12-02 15:27:27,237 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ccc5de86-7e6c-4cdc-a964-edda0784c87f.wav
2024-12-02 15:27:27,253 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:27:28,110 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:27:28,112 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ccc5de86-7e6c-4cdc-a964-edda0784c87f.wav
2024-12-02 15:27:28,655 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:27:28,656 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d97388e9e62045929a6f5ef346b509ed, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:28,656 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:27:28,661 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:28,666 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:28,668 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:28,950 [DEBUG] app1.py:1214 - Speech recognizing: hi what are
2024-12-02 15:27:28,952 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d5157161b9be4dc8bf4e83bb6f6ceee7, text="hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:28,953 [DEBUG] app1.py:1104 - Sending transcription: hi what are (is_final: False)
2024-12-02 15:27:28,958 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:28,958 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:28,960 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:29,261 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:27:29,262 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc7763ebb1ae44689eeeb000de447663, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:29,263 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:27:29,267 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:29,268 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you doing', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:29,268 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:29,959 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing? Hi.
2024-12-02 15:27:29,961 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=56d5fd951b9542de9fb2700c11c63714, text="Hi, what are you doing? Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:29,962 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? Hi. (is_final: True)
2024-12-02 15:27:29,966 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:29,966 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, what are you doing? Hi.', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: True
2024-12-02 15:27:29,968 [DEBUG] app1.py:1042 - Normalized text: 'hi, what are you doing? hi.'
2024-12-02 15:27:29,968 [DEBUG] app1.py:1048 - Time since last translation for 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc:es: 3.3480820655822754s
2024-12-02 15:27:29,969 [DEBUG] app1.py:1056 - Checking cache with key: hi, what are you doing? hi.:es
2024-12-02 15:27:29,969 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:27:29,970 [INFO] app1.py:933 - Starting translation request - Text: 'hi, what are you doing? hi.', Target language: es
2024-12-02 15:27:29,970 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:27:29,971 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:27:29,971 [DEBUG] app1.py:964 - Request body: [{'text': 'hi, what are you doing? hi.'}]
2024-12-02 15:27:30,481 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:27:30,482 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'hola, qu est haciendo? hola.', 'to': 'es'}]}]
2024-12-02 15:27:30,482 [DEBUG] app1.py:974 - Extracted translation: hola, qu est haciendo? hola.
2024-12-02 15:27:30,482 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi, what are you doing? hi.' -> Translation: 'hola, qu est haciendo? hola.' (es)
2024-12-02 15:27:30,483 [DEBUG] app1.py:918 - Sending translation to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: hola, qu est haciendo? hola.
2024-12-02 15:27:30,484 [DEBUG] app1.py:925 - Translation sent successfully to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc
2024-12-02 15:27:30,484 [DEBUG] app1.py:1144 - Sending message to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: {'type': 'final', 'translation': 'hola, qu est haciendo? hola.'}
2024-12-02 15:27:30,495 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'hola, qu est haciendo? hola.', Language: es
2024-12-02 15:27:30,496 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4838e29a-e80e-4215-9364-01ffb97f9c94.wav
2024-12-02 15:27:30,497 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:27:31,482 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:27:31,483 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4838e29a-e80e-4215-9364-01ffb97f9c94.wav
2024-12-02 15:27:37,884 [DEBUG] app1.py:1214 - Speech recognizing: one of these
2024-12-02 15:27:37,885 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=01c01a132489441ea340f8f9c957f7ae, text="one of these", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:37,886 [DEBUG] app1.py:1104 - Sending transcription: one of these (is_final: False)
2024-12-02 15:27:37,892 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:37,892 [DEBUG] app1.py:1031 - Received translation request - Text: 'one of these', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:37,893 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:38,496 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of
2024-12-02 15:27:38,496 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9509c12162b4ca99b0e55b8b2c8d836, text="one of these couple of", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:38,497 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of (is_final: False)
2024-12-02 15:27:38,502 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:38,503 [DEBUG] app1.py:1031 - Received translation request - Text: 'one of these couple of', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:38,504 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:38,679 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of stopquir
2024-12-02 15:27:38,679 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=249c760e0ccd443eb1066898856f0d57, text="one of these couple of stopquir", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:38,679 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of stopquir (is_final: False)
2024-12-02 15:27:38,685 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:38,685 [DEBUG] app1.py:1031 - Received translation request - Text: 'one of these couple of stopquir', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:38,686 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:39,081 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of stopquirking
2024-12-02 15:27:39,082 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=636491b51fb74ee6b0bf698400b246cd, text="one of these couple of stopquirking", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:39,082 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of stopquirking (is_final: False)
2024-12-02 15:27:39,087 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:39,087 [DEBUG] app1.py:1031 - Received translation request - Text: 'one of these couple of stopquirking', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:39,088 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:39,389 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of stopquirking prothu
2024-12-02 15:27:39,389 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f6d1a542907945369fbd84df8a9bb3f7, text="one of these couple of stopquirking prothu", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:39,391 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of stopquirking prothu (is_final: False)
2024-12-02 15:27:39,395 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:39,395 [DEBUG] app1.py:1031 - Received translation request - Text: 'one of these couple of stopquirking prothu', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:39,396 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:39,978 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of stopquirking prothu lever
2024-12-02 15:27:39,979 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f64d78ad36054d3d88ac95a0fc9ca20d, text="one of these couple of stopquirking prothu lever", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:39,980 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of stopquirking prothu lever (is_final: False)
2024-12-02 15:27:39,984 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:39,984 [DEBUG] app1.py:1031 - Received translation request - Text: 'one of these couple of stopquirking prothu lever', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:39,989 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:40,381 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of stopquirking prothu lever lever
2024-12-02 15:27:40,382 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b69c6a7a35b0403bb0d57a07d3a9e2f3, text="one of these couple of stopquirking prothu lever lever", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:40,383 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of stopquirking prothu lever lever (is_final: False)
2024-12-02 15:27:40,387 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:40,388 [DEBUG] app1.py:1031 - Received translation request - Text: 'one of these couple of stopquirking prothu lever lever', Target: es, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:40,389 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:40,488 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of stopquirking prothu lever leveraged
2024-12-02 15:27:40,489 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce61ff34c7124a7db5fb293b6ce1553e, text="one of these couple of stopquirking prothu lever leveraged", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:40,489 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of stopquirking prothu lever leveraged (is_final: False)
2024-12-02 15:27:40,523 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:27:40,752 [DEBUG] app1.py:1214 - Speech recognizing: one of these couple of stopquirking prothu lever limburger
2024-12-02 15:27:40,754 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=760bdbe7985b45d5b82f5dad81ad95aa, text="one of these couple of stopquirking prothu lever limburger", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:40,755 [DEBUG] app1.py:1104 - Sending transcription: one of these couple of stopquirking prothu lever limburger (is_final: False)
2024-12-02 15:27:40,785 [INFO] app1.py:1205 - Speech recognized: One of these couple of stop querking Prothu lever leveraged.
2024-12-02 15:27:40,787 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6905dc438fca4a9da3eadb4000100015, text="One of these couple of stop querking Prothu lever leveraged.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:40,787 [DEBUG] app1.py:1104 - Sending transcription: One of these couple of stop querking Prothu lever leveraged. (is_final: True)
2024-12-02 15:27:40,787 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:27:42,726 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:27:42,736 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:27:42,737 [INFO] app1.py:1121 - New translation stream connection for client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, language: pt
2024-12-02 15:27:42,739 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:27:42,779 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:27:42,866 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:27:45,554 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:27:45,555 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1c17b803bfb043daa05aec43039dda29, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:45,556 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:27:45,564 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:45,565 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:45,565 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:45,661 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:27:45,661 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=209d5b62b3dc4c5a944f531d7b532282, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:45,662 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:27:45,666 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:45,667 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: True
2024-12-02 15:27:45,668 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 15:27:45,668 [DEBUG] app1.py:1056 - Checking cache with key: hi.:pt
2024-12-02 15:27:45,668 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:27:45,669 [DEBUG] app1.py:918 - Sending translation to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: Oi.
2024-12-02 15:27:45,669 [DEBUG] app1.py:925 - Translation sent successfully to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc
2024-12-02 15:27:45,669 [DEBUG] app1.py:1144 - Sending message to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: {'type': 'final', 'translation': 'Oi.'}
2024-12-02 15:27:45,675 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Oi.', Language: pt
2024-12-02 15:27:45,677 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_2db67137-4cf0-4b4f-ac32-bab599b87d9d.wav
2024-12-02 15:27:45,678 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:27:46,434 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:27:46,435 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=18751db0aa6b4bbcb873333723917a61, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:46,436 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:27:46,441 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:46,441 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:46,442 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:46,510 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:27:46,511 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_2db67137-4cf0-4b4f-ac32-bab599b87d9d.wav
2024-12-02 15:27:47,343 [DEBUG] app1.py:1214 - Speech recognizing: hello hello
2024-12-02 15:27:47,344 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=63b59bc763594229abdc89311bc6a8a1, text="hello hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:47,345 [DEBUG] app1.py:1104 - Sending transcription: hello hello (is_final: False)
2024-12-02 15:27:47,350 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:47,351 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello hello', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:47,351 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:48,510 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc']
2024-12-02 15:27:49,261 [INFO] app1.py:1205 - Speech recognized: Hello. Hello.
2024-12-02 15:27:49,262 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0e80519190044473a916380fff7c9298, text="Hello. Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:49,263 [DEBUG] app1.py:1104 - Sending transcription: Hello. Hello. (is_final: True)
2024-12-02 15:27:49,268 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:49,268 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello. Hello.', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: True
2024-12-02 15:27:49,268 [DEBUG] app1.py:1042 - Normalized text: 'hello. hello.'
2024-12-02 15:27:49,269 [DEBUG] app1.py:1048 - Time since last translation for 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc:pt: 3.6016862392425537s
2024-12-02 15:27:49,270 [DEBUG] app1.py:1056 - Checking cache with key: hello. hello.:pt
2024-12-02 15:27:49,270 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:27:49,270 [INFO] app1.py:933 - Starting translation request - Text: 'hello. hello.', Target language: pt
2024-12-02 15:27:49,271 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:27:49,271 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:27:49,272 [DEBUG] app1.py:964 - Request body: [{'text': 'hello. hello.'}]
2024-12-02 15:27:50,052 [DEBUG] app1.py:1214 - Speech recognizing: this is
2024-12-02 15:27:50,053 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0e06d6b9d1cd4b9b9c6f6595e6b74fac, text="this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:50,053 [DEBUG] app1.py:1104 - Sending transcription: this is (is_final: False)
2024-12-02 15:27:50,056 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:50,058 [DEBUG] app1.py:1031 - Received translation request - Text: 'this is', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:50,058 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:50,253 [DEBUG] app1.py:1214 - Speech recognizing: this is aman
2024-12-02 15:27:50,253 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=69a223ea077e43ef9aec1cdc0b68c019, text="this is aman", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:50,254 [DEBUG] app1.py:1104 - Sending transcription: this is aman (is_final: False)
2024-12-02 15:27:50,258 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:50,259 [DEBUG] app1.py:1031 - Received translation request - Text: 'this is aman', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:50,260 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:50,466 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:27:50,467 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Ol. Ol.', 'to': 'pt'}]}]
2024-12-02 15:27:50,467 [DEBUG] app1.py:974 - Extracted translation: Ol. Ol.
2024-12-02 15:27:50,468 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello. hello.' -> Translation: 'Ol. Ol.' (pt)
2024-12-02 15:27:50,469 [DEBUG] app1.py:918 - Sending translation to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: Ol. Ol.
2024-12-02 15:27:50,469 [DEBUG] app1.py:925 - Translation sent successfully to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc
2024-12-02 15:27:50,469 [DEBUG] app1.py:1144 - Sending message to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: {'type': 'final', 'translation': 'Ol. Ol.'}
2024-12-02 15:27:50,473 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Ol. Ol.', Language: pt
2024-12-02 15:27:50,474 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_f5908943-13b4-4cca-9033-fbfd7527699e.wav
2024-12-02 15:27:50,477 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:27:50,642 [DEBUG] app1.py:1214 - Speech recognizing: this is aman what are
2024-12-02 15:27:50,643 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6a9ebc1e93bd4fd49ed3147c1a9158d2, text="this is aman what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:50,644 [DEBUG] app1.py:1104 - Sending transcription: this is aman what are (is_final: False)
2024-12-02 15:27:50,651 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:50,651 [DEBUG] app1.py:1031 - Received translation request - Text: 'this is aman what are', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:50,652 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:50,956 [DEBUG] app1.py:1214 - Speech recognizing: this is aman what are you doing
2024-12-02 15:27:50,956 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e5c69450ef9d4605af014ce15e07f62d, text="this is aman what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:27:50,958 [DEBUG] app1.py:1104 - Sending transcription: this is aman what are you doing (is_final: False)
2024-12-02 15:27:50,963 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:50,963 [DEBUG] app1.py:1031 - Received translation request - Text: 'this is aman what are you doing', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: False
2024-12-02 15:27:50,964 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:27:51,407 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:27:51,407 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_f5908943-13b4-4cca-9033-fbfd7527699e.wav
2024-12-02 15:27:52,764 [INFO] app1.py:1205 - Speech recognized: This is Aman. What are you doing?
2024-12-02 15:27:52,765 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=734a541d12cc4e0ca9f32b524c5ec311, text="This is Aman. What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:27:52,766 [DEBUG] app1.py:1104 - Sending transcription: This is Aman. What are you doing? (is_final: True)
2024-12-02 15:27:52,771 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:27:52,771 [DEBUG] app1.py:1031 - Received translation request - Text: 'This is Aman. What are you doing?', Target: pt, Client: 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc, Final: True
2024-12-02 15:27:52,772 [DEBUG] app1.py:1042 - Normalized text: 'this is aman. what are you doing?'
2024-12-02 15:27:52,772 [DEBUG] app1.py:1048 - Time since last translation for 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc:pt: 3.5029239654541016s
2024-12-02 15:27:52,772 [DEBUG] app1.py:1056 - Checking cache with key: this is aman. what are you doing?:pt
2024-12-02 15:27:52,774 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:27:52,774 [INFO] app1.py:933 - Starting translation request - Text: 'this is aman. what are you doing?', Target language: pt
2024-12-02 15:27:52,775 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:27:52,776 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:27:52,776 [DEBUG] app1.py:964 - Request body: [{'text': 'this is aman. what are you doing?'}]
2024-12-02 15:27:53,070 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:27:53,071 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Este  Aman. O que  que est a fazer?', 'to': 'pt'}]}]
2024-12-02 15:27:53,072 [DEBUG] app1.py:974 - Extracted translation: Este  Aman. O que  que est a fazer?
2024-12-02 15:27:53,073 [INFO] app1.py:975 - Translation completed successfully - Original: 'this is aman. what are you doing?' -> Translation: 'Este  Aman. O que  que est a fazer?' (pt)
2024-12-02 15:27:53,074 [DEBUG] app1.py:918 - Sending translation to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: Este  Aman. O que  que est a fazer?
2024-12-02 15:27:53,074 [DEBUG] app1.py:925 - Translation sent successfully to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc
2024-12-02 15:27:53,074 [DEBUG] app1.py:1144 - Sending message to client 5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc: {'type': 'final', 'translation': 'Este  Aman. O que  que est a fazer?'}
2024-12-02 15:28:06,183 [INFO] app1.py:1205 - Speech recognized: Bhulani.
2024-12-02 15:28:06,184 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d985202e3ed745528459a3994f50159f, text="Bhulani.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:28:06,184 [DEBUG] app1.py:1104 - Sending transcription: Bhulani. (is_final: True)
2024-12-02 15:28:09,041 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:28:09,041 [INFO] app1.py:1121 - New translation stream connection for client: d9f0bfec-df8f-4a05-ba9b-129af61b114a, language: pt
2024-12-02 15:28:09,042 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:28:09,042 [INFO] app1.py:1131 - Creating new client connection: d9f0bfec-df8f-4a05-ba9b-129af61b114a
2024-12-02 15:28:11,645 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:28:11,645 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=066f701bc31744b09e890ebe33685a77, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:28:11,647 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:28:11,652 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:28:11,653 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: pt, Client: d9f0bfec-df8f-4a05-ba9b-129af61b114a, Final: False
2024-12-02 15:28:11,653 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:28:12,640 [DEBUG] app1.py:1214 - Speech recognizing: hello this is
2024-12-02 15:28:12,641 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c0c15ed24d1c4e04bb8c13cb03eff875, text="hello this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:28:12,646 [DEBUG] app1.py:1104 - Sending transcription: hello this is (is_final: False)
2024-12-02 15:28:12,656 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:28:12,657 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is', Target: pt, Client: d9f0bfec-df8f-4a05-ba9b-129af61b114a, Final: False
2024-12-02 15:28:12,657 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:28:13,236 [DEBUG] app1.py:1214 - Speech recognizing: hello this is AM
2024-12-02 15:28:13,236 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a0c60e3cd780469ebc6e77b878808ba5, text="hello this is AM", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:28:13,237 [DEBUG] app1.py:1104 - Sending transcription: hello this is AM (is_final: False)
2024-12-02 15:28:13,241 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:28:13,242 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is AM', Target: pt, Client: d9f0bfec-df8f-4a05-ba9b-129af61b114a, Final: False
2024-12-02 15:28:13,242 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:28:13,345 [DEBUG] app1.py:1214 - Speech recognizing: hello this is aman can you
2024-12-02 15:28:13,346 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=32934fea81aa40a3b582fb1b0df07525, text="hello this is aman can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:28:13,349 [DEBUG] app1.py:1104 - Sending transcription: hello this is aman can you (is_final: False)
2024-12-02 15:28:13,353 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:28:13,353 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is aman can you', Target: pt, Client: d9f0bfec-df8f-4a05-ba9b-129af61b114a, Final: False
2024-12-02 15:28:13,355 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:28:13,543 [DEBUG] app1.py:1214 - Speech recognizing: hello this is aman can you hear me
2024-12-02 15:28:13,544 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d2ebbbdd35b14053a1aef5088f5c9b7f, text="hello this is aman can you hear me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:28:13,544 [DEBUG] app1.py:1104 - Sending transcription: hello this is aman can you hear me (is_final: False)
2024-12-02 15:28:13,551 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:28:13,552 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is aman can you hear me', Target: pt, Client: d9f0bfec-df8f-4a05-ba9b-129af61b114a, Final: False
2024-12-02 15:28:13,554 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:28:14,492 [INFO] app1.py:1205 - Speech recognized: Hello, this is Aman. Can you hear me?
2024-12-02 15:28:14,493 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ff1f3a8b37ac42c28fe42a1e37434b09, text="Hello, this is Aman. Can you hear me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:28:14,493 [DEBUG] app1.py:1104 - Sending transcription: Hello, this is Aman. Can you hear me? (is_final: True)
2024-12-02 15:28:14,498 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:28:14,499 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello, this is Aman. Can you hear me?', Target: pt, Client: d9f0bfec-df8f-4a05-ba9b-129af61b114a, Final: True
2024-12-02 15:28:14,500 [DEBUG] app1.py:1042 - Normalized text: 'hello, this is aman. can you hear me?'
2024-12-02 15:28:14,500 [DEBUG] app1.py:1056 - Checking cache with key: hello, this is aman. can you hear me?:pt
2024-12-02 15:28:14,501 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:28:14,501 [INFO] app1.py:933 - Starting translation request - Text: 'hello, this is aman. can you hear me?', Target language: pt
2024-12-02 15:28:14,502 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:28:14,502 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:28:14,504 [DEBUG] app1.py:964 - Request body: [{'text': 'hello, this is aman. can you hear me?'}]
2024-12-02 15:28:14,810 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:28:14,812 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Ol, aqui  Aman. Voc consegue me ouvir?', 'to': 'pt'}]}]
2024-12-02 15:28:14,813 [DEBUG] app1.py:974 - Extracted translation: Ol, aqui  Aman. Voc consegue me ouvir?
2024-12-02 15:28:14,814 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello, this is aman. can you hear me?' -> Translation: 'Ol, aqui  Aman. Voc consegue me ouvir?' (pt)
2024-12-02 15:28:14,816 [DEBUG] app1.py:918 - Sending translation to client d9f0bfec-df8f-4a05-ba9b-129af61b114a: Ol, aqui  Aman. Voc consegue me ouvir?
2024-12-02 15:28:14,816 [DEBUG] app1.py:925 - Translation sent successfully to client d9f0bfec-df8f-4a05-ba9b-129af61b114a
2024-12-02 15:28:14,817 [DEBUG] app1.py:1144 - Sending message to client d9f0bfec-df8f-4a05-ba9b-129af61b114a: {'type': 'final', 'translation': 'Ol, aqui  Aman. Voc consegue me ouvir?'}
2024-12-02 15:28:14,826 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Ol, aqui  Aman. Voc consegue me ouvir?', Language: pt
2024-12-02 15:28:14,827 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d9dba30c-d9bd-455c-9fa1-31308d16fd41.wav
2024-12-02 15:28:14,828 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:28:15,840 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:28:15,841 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d9dba30c-d9bd-455c-9fa1-31308d16fd41.wav
2024-12-02 15:28:18,512 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a']
2024-12-02 15:28:22,554 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:28:22,804 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:28:48,513 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a']
2024-12-02 15:29:18,515 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a']
2024-12-02 15:29:48,524 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a']
2024-12-02 15:29:57,184 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:29:57,354 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:29:57,445 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:29:59,405 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:29:59,405 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=81a427c651b34c76a52fd6b76c475ed5, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:29:59,809 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:29:59,810 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6a4045ca08c8411d900d46af9d021b68, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:00,505 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:30:00,506 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a37251350a4c42e895dddbe69e272b3a, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:00,932 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:30:00,934 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:30:00,934 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:30:00,935 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:30:00,936 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:30:02,894 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:30:02,894 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2889e9322054433bac9bc35b84463f46, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:02,896 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:30:03,098 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:30:03,099 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8eb18b2d1e624d329e8d96eb4093ce68, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:03,099 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:30:03,503 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:30:03,503 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=33b40c3577934648ba65732f57bc0d28, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:03,504 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:30:04,871 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:30:05,105 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:30:05,106 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f01c14a4c9814a9da779a7400d1083e1, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:05,107 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:30:05,108 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:30:09,627 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:30:09,640 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:30:09,641 [INFO] app1.py:1121 - New translation stream connection for client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, language: es
2024-12-02 15:30:09,642 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:30:09,642 [INFO] app1.py:1131 - Creating new client connection: 29f82839-12f3-4d63-a0cb-4c0ab67e39de
2024-12-02 15:30:09,690 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:30:09,781 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:30:13,135 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:30:13,136 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bea1c3e72e5d45f4967a6d97276dae53, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:13,138 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:30:13,146 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:13,149 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:13,149 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:13,822 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 15:30:13,822 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=be5e6eb74eab442993ee90401cbf80f7, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:13,823 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 15:30:13,826 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:13,827 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: True
2024-12-02 15:30:13,827 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 15:30:13,828 [DEBUG] app1.py:1056 - Checking cache with key: hello.:es
2024-12-02 15:30:13,828 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:30:13,829 [DEBUG] app1.py:918 - Sending translation to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: Hola.
2024-12-02 15:30:13,829 [DEBUG] app1.py:925 - Translation sent successfully to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de
2024-12-02 15:30:13,829 [DEBUG] app1.py:1144 - Sending message to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 15:30:13,837 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola.', Language: es
2024-12-02 15:30:13,843 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ba4a7cb3-f056-4cab-b7ed-a50620892bc9.wav
2024-12-02 15:30:13,844 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:30:14,690 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:30:14,690 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ba4a7cb3-f056-4cab-b7ed-a50620892bc9.wav
2024-12-02 15:30:15,223 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:30:15,224 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f668c40b0b72436392ad36454352d5ba, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:15,225 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:30:15,233 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:15,234 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:15,236 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:16,527 [INFO] app1.py:1205 - Speech recognized: Hello on.
2024-12-02 15:30:16,528 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eeb44e4ff48f4ecd8d134584d372b9d3, text="Hello on.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:16,530 [DEBUG] app1.py:1104 - Sending transcription: Hello on. (is_final: True)
2024-12-02 15:30:16,535 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:16,535 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello on.', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: True
2024-12-02 15:30:16,535 [DEBUG] app1.py:1042 - Normalized text: 'hello on.'
2024-12-02 15:30:16,536 [DEBUG] app1.py:1048 - Time since last translation for 29f82839-12f3-4d63-a0cb-4c0ab67e39de:es: 2.708083391189575s
2024-12-02 15:30:16,536 [DEBUG] app1.py:1056 - Checking cache with key: hello on.:es
2024-12-02 15:30:16,537 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:30:16,537 [INFO] app1.py:933 - Starting translation request - Text: 'hello on.', Target language: es
2024-12-02 15:30:16,539 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:30:16,539 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:30:16,539 [DEBUG] app1.py:964 - Request body: [{'text': 'hello on.'}]
2024-12-02 15:30:17,737 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:30:17,738 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola.', 'to': 'es'}]}]
2024-12-02 15:30:17,740 [DEBUG] app1.py:974 - Extracted translation: Hola.
2024-12-02 15:30:17,740 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello on.' -> Translation: 'Hola.' (es)
2024-12-02 15:30:17,741 [DEBUG] app1.py:918 - Sending translation to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: Hola.
2024-12-02 15:30:17,743 [DEBUG] app1.py:925 - Translation sent successfully to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de
2024-12-02 15:30:17,743 [DEBUG] app1.py:1144 - Sending message to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 15:30:18,527 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de']
2024-12-02 15:30:36,634 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:30:36,635 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8956168d1dfe4d36b0fb7512314e521e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:36,637 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:30:39,536 [DEBUG] app1.py:1214 - Speech recognizing: at the portuguese
2024-12-02 15:30:39,537 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=73164ac3a4904af28d572930f9c84988, text="at the portuguese", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:39,539 [DEBUG] app1.py:1104 - Sending transcription: at the portuguese (is_final: False)
2024-12-02 15:30:39,548 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:39,549 [DEBUG] app1.py:1031 - Received translation request - Text: 'at the portuguese', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:39,549 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:40,435 [DEBUG] app1.py:1214 - Speech recognizing: at the portuguese connect
2024-12-02 15:30:40,435 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e32db93e364e41e0ab02f175ff491d30, text="at the portuguese connect", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:40,435 [DEBUG] app1.py:1104 - Sending transcription: at the portuguese connect (is_final: False)
2024-12-02 15:30:40,440 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:40,441 [DEBUG] app1.py:1031 - Received translation request - Text: 'at the portuguese connect', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:40,442 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:41,043 [DEBUG] app1.py:1214 - Speech recognizing: at the portuguese
2024-12-02 15:30:41,043 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=91792e7ffa5145ba87416dcba98ea43e, text="at the portuguese", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:41,044 [DEBUG] app1.py:1104 - Sending transcription: at the portuguese (is_final: False)
2024-12-02 15:30:41,048 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:41,048 [DEBUG] app1.py:1031 - Received translation request - Text: 'at the portuguese', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:41,050 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:41,431 [DEBUG] app1.py:1214 - Speech recognizing: at the portuguese connect
2024-12-02 15:30:41,431 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f5df5d600a584ea3b6943a0dc8b2b2af, text="at the portuguese connect", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:41,432 [DEBUG] app1.py:1104 - Sending transcription: at the portuguese connect (is_final: False)
2024-12-02 15:30:41,437 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:41,438 [DEBUG] app1.py:1031 - Received translation request - Text: 'at the portuguese connect', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:41,438 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:41,741 [DEBUG] app1.py:1214 - Speech recognizing: at the portuguese english
2024-12-02 15:30:41,741 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6dab8e26feb8454da822ca3121751fb6, text="at the portuguese english", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:41,743 [DEBUG] app1.py:1104 - Sending transcription: at the portuguese english (is_final: False)
2024-12-02 15:30:41,747 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:41,748 [DEBUG] app1.py:1031 - Received translation request - Text: 'at the portuguese english', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:41,748 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:42,335 [DEBUG] app1.py:1214 - Speech recognizing: at the portuguese is a refresher
2024-12-02 15:30:42,335 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a82880bc87704e9d8eac385b21ba7488, text="at the portuguese is a refresher", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:42,336 [DEBUG] app1.py:1104 - Sending transcription: at the portuguese is a refresher (is_final: False)
2024-12-02 15:30:42,341 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:42,342 [DEBUG] app1.py:1031 - Received translation request - Text: 'at the portuguese is a refresher', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:42,342 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:43,344 [DEBUG] app1.py:1214 - Speech recognizing: at the portuguese is a refresher english
2024-12-02 15:30:43,345 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1a4cffd8480c479888a9636f6e0ce528, text="at the portuguese is a refresher english", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:43,346 [DEBUG] app1.py:1104 - Sending transcription: at the portuguese is a refresher english (is_final: False)
2024-12-02 15:30:43,351 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:43,352 [DEBUG] app1.py:1031 - Received translation request - Text: 'at the portuguese is a refresher english', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:43,352 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:44,904 [INFO] app1.py:1205 - Speech recognized: At the Portuguese is a refresher English.
2024-12-02 15:30:44,909 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da5e6d9d5a6a473f9aa1b93bde787954, text="At the Portuguese is a refresher English.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:44,910 [DEBUG] app1.py:1104 - Sending transcription: At the Portuguese is a refresher English. (is_final: True)
2024-12-02 15:30:44,923 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:44,923 [DEBUG] app1.py:1031 - Received translation request - Text: 'At the Portuguese is a refresher English.', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: True
2024-12-02 15:30:44,925 [DEBUG] app1.py:1042 - Normalized text: 'at the portuguese is a refresher english.'
2024-12-02 15:30:44,925 [DEBUG] app1.py:1048 - Time since last translation for 29f82839-12f3-4d63-a0cb-4c0ab67e39de:es: 28.38836121559143s
2024-12-02 15:30:44,926 [DEBUG] app1.py:1056 - Checking cache with key: at the portuguese is a refresher english.:es
2024-12-02 15:30:44,926 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:30:44,927 [INFO] app1.py:933 - Starting translation request - Text: 'at the portuguese is a refresher english.', Target language: es
2024-12-02 15:30:44,927 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:30:44,927 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:30:44,928 [DEBUG] app1.py:964 - Request body: [{'text': 'at the portuguese is a refresher english.'}]
2024-12-02 15:30:45,487 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:30:45,488 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'En el portugus hay un repaso de ingls.', 'to': 'es'}]}]
2024-12-02 15:30:45,489 [DEBUG] app1.py:974 - Extracted translation: En el portugus hay un repaso de ingls.
2024-12-02 15:30:45,489 [INFO] app1.py:975 - Translation completed successfully - Original: 'at the portuguese is a refresher english.' -> Translation: 'En el portugus hay un repaso de ingls.' (es)
2024-12-02 15:30:45,490 [DEBUG] app1.py:918 - Sending translation to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: En el portugus hay un repaso de ingls.
2024-12-02 15:30:45,490 [DEBUG] app1.py:925 - Translation sent successfully to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de
2024-12-02 15:30:45,491 [DEBUG] app1.py:1144 - Sending message to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: {'type': 'final', 'translation': 'En el portugus hay un repaso de ingls.'}
2024-12-02 15:30:45,496 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'En el portugus hay un repaso de ingls.', Language: es
2024-12-02 15:30:45,497 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4659db9b-35e9-4451-9fd7-1c16a0153d85.wav
2024-12-02 15:30:45,499 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:30:45,528 [DEBUG] app1.py:1214 - Speech recognizing: refresh
2024-12-02 15:30:45,528 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0876256be9684caaa175731a5e7c5316, text="refresh", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:45,528 [DEBUG] app1.py:1104 - Sending transcription: refresh (is_final: False)
2024-12-02 15:30:45,533 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:45,534 [DEBUG] app1.py:1031 - Received translation request - Text: 'refresh', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:45,535 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:46,453 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:30:46,454 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4659db9b-35e9-4451-9fd7-1c16a0153d85.wav
2024-12-02 15:30:47,239 [INFO] app1.py:1205 - Speech recognized: Refresh.
2024-12-02 15:30:47,239 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e3c07c2bc4ab43cd88cd3233ac96e035, text="Refresh.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:47,240 [DEBUG] app1.py:1104 - Sending transcription: Refresh. (is_final: True)
2024-12-02 15:30:47,253 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:47,254 [DEBUG] app1.py:1031 - Received translation request - Text: 'Refresh.', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: True
2024-12-02 15:30:47,254 [DEBUG] app1.py:1042 - Normalized text: 'refresh.'
2024-12-02 15:30:47,254 [DEBUG] app1.py:1048 - Time since last translation for 29f82839-12f3-4d63-a0cb-4c0ab67e39de:es: 2.329216957092285s
2024-12-02 15:30:47,254 [DEBUG] app1.py:1056 - Checking cache with key: refresh.:es
2024-12-02 15:30:47,255 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:30:47,255 [INFO] app1.py:933 - Starting translation request - Text: 'refresh.', Target language: es
2024-12-02 15:30:47,257 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:30:47,263 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:30:47,264 [DEBUG] app1.py:964 - Request body: [{'text': 'refresh.'}]
2024-12-02 15:30:48,528 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de']
2024-12-02 15:30:48,644 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:30:48,646 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.96}, 'translations': [{'text': 'actualizar.', 'to': 'es'}]}]
2024-12-02 15:30:48,646 [DEBUG] app1.py:974 - Extracted translation: actualizar.
2024-12-02 15:30:48,647 [INFO] app1.py:975 - Translation completed successfully - Original: 'refresh.' -> Translation: 'actualizar.' (es)
2024-12-02 15:30:48,647 [DEBUG] app1.py:918 - Sending translation to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: actualizar.
2024-12-02 15:30:48,648 [DEBUG] app1.py:925 - Translation sent successfully to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de
2024-12-02 15:30:48,648 [DEBUG] app1.py:1144 - Sending message to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: {'type': 'final', 'translation': 'actualizar.'}
2024-12-02 15:30:49,026 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:30:49,026 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:30:50,974 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:30:50,976 [INFO] app1.py:1121 - New translation stream connection for client: f80826cc-6b48-4732-8c37-b486d19dc8d1, language: pt
2024-12-02 15:30:50,976 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:30:50,977 [INFO] app1.py:1131 - Creating new client connection: f80826cc-6b48-4732-8c37-b486d19dc8d1
2024-12-02 15:30:55,421 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:30:55,422 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c869a027cf9041d7893e0ed2d9d3d28d, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:55,423 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:30:55,428 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:55,429 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: pt, Client: f80826cc-6b48-4732-8c37-b486d19dc8d1, Final: False
2024-12-02 15:30:55,430 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:55,624 [DEBUG] app1.py:1214 - Speech recognizing: hello this is
2024-12-02 15:30:55,626 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f7846d8a37d24f94b25f85e0b3a432da, text="hello this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:55,627 [DEBUG] app1.py:1104 - Sending transcription: hello this is (is_final: False)
2024-12-02 15:30:56,030 [DEBUG] app1.py:1214 - Speech recognizing: hello this is aman
2024-12-02 15:30:56,032 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a84f2192f4bf4535877b33131b9e4af4, text="hello this is aman", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:56,033 [DEBUG] app1.py:1104 - Sending transcription: hello this is aman (is_final: False)
2024-12-02 15:30:56,037 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:56,037 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is aman', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:56,038 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:56,329 [DEBUG] app1.py:1214 - Speech recognizing: hello this is aman can you
2024-12-02 15:30:56,330 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b62af4db6b6b4f71b8034aac78b5b731, text="hello this is aman can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:56,331 [DEBUG] app1.py:1104 - Sending transcription: hello this is aman can you (is_final: False)
2024-12-02 15:30:56,336 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:56,336 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is aman can you', Target: pt, Client: f80826cc-6b48-4732-8c37-b486d19dc8d1, Final: False
2024-12-02 15:30:56,338 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:56,728 [DEBUG] app1.py:1214 - Speech recognizing: hello this is aman can you hear me
2024-12-02 15:30:56,728 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2b1ccdbaab884e9ca4860a25d7d6ea38, text="hello this is aman can you hear me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:56,729 [DEBUG] app1.py:1104 - Sending transcription: hello this is aman can you hear me (is_final: False)
2024-12-02 15:30:56,734 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:56,734 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is aman can you hear me', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:30:56,735 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:30:57,564 [INFO] app1.py:1205 - Speech recognized: Hello, this is Aman. Can you hear me?
2024-12-02 15:30:57,564 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8a934b061ee44640a6d3a572adf06e3a, text="Hello, this is Aman. Can you hear me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:30:57,565 [DEBUG] app1.py:1104 - Sending transcription: Hello, this is Aman. Can you hear me? (is_final: True)
2024-12-02 15:30:59,936 [DEBUG] app1.py:1214 - Speech recognizing: hello this is
2024-12-02 15:30:59,937 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ed73d3d53d0e444f8b0017a3fa69eb69, text="hello this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:30:59,939 [DEBUG] app1.py:1104 - Sending transcription: hello this is (is_final: False)
2024-12-02 15:30:59,949 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:30:59,953 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is', Target: pt, Client: f80826cc-6b48-4732-8c37-b486d19dc8d1, Final: False
2024-12-02 15:30:59,954 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:31:00,741 [DEBUG] app1.py:1214 - Speech recognizing: hello this is allah
2024-12-02 15:31:00,741 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=060e0d9491d442b7ac79720aca68d7ea, text="hello this is allah", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:00,741 [DEBUG] app1.py:1104 - Sending transcription: hello this is allah (is_final: False)
2024-12-02 15:31:00,747 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:00,748 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello this is allah', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:31:00,748 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:31:01,381 [DEBUG] app1.py:1214 - Speech recognizing: hello this is allah can you hear
2024-12-02 15:31:01,382 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f59f48fd4ba94662bcae2908dc3b6d8c, text="hello this is allah can you hear", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:01,384 [DEBUG] app1.py:1104 - Sending transcription: hello this is allah can you hear (is_final: False)
2024-12-02 15:31:01,395 [INFO] app1.py:1205 - Speech recognized: Hello, this is Allah. Can you hear me?
2024-12-02 15:31:01,396 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=316a0e4c04c94365985c53f1db7067aa, text="Hello, this is Allah. Can you hear me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:31:01,397 [DEBUG] app1.py:1104 - Sending transcription: Hello, this is Allah. Can you hear me? (is_final: True)
2024-12-02 15:31:01,402 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:01,403 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello, this is Allah. Can you hear me?', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: True
2024-12-02 15:31:01,403 [DEBUG] app1.py:1042 - Normalized text: 'hello, this is allah. can you hear me?'
2024-12-02 15:31:01,404 [DEBUG] app1.py:1048 - Time since last translation for 29f82839-12f3-4d63-a0cb-4c0ab67e39de:es: 14.150136947631836s
2024-12-02 15:31:01,404 [DEBUG] app1.py:1056 - Checking cache with key: hello, this is allah. can you hear me?:es
2024-12-02 15:31:01,404 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:31:01,406 [INFO] app1.py:933 - Starting translation request - Text: 'hello, this is allah. can you hear me?', Target language: es
2024-12-02 15:31:01,406 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:31:01,407 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:31:01,408 [DEBUG] app1.py:964 - Request body: [{'text': 'hello, this is allah. can you hear me?'}]
2024-12-02 15:31:01,954 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:31:01,955 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola, soy Al. Puedes orme?', 'to': 'es'}]}]
2024-12-02 15:31:01,956 [DEBUG] app1.py:974 - Extracted translation: Hola, soy Al. Puedes orme?
2024-12-02 15:31:01,956 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello, this is allah. can you hear me?' -> Translation: 'Hola, soy Al. Puedes orme?' (es)
2024-12-02 15:31:01,957 [DEBUG] app1.py:918 - Sending translation to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: Hola, soy Al. Puedes orme?
2024-12-02 15:31:01,958 [DEBUG] app1.py:925 - Translation sent successfully to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de
2024-12-02 15:31:01,958 [DEBUG] app1.py:1144 - Sending message to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: {'type': 'final', 'translation': 'Hola, soy Al. Puedes orme?'}
2024-12-02 15:31:01,964 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola, soy Al. Puedes orme?', Language: es
2024-12-02 15:31:01,969 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3533d5a5-14ff-44e3-8f5c-b7848fd99ee6.wav
2024-12-02 15:31:01,971 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:31:03,170 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:31:03,172 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3533d5a5-14ff-44e3-8f5c-b7848fd99ee6.wav
2024-12-02 15:31:04,229 [DEBUG] app1.py:1214 - Speech recognizing: in his field
2024-12-02 15:31:04,229 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c837e7083d6448dfa362d6ce95abd845, text="in his field", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:04,230 [DEBUG] app1.py:1104 - Sending transcription: in his field (is_final: False)
2024-12-02 15:31:05,425 [DEBUG] app1.py:1214 - Speech recognizing: in his field hola
2024-12-02 15:31:05,426 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=be89187b0da34cfab68f98d75bad3ab3, text="in his field hola", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:05,427 [DEBUG] app1.py:1104 - Sending transcription: in his field hola (is_final: False)
2024-12-02 15:31:05,431 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:05,431 [DEBUG] app1.py:1031 - Received translation request - Text: 'in his field hola', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:31:05,433 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:31:06,953 [INFO] app1.py:1205 - Speech recognized: In his field, Hola.
2024-12-02 15:31:06,953 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d284b70dac66425b941c3c0d6811a0b1, text="In his field, Hola.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:31:06,954 [DEBUG] app1.py:1104 - Sending transcription: In his field, Hola. (is_final: True)
2024-12-02 15:31:06,959 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:06,959 [DEBUG] app1.py:1031 - Received translation request - Text: 'In his field, Hola.', Target: pt, Client: f80826cc-6b48-4732-8c37-b486d19dc8d1, Final: True
2024-12-02 15:31:06,960 [DEBUG] app1.py:1042 - Normalized text: 'in his field, hola.'
2024-12-02 15:31:06,961 [DEBUG] app1.py:1056 - Checking cache with key: in his field, hola.:pt
2024-12-02 15:31:06,961 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:31:06,962 [INFO] app1.py:933 - Starting translation request - Text: 'in his field, hola.', Target language: pt
2024-12-02 15:31:06,962 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:31:06,963 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:31:06,963 [DEBUG] app1.py:964 - Request body: [{'text': 'in his field, hola.'}]
2024-12-02 15:31:08,186 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:31:08,188 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'em seu campo, hola.', 'to': 'pt'}]}]
2024-12-02 15:31:08,189 [DEBUG] app1.py:974 - Extracted translation: em seu campo, hola.
2024-12-02 15:31:08,190 [INFO] app1.py:975 - Translation completed successfully - Original: 'in his field, hola.' -> Translation: 'em seu campo, hola.' (pt)
2024-12-02 15:31:08,194 [DEBUG] app1.py:918 - Sending translation to client f80826cc-6b48-4732-8c37-b486d19dc8d1: em seu campo, hola.
2024-12-02 15:31:08,195 [DEBUG] app1.py:925 - Translation sent successfully to client f80826cc-6b48-4732-8c37-b486d19dc8d1
2024-12-02 15:31:08,195 [DEBUG] app1.py:1144 - Sending message to client f80826cc-6b48-4732-8c37-b486d19dc8d1: {'type': 'final', 'translation': 'em seu campo, hola.'}
2024-12-02 15:31:08,204 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'em seu campo, hola.', Language: pt
2024-12-02 15:31:08,207 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_935c8ac2-9851-45b2-af12-e405c7dc783e.wav
2024-12-02 15:31:08,209 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:31:09,129 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:31:09,130 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_935c8ac2-9851-45b2-af12-e405c7dc783e.wav
2024-12-02 15:31:13,248 [DEBUG] app1.py:1214 - Speech recognizing: achini
2024-12-02 15:31:13,249 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6d8163b4dba247c698fe9921d1d20c5c, text="achini", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:13,251 [DEBUG] app1.py:1104 - Sending transcription: achini (is_final: False)
2024-12-02 15:31:13,436 [DEBUG] app1.py:1214 - Speech recognizing: achini bari bar
2024-12-02 15:31:13,437 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4f1ab5d9643c4f4cb8089dd5adf4a582, text="achini bari bar", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:13,438 [DEBUG] app1.py:1104 - Sending transcription: achini bari bar (is_final: False)
2024-12-02 15:31:13,447 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:13,448 [DEBUG] app1.py:1031 - Received translation request - Text: 'achini bari bar', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: False
2024-12-02 15:31:13,449 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:31:13,844 [DEBUG] app1.py:1214 - Speech recognizing: achini bari bariat
2024-12-02 15:31:13,846 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=94045c7fd267407aa71f3b4e6942fc32, text="achini bari bariat", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:13,848 [DEBUG] app1.py:1104 - Sending transcription: achini bari bariat (is_final: False)
2024-12-02 15:31:13,853 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:13,854 [DEBUG] app1.py:1031 - Received translation request - Text: 'achini bari bariat', Target: pt, Client: f80826cc-6b48-4732-8c37-b486d19dc8d1, Final: False
2024-12-02 15:31:13,855 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:31:14,141 [DEBUG] app1.py:1214 - Speech recognizing: achini bari bariatkan
2024-12-02 15:31:14,142 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bbb41a0d37b2455aa2cf6e7ea1197069, text="achini bari bariatkan", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:14,144 [DEBUG] app1.py:1104 - Sending transcription: achini bari bariatkan (is_final: False)
2024-12-02 15:31:14,546 [DEBUG] app1.py:1214 - Speech recognizing: achini bari bariatkan tera
2024-12-02 15:31:14,546 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=103d034a25eb4a4d92c7a17b6bca8ed2, text="achini bari bariatkan tera", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:31:14,548 [DEBUG] app1.py:1104 - Sending transcription: achini bari bariatkan tera (is_final: False)
2024-12-02 15:31:14,554 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:14,554 [DEBUG] app1.py:1031 - Received translation request - Text: 'achini bari bariatkan tera', Target: pt, Client: f80826cc-6b48-4732-8c37-b486d19dc8d1, Final: False
2024-12-02 15:31:14,555 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:31:16,361 [INFO] app1.py:1205 - Speech recognized: Achini Bari bariatkan Tera.
2024-12-02 15:31:16,362 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5f8a2d92fbe64ec590a9d598b806c64a, text="Achini Bari bariatkan Tera.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:31:16,362 [DEBUG] app1.py:1104 - Sending transcription: Achini Bari bariatkan Tera. (is_final: True)
2024-12-02 15:31:16,367 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:31:16,368 [DEBUG] app1.py:1031 - Received translation request - Text: 'Achini Bari bariatkan Tera.', Target: es, Client: 29f82839-12f3-4d63-a0cb-4c0ab67e39de, Final: True
2024-12-02 15:31:16,368 [DEBUG] app1.py:1042 - Normalized text: 'achini bari bariatkan tera.'
2024-12-02 15:31:16,369 [DEBUG] app1.py:1048 - Time since last translation for 29f82839-12f3-4d63-a0cb-4c0ab67e39de:es: 14.963624715805054s
2024-12-02 15:31:16,369 [DEBUG] app1.py:1056 - Checking cache with key: achini bari bariatkan tera.:es
2024-12-02 15:31:16,369 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:31:16,370 [INFO] app1.py:933 - Starting translation request - Text: 'achini bari bariatkan tera.', Target language: es
2024-12-02 15:31:16,370 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:31:16,370 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:31:16,371 [DEBUG] app1.py:964 - Request body: [{'text': 'achini bari bariatkan tera.'}]
2024-12-02 15:31:17,642 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:31:17,643 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'id', 'score': 0.95}, 'translations': [{'text': 'achini bari bariat tera.', 'to': 'es'}]}]
2024-12-02 15:31:17,644 [DEBUG] app1.py:974 - Extracted translation: achini bari bariat tera.
2024-12-02 15:31:17,644 [INFO] app1.py:975 - Translation completed successfully - Original: 'achini bari bariatkan tera.' -> Translation: 'achini bari bariat tera.' (es)
2024-12-02 15:31:17,645 [DEBUG] app1.py:918 - Sending translation to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: achini bari bariat tera.
2024-12-02 15:31:17,646 [DEBUG] app1.py:925 - Translation sent successfully to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de
2024-12-02 15:31:17,646 [DEBUG] app1.py:1144 - Sending message to client 29f82839-12f3-4d63-a0cb-4c0ab67e39de: {'type': 'final', 'translation': 'achini bari bariat tera.'}
2024-12-02 15:31:17,662 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'achini bari bariat tera.', Language: es
2024-12-02 15:31:17,671 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_8c7be264-65f6-4197-81c4-0f9f0e839b54.wav
2024-12-02 15:31:17,676 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 15:31:17,690 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:31:17,900 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:31:18,509 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 15:31:18,509 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_8c7be264-65f6-4197-81c4-0f9f0e839b54.wav
2024-12-02 15:31:18,530 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1']
2024-12-02 15:31:48,532 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1']
2024-12-02 15:31:58,688 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:31:58,843 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:31:58,927 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:32:00,301 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:32:00,302 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ea0a8a26b7a7427b80b97f434739c917, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:02,007 [DEBUG] app1.py:1214 - Speech recognizing: hi hi
2024-12-02 15:32:02,008 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=65d22f8845c8422db16a840b845df981, text="hi hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:02,804 [DEBUG] app1.py:1214 - Speech recognizing: hi hi what are
2024-12-02 15:32:02,805 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1ae1def448bf4814bb44d500851a5a4d, text="hi hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:03,213 [DEBUG] app1.py:1214 - Speech recognizing: hi hi what are you
2024-12-02 15:32:03,214 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e8bb72a8235c4b47895f68534394d48b, text="hi hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:03,507 [DEBUG] app1.py:1214 - Speech recognizing: hi hi what are you doing
2024-12-02 15:32:03,508 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e3586a72c429432aa2db50308114fccc, text="hi hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:03,697 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:32:03,698 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:32:03,698 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:32:03,699 [DEBUG] app1.py:1104 - Sending transcription: hi hi (is_final: False)
2024-12-02 15:32:03,700 [DEBUG] app1.py:1104 - Sending transcription: hi hi what are (is_final: False)
2024-12-02 15:32:03,701 [DEBUG] app1.py:1104 - Sending transcription: hi hi what are you (is_final: False)
2024-12-02 15:32:03,701 [DEBUG] app1.py:1104 - Sending transcription: hi hi what are you doing (is_final: False)
2024-12-02 15:32:04,443 [INFO] app1.py:1205 - Speech recognized: Hi. Hi. What are you doing?
2024-12-02 15:32:04,443 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0e0cd54e2a6846f6b9dd1238c71dfb08, text="Hi. Hi. What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:04,444 [DEBUG] app1.py:1104 - Sending transcription: Hi. Hi. What are you doing? (is_final: True)
2024-12-02 15:32:08,404 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 15:32:08,404 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=316688613faa4182a9ba3ded2433ebd7, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:08,406 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 15:32:08,949 [DEBUG] app1.py:1214 - Speech recognizing: what are you
2024-12-02 15:32:08,950 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9f871c8998c6446a808611dd90960a46, text="what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:08,951 [DEBUG] app1.py:1104 - Sending transcription: what are you (is_final: False)
2024-12-02 15:32:08,955 [INFO] app1.py:1205 - Speech recognized: What are you?
2024-12-02 15:32:08,956 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4c9027c5bc7a41debc04d173cf07b97f, text="What are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:08,957 [DEBUG] app1.py:1104 - Sending transcription: What are you? (is_final: True)
2024-12-02 15:32:10,235 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:32:10,236 [INFO] app1.py:1121 - New translation stream connection for client: c20100b0-4860-4dd6-91cf-b286e69cb563, language: pt
2024-12-02 15:32:10,236 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:32:10,237 [INFO] app1.py:1131 - Creating new client connection: c20100b0-4860-4dd6-91cf-b286e69cb563
2024-12-02 15:32:10,282 [DEBUG] app1.py:1214 - Speech recognizing: what are you
2024-12-02 15:32:10,283 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=78086b6121f747309d030836fd76be91, text="what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:10,284 [DEBUG] app1.py:1104 - Sending transcription: what are you (is_final: False)
2024-12-02 15:32:10,811 [INFO] app1.py:1205 - Speech recognized: What are you?
2024-12-02 15:32:10,812 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=392014af1b9243c29a76f629c2c73208, text="What are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:10,812 [DEBUG] app1.py:1104 - Sending transcription: What are you? (is_final: True)
2024-12-02 15:32:10,820 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:10,821 [DEBUG] app1.py:1031 - Received translation request - Text: 'What are you?', Target: pt, Client: c20100b0-4860-4dd6-91cf-b286e69cb563, Final: True
2024-12-02 15:32:10,821 [DEBUG] app1.py:1042 - Normalized text: 'what are you?'
2024-12-02 15:32:10,822 [DEBUG] app1.py:1056 - Checking cache with key: what are you?:pt
2024-12-02 15:32:10,822 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:32:10,822 [INFO] app1.py:933 - Starting translation request - Text: 'what are you?', Target language: pt
2024-12-02 15:32:10,823 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:32:10,823 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 15:32:10,824 [DEBUG] app1.py:964 - Request body: [{'text': 'what are you?'}]
2024-12-02 15:32:12,020 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:32:12,021 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'O que voc est?', 'to': 'pt'}]}]
2024-12-02 15:32:12,022 [DEBUG] app1.py:974 - Extracted translation: O que voc est?
2024-12-02 15:32:12,023 [INFO] app1.py:975 - Translation completed successfully - Original: 'what are you?' -> Translation: 'O que voc est?' (pt)
2024-12-02 15:32:12,024 [DEBUG] app1.py:918 - Sending translation to client c20100b0-4860-4dd6-91cf-b286e69cb563: O que voc est?
2024-12-02 15:32:12,024 [DEBUG] app1.py:925 - Translation sent successfully to client c20100b0-4860-4dd6-91cf-b286e69cb563
2024-12-02 15:32:12,025 [DEBUG] app1.py:1144 - Sending message to client c20100b0-4860-4dd6-91cf-b286e69cb563: {'type': 'final', 'translation': 'O que voc est?'}
2024-12-02 15:32:15,290 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:32:15,291 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c75d6b81934c4ed5a48bd21e4d997037, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:15,292 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:32:15,648 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:32:15,649 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fbfe2fa589af41c289f3aac01c5d66e5, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:15,649 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:32:15,653 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:15,654 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: pt, Client: c20100b0-4860-4dd6-91cf-b286e69cb563, Final: True
2024-12-02 15:32:15,654 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 15:32:15,655 [DEBUG] app1.py:1048 - Time since last translation for c20100b0-4860-4dd6-91cf-b286e69cb563:pt: 4.832786321640015s
2024-12-02 15:32:15,656 [DEBUG] app1.py:1056 - Checking cache with key: hi.:pt
2024-12-02 15:32:15,656 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:32:15,657 [DEBUG] app1.py:918 - Sending translation to client c20100b0-4860-4dd6-91cf-b286e69cb563: Oi.
2024-12-02 15:32:15,657 [DEBUG] app1.py:925 - Translation sent successfully to client c20100b0-4860-4dd6-91cf-b286e69cb563
2024-12-02 15:32:15,657 [DEBUG] app1.py:1144 - Sending message to client c20100b0-4860-4dd6-91cf-b286e69cb563: {'type': 'final', 'translation': 'Oi.'}
2024-12-02 15:32:16,705 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:32:16,706 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=18bd7dc74e594cbdb53c1c6273a1d356, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:16,707 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:32:18,109 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 15:32:18,109 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6ceb6091cc794ad484965189fd1ae608, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:18,112 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 15:32:18,118 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:18,119 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: pt, Client: c20100b0-4860-4dd6-91cf-b286e69cb563, Final: True
2024-12-02 15:32:18,119 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 15:32:18,120 [DEBUG] app1.py:1048 - Time since last translation for c20100b0-4860-4dd6-91cf-b286e69cb563:pt: 2.4653310775756836s
2024-12-02 15:32:18,120 [DEBUG] app1.py:1056 - Checking cache with key: hello.:pt
2024-12-02 15:32:18,121 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:32:18,121 [DEBUG] app1.py:918 - Sending translation to client c20100b0-4860-4dd6-91cf-b286e69cb563: Ol.
2024-12-02 15:32:18,122 [DEBUG] app1.py:925 - Translation sent successfully to client c20100b0-4860-4dd6-91cf-b286e69cb563
2024-12-02 15:32:18,122 [DEBUG] app1.py:1144 - Sending message to client c20100b0-4860-4dd6-91cf-b286e69cb563: {'type': 'final', 'translation': 'Ol.'}
2024-12-02 15:32:18,533 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563']
2024-12-02 15:32:20,787 [DEBUG] app1.py:1214 - Speech recognizing: any more
2024-12-02 15:32:20,788 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e9b51536742e4fc68b4c1ca6beb3402c, text="any more", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:20,789 [DEBUG] app1.py:1104 - Sending transcription: any more (is_final: False)
2024-12-02 15:32:20,793 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:20,794 [DEBUG] app1.py:1031 - Received translation request - Text: 'any more', Target: pt, Client: c20100b0-4860-4dd6-91cf-b286e69cb563, Final: False
2024-12-02 15:32:20,794 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:32:21,640 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:32:21,641 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=db440316f8ea48218b59a4f63d911f20, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:21,642 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:32:26,502 [DEBUG] app1.py:1214 - Speech recognizing: hi hi
2024-12-02 15:32:26,504 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d9b40057fe554adfaf4d720181b241fa, text="hi hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:26,505 [DEBUG] app1.py:1104 - Sending transcription: hi hi (is_final: False)
2024-12-02 15:32:27,106 [INFO] app1.py:1205 - Speech recognized: Hi. Hi.
2024-12-02 15:32:27,107 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=31d6626a9da4400f899c5d11b02d6e7e, text="Hi. Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:27,108 [DEBUG] app1.py:1104 - Sending transcription: Hi. Hi. (is_final: True)
2024-12-02 15:32:30,030 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:32:30,030 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:32:33,699 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:32:33,700 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:32:33,700 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:32:33,701 [INFO] app1.py:1131 - Creating new client connection: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:32:35,901 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:32:35,902 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=18b5931577984f2ca1e7aba3e54d8304, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:35,903 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:32:35,909 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:35,910 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:32:35,910 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:32:36,310 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:32:36,311 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6d6ca359485c47278b76fad06848ff97, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:36,313 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:32:36,319 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:36,320 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you doing', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:32:36,320 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:32:36,945 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:32:36,945 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d4e591d3026944cb8c6f962063e721dc, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:36,947 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:32:36,952 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:36,952 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, what are you doing?', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:32:36,953 [DEBUG] app1.py:1042 - Normalized text: 'hi, what are you doing?'
2024-12-02 15:32:36,953 [DEBUG] app1.py:1056 - Checking cache with key: hi, what are you doing?:es
2024-12-02 15:32:36,954 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:32:36,954 [INFO] app1.py:933 - Starting translation request - Text: 'hi, what are you doing?', Target language: es
2024-12-02 15:32:36,955 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:32:36,955 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:32:36,955 [DEBUG] app1.py:964 - Request body: [{'text': 'hi, what are you doing?'}]
2024-12-02 15:32:37,213 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:32:37,214 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'hola, qu est haciendo?', 'to': 'es'}]}]
2024-12-02 15:32:37,215 [DEBUG] app1.py:974 - Extracted translation: hola, qu est haciendo?
2024-12-02 15:32:37,215 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi, what are you doing?' -> Translation: 'hola, qu est haciendo?' (es)
2024-12-02 15:32:37,217 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: hola, qu est haciendo?
2024-12-02 15:32:37,217 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:32:37,217 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'hola, qu est haciendo?'}
2024-12-02 15:32:39,008 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:32:39,008 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ae2540d1e68c473d93e7eece138859ed, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:39,010 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:32:39,013 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:39,014 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:32:39,014 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:32:40,813 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 15:32:40,814 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a42dd5d960834d889f5ccd663a459729, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:40,816 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 15:32:40,821 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:40,822 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:32:40,822 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 15:32:40,824 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 3.870496988296509s
2024-12-02 15:32:40,825 [DEBUG] app1.py:1056 - Checking cache with key: hello.:es
2024-12-02 15:32:40,825 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:32:40,825 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Hola.
2024-12-02 15:32:40,826 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:32:40,826 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 15:32:47,484 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:32:47,484 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4aa45c3878f7428898627d8da4e11c49, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:47,486 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:32:47,492 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:47,492 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:32:47,493 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:32:47,886 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:32:47,886 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e09ac92f88f44ce5b9d76ed21ca396c5, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:47,887 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:32:47,890 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:47,891 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:32:47,892 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:32:48,182 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:32:48,184 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=11c4a4aae3f44c079362fd6d69d8e46a, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:32:48,186 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:32:48,196 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:48,200 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you doing', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:32:48,214 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:32:48,536 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:32:49,406 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:32:49,407 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a2eb8aeac0d54adb8fe6a14c02504733, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:32:49,409 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:32:49,413 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:32:49,413 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, what are you doing?', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:32:49,414 [DEBUG] app1.py:1042 - Normalized text: 'hi, what are you doing?'
2024-12-02 15:32:49,414 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 8.590443134307861s
2024-12-02 15:32:49,415 [DEBUG] app1.py:1056 - Checking cache with key: hi, what are you doing?:es
2024-12-02 15:32:49,415 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:32:49,416 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: hola, qu est haciendo?
2024-12-02 15:32:49,416 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:32:49,416 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'hola, qu est haciendo?'}
2024-12-02 15:33:01,697 [DEBUG] app1.py:1214 - Speech recognizing: users
2024-12-02 15:33:01,698 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3adc35e4d7fb498eb8c39500b5a72fc8, text="users", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:01,700 [DEBUG] app1.py:1104 - Sending transcription: users (is_final: False)
2024-12-02 15:33:01,707 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:01,707 [DEBUG] app1.py:1031 - Received translation request - Text: 'users', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:01,708 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:03,604 [INFO] app1.py:1205 - Speech recognized: Users.
2024-12-02 15:33:03,605 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=309e27c82a6042deae70f356ee2a9973, text="Users.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:33:03,607 [DEBUG] app1.py:1104 - Sending transcription: Users. (is_final: True)
2024-12-02 15:33:03,611 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:03,611 [DEBUG] app1.py:1031 - Received translation request - Text: 'Users.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:33:03,611 [DEBUG] app1.py:1042 - Normalized text: 'users.'
2024-12-02 15:33:03,612 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 14.19832968711853s
2024-12-02 15:33:03,612 [DEBUG] app1.py:1056 - Checking cache with key: users.:es
2024-12-02 15:33:03,614 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:33:03,614 [INFO] app1.py:933 - Starting translation request - Text: 'users.', Target language: es
2024-12-02 15:33:03,614 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:33:03,615 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:33:03,616 [DEBUG] app1.py:964 - Request body: [{'text': 'users.'}]
2024-12-02 15:33:04,116 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:33:04,117 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Usuarios.', 'to': 'es'}]}]
2024-12-02 15:33:04,117 [DEBUG] app1.py:974 - Extracted translation: Usuarios.
2024-12-02 15:33:04,117 [INFO] app1.py:975 - Translation completed successfully - Original: 'users.' -> Translation: 'Usuarios.' (es)
2024-12-02 15:33:04,119 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Usuarios.
2024-12-02 15:33:04,119 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:33:04,119 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Usuarios.'}
2024-12-02 15:33:12,593 [DEBUG] app1.py:1214 - Speech recognizing: literally
2024-12-02 15:33:12,594 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9612588b23fb45ce80df634a22a01a7a, text="literally", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:12,596 [DEBUG] app1.py:1104 - Sending transcription: literally (is_final: False)
2024-12-02 15:33:12,604 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:12,605 [DEBUG] app1.py:1031 - Received translation request - Text: 'literally', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:12,606 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:12,890 [DEBUG] app1.py:1214 - Speech recognizing: literally junks
2024-12-02 15:33:12,906 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=00af667ddfd94ba9a1a22d1da1d764f0, text="literally junks", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:12,908 [DEBUG] app1.py:1104 - Sending transcription: literally junks (is_final: False)
2024-12-02 15:33:12,913 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:12,914 [DEBUG] app1.py:1031 - Received translation request - Text: 'literally junks', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:12,915 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:13,495 [DEBUG] app1.py:1214 - Speech recognizing: literally junk's valadina
2024-12-02 15:33:13,496 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cec80410008046bab0043ba87b99731d, text="literally junk's valadina", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:13,498 [DEBUG] app1.py:1104 - Sending transcription: literally junk's valadina (is_final: False)
2024-12-02 15:33:13,506 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:13,507 [DEBUG] app1.py:1031 - Received translation request - Text: 'literally junk's valadina', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:13,508 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:13,898 [DEBUG] app1.py:1214 - Speech recognizing: literally junks vanadina duplic
2024-12-02 15:33:13,898 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7f92b43d6b6340a4bcfd27a3776478ca, text="literally junks vanadina duplic", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:13,899 [DEBUG] app1.py:1104 - Sending transcription: literally junks vanadina duplic (is_final: False)
2024-12-02 15:33:13,904 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:13,904 [DEBUG] app1.py:1031 - Received translation request - Text: 'literally junks vanadina duplic', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:13,906 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:14,208 [DEBUG] app1.py:1214 - Speech recognizing: literally junks vanadina duplicated
2024-12-02 15:33:14,209 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d87ea92284d64039a220bd867879c5da, text="literally junks vanadina duplicated", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:14,210 [DEBUG] app1.py:1104 - Sending transcription: literally junks vanadina duplicated (is_final: False)
2024-12-02 15:33:14,215 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:14,216 [DEBUG] app1.py:1031 - Received translation request - Text: 'literally junks vanadina duplicated', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:14,216 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:16,093 [DEBUG] app1.py:1214 - Speech recognizing: literally junks vanadina duplicated boy you check when i
2024-12-02 15:33:16,094 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4508bfab4acb4fdb80f09f8de3f16d5c, text="literally junks vanadina duplicated boy you check when i", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:16,095 [DEBUG] app1.py:1104 - Sending transcription: literally junks vanadina duplicated boy you check when i (is_final: False)
2024-12-02 15:33:16,100 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:16,100 [DEBUG] app1.py:1031 - Received translation request - Text: 'literally junks vanadina duplicated boy you check when i', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:16,101 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:17,916 [INFO] app1.py:1205 - Speech recognized: Literally junks duplicated.
2024-12-02 15:33:17,917 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c0ba97225a3e4544b1721de159466f55, text="Literally junks duplicated.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:33:17,919 [DEBUG] app1.py:1104 - Sending transcription: Literally junks duplicated. (is_final: True)
2024-12-02 15:33:17,925 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:17,926 [DEBUG] app1.py:1031 - Received translation request - Text: 'Literally junks duplicated.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:33:17,927 [DEBUG] app1.py:1042 - Normalized text: 'literally junks duplicated.'
2024-12-02 15:33:17,927 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 14.314579248428345s
2024-12-02 15:33:17,927 [DEBUG] app1.py:1056 - Checking cache with key: literally junks duplicated.:es
2024-12-02 15:33:17,927 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:33:17,928 [INFO] app1.py:933 - Starting translation request - Text: 'literally junks duplicated.', Target language: es
2024-12-02 15:33:17,928 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:33:17,929 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:33:17,929 [DEBUG] app1.py:964 - Request body: [{'text': 'literally junks duplicated.'}]
2024-12-02 15:33:18,229 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:33:18,229 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Literalmente chatarra duplicada.', 'to': 'es'}]}]
2024-12-02 15:33:18,230 [DEBUG] app1.py:974 - Extracted translation: Literalmente chatarra duplicada.
2024-12-02 15:33:18,232 [INFO] app1.py:975 - Translation completed successfully - Original: 'literally junks duplicated.' -> Translation: 'Literalmente chatarra duplicada.' (es)
2024-12-02 15:33:18,233 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Literalmente chatarra duplicada.
2024-12-02 15:33:18,235 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:33:18,235 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Literalmente chatarra duplicada.'}
2024-12-02 15:33:18,540 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:33:19,698 [DEBUG] app1.py:1214 - Speech recognizing: buy
2024-12-02 15:33:19,715 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bd888b0d497049ea9f5fa6d6387d07d8, text="buy", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:19,715 [DEBUG] app1.py:1104 - Sending transcription: buy (is_final: False)
2024-12-02 15:33:19,720 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:19,721 [DEBUG] app1.py:1031 - Received translation request - Text: 'buy', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:19,721 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:19,790 [DEBUG] app1.py:1214 - Speech recognizing: buy this
2024-12-02 15:33:19,792 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e7e5e8af8df34f54b3d20249ce751bf9, text="buy this", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:19,794 [DEBUG] app1.py:1104 - Sending transcription: buy this (is_final: False)
2024-12-02 15:33:19,797 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:19,797 [DEBUG] app1.py:1031 - Received translation request - Text: 'buy this', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:19,798 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:20,088 [INFO] app1.py:1205 - Speech recognized: Buy this.
2024-12-02 15:33:20,088 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=611f246bb0744bf7be9f9947ecce1f08, text="Buy this.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:33:20,089 [DEBUG] app1.py:1104 - Sending transcription: Buy this. (is_final: True)
2024-12-02 15:33:20,095 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:20,096 [DEBUG] app1.py:1031 - Received translation request - Text: 'Buy this.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:33:20,097 [DEBUG] app1.py:1042 - Normalized text: 'buy this.'
2024-12-02 15:33:20,098 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 2.1705665588378906s
2024-12-02 15:33:20,098 [DEBUG] app1.py:1056 - Checking cache with key: buy this.:es
2024-12-02 15:33:20,099 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:33:20,099 [INFO] app1.py:933 - Starting translation request - Text: 'buy this.', Target language: es
2024-12-02 15:33:20,099 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:33:20,100 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:33:20,100 [DEBUG] app1.py:964 - Request body: [{'text': 'buy this.'}]
2024-12-02 15:33:20,393 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:33:20,394 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Compra esto.', 'to': 'es'}]}]
2024-12-02 15:33:20,395 [DEBUG] app1.py:974 - Extracted translation: Compra esto.
2024-12-02 15:33:20,396 [INFO] app1.py:975 - Translation completed successfully - Original: 'buy this.' -> Translation: 'Compra esto.' (es)
2024-12-02 15:33:20,398 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Compra esto.
2024-12-02 15:33:20,399 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:33:20,399 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Compra esto.'}
2024-12-02 15:33:40,018 [DEBUG] app1.py:1214 - Speech recognizing: etho era decoder
2024-12-02 15:33:40,019 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=21425a9cd6d6437caaff86bef110220b, text="etho era decoder", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:33:40,020 [DEBUG] app1.py:1104 - Sending transcription: etho era decoder (is_final: False)
2024-12-02 15:33:40,026 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:33:40,026 [DEBUG] app1.py:1031 - Received translation request - Text: 'etho era decoder', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:33:40,027 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:33:40,294 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:33:40,295 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5632f64fe4fa47b8bacd8ecd1185c9b6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:33:40,296 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:33:48,542 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:33:50,683 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:33:53,662 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:33:54,675 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:33:55,511 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:33:55,512 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c7e8ea4392c34b43867df340d19ab9f5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:33:55,514 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:33:57,657 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:33:58,663 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:01,653 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:02,670 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:05,660 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:06,671 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:09,649 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:10,653 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:10,828 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:34:10,829 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d4845ef45ec24bcb83166efc217dd56d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:34:10,829 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:34:13,655 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:14,661 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:17,659 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:18,543 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:34:18,662 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:21,659 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:22,666 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:22,714 [INFO] app1.py:1205 - Speech recognized: Hey, Cortana, Play.
2024-12-02 15:34:22,714 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7695f256cc7a441598034635838c4843, text="Hey, Cortana, Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:34:22,715 [DEBUG] app1.py:1104 - Sending transcription: Hey, Cortana, Play. (is_final: True)
2024-12-02 15:34:22,727 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:34:22,729 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hey, Cortana, Play.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:34:22,731 [DEBUG] app1.py:1042 - Normalized text: 'hey, cortana, play.'
2024-12-02 15:34:22,732 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 62.63410234451294s
2024-12-02 15:34:22,732 [DEBUG] app1.py:1056 - Checking cache with key: hey, cortana, play.:es
2024-12-02 15:34:22,733 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:34:22,733 [INFO] app1.py:933 - Starting translation request - Text: 'hey, cortana, play.', Target language: es
2024-12-02 15:34:22,733 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:34:22,733 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:34:22,734 [DEBUG] app1.py:964 - Request body: [{'text': 'hey, cortana, play.'}]
2024-12-02 15:34:23,049 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:34:23,050 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola, Cortana, juega.', 'to': 'es'}]}]
2024-12-02 15:34:23,053 [DEBUG] app1.py:974 - Extracted translation: Hola, Cortana, juega.
2024-12-02 15:34:23,054 [INFO] app1.py:975 - Translation completed successfully - Original: 'hey, cortana, play.' -> Translation: 'Hola, Cortana, juega.' (es)
2024-12-02 15:34:23,056 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Hola, Cortana, juega.
2024-12-02 15:34:23,058 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:34:25,652 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:25,654 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Hola, Cortana, juega.'}
2024-12-02 15:34:42,770 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:34:42,771 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=21da4d784af24d4b8e73a9241108c281, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:34:42,771 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:34:48,546 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:34:55,920 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:34:58,022 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:34:58,023 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a36d1e7ea3ff423e842112f131342431, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:34:58,024 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:34:58,646 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:34:59,655 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:35:02,653 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:35:03,661 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:35:06,654 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:35:07,669 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:35:09,475 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 15:35:09,475 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8712a84798f04ee4b0a8cce52a7ef021, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:35:09,476 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:35:09,483 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:35:09,483 [DEBUG] app1.py:1031 - Received translation request - Text: 'I.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:35:09,484 [DEBUG] app1.py:1042 - Normalized text: 'i.'
2024-12-02 15:35:09,484 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 46.75247502326965s
2024-12-02 15:35:09,484 [DEBUG] app1.py:1056 - Checking cache with key: i.:es
2024-12-02 15:35:09,486 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:35:09,486 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Yo.
2024-12-02 15:35:09,486 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:35:10,658 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:35:10,660 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Yo.'}
2024-12-02 15:35:18,547 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:35:23,510 [DEBUG] app1.py:1214 - Speech recognizing: when google
2024-12-02 15:35:23,511 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e3c0035dd8db4975a1541703a32b3339, text="when google", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:35:23,512 [DEBUG] app1.py:1104 - Sending transcription: when google (is_final: False)
2024-12-02 15:35:23,518 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:35:23,522 [DEBUG] app1.py:1031 - Received translation request - Text: 'when google', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:35:23,523 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:35:23,807 [DEBUG] app1.py:1214 - Speech recognizing: when google workspace
2024-12-02 15:35:23,807 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ec547b04ad448919910106f3b47d485, text="when google workspace", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:35:23,807 [DEBUG] app1.py:1104 - Sending transcription: when google workspace (is_final: False)
2024-12-02 15:35:23,812 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:35:23,812 [DEBUG] app1.py:1031 - Received translation request - Text: 'when google workspace', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:35:23,813 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:35:25,639 [INFO] app1.py:1205 - Speech recognized: When Google Workspace.
2024-12-02 15:35:25,641 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0ad7dc91c92a469e822182f5f65a5abb, text="When Google Workspace.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:35:25,641 [DEBUG] app1.py:1104 - Sending transcription: When Google Workspace. (is_final: True)
2024-12-02 15:35:25,646 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:35:25,646 [DEBUG] app1.py:1031 - Received translation request - Text: 'When Google Workspace.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:35:25,647 [DEBUG] app1.py:1042 - Normalized text: 'when google workspace.'
2024-12-02 15:35:25,647 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 16.163227558135986s
2024-12-02 15:35:25,647 [DEBUG] app1.py:1056 - Checking cache with key: when google workspace.:es
2024-12-02 15:35:25,649 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:35:25,649 [INFO] app1.py:933 - Starting translation request - Text: 'when google workspace.', Target language: es
2024-12-02 15:35:25,650 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:35:25,650 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:35:25,650 [DEBUG] app1.py:964 - Request body: [{'text': 'when google workspace.'}]
2024-12-02 15:35:25,946 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:35:25,950 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Cuando Google Workspace.', 'to': 'es'}]}]
2024-12-02 15:35:25,951 [DEBUG] app1.py:974 - Extracted translation: Cuando Google Workspace.
2024-12-02 15:35:25,953 [INFO] app1.py:975 - Translation completed successfully - Original: 'when google workspace.' -> Translation: 'Cuando Google Workspace.' (es)
2024-12-02 15:35:25,955 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Cuando Google Workspace.
2024-12-02 15:35:25,956 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:35:25,957 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Cuando Google Workspace.'}
2024-12-02 15:35:45,660 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:35:45,661 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=837cd4b0836347f387a0294cd5a70fd1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:35:45,662 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:35:48,549 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:35:56,269 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:35:58,657 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:35:59,664 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:00,786 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:36:00,788 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6b80d7903266415283ed1aefde1057b4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:36:00,789 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:36:02,657 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:03,667 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:06,657 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:07,681 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:10,658 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:11,663 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:14,656 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:15,662 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:15,989 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:36:15,989 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=879ee1beb6484a59871504cf3f0fc3f7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:36:15,990 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:36:18,551 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:36:18,655 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:19,664 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:22,650 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:23,653 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:26,650 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:27,660 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:30,656 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:31,086 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:36:31,086 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9f7a2d575ac84ea6b7fb28a8250727ae, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:36:31,086 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:36:31,658 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:34,658 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:35,670 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:38,651 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:39,655 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:42,648 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:43,658 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:46,310 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:36:46,310 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a9aa669dd1494da3bd45f891f3189a50, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:36:46,311 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:36:46,653 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:47,703 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:48,552 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:36:50,683 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:51,697 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:54,649 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:55,663 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:36:58,654 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:36:59,666 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:01,358 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:37:01,362 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c23bb34f5d174a3fba1eda3041746a80, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:37:01,364 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:37:02,657 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:03,672 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:06,687 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:07,695 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:10,668 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:11,670 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:14,654 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:15,664 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:16,368 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:37:16,368 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a35828a7e454454e91cd9b3d4292be5d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:37:16,369 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:37:18,553 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:37:18,661 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:19,663 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:22,663 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:23,671 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:26,650 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:27,660 [WARNING] app1.py:1148 - Client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5 connection timed out
2024-12-02 15:37:28,692 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 15:37:28,693 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=43c7d0422dc24bcb9f8b332395acfa49, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:37:28,693 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:37:28,700 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:37:28,701 [DEBUG] app1.py:1031 - Received translation request - Text: 'Play.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:37:28,703 [DEBUG] app1.py:1042 - Normalized text: 'play.'
2024-12-02 15:37:28,704 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 123.05681610107422s
2024-12-02 15:37:28,704 [DEBUG] app1.py:1056 - Checking cache with key: play.:es
2024-12-02 15:37:28,709 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:37:28,710 [INFO] app1.py:933 - Starting translation request - Text: 'play.', Target language: es
2024-12-02 15:37:28,710 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:37:28,710 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:37:28,711 [DEBUG] app1.py:964 - Request body: [{'text': 'play.'}]
2024-12-02 15:37:28,996 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:37:28,997 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.95}, 'translations': [{'text': 'jugar.', 'to': 'es'}]}]
2024-12-02 15:37:28,998 [DEBUG] app1.py:974 - Extracted translation: jugar.
2024-12-02 15:37:28,998 [INFO] app1.py:975 - Translation completed successfully - Original: 'play.' -> Translation: 'jugar.' (es)
2024-12-02 15:37:28,999 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: jugar.
2024-12-02 15:37:28,999 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:37:30,655 [INFO] app1.py:1121 - New translation stream connection for client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, language: es
2024-12-02 15:37:30,655 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'jugar.'}
2024-12-02 15:37:36,313 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 15:37:36,313 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fa251f53c9634e289415690c725401bd, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:37:36,314 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 15:37:36,321 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:37:36,322 [DEBUG] app1.py:1031 - Received translation request - Text: 'I.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:37:36,324 [DEBUG] app1.py:1042 - Normalized text: 'i.'
2024-12-02 15:37:36,325 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 7.620871305465698s
2024-12-02 15:37:36,325 [DEBUG] app1.py:1056 - Checking cache with key: i.:es
2024-12-02 15:37:36,325 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 15:37:36,326 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Yo.
2024-12-02 15:37:36,326 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:37:36,326 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Yo.'}
2024-12-02 15:37:48,555 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:37:53,395 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:37:53,395 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0c7f04b745dc4ea6be5c2e588d89157b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:37:53,396 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:38:05,552 [DEBUG] app1.py:1214 - Speech recognizing: mmm
2024-12-02 15:38:05,552 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9692f4f8c38647bfb9b2239fcb20d88c, text="mmm", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:38:05,553 [DEBUG] app1.py:1104 - Sending transcription: mmm (is_final: False)
2024-12-02 15:38:05,555 [INFO] app1.py:1205 - Speech recognized: MMM.
2024-12-02 15:38:05,555 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2840480a32564eaba4e03548078e8773, text="MMM.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:38:05,556 [DEBUG] app1.py:1104 - Sending transcription: MMM. (is_final: True)
2024-12-02 15:38:05,560 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:38:05,560 [DEBUG] app1.py:1031 - Received translation request - Text: 'mmm', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: False
2024-12-02 15:38:05,560 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 15:38:05,563 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:38:05,564 [DEBUG] app1.py:1031 - Received translation request - Text: 'MMM.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:38:05,564 [DEBUG] app1.py:1042 - Normalized text: 'mmm.'
2024-12-02 15:38:05,564 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 29.238630771636963s
2024-12-02 15:38:05,565 [DEBUG] app1.py:1056 - Checking cache with key: mmm.:es
2024-12-02 15:38:05,565 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:38:05,566 [INFO] app1.py:933 - Starting translation request - Text: 'mmm.', Target language: es
2024-12-02 15:38:05,567 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:38:05,567 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:38:05,567 [DEBUG] app1.py:964 - Request body: [{'text': 'mmm.'}]
2024-12-02 15:38:05,840 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:38:05,841 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.94}, 'translations': [{'text': 'Mmm.', 'to': 'es'}]}]
2024-12-02 15:38:05,842 [DEBUG] app1.py:974 - Extracted translation: Mmm.
2024-12-02 15:38:05,842 [INFO] app1.py:975 - Translation completed successfully - Original: 'mmm.' -> Translation: 'Mmm.' (es)
2024-12-02 15:38:05,843 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: Mmm.
2024-12-02 15:38:05,843 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:38:05,843 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'Mmm.'}
2024-12-02 15:38:18,002 [INFO] app1.py:1205 - Speech recognized: N.
2024-12-02 15:38:18,002 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fdfbaf606c9c4d23a78592824daa3d2d, text="N.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:38:18,004 [DEBUG] app1.py:1104 - Sending transcription: N. (is_final: True)
2024-12-02 15:38:18,011 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 15:38:18,011 [DEBUG] app1.py:1031 - Received translation request - Text: 'N.', Target: es, Client: aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5, Final: True
2024-12-02 15:38:18,012 [DEBUG] app1.py:1042 - Normalized text: 'n.'
2024-12-02 15:38:18,012 [DEBUG] app1.py:1048 - Time since last translation for aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5:es: 12.448065996170044s
2024-12-02 15:38:18,012 [DEBUG] app1.py:1056 - Checking cache with key: n.:es
2024-12-02 15:38:18,013 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 15:38:18,013 [INFO] app1.py:933 - Starting translation request - Text: 'n.', Target language: es
2024-12-02 15:38:18,013 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 15:38:18,014 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 15:38:18,014 [DEBUG] app1.py:964 - Request body: [{'text': 'n.'}]
2024-12-02 15:38:18,301 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 15:38:18,313 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'fr', 'score': 0.99}, 'translations': [{'text': 'n.', 'to': 'es'}]}]
2024-12-02 15:38:18,315 [DEBUG] app1.py:974 - Extracted translation: n.
2024-12-02 15:38:18,315 [INFO] app1.py:975 - Translation completed successfully - Original: 'n.' -> Translation: 'n.' (es)
2024-12-02 15:38:18,316 [DEBUG] app1.py:918 - Sending translation to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: n.
2024-12-02 15:38:18,317 [DEBUG] app1.py:925 - Translation sent successfully to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5
2024-12-02 15:38:18,317 [DEBUG] app1.py:1144 - Sending message to client aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5: {'type': 'final', 'translation': 'n.'}
2024-12-02 15:38:18,557 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:38:38,060 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:38:38,061 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5cc31745b2524cc690a53cd0248c7ca8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:38:38,062 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:38:48,559 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:38:53,055 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:38:53,055 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7adef8c7a2584a3cb21f7a9714333e77, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:38:58,383 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 15:38:58,383 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e2edabdc64674dcab56045dc2877b0ae, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:38:58,787 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 15:38:58,787 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b18acaa9b7034713a8f2a59a2300a449, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:38:59,019 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 15:38:59,019 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ab6ad637f6c640ddb27f94c3d3acde02, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:38:59,613 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 15:38:59,613 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bb6134a541954d649109252492cecd01, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:39:02,986 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:39:02,986 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dd87e31ca1e1459cacfcc05794cec15a, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:39:03,391 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:39:03,392 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dfed8b5da4a94bc7b7e6d28e849d11f4, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:39:08,479 [DEBUG] app1.py:1214 - Speech recognizing: API
2024-12-02 15:39:08,480 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b40d6ee509994d3bac59eb89732b7c9b, text="API", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:39:08,682 [DEBUG] app1.py:1214 - Speech recognizing: API gulfs kanji
2024-12-02 15:39:08,683 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8875fb5ba38e4d27a5bdf9c5b0e7d67d, text="API gulfs kanji", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:39:09,821 [INFO] app1.py:1205 - Speech recognized: API Gulfscontinue.
2024-12-02 15:39:09,821 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=06dd1f8bb8b24ba2a2560ae42f37696c, text="API Gulfscontinue.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:39:14,828 [INFO] app1.py:1205 - Speech recognized: Today.
2024-12-02 15:39:14,829 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5ab7b0e7b8a74dd49b37351e9be68178, text="Today.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:39:16,899 [DEBUG] app1.py:1214 - Speech recognizing: djibouti
2024-12-02 15:39:16,899 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f0b44e863b164910b526c93f048e6737, text="djibouti", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:39:17,709 [INFO] app1.py:1205 - Speech recognized: Djibouti.
2024-12-02 15:39:17,710 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4e45cf587dd24ef89d3d98cdbd9e2b50, text="Djibouti.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:39:18,561 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:39:37,396 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:39:37,397 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ddb9a72fd1b44bafa8710b5fcf79617c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:39:48,562 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:39:52,743 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:39:52,744 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=896ad1821458416daf41b852f31b24cd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:40:07,900 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:40:07,901 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=75c9203f76c749b3b6f39462518b5ece, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:40:18,566 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:40:22,000 [INFO] app1.py:1205 - Speech recognized: BJP.
2024-12-02 15:40:22,000 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8c1d92e229954ddcb39b3eb0c2587537, text="BJP.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:40:26,905 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:40:26,905 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9a1dbd1663a4ccebe99ff7c31008220, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:40:27,306 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:40:27,306 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=848bffad9ad24f6586539620278b1756, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:40:28,408 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you
2024-12-02 15:40:28,412 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=094b9fcf76a847eb96166b2d779544a3, text="hi what are you doing are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:40:28,702 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you listening
2024-12-02 15:40:28,703 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7c1ba8cf4764404092bf02b86d5d3392, text="hi what are you doing are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:40:28,763 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:40:28,765 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:40:28,765 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:40:28,765 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 15:40:28,766 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 15:40:28,766 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 15:40:28,769 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 15:40:28,769 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:40:28,770 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:40:28,773 [DEBUG] app1.py:1104 - Sending transcription: API (is_final: False)
2024-12-02 15:40:28,788 [DEBUG] app1.py:1104 - Sending transcription: API gulfs kanji (is_final: False)
2024-12-02 15:40:28,796 [DEBUG] app1.py:1104 - Sending transcription: API Gulfscontinue. (is_final: True)
2024-12-02 15:40:28,801 [DEBUG] app1.py:1104 - Sending transcription: Today. (is_final: True)
2024-12-02 15:40:28,804 [DEBUG] app1.py:1104 - Sending transcription: djibouti (is_final: False)
2024-12-02 15:40:28,805 [DEBUG] app1.py:1104 - Sending transcription: Djibouti. (is_final: True)
2024-12-02 15:40:28,815 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:40:28,819 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:40:28,821 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:40:28,821 [DEBUG] app1.py:1104 - Sending transcription: BJP. (is_final: True)
2024-12-02 15:40:28,831 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:40:28,834 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:40:28,836 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you (is_final: False)
2024-12-02 15:40:28,838 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you listening (is_final: False)
2024-12-02 15:40:29,297 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you listening me
2024-12-02 15:40:29,298 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=52e3ab118a014b7e80fd07eb33c0a22b, text="hi what are you doing are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:40:29,299 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you listening me (is_final: False)
2024-12-02 15:40:29,900 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing? Are you listening me?
2024-12-02 15:40:29,901 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8a9876e483ed4695895838cd8487c554, text="Hi, what are you doing? Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:40:29,902 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? Are you listening me? (is_final: True)
2024-12-02 15:40:36,400 [DEBUG] app1.py:1214 - Speech recognizing: valar
2024-12-02 15:40:36,400 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=62c60997011c4689afa8613723728369, text="valar", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:40:36,400 [DEBUG] app1.py:1104 - Sending transcription: valar (is_final: False)
2024-12-02 15:40:36,586 [DEBUG] app1.py:1214 - Speech recognizing: balraj
2024-12-02 15:40:36,586 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=801b1e5ffaeb4eaab48eaab3903759a9, text="balraj", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:40:36,587 [DEBUG] app1.py:1104 - Sending transcription: balraj (is_final: False)
2024-12-02 15:40:37,504 [INFO] app1.py:1205 - Speech recognized: Balraj.
2024-12-02 15:40:37,504 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a30976f0e7d844a39b5518ed157a26f8, text="Balraj.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:40:37,504 [DEBUG] app1.py:1104 - Sending transcription: Balraj. (is_final: True)
2024-12-02 15:40:48,568 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:40:56,994 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:40:56,995 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1ca2613780d64364b2f0df1d090260ea, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:40:56,996 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:41:09,462 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:41:09,466 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:41:11,693 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:41:11,694 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=126860c6dc084b959cd909df9057e10f, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:11,695 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:41:11,987 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:41:11,988 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a2ac8ac445a04d3ebadef89a8652554c, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:11,990 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:41:12,892 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are
2024-12-02 15:41:12,893 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aba9badc61934002b4519fdfc9e030f6, text="hi what are you doing are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:12,894 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are (is_final: False)
2024-12-02 15:41:13,001 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you
2024-12-02 15:41:13,002 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a9389873efd040e69d9986300609721e, text="hi what are you doing are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:13,002 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you (is_final: False)
2024-12-02 15:41:13,389 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you listening me
2024-12-02 15:41:13,390 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=695a633b7d2247ae93609966c76a9194, text="hi what are you doing are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:13,392 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you listening me (is_final: False)
2024-12-02 15:41:14,297 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing? Are you listening me?
2024-12-02 15:41:14,297 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0f8f1ded0c0141c9835d056edeeca50e, text="Hi, what are you doing? Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:41:14,298 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? Are you listening me? (is_final: True)
2024-12-02 15:41:18,570 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:41:27,353 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:41:27,356 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:41:28,904 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:41:28,905 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4456db69599b4bd886d60a3cfaad5bdf, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:28,906 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:41:29,103 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 15:41:29,104 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ab4f777a507f47b089d29e7f945d586b, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:29,105 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 15:41:29,727 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:41:29,728 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d66355dd206d4c469697a29f86dd8434, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:41:29,728 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:41:33,032 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:41:33,035 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:41:34,900 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:41:34,902 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a5e2ebe784654872ab1ddd1d74144617, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:34,902 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:41:35,104 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 15:41:35,105 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=00a08d3238554faaa0d17325e21e572f, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:41:35,106 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 15:41:35,915 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:41:35,916 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=90b54ecca5db4c1e8b3435de5ecd1095, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:41:35,917 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:41:48,572 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:41:55,896 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:41:55,896 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=62c2cfb92460421cba1dbcd2f0c86eb2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:41:55,897 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:42:10,957 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:42:10,958 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bfcbcaea20b84889bdadd1a92092cb9f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:42:10,958 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:42:18,575 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:42:26,015 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:42:26,015 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c4d6f29913bc445990133dd1d77175e4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:42:26,016 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:42:41,007 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:42:41,007 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e866765a4e8547069d8d550654ce9f6a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:42:41,008 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:42:48,577 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:42:56,135 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:42:56,136 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8fbc7ea24f5b4759a3a2311cbdd075de, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:42:56,136 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:43:11,196 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:43:11,198 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aae7b3b74f5b47f58723683e5e1ff580, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:43:11,199 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:43:18,579 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:43:26,256 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:43:26,257 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da3eae75d2654555be9fdae5cc94cdb0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:43:26,257 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:43:41,258 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:43:41,259 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d1251b2412454e9a9d60e6aaf00e9250, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:43:41,259 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:43:48,580 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:43:56,301 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:43:56,301 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9d2837edc4364e88912467b11217aea0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:43:56,302 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:44:11,268 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:44:11,270 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bc75833f3e06465884e979d26ede46f4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:44:11,271 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:44:18,583 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:44:26,270 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:44:26,271 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e6146f524e3e4381bccf40935e1d666f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:44:26,271 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:44:34,491 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:44:34,498 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2e4dac1e5af2427f9ded30261d07a372, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:44:34,787 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:44:34,789 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5615b3d0795e4a288c1cd6510f4d8ca1, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:44:35,208 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:44:35,209 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2429ab0625ea45f9b4f150fa1cebf6a2, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:44:35,378 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:44:35,380 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:44:35,380 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:44:35,384 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:44:35,387 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:44:35,703 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:44:35,703 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4a9026bee58e4dd69e254a492d2c2940, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:44:35,703 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:44:39,602 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:44:39,605 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e463b7a25f67444d9f788bc6f290a60e, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:44:39,605 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:44:40,906 [DEBUG] app1.py:1214 - Speech recognizing: hi are you listening
2024-12-02 15:44:40,906 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bd5d4f89e6d84b6bac01372f5ea69adb, text="hi are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:44:40,907 [DEBUG] app1.py:1104 - Sending transcription: hi are you listening (is_final: False)
2024-12-02 15:44:41,200 [DEBUG] app1.py:1214 - Speech recognizing: hi are you listening me
2024-12-02 15:44:41,200 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a853e0a44dae422b8aa55e2683a85b7c, text="hi are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:44:41,201 [DEBUG] app1.py:1104 - Sending transcription: hi are you listening me (is_final: False)
2024-12-02 15:44:42,146 [INFO] app1.py:1205 - Speech recognized: Hi, are you listening me?
2024-12-02 15:44:42,146 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0728b6c8867e4fd2b07300554d9b8e23, text="Hi, are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:44:42,146 [DEBUG] app1.py:1104 - Sending transcription: Hi, are you listening me? (is_final: True)
2024-12-02 15:44:47,083 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:44:47,083 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:44:48,584 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:44:48,799 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:44:48,800 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=95a23c2eea1c436996e4c8ca37be34ca, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:44:48,801 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:44:49,311 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:44:49,312 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e5472068945c4d56bd7099872912bc28, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:44:49,313 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:45:05,796 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:45:05,796 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b03905d2c3494ea5b509035763d43781, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:45:05,797 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:45:18,586 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:45:24,556 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:45:24,556 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7959829d81e64ee0b5e5b752af04c877, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:45:24,557 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:45:39,731 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:45:39,732 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9e040a35527646db9b2d21bd3c73ce73, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:45:39,734 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:45:48,590 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:45:54,656 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:45:54,657 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=efaa6774b2cd4bc6a042d354bc66598f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:45:54,657 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:46:09,897 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:46:09,898 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c34b1b9c3caf413a8a1926f8fa17fceb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:46:09,899 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:46:18,593 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:46:24,857 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:46:24,858 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c8a81c03fd9b4d0d99817530b2eee5b7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:46:24,859 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:46:40,095 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:46:40,097 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a4ae6f30d60142abbd08534904fc0a18, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:46:40,099 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:46:48,595 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:46:55,047 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:46:55,048 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b9e2b8a534c54d2aa66130a285493d9a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:46:55,048 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:47:10,069 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:47:10,070 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fb5d60b9434b4c32b2d93d4afdcbd0d5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:47:10,070 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:47:18,597 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:47:25,119 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:47:25,120 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d3cc6411398e4e36998cb0be1cd8b2dc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:47:25,121 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:47:40,397 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:47:40,398 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b4f4fe83a34a4b8b870860d0bfffcde7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:47:40,399 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:47:48,599 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:47:55,378 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:47:55,378 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cb68a611c21141acaaee56244ca5e591, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:47:55,379 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:48:10,353 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:48:10,353 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1eda27ef81bd433fa074fab61788eee6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:48:10,354 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:48:16,011 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 15:48:16,011 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=967ad77ff6f441b4b805c9b19b337cde, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:48:16,012 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:48:18,601 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:48:33,397 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:48:33,398 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a7552d2eb87f426d9f21625d47a2106b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:48:33,398 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:48:48,602 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:48:51,058 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:48:51,058 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5c034ff5180f4de791c05116628870da, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:48:51,059 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:49:06,112 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:49:06,114 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2004d91b689344858de371fb906936e4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:49:06,117 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:49:18,604 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5']
2024-12-02 15:49:21,057 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:49:21,057 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8338227bec5e4da59857c88031fa2e19, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:49:22,895 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:49:22,896 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=00c2123ce9904a3a90499b80c2bcd209, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:49:23,299 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:49:23,300 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=72b120e008c04b4eb5f692584531cc78, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:49:27,507 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:49:27,511 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:49:27,512 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:49:27,516 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:49:27,522 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:49:31,413 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 15:49:31,414 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=577c249a4bb547a9adfd2057ede994f4, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:49:31,415 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 15:49:31,705 [DEBUG] app1.py:1214 - Speech recognizing: what are
2024-12-02 15:49:31,705 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fc9c4f5e809a438a92130ff6421ac2de, text="what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:49:31,705 [DEBUG] app1.py:1104 - Sending transcription: what are (is_final: False)
2024-12-02 15:49:31,799 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 15:49:31,800 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cd9f2621235048a396ab899ac1100d74, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:49:31,801 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 15:49:32,329 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 15:49:32,330 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=694b49fa6d0146f0b883589339ccea94, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:49:32,331 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 15:49:34,306 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:49:34,308 [INFO] app1.py:1131 - Creating new client connection: 72605ad0-02ec-43d6-9d83-45aa2000f04f
2024-12-02 15:49:35,994 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:49:35,995 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ed7f6c54c70d4b30ab2b2e0af6be5b6b, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:49:35,995 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:49:36,588 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 15:49:36,589 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c34d795dd12f4cdc80ba815015df39b1, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:49:36,589 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 15:49:37,006 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:49:37,008 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8db9fd9c6b9148ecbcffc7eac327c5c4, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:49:37,008 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:49:48,606 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f']
2024-12-02 15:49:57,121 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:49:57,122 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0e9a8611ac0f4e0cbe53ba76f900d11d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:49:57,123 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:50:04,604 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:06,656 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:07,659 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:10,659 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:11,668 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:12,056 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:50:12,056 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ba3a1884d37f42f195d64564aa81ba9f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:50:12,057 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:50:14,648 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:15,656 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:18,609 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f']
2024-12-02 15:50:18,657 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:19,665 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:22,660 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:23,672 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:26,659 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:27,313 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:50:27,314 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7a946339212b4f2dad2d281abaab9dad, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:50:27,315 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:50:27,668 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:30,652 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:31,663 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:34,646 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:35,660 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:38,651 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:39,661 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:42,370 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:50:42,371 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e4c53094afbf4c85a32be203fd9eabf7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:50:42,371 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:50:42,651 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:43,664 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:46,667 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:47,674 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:48,611 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f']
2024-12-02 15:50:50,657 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:51,674 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:54,662 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:55,668 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:50:57,584 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:50:57,584 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c613277699ac411b9526fb5bc39edd68, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:50:57,585 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:50:58,658 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:50:59,707 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:51:02,662 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:51:03,669 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:51:06,662 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:51:07,668 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:51:10,655 [INFO] app1.py:1121 - New translation stream connection for client: 72605ad0-02ec-43d6-9d83-45aa2000f04f, language: es
2024-12-02 15:51:10,840 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 15:51:10,879 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9ba523250dea4887a31a8e27f8d0e15d, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:51:10,909 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:51:11,709 [WARNING] app1.py:1148 - Client 72605ad0-02ec-43d6-9d83-45aa2000f04f connection timed out
2024-12-02 15:51:17,402 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:51:17,534 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:51:18,614 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f']
2024-12-02 15:51:24,305 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 15:51:24,418 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 15:51:24,510 [INFO] app1.py:1240 - Audio stream started
2024-12-02 15:51:26,907 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:51:26,909 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=300ca141f68c4580945d0e237db9c55f, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:27,203 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:51:27,204 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2f1c6bdde8ff4b4fabf1bb10f736b14f, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:27,767 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:51:27,768 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6524e35e13ac45efbff56d3e2e667d1c, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:51:27,989 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:51:27,990 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:51:27,990 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:51:27,991 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:51:28,010 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:51:29,980 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:51:29,980 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=43b7624e041242fd8b0d29bafa816668, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:29,981 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:51:30,277 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 15:51:30,277 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c1bb07058ca40f1834cd06eb917c04c, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:30,278 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 15:51:30,478 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:51:30,479 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a922bf417327439bb77856cba39898c9, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:30,480 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:51:30,482 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:51:30,483 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=020ad6dc3b9a440ca63433e4572a842b, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:51:30,485 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:51:44,975 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 15:51:44,976 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7a3a1781ad6b4417b6046a401c0172c3, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:46,379 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 15:51:46,379 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0c8ed514483d4231a79c5d47681a263c, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:51:48,618 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f']
2024-12-02 15:51:49,643 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:51:49,644 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:51:49,644 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 15:51:49,645 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 15:51:51,797 [DEBUG] app1.py:1214 - Speech recognizing: sorry what are you doing
2024-12-02 15:51:51,798 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c6d03c1970c43d5832b6fb96d510ca6, text="sorry what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:51,800 [DEBUG] app1.py:1104 - Sending transcription: sorry what are you doing (is_final: False)
2024-12-02 15:51:53,196 [DEBUG] app1.py:1214 - Speech recognizing: sorry what are you doing are you listening
2024-12-02 15:51:53,196 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d7a7c5386411454781357f6ca069c95d, text="sorry what are you doing are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:53,197 [DEBUG] app1.py:1104 - Sending transcription: sorry what are you doing are you listening (is_final: False)
2024-12-02 15:51:54,186 [DEBUG] app1.py:1214 - Speech recognizing: sorry what are you doing are you listening me
2024-12-02 15:51:54,187 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=db3d75cc5132404885245521cbd5b30f, text="sorry what are you doing are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:51:54,187 [DEBUG] app1.py:1104 - Sending transcription: sorry what are you doing are you listening me (is_final: False)
2024-12-02 15:51:55,136 [INFO] app1.py:1205 - Speech recognized: Sorry, what are you doing? Are you listening me?
2024-12-02 15:51:55,138 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=40c921a763544d88b42ee45a2a5ba9ec, text="Sorry, what are you doing? Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:51:55,139 [DEBUG] app1.py:1104 - Sending transcription: Sorry, what are you doing? Are you listening me? (is_final: True)
2024-12-02 15:51:59,018 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:51:59,019 [INFO] app1.py:1131 - Creating new client connection: 10200d57-8db3-458d-923f-f3916c12eb96
2024-12-02 15:52:01,880 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:52:01,881 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1cf7e4fc2a344d28966a6b6c90b428c8, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:52:01,883 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:52:02,174 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 15:52:02,175 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=80455b53debd4a29887145a6b46a58d1, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:52:02,176 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 15:52:02,469 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:52:02,470 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=09dfcb320dbe4b3987d5a74a3bc73d72, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:52:02,471 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:52:18,621 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96']
2024-12-02 15:52:22,664 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:52:22,665 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=24a4ecfd03654e36888a167223123e2b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:52:22,666 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:52:29,339 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:31,649 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:52:32,659 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:35,659 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:52:36,663 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:38,060 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:52:38,061 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cc23d26cef944f88a9eba5811c0a4cbd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:52:38,061 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:52:39,654 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:52:40,661 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:43,656 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:52:44,668 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:47,661 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:52:48,624 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96']
2024-12-02 15:52:48,665 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:51,661 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:52:52,672 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:53,032 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:52:53,033 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=057a79aeb52149b8a9aa79d9bd5e9150, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:52:53,034 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:52:55,652 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:52:56,659 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:52:59,658 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:00,663 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:03,651 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:04,659 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:07,661 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:07,876 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 15:53:07,877 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5871178760af43d4883ec6a3ac2b2e97, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:53:07,877 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 15:53:08,666 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:11,654 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:12,663 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:15,649 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:16,658 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:18,625 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96']
2024-12-02 15:53:19,648 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:20,660 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:23,654 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:24,660 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:27,657 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:28,076 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:53:28,077 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b08062cb372c40efb46adeeba80cc2ba, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:53:28,077 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:53:28,665 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:31,070 [DEBUG] app1.py:1214 - Speech recognizing: virgo velig
2024-12-02 15:53:31,070 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f7ddf1650d6d45d7832fa576331a91bc, text="virgo velig", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:31,072 [DEBUG] app1.py:1104 - Sending transcription: virgo velig (is_final: False)
2024-12-02 15:53:31,366 [DEBUG] app1.py:1214 - Speech recognizing: virgo veligamade
2024-12-02 15:53:31,366 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bf1df644a8e44376a6b28af1a4a26810, text="virgo veligamade", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:31,369 [DEBUG] app1.py:1104 - Sending transcription: virgo veligamade (is_final: False)
2024-12-02 15:53:31,647 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:31,771 [DEBUG] app1.py:1214 - Speech recognizing: virgo veligamadella
2024-12-02 15:53:31,772 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=94e8913403914aa187525bd9062da5cc, text="virgo veligamadella", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:31,773 [DEBUG] app1.py:1104 - Sending transcription: virgo veligamadella (is_final: False)
2024-12-02 15:53:31,973 [DEBUG] app1.py:1214 - Speech recognizing: virgo veligamadella mazhab
2024-12-02 15:53:31,976 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f262852627e146199c340334399b97d7, text="virgo veligamadella mazhab", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:31,977 [DEBUG] app1.py:1104 - Sending transcription: virgo veligamadella mazhab (is_final: False)
2024-12-02 15:53:32,362 [DEBUG] app1.py:1214 - Speech recognizing: virgo veliga madhya pradesh
2024-12-02 15:53:32,362 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a06f0754f27a42e4a45b8e78cdafabbb, text="virgo veliga madhya pradesh", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:32,363 [DEBUG] app1.py:1104 - Sending transcription: virgo veliga madhya pradesh (is_final: False)
2024-12-02 15:53:32,455 [INFO] app1.py:1205 - Speech recognized: Virgo Williams.
2024-12-02 15:53:32,456 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1b895a433d9f4446a97618d70beb8e9e, text="Virgo Williams.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:53:32,457 [DEBUG] app1.py:1104 - Sending transcription: Virgo Williams. (is_final: True)
2024-12-02 15:53:32,656 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:35,664 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:36,681 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:39,091 [DEBUG] app1.py:1214 - Speech recognizing: how are you
2024-12-02 15:53:39,091 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6541255bf9884d0499c8d6df44044c9a, text="how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:39,092 [DEBUG] app1.py:1104 - Sending transcription: how are you (is_final: False)
2024-12-02 15:53:39,497 [INFO] app1.py:1205 - Speech recognized: How are you?
2024-12-02 15:53:39,497 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e775d2f26cff4a2ba9d5d638e23547b3, text="How are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:53:39,498 [DEBUG] app1.py:1104 - Sending transcription: How are you? (is_final: True)
2024-12-02 15:53:39,656 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:40,666 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:42,286 [DEBUG] app1.py:1214 - Speech recognizing: aman how are you
2024-12-02 15:53:42,286 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e0f727fc7dee413ea62db68ee2ef3881, text="aman how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:42,287 [DEBUG] app1.py:1104 - Sending transcription: aman how are you (is_final: False)
2024-12-02 15:53:42,811 [INFO] app1.py:1205 - Speech recognized: Aman, how are you?
2024-12-02 15:53:42,812 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9a03db53864449088978247fc8be5d26, text="Aman, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:53:42,812 [DEBUG] app1.py:1104 - Sending transcription: Aman, how are you? (is_final: True)
2024-12-02 15:53:43,651 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:44,654 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:47,489 [DEBUG] app1.py:1214 - Speech recognizing: i am
2024-12-02 15:53:47,489 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a3b5fd1a708344e59f504386fc4e5d99, text="i am", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:47,490 [DEBUG] app1.py:1104 - Sending transcription: i am (is_final: False)
2024-12-02 15:53:47,662 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:47,894 [DEBUG] app1.py:1214 - Speech recognizing: i am good what are you
2024-12-02 15:53:47,895 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=68f5dbd969b24eb9a388496707e81a17, text="i am good what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:47,897 [DEBUG] app1.py:1104 - Sending transcription: i am good what are you (is_final: False)
2024-12-02 15:53:48,096 [DEBUG] app1.py:1214 - Speech recognizing: i am good what are you doing
2024-12-02 15:53:48,098 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c9170494326e4417bd1b3e44cbf9389a, text="i am good what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:48,099 [DEBUG] app1.py:1104 - Sending transcription: i am good what are you doing (is_final: False)
2024-12-02 15:53:48,426 [INFO] app1.py:1205 - Speech recognized: I am good. What are you doing?
2024-12-02 15:53:48,427 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=968bf20912384a27a3320d03c8e00d7d, text="I am good. What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:53:48,428 [DEBUG] app1.py:1104 - Sending transcription: I am good. What are you doing? (is_final: True)
2024-12-02 15:53:48,627 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96']
2024-12-02 15:53:48,671 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:51,661 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:52,667 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:53,292 [DEBUG] app1.py:1214 - Speech recognizing: ola
2024-12-02 15:53:53,295 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aee24e748b104a24ab08dfdc36e2ac28, text="ola", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:53,296 [DEBUG] app1.py:1104 - Sending transcription: ola (is_final: False)
2024-12-02 15:53:53,386 [DEBUG] app1.py:1214 - Speech recognizing: ola is strugg
2024-12-02 15:53:53,387 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4762a8e417d044f8a13c7534f37e9ab5, text="ola is strugg", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:53,388 [DEBUG] app1.py:1104 - Sending transcription: ola is strugg (is_final: False)
2024-12-02 15:53:53,883 [DEBUG] app1.py:1214 - Speech recognizing: ola is struggled
2024-12-02 15:53:53,883 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ed2c6ecf2ab341b9bf459c61afa5f6c2, text="ola is struggled", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:53,884 [DEBUG] app1.py:1104 - Sending transcription: ola is struggled (is_final: False)
2024-12-02 15:53:54,194 [DEBUG] app1.py:1214 - Speech recognizing: ola is struggled through
2024-12-02 15:53:54,195 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c88af8139b7245859817d886e381f285, text="ola is struggled through", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:54,196 [DEBUG] app1.py:1104 - Sending transcription: ola is struggled through (is_final: False)
2024-12-02 15:53:55,191 [DEBUG] app1.py:1214 - Speech recognizing: ola is struggled throughout
2024-12-02 15:53:55,192 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=83fb8371c57a49afab488d44f65c186f, text="ola is struggled throughout", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:53:55,192 [DEBUG] app1.py:1104 - Sending transcription: ola is struggled throughout (is_final: False)
2024-12-02 15:53:55,657 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:53:56,665 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:53:57,011 [INFO] app1.py:1205 - Speech recognized: Ola is struggled throughout.
2024-12-02 15:53:57,012 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=51f9723d7fcf45f296bd2cb45a60d324, text="Ola is struggled throughout.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:53:57,013 [DEBUG] app1.py:1104 - Sending transcription: Ola is struggled throughout. (is_final: True)
2024-12-02 15:53:59,652 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:00,656 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:03,490 [DEBUG] app1.py:1214 - Speech recognizing: holistic
2024-12-02 15:54:03,491 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fabee82b80df409987ea5073b73381f5, text="holistic", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:03,491 [DEBUG] app1.py:1104 - Sending transcription: holistic (is_final: False)
2024-12-02 15:54:03,662 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:04,666 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:05,321 [INFO] app1.py:1205 - Speech recognized: Holistic.
2024-12-02 15:54:05,322 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ce79b9b7467b462986187ebd3cbe8169, text="Holistic.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:54:05,322 [DEBUG] app1.py:1104 - Sending transcription: Holistic. (is_final: True)
2024-12-02 15:54:07,658 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:08,643 [DEBUG] app1.py:1214 - Speech recognizing: madam era
2024-12-02 15:54:08,653 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=49c1fe0ce27a4ddebc5e82b1b558422a, text="madam era", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:08,660 [DEBUG] app1.py:1104 - Sending transcription: madam era (is_final: False)
2024-12-02 15:54:08,675 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:11,655 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:12,666 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:15,650 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:16,662 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:17,941 [DEBUG] app1.py:1214 - Speech recognizing: piyum pada
2024-12-02 15:54:17,941 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ee6122628ca45fca0a34a71a5ebf21d, text="piyum pada", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:17,942 [DEBUG] app1.py:1104 - Sending transcription: piyum pada (is_final: False)
2024-12-02 15:54:18,326 [DEBUG] app1.py:1214 - Speech recognizing: piyum pada marada
2024-12-02 15:54:18,326 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b95d9f8eea034c8d9f3435d8bed6b93e, text="piyum pada marada", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:18,327 [DEBUG] app1.py:1104 - Sending transcription: piyum pada marada (is_final: False)
2024-12-02 15:54:18,630 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96']
2024-12-02 15:54:19,277 [INFO] app1.py:1205 - Speech recognized: Piyum pada marada.
2024-12-02 15:54:19,278 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eaf431e7371f4876aaa658a6292d4b77, text="Piyum pada marada.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:54:19,279 [DEBUG] app1.py:1104 - Sending transcription: Piyum pada marada. (is_final: True)
2024-12-02 15:54:19,652 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:20,661 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:22,790 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:23,795 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:26,658 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:27,665 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:30,658 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:31,662 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:34,650 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:35,658 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:38,649 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:39,592 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:54:39,592 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d3caf6c9d179403aa90612a44e573524, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:54:39,654 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:42,681 [INFO] app1.py:1121 - New translation stream connection for client: 10200d57-8db3-458d-923f-f3916c12eb96, language: es
2024-12-02 15:54:43,687 [WARNING] app1.py:1148 - Client 10200d57-8db3-458d-923f-f3916c12eb96 connection timed out
2024-12-02 15:54:48,636 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96']
2024-12-02 15:54:52,860 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 15:54:52,861 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c24e9c44d7f64781838c29509357d21f, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:53,158 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 15:54:53,160 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=72239f79b78e43a28017ab5c5093f819, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:53,557 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 15:54:53,557 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f4ebc4755c1f470aa90a66f992e148f9, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:53,740 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:54:53,741 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4d992c4ce6e1465e827dc3cbf39986d3, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:54:53,853 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 15:54:53,855 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 15:54:53,856 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:54:53,859 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 15:54:53,863 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 15:54:53,878 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 15:54:53,891 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:54:57,785 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:54:57,786 [INFO] app1.py:1131 - Creating new client connection: 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 15:54:59,866 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 15:54:59,868 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=768a3b1327fe433599b0c8cab7e4ffba, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:59,869 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 15:54:59,976 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 15:54:59,977 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9b8dfbe15dec42f296b3fed7ed1afeff, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:54:59,979 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 15:55:00,690 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 15:55:00,690 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1543555c2e374accb8a83fd3be94f648, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:55:00,691 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 15:55:05,970 [DEBUG] app1.py:1214 - Speech recognizing: match kathingalika translator
2024-12-02 15:55:05,970 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=475856f806e34a989a9433043777c45b, text="match kathingalika translator", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:05,972 [DEBUG] app1.py:1104 - Sending transcription: match kathingalika translator (is_final: False)
2024-12-02 15:55:09,981 [DEBUG] app1.py:1214 - Speech recognizing: digvijaya
2024-12-02 15:55:09,982 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=605216d93db1423b9210a06030e210ed, text="digvijaya", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:09,982 [DEBUG] app1.py:1104 - Sending transcription: digvijaya (is_final: False)
2024-12-02 15:55:10,372 [DEBUG] app1.py:1214 - Speech recognizing: digvijaya neen
2024-12-02 15:55:10,372 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=72cd08b29a1d41c9814b09cb48295931, text="digvijaya neen", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:10,373 [DEBUG] app1.py:1104 - Sending transcription: digvijaya neen (is_final: False)
2024-12-02 15:55:10,482 [DEBUG] app1.py:1214 - Speech recognizing: digvijaya neel
2024-12-02 15:55:10,483 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=18bb106cf55c47c08b94f8fe1d083da8, text="digvijaya neel", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:10,484 [DEBUG] app1.py:1104 - Sending transcription: digvijaya neel (is_final: False)
2024-12-02 15:55:10,574 [DEBUG] app1.py:1214 - Speech recognizing: digvijaya neelap
2024-12-02 15:55:10,574 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f618f4b025aa4c0492dcb1b1900633cb, text="digvijaya neelap", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:10,575 [DEBUG] app1.py:1104 - Sending transcription: digvijaya neelap (is_final: False)
2024-12-02 15:55:10,684 [DEBUG] app1.py:1214 - Speech recognizing: digvijaya neelapakkam
2024-12-02 15:55:10,684 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ea1956b11b554f80bf065f171080b0c0, text="digvijaya neelapakkam", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:10,685 [DEBUG] app1.py:1104 - Sending transcription: digvijaya neelapakkam (is_final: False)
2024-12-02 15:55:11,274 [INFO] app1.py:1205 - Speech recognized: Digvijaya Neelapakkam.
2024-12-02 15:55:11,274 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8124d9eaf46446a2b95af8862a4c065d, text="Digvijaya Neelapakkam.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:55:11,276 [DEBUG] app1.py:1104 - Sending transcription: Digvijaya Neelapakkam. (is_final: True)
2024-12-02 15:55:15,874 [DEBUG] app1.py:1214 - Speech recognizing: make the way
2024-12-02 15:55:15,874 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7644f59990b44f88b44d5dd25047d020, text="make the way", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:15,874 [DEBUG] app1.py:1104 - Sending transcription: make the way (is_final: False)
2024-12-02 15:55:16,965 [DEBUG] app1.py:1214 - Speech recognizing: make the way hi what
2024-12-02 15:55:16,966 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c2d3293c0ce74a57b21d1128bae65750, text="make the way hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:16,968 [DEBUG] app1.py:1104 - Sending transcription: make the way hi what (is_final: False)
2024-12-02 15:55:17,260 [DEBUG] app1.py:1214 - Speech recognizing: make the way hi what are
2024-12-02 15:55:17,260 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a64778e9b48e48288fdeb1c53c248c8e, text="make the way hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:17,261 [DEBUG] app1.py:1104 - Sending transcription: make the way hi what are (is_final: False)
2024-12-02 15:55:17,369 [DEBUG] app1.py:1214 - Speech recognizing: make the way hi what are you doing
2024-12-02 15:55:17,369 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=33a2765d5b1840fa95a58c89c3ab44bc, text="make the way hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:17,370 [DEBUG] app1.py:1104 - Sending transcription: make the way hi what are you doing (is_final: False)
2024-12-02 15:55:17,681 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 15:55:17,682 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f4f16d7f42934e748d8f65d394481174, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:55:17,683 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 15:55:18,638 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:55:28,101 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:30,115 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:31,121 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:33,134 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:34,146 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:36,152 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:37,164 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:37,881 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:55:37,883 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b9e77bd6ba6e4c848a521e0025e3f73b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:55:37,883 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:55:39,172 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:40,176 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:42,198 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:43,202 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:45,653 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:46,656 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:48,641 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:55:49,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:50,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:51,162 [DEBUG] app1.py:1214 - Speech recognizing: no don't kalk
2024-12-02 15:55:51,162 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c8eec39828984fc08c24a9d602b35bba, text="no don't kalk", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:51,164 [DEBUG] app1.py:1104 - Sending transcription: no don't kalk (is_final: False)
2024-12-02 15:55:51,565 [DEBUG] app1.py:1214 - Speech recognizing: kalkata vinyl
2024-12-02 15:55:51,566 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4859aa62c51041e396941783ada384fc, text="kalkata vinyl", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:51,567 [DEBUG] app1.py:1104 - Sending transcription: kalkata vinyl (is_final: False)
2024-12-02 15:55:52,075 [DEBUG] app1.py:1214 - Speech recognizing: kalkata vinyl rana
2024-12-02 15:55:52,075 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=95c902da70c542efbcd62d033c8fa586, text="kalkata vinyl rana", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:52,077 [DEBUG] app1.py:1104 - Sending transcription: kalkata vinyl rana (is_final: False)
2024-12-02 15:55:52,465 [DEBUG] app1.py:1214 - Speech recognizing: kalkata vinyl analysis
2024-12-02 15:55:52,465 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=48556ad89b3149c59e40ef53b1e92206, text="kalkata vinyl analysis", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:52,467 [DEBUG] app1.py:1104 - Sending transcription: kalkata vinyl analysis (is_final: False)
2024-12-02 15:55:52,820 [INFO] app1.py:1205 - Speech recognized: Kalkata vinyl analysis.
2024-12-02 15:55:52,821 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b226ebb3006c47b58dba433c07105be8, text="Kalkata vinyl analysis.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:55:52,822 [DEBUG] app1.py:1104 - Sending transcription: Kalkata vinyl analysis. (is_final: True)
2024-12-02 15:55:53,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:54,655 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:55:54,751 [DEBUG] app1.py:1214 - Speech recognizing: call mama
2024-12-02 15:55:54,752 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=81aa09653303459f8d219938d7761186, text="call mama", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:55:54,753 [DEBUG] app1.py:1104 - Sending transcription: call mama (is_final: False)
2024-12-02 15:55:55,006 [INFO] app1.py:1205 - Speech recognized: Call my wife.
2024-12-02 15:55:55,025 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=833a7a151be04c28acb2ab582e50c262, text="Call my wife.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:55:55,026 [DEBUG] app1.py:1104 - Sending transcription: Call my wife. (is_final: True)
2024-12-02 15:55:57,542 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:55:58,552 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:00,178 [DEBUG] app1.py:1214 - Speech recognizing: call my wife
2024-12-02 15:56:00,179 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3ba0b3beea8f4209914e45812a89f563, text="call my wife", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:00,179 [DEBUG] app1.py:1104 - Sending transcription: call my wife (is_final: False)
2024-12-02 15:56:00,572 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:01,577 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:01,997 [INFO] app1.py:1205 - Speech recognized: Call my wife.
2024-12-02 15:56:01,997 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=deda62d4e6004387a7b177b1b57958e7, text="Call my wife.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:56:01,998 [DEBUG] app1.py:1104 - Sending transcription: Call my wife. (is_final: True)
2024-12-02 15:56:03,589 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:04,599 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:05,876 [DEBUG] app1.py:1214 - Speech recognizing: OK
2024-12-02 15:56:05,876 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a04842842a35446e8052ea81143add80, text="OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:05,877 [DEBUG] app1.py:1104 - Sending transcription: OK (is_final: False)
2024-12-02 15:56:06,482 [DEBUG] app1.py:1214 - Speech recognizing: OK i
2024-12-02 15:56:06,484 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ef1c55ab918843e1886ec01b2a0e26b3, text="OK i", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:06,485 [DEBUG] app1.py:1104 - Sending transcription: OK i (is_final: False)
2024-12-02 15:56:06,609 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:06,885 [DEBUG] app1.py:1214 - Speech recognizing: OK i'm calling
2024-12-02 15:56:06,885 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8a92d56a14b7444d9df90a4b21e4d85f, text="OK i'm calling", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:06,887 [DEBUG] app1.py:1104 - Sending transcription: OK i'm calling (is_final: False)
2024-12-02 15:56:06,978 [DEBUG] app1.py:1214 - Speech recognizing: OK i'm calling now
2024-12-02 15:56:06,979 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a9ac432c1ff94ab299bccdbb422f6370, text="OK i'm calling now", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:06,980 [DEBUG] app1.py:1104 - Sending transcription: OK i'm calling now (is_final: False)
2024-12-02 15:56:07,616 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:07,991 [INFO] app1.py:1205 - Speech recognized: OK, I'm calling now.
2024-12-02 15:56:07,992 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=93560f8c5a504cffbf87a4cdbe325d3f, text="OK, I'm calling now.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:56:07,992 [DEBUG] app1.py:1104 - Sending transcription: OK, I'm calling now. (is_final: True)
2024-12-02 15:56:09,635 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:10,639 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:12,662 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:13,673 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:16,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:17,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:18,644 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:56:20,655 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:21,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:24,661 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:25,670 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:28,163 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:56:28,164 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=29ab7b3300eb498db8177a04e49090d6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:56:28,164 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:56:28,648 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:29,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:32,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:33,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:33,975 [DEBUG] app1.py:1214 - Speech recognizing: ezhuvar naina teenage
2024-12-02 15:56:33,975 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b7018e40ce2c42cdbd8f75345f373267, text="ezhuvar naina teenage", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:33,976 [DEBUG] app1.py:1104 - Sending transcription: ezhuvar naina teenage (is_final: False)
2024-12-02 15:56:34,379 [DEBUG] app1.py:1214 - Speech recognizing: ezhuvar naina teenage karunanidhi
2024-12-02 15:56:34,379 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a2004707bf804c039fe5d9c4f2bf1cd8, text="ezhuvar naina teenage karunanidhi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:34,380 [DEBUG] app1.py:1104 - Sending transcription: ezhuvar naina teenage karunanidhi (is_final: False)
2024-12-02 15:56:35,276 [DEBUG] app1.py:1214 - Speech recognizing: ezhuvar naina teenage karunanidhi karunanidhi
2024-12-02 15:56:35,277 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1cb8bc7214f44e0db87104064bf2546c, text="ezhuvar naina teenage karunanidhi karunanidhi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:35,278 [DEBUG] app1.py:1104 - Sending transcription: ezhuvar naina teenage karunanidhi karunanidhi (is_final: False)
2024-12-02 15:56:36,065 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:37,079 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:39,090 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:39,675 [DEBUG] app1.py:1214 - Speech recognizing: language
2024-12-02 15:56:39,677 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e4fc9fe11c974ddf949318e20f2d2981, text="language", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:39,677 [DEBUG] app1.py:1104 - Sending transcription: language (is_final: False)
2024-12-02 15:56:40,094 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:41,185 [INFO] app1.py:1205 - Speech recognized: Language.
2024-12-02 15:56:41,187 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=698c210d9392409c8724839ee19699c8, text="Language.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:56:41,188 [DEBUG] app1.py:1104 - Sending transcription: Language. (is_final: True)
2024-12-02 15:56:42,102 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:43,113 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:45,655 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:46,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:48,645 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:56:49,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:50,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:50,681 [DEBUG] app1.py:1214 - Speech recognizing: a
2024-12-02 15:56:50,681 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2b535c922b51482e8d26234476b27f75, text="a", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:50,682 [DEBUG] app1.py:1104 - Sending transcription: a (is_final: False)
2024-12-02 15:56:50,864 [DEBUG] app1.py:1214 - Speech recognizing: aayad
2024-12-02 15:56:50,865 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=67a4bb65cf654a67a2920c74dd7209c3, text="aayad", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:56:50,867 [DEBUG] app1.py:1104 - Sending transcription: aayad (is_final: False)
2024-12-02 15:56:51,283 [INFO] app1.py:1205 - Speech recognized: Ayaan.
2024-12-02 15:56:51,283 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2c392f2d8ac448c7a1be73034ef9a316, text="Ayaan.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:56:51,283 [DEBUG] app1.py:1104 - Sending transcription: Ayaan. (is_final: True)
2024-12-02 15:56:53,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:54,658 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:56:57,649 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:56:58,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:01,270 [DEBUG] app1.py:1214 - Speech recognizing: are you calling me
2024-12-02 15:57:01,272 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8e07a0b4678f4d8599fd250d13bf7650, text="are you calling me", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:01,272 [DEBUG] app1.py:1104 - Sending transcription: are you calling me (is_final: False)
2024-12-02 15:57:01,648 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:02,160 [INFO] app1.py:1205 - Speech recognized: Are you calling me?
2024-12-02 15:57:02,161 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3619a6bca5a14e21aaa407943f446a92, text="Are you calling me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:57:02,162 [DEBUG] app1.py:1104 - Sending transcription: Are you calling me? (is_final: True)
2024-12-02 15:57:02,654 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:05,450 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:06,462 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:08,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:09,666 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:10,479 [INFO] app1.py:1205 - Speech recognized: Activity. The only guy here is.
2024-12-02 15:57:10,480 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c5a2a0991f694539a65c209793316056, text="Activity. The only guy here is.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:57:10,482 [DEBUG] app1.py:1104 - Sending transcription: Activity. The only guy here is. (is_final: True)
2024-12-02 15:57:12,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:13,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:15,360 [DEBUG] app1.py:1214 - Speech recognizing: what are
2024-12-02 15:57:15,361 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=38db5df2eb86489891783bb119389949, text="what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:15,362 [DEBUG] app1.py:1104 - Sending transcription: what are (is_final: False)
2024-12-02 15:57:15,558 [DEBUG] app1.py:1214 - Speech recognizing: what are you what are you
2024-12-02 15:57:15,578 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e5b67b0cd79a49f6b0d9ca07d79e7ce0, text="what are you what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:15,579 [DEBUG] app1.py:1104 - Sending transcription: what are you what are you (is_final: False)
2024-12-02 15:57:15,945 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 15:57:15,947 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=362fe7711d544d3b9cd2ba375d8eff12, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:15,948 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 15:57:16,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:16,851 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing what
2024-12-02 15:57:16,852 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e4faf803c8114fce976c63b5748e02f4, text="what are you doing what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:16,854 [DEBUG] app1.py:1104 - Sending transcription: what are you doing what (is_final: False)
2024-12-02 15:57:17,255 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing what activ
2024-12-02 15:57:17,257 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=09b38674d8e6409a88d7a0b271c6c043, text="what are you doing what activ", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:17,259 [DEBUG] app1.py:1104 - Sending transcription: what are you doing what activ (is_final: False)
2024-12-02 15:57:17,458 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing what activity
2024-12-02 15:57:17,459 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=276dcfbca0bb4f9e98ef2ac9b30d4ef9, text="what are you doing what activity", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:17,460 [DEBUG] app1.py:1104 - Sending transcription: what are you doing what activity (is_final: False)
2024-12-02 15:57:17,657 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:17,860 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing what activity you are doing
2024-12-02 15:57:17,861 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e9f80b8b4ca94b258f6cb1aa12631ca6, text="what are you doing what activity you are doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:17,862 [DEBUG] app1.py:1104 - Sending transcription: what are you doing what activity you are doing (is_final: False)
2024-12-02 15:57:18,648 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:57:19,151 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing what activity you are doing right now
2024-12-02 15:57:19,152 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=efea464832b94dd7a98d666e7e309750, text="what are you doing what activity you are doing right now", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:19,153 [DEBUG] app1.py:1104 - Sending transcription: what are you doing what activity you are doing right now (is_final: False)
2024-12-02 15:57:20,285 [INFO] app1.py:1205 - Speech recognized: What are you? What are you doing? What activity you are doing right now?
2024-12-02 15:57:20,287 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4b6aa4d38bc04a2587c0308058a3602f, text="What are you? What are you doing? What activity you are doing right now?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:57:20,289 [DEBUG] app1.py:1104 - Sending transcription: What are you? What are you doing? What activity you are doing right now? (is_final: True)
2024-12-02 15:57:20,663 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:21,671 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:24,651 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:25,659 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:27,072 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 15:57:27,073 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=32c8c3cf231046829fe20cd7c41147d4, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:27,073 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 15:57:27,364 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 15:57:27,364 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4032a35861534640aad03b59cebe25cd, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:27,366 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 15:57:27,758 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing right now
2024-12-02 15:57:27,759 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7036abf035ff451eb178b66d7f846dd0, text="what are you doing right now", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:27,761 [DEBUG] app1.py:1104 - Sending transcription: what are you doing right now (is_final: False)
2024-12-02 15:57:28,514 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:28,796 [INFO] app1.py:1205 - Speech recognized: What are you doing right now?
2024-12-02 15:57:28,797 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fb0f38c9c5a34e8f9cbee9944dc14f01, text="What are you doing right now?", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:57:28,799 [DEBUG] app1.py:1104 - Sending transcription: What are you doing right now? (is_final: True)
2024-12-02 15:57:29,529 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:31,549 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:32,557 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:33,197 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti
2024-12-02 15:57:33,198 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e02be02ddf874be38d9d8d31d48bc80c, text="kurika majumdar abhi otti", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:33,200 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti (is_final: False)
2024-12-02 15:57:33,304 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnat
2024-12-02 15:57:33,306 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=553ef6fff47d4a7ab0c8dde5c7f64b0e, text="kurika majumdar abhi otti karnat", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:33,308 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnat (is_final: False)
2024-12-02 15:57:33,398 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnataka
2024-12-02 15:57:33,403 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=227d509fc0e44e3d87e7421ef6a48d0c, text="kurika majumdar abhi otti karnataka", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:33,405 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnataka (is_final: False)
2024-12-02 15:57:33,694 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnatak
2024-12-02 15:57:33,696 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ff81409a13674c07bcb0fdc3f2b839c9, text="kurika majumdar abhi otti karnadi karnatak", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:33,697 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnatak (is_final: False)
2024-12-02 15:57:33,802 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnataka
2024-12-02 15:57:33,804 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=305736761fc841ea89d85b77ee350bd5, text="kurika majumdar abhi otti karnadi karnataka", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:33,805 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnataka (is_final: False)
2024-12-02 15:57:34,301 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnataka rabbi
2024-12-02 15:57:34,302 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ca9bc1dff2c94e3aabb75dee355197ca, text="kurika majumdar abhi otti karnadi karnataka rabbi", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:34,303 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnataka rabbi (is_final: False)
2024-12-02 15:57:34,663 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:35,685 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:35,902 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnataka rabbi karan
2024-12-02 15:57:35,902 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=658a0080c73648bca3666f016a01d7ab, text="kurika majumdar abhi otti karnadi karnataka rabbi karan", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:35,902 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnataka rabbi karan (is_final: False)
2024-12-02 15:57:35,996 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnataka rabbi karani
2024-12-02 15:57:35,997 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=084882b736fb45ddb130763f10b7e07d, text="kurika majumdar abhi otti karnadi karnataka rabbi karani", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:35,997 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnataka rabbi karani (is_final: False)
2024-12-02 15:57:36,307 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnataka rabbi karani karak
2024-12-02 15:57:36,308 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=817d63d718184a5c8bc74ab6c5189da5, text="kurika majumdar abhi otti karnadi karnataka rabbi karani karak", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:36,309 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnataka rabbi karani karak (is_final: False)
2024-12-02 15:57:36,493 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnataka rabbi karani karako
2024-12-02 15:57:36,494 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6a3b31522593480395afcd7535119637, text="kurika majumdar abhi otti karnadi karnataka rabbi karani karako", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:36,495 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnataka rabbi karani karako (is_final: False)
2024-12-02 15:57:36,893 [DEBUG] app1.py:1214 - Speech recognizing: kurika majumdar abhi otti karnadi karnataka rabbi karani karakani
2024-12-02 15:57:36,894 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d235a476d4e2472caeedb2418bdb8205, text="kurika majumdar abhi otti karnadi karnataka rabbi karani karakani", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:57:36,896 [DEBUG] app1.py:1104 - Sending transcription: kurika majumdar abhi otti karnadi karnataka rabbi karani karakani (is_final: False)
2024-12-02 15:57:37,701 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:38,703 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:41,653 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:42,656 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:45,658 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:46,666 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:48,650 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:57:49,084 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:57:49,089 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6b907b83e0d74bd6bb53c4050377ea5b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:57:49,090 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:57:49,661 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:50,664 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:53,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:54,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:57:57,661 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:57:58,668 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:01,659 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:02,670 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:04,289 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:58:04,290 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8140e2d70479405db322f884380ec000, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:58:04,291 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:58:05,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:06,665 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:09,653 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:10,658 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:13,664 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:14,670 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:17,656 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:18,653 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:58:18,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:19,489 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 15:58:19,489 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e298b42297774755930bf918d593031c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:58:19,490 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 15:58:21,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:22,658 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:25,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:26,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:27,458 [DEBUG] app1.py:1214 - Speech recognizing: hallelujah
2024-12-02 15:58:27,459 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ba3779098b9348f6a1469ca177473f3d, text="hallelujah", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:58:27,460 [DEBUG] app1.py:1104 - Sending transcription: hallelujah (is_final: False)
2024-12-02 15:58:29,289 [INFO] app1.py:1205 - Speech recognized: Hallelujah.
2024-12-02 15:58:29,290 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=49e3b44968ee411bb3040d7bb34bbd83, text="Hallelujah.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:58:29,291 [DEBUG] app1.py:1104 - Sending transcription: Hallelujah. (is_final: True)
2024-12-02 15:58:29,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:30,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:32,583 [DEBUG] app1.py:1214 - Speech recognizing: junior
2024-12-02 15:58:32,583 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=34b79a0646ea4784a14cd05d991fddcf, text="junior", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:58:32,584 [DEBUG] app1.py:1104 - Sending transcription: junior (is_final: False)
2024-12-02 15:58:32,855 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:33,863 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:34,380 [INFO] app1.py:1205 - Speech recognized: Junior.
2024-12-02 15:58:34,381 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f702ae9a53914452a432982c5faa3a35, text="Junior.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:58:34,382 [DEBUG] app1.py:1104 - Sending transcription: Junior. (is_final: True)
2024-12-02 15:58:35,869 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:36,872 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:38,885 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:38,963 [DEBUG] app1.py:1214 - Speech recognizing: please stop
2024-12-02 15:58:38,964 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=42a399766db547f28892671507489fc8, text="please stop", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:58:38,964 [DEBUG] app1.py:1104 - Sending transcription: please stop (is_final: False)
2024-12-02 15:58:39,102 [INFO] app1.py:1205 - Speech recognized: Please stop.
2024-12-02 15:58:39,103 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=667055c1061d43fbaa8be97ee26954f6, text="Please stop.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:58:39,103 [DEBUG] app1.py:1104 - Sending transcription: Please stop. (is_final: True)
2024-12-02 15:58:39,894 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:42,381 [DEBUG] app1.py:1214 - Speech recognizing: please call
2024-12-02 15:58:42,381 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=67e04ef811ca4047b87d245e0e4825f9, text="please call", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:58:42,381 [DEBUG] app1.py:1104 - Sending transcription: please call (is_final: False)
2024-12-02 15:58:42,458 [INFO] app1.py:1205 - Speech recognized: Please call.
2024-12-02 15:58:42,458 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e176ca810198427fbaf831ed6ad66037, text="Please call.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:58:42,460 [DEBUG] app1.py:1104 - Sending transcription: Please call. (is_final: True)
2024-12-02 15:58:42,649 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:43,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:46,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:47,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:48,654 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:58:49,930 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:50,946 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:52,953 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:53,954 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:54,042 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 15:58:54,266 [DEBUG] app1.py:1214 - Speech recognizing: bollywood jhum
2024-12-02 15:58:54,268 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=03ee62f0eef843e3af4f055254d235b5, text="bollywood jhum", reason=ResultReason.RecognizingSpeech)
2024-12-02 15:58:54,270 [DEBUG] app1.py:1104 - Sending transcription: bollywood jhum (is_final: False)
2024-12-02 15:58:54,285 [INFO] app1.py:1205 - Speech recognized: Bollywood Jhum.
2024-12-02 15:58:54,288 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7eda5882921a4f14b53c136ac17bc08e, text="Bollywood Jhum.", reason=ResultReason.RecognizedSpeech)
2024-12-02 15:58:54,289 [DEBUG] app1.py:1104 - Sending transcription: Bollywood Jhum. (is_final: True)
2024-12-02 15:58:54,291 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 15:58:55,975 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:58:56,981 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:58:58,991 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:00,007 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:02,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:03,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:06,679 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:07,693 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:10,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:11,667 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:14,656 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:15,666 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:18,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:18,656 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:59:19,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:22,658 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:23,669 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:26,665 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:27,673 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:30,655 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:31,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:34,653 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:35,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:38,692 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:39,700 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:42,660 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:43,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:46,661 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:47,669 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:48,657 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 15:59:50,662 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:51,669 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:54,660 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:55,666 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 15:59:58,853 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 15:59:59,940 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:02,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:03,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:06,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:07,658 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:10,653 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:11,664 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:14,659 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:15,673 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:18,659 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:00:18,663 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:19,668 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:22,651 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:23,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:26,653 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:27,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:30,658 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:31,667 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:34,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:35,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:38,656 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:39,667 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:42,658 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:43,664 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:46,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:47,658 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:48,662 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:00:50,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:51,657 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:54,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:55,664 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:00:58,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:00:59,659 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:02,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:03,666 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:06,649 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:07,659 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:10,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:11,656 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:14,663 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:15,667 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:18,649 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:18,665 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:01:19,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:22,661 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:23,671 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:26,663 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:27,671 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:30,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:31,656 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:34,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:35,654 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:38,656 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:39,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:42,656 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:43,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:46,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:47,659 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:48,667 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:01:50,658 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:51,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:54,649 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:55,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:01:58,660 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:01:59,668 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:02,658 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:03,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:06,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:07,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:10,660 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:11,670 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:14,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:15,655 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:18,656 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:18,671 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:02:19,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:22,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:23,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:26,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:27,672 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:30,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:31,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:34,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:35,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:38,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:39,669 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:42,662 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:43,666 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:46,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:47,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:48,673 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:02:50,648 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:51,657 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:54,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:55,663 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:02:58,657 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:02:59,664 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:02,648 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:03,659 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:06,651 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:07,660 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:10,650 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:11,658 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:14,654 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:15,661 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:18,391 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:03:18,520 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:03:18,612 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:03:18,659 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:18,677 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:03:19,662 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:20,985 [DEBUG] app1.py:1214 - Speech recognizing: hey i love
2024-12-02 16:03:20,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3cbf31dd42bc4aa196a2f090eaac5801, text="hey i love", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:03:21,293 [DEBUG] app1.py:1214 - Speech recognizing: hey i love you
2024-12-02 16:03:21,293 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ff0b878a423d41b89ed95c07c856027e, text="hey i love you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:03:21,795 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:22,288 [INFO] app1.py:1205 - Speech recognized: Hey, I love you.
2024-12-02 16:03:22,289 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e91463ba3c984797b11d67149558ef5e, text="Hey, I love you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:03:22,818 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:24,831 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:25,845 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:03:26,551 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:03:26,551 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:26,552 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:03:26,554 [DEBUG] app1.py:1104 - Sending transcription: hey i love (is_final: False)
2024-12-02 16:03:26,559 [DEBUG] app1.py:1104 - Sending transcription: hey i love you (is_final: False)
2024-12-02 16:03:26,568 [DEBUG] app1.py:1104 - Sending transcription: Hey, I love you. (is_final: True)
2024-12-02 16:03:26,591 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:03:26,603 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey i love', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:03:26,603 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:03:26,604 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:03:26,604 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:03:26,611 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey i love you', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:03:26,613 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hey, I love you.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:03:26,616 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:03:26,617 [DEBUG] app1.py:1042 - Normalized text: 'hey, i love you.'
2024-12-02 16:03:26,621 [DEBUG] app1.py:1056 - Checking cache with key: hey, i love you.:es
2024-12-02 16:03:26,624 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:03:26,628 [INFO] app1.py:933 - Starting translation request - Text: 'hey, i love you.', Target language: es
2024-12-02 16:03:26,632 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:03:26,636 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:03:26,636 [DEBUG] app1.py:964 - Request body: [{'text': 'hey, i love you.'}]
2024-12-02 16:03:27,237 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:03:27,238 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Oye, te quiero.', 'to': 'es'}]}]
2024-12-02 16:03:27,239 [DEBUG] app1.py:974 - Extracted translation: Oye, te quiero.
2024-12-02 16:03:27,240 [INFO] app1.py:975 - Translation completed successfully - Original: 'hey, i love you.' -> Translation: 'Oye, te quiero.' (es)
2024-12-02 16:03:27,243 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Oye, te quiero.
2024-12-02 16:03:27,246 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:03:27,246 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'Oye, te quiero.'}
2024-12-02 16:03:27,270 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Oye, te quiero.', Language: es
2024-12-02 16:03:27,277 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_653e6994-41c0-4b32-987c-76cde2155752.wav
2024-12-02 16:03:27,280 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:03:27,854 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:28,361 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:03:28,361 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_653e6994-41c0-4b32-987c-76cde2155752.wav
2024-12-02 16:03:42,035 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: pt
2024-12-02 16:03:42,579 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:03:42,580 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b0a8f278eb5d4ac99f5ca2bacb93a335, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:03:42,581 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:03:44,991 [DEBUG] app1.py:1214 - Speech recognizing: i love you
2024-12-02 16:03:44,992 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=482d0dbeba9c40b9b4aa3e46fe7cfad4, text="i love you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:03:44,993 [DEBUG] app1.py:1104 - Sending transcription: i love you (is_final: False)
2024-12-02 16:03:45,005 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:03:45,014 [DEBUG] app1.py:1031 - Received translation request - Text: 'i love you', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:03:45,015 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:03:45,585 [INFO] app1.py:1205 - Speech recognized: I love you.
2024-12-02 16:03:45,585 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c2eec1d0f15c43ecb309d37ddb43d33d, text="I love you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:03:45,586 [DEBUG] app1.py:1104 - Sending transcription: I love you. (is_final: True)
2024-12-02 16:03:45,591 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:03:45,592 [DEBUG] app1.py:1031 - Received translation request - Text: 'I love you.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:03:45,593 [DEBUG] app1.py:1042 - Normalized text: 'i love you.'
2024-12-02 16:03:45,593 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 18.971487998962402s
2024-12-02 16:03:45,594 [DEBUG] app1.py:1056 - Checking cache with key: i love you.:es
2024-12-02 16:03:45,595 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:03:45,596 [INFO] app1.py:933 - Starting translation request - Text: 'i love you.', Target language: es
2024-12-02 16:03:45,599 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:03:45,599 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:03:45,599 [DEBUG] app1.py:964 - Request body: [{'text': 'i love you.'}]
2024-12-02 16:03:46,132 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:03:46,133 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'te amo.', 'to': 'es'}]}]
2024-12-02 16:03:46,133 [DEBUG] app1.py:974 - Extracted translation: te amo.
2024-12-02 16:03:46,133 [INFO] app1.py:975 - Translation completed successfully - Original: 'i love you.' -> Translation: 'te amo.' (es)
2024-12-02 16:03:46,134 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: te amo.
2024-12-02 16:03:46,135 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:03:46,135 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'te amo.'}
2024-12-02 16:03:46,145 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'te amo.', Language: es
2024-12-02 16:03:46,150 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_8c91684d-d52b-48b5-a0f6-cd325970a763.wav
2024-12-02 16:03:46,152 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:03:46,964 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:03:46,965 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_8c91684d-d52b-48b5-a0f6-cd325970a763.wav
2024-12-02 16:03:48,678 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:03:51,813 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:03:55,092 [DEBUG] app1.py:1214 - Speech recognizing: i love you
2024-12-02 16:03:55,092 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d69f9a4834ed4e7e8bfbfce7adfd0d53, text="i love you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:03:55,094 [DEBUG] app1.py:1104 - Sending transcription: i love you (is_final: False)
2024-12-02 16:03:55,102 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:03:55,103 [DEBUG] app1.py:1031 - Received translation request - Text: 'i love you', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:03:55,104 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:03:56,006 [INFO] app1.py:1205 - Speech recognized: I love you.
2024-12-02 16:03:56,008 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=920153b7764540c3a24ed76f1fa96dae, text="I love you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:03:56,008 [DEBUG] app1.py:1104 - Sending transcription: I love you. (is_final: True)
2024-12-02 16:03:56,012 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:03:56,013 [DEBUG] app1.py:1031 - Received translation request - Text: 'I love you.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:03:56,013 [DEBUG] app1.py:1042 - Normalized text: 'i love you.'
2024-12-02 16:03:56,014 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 10.421601057052612s
2024-12-02 16:03:56,015 [DEBUG] app1.py:1056 - Checking cache with key: i love you.:es
2024-12-02 16:03:56,017 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:03:56,017 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: te amo.
2024-12-02 16:03:56,018 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:03:56,019 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'te amo.'}
2024-12-02 16:03:56,044 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'te amo.', Language: pt
2024-12-02 16:03:56,046 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d6b6a117-037e-4013-aefd-0194d163350b.wav
2024-12-02 16:03:56,048 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:03:56,902 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:03:56,902 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d6b6a117-037e-4013-aefd-0194d163350b.wav
2024-12-02 16:04:00,110 [DEBUG] app1.py:1214 - Speech recognizing: new
2024-12-02 16:04:00,112 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ca86b9d55c0b4d6a88d27aaf9806c897, text="new", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:00,113 [DEBUG] app1.py:1104 - Sending transcription: new (is_final: False)
2024-12-02 16:04:00,123 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:00,123 [DEBUG] app1.py:1031 - Received translation request - Text: 'new', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:00,123 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:00,897 [DEBUG] app1.py:1214 - Speech recognizing: chili's
2024-12-02 16:04:00,898 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b2fdbfee7884211ba5fb7160c546ecc, text="chili's", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:00,899 [DEBUG] app1.py:1104 - Sending transcription: chili's (is_final: False)
2024-12-02 16:04:00,903 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:00,905 [DEBUG] app1.py:1031 - Received translation request - Text: 'chili's', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:00,905 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:01,987 [DEBUG] app1.py:1214 - Speech recognizing: chili's in port
2024-12-02 16:04:01,988 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=837e3f85576741a895aaadedc8ec198b, text="chili's in port", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:01,989 [DEBUG] app1.py:1104 - Sending transcription: chili's in port (is_final: False)
2024-12-02 16:04:01,993 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:01,993 [DEBUG] app1.py:1031 - Received translation request - Text: 'chili's in port', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:01,995 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:02,300 [DEBUG] app1.py:1214 - Speech recognizing: chili's in portuguese
2024-12-02 16:04:02,301 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=04e510a15fa140d58251d0d388ea6dae, text="chili's in portuguese", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:02,301 [DEBUG] app1.py:1104 - Sending transcription: chili's in portuguese (is_final: False)
2024-12-02 16:04:02,305 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:02,307 [DEBUG] app1.py:1031 - Received translation request - Text: 'chili's in portuguese', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:02,307 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:02,703 [DEBUG] app1.py:1214 - Speech recognizing: chili's in portuguese india
2024-12-02 16:04:02,704 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=043038f45a8b4598994ad80c4da9a9aa, text="chili's in portuguese india", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:02,705 [DEBUG] app1.py:1104 - Sending transcription: chili's in portuguese india (is_final: False)
2024-12-02 16:04:02,710 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:02,711 [DEBUG] app1.py:1031 - Received translation request - Text: 'chili's in portuguese india', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:02,712 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:02,888 [DEBUG] app1.py:1214 - Speech recognizing: chili's in portuguese india portuguese
2024-12-02 16:04:02,889 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e04d6d3a2b3a402da3f0033568948b0d, text="chili's in portuguese india portuguese", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:02,890 [DEBUG] app1.py:1104 - Sending transcription: chili's in portuguese india portuguese (is_final: False)
2024-12-02 16:04:02,893 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:02,894 [DEBUG] app1.py:1031 - Received translation request - Text: 'chili's in portuguese india portuguese', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:02,894 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:03,903 [DEBUG] app1.py:1214 - Speech recognizing: chili's in portuguese india portuguese management
2024-12-02 16:04:03,904 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f9aaeb605012466794961bb272d55761, text="chili's in portuguese india portuguese management", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:03,904 [DEBUG] app1.py:1104 - Sending transcription: chili's in portuguese india portuguese management (is_final: False)
2024-12-02 16:04:03,909 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:03,912 [DEBUG] app1.py:1031 - Received translation request - Text: 'chili's in portuguese india portuguese management', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:03,913 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:05,441 [INFO] app1.py:1205 - Speech recognized: Chili's in Portuguese India. Portuguese management.
2024-12-02 16:04:05,442 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=959409b7c88647ed975316e10af7bceb, text="Chili's in Portuguese India. Portuguese management.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:04:05,444 [DEBUG] app1.py:1104 - Sending transcription: Chili's in Portuguese India. Portuguese management. (is_final: True)
2024-12-02 16:04:05,452 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:05,452 [DEBUG] app1.py:1031 - Received translation request - Text: 'Chili's in Portuguese India. Portuguese management.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:04:05,456 [DEBUG] app1.py:1042 - Normalized text: 'chili's in portuguese india. portuguese management.'
2024-12-02 16:04:05,457 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 9.442426443099976s
2024-12-02 16:04:05,458 [DEBUG] app1.py:1056 - Checking cache with key: chili's in portuguese india. portuguese management.:es
2024-12-02 16:04:05,459 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:04:05,460 [INFO] app1.py:933 - Starting translation request - Text: 'chili's in portuguese india. portuguese management.', Target language: es
2024-12-02 16:04:05,461 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:04:05,461 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:04:05,462 [DEBUG] app1.py:964 - Request body: [{'text': "chili's in portuguese india. portuguese management."}]
2024-12-02 16:04:06,039 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:04:06,040 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': "Chili's en la India portuguesa. Gestin portuguesa.", 'to': 'es'}]}]
2024-12-02 16:04:06,041 [DEBUG] app1.py:974 - Extracted translation: Chili's en la India portuguesa. Gestin portuguesa.
2024-12-02 16:04:06,041 [INFO] app1.py:975 - Translation completed successfully - Original: 'chili's in portuguese india. portuguese management.' -> Translation: 'Chili's en la India portuguesa. Gestin portuguesa.' (es)
2024-12-02 16:04:06,042 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Chili's en la India portuguesa. Gestin portuguesa.
2024-12-02 16:04:06,043 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:04:06,043 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': "Chili's en la India portuguesa. Gestin portuguesa."}
2024-12-02 16:04:06,053 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Chili's en la India portuguesa. Gestin portuguesa.', Language: pt
2024-12-02 16:04:06,058 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_828667c7-0be2-429a-b74c-77b159e4c3ff.wav
2024-12-02 16:04:06,062 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:04:07,102 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:04:07,103 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_828667c7-0be2-429a-b74c-77b159e4c3ff.wav
2024-12-02 16:04:12,484 [DEBUG] app1.py:1214 - Speech recognizing: in change
2024-12-02 16:04:12,484 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=02f4d5c0d4ee44c884803a0e4cb47100, text="in change", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:12,486 [DEBUG] app1.py:1104 - Sending transcription: in change (is_final: False)
2024-12-02 16:04:12,493 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:12,493 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:12,495 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:12,888 [DEBUG] app1.py:1214 - Speech recognizing: in change relatively
2024-12-02 16:04:12,889 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=079c8179d3864144a84e844d64161f82, text="in change relatively", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:12,890 [DEBUG] app1.py:1104 - Sending transcription: in change relatively (is_final: False)
2024-12-02 16:04:12,896 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:12,896 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change relatively', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:12,897 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:14,785 [DEBUG] app1.py:1214 - Speech recognizing: in change relatively in
2024-12-02 16:04:14,785 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fe743b06d28948abbd3cab52a0068045, text="in change relatively in", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:14,785 [DEBUG] app1.py:1104 - Sending transcription: in change relatively in (is_final: False)
2024-12-02 16:04:14,811 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:14,811 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change relatively in', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:14,812 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:15,099 [DEBUG] app1.py:1214 - Speech recognizing: in change relatively in spanish
2024-12-02 16:04:15,100 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1b378a3ab3694d0a86c0e0622cb4bbc5, text="in change relatively in spanish", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:15,101 [DEBUG] app1.py:1104 - Sending transcription: in change relatively in spanish (is_final: False)
2024-12-02 16:04:15,106 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:15,107 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change relatively in spanish', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:15,107 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:15,685 [DEBUG] app1.py:1214 - Speech recognizing: in change relatively in spanish record
2024-12-02 16:04:15,685 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cd92dc8f82c2499683591d69e08ce744, text="in change relatively in spanish record", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:15,685 [DEBUG] app1.py:1104 - Sending transcription: in change relatively in spanish record (is_final: False)
2024-12-02 16:04:15,690 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:15,691 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change relatively in spanish record', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:15,692 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:16,694 [DEBUG] app1.py:1214 - Speech recognizing: in change relatively in spanish record is
2024-12-02 16:04:16,695 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6e3a7f80daf6406f8cc2e7dc800117dd, text="in change relatively in spanish record is", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:16,697 [DEBUG] app1.py:1104 - Sending transcription: in change relatively in spanish record is (is_final: False)
2024-12-02 16:04:16,701 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:16,701 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change relatively in spanish record is', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:16,702 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:16,975 [DEBUG] app1.py:1214 - Speech recognizing: in change relatively in spanish record is sp
2024-12-02 16:04:16,975 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=049a7a747f0441ceb99a673c663fdee2, text="in change relatively in spanish record is sp", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:16,976 [DEBUG] app1.py:1104 - Sending transcription: in change relatively in spanish record is sp (is_final: False)
2024-12-02 16:04:16,980 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:16,981 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change relatively in spanish record is sp', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:16,981 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:17,053 [DEBUG] app1.py:1214 - Speech recognizing: in change relatively in spanish record is spanish
2024-12-02 16:04:17,053 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a8704d3ab2954ad6a6109427546f8106, text="in change relatively in spanish record is spanish", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:17,054 [DEBUG] app1.py:1104 - Sending transcription: in change relatively in spanish record is spanish (is_final: False)
2024-12-02 16:04:17,059 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:17,060 [DEBUG] app1.py:1031 - Received translation request - Text: 'in change relatively in spanish record is spanish', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:17,061 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:18,680 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:04:20,880 [INFO] app1.py:1205 - Speech recognized: Engineer 2A Spanish record is Spanish.
2024-12-02 16:04:20,881 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a596fcaf4b814e8c9f09b6add8f17f23, text="Engineer 2A Spanish record is Spanish.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:04:20,881 [DEBUG] app1.py:1104 - Sending transcription: Engineer 2A Spanish record is Spanish. (is_final: True)
2024-12-02 16:04:20,890 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:20,890 [DEBUG] app1.py:1031 - Received translation request - Text: 'Engineer 2A Spanish record is Spanish.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:04:20,891 [DEBUG] app1.py:1042 - Normalized text: 'engineer 2a spanish record is spanish.'
2024-12-02 16:04:20,892 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 15.435093641281128s
2024-12-02 16:04:20,892 [DEBUG] app1.py:1056 - Checking cache with key: engineer 2a spanish record is spanish.:es
2024-12-02 16:04:20,892 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:04:20,893 [INFO] app1.py:933 - Starting translation request - Text: 'engineer 2a spanish record is spanish.', Target language: es
2024-12-02 16:04:20,893 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:04:20,894 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:04:20,894 [DEBUG] app1.py:964 - Request body: [{'text': 'engineer 2a spanish record is spanish.'}]
2024-12-02 16:04:21,467 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:04:21,467 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Ingeniero 2A El registro espaol es espaol.', 'to': 'es'}]}]
2024-12-02 16:04:21,468 [DEBUG] app1.py:974 - Extracted translation: Ingeniero 2A El registro espaol es espaol.
2024-12-02 16:04:21,469 [INFO] app1.py:975 - Translation completed successfully - Original: 'engineer 2a spanish record is spanish.' -> Translation: 'Ingeniero 2A El registro espaol es espaol.' (es)
2024-12-02 16:04:21,469 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Ingeniero 2A El registro espaol es espaol.
2024-12-02 16:04:21,470 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:04:21,470 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'Ingeniero 2A El registro espaol es espaol.'}
2024-12-02 16:04:21,475 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Ingeniero 2A El registro espaol es espaol.', Language: pt
2024-12-02 16:04:21,477 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_be180a1f-ab33-487b-b05b-34f79279ddbf.wav
2024-12-02 16:04:21,478 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:04:22,586 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:04:22,587 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_be180a1f-ab33-487b-b05b-34f79279ddbf.wav
2024-12-02 16:04:27,582 [DEBUG] app1.py:1214 - Speech recognizing: i love you
2024-12-02 16:04:27,583 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c2d378449e0340e9b8f12af564ec4bdf, text="i love you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:27,583 [DEBUG] app1.py:1104 - Sending transcription: i love you (is_final: False)
2024-12-02 16:04:27,590 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:27,590 [DEBUG] app1.py:1031 - Received translation request - Text: 'i love you', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:27,591 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:28,204 [INFO] app1.py:1205 - Speech recognized: I love you.
2024-12-02 16:04:28,205 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5cb32016d17942b68a84a1a8a4293bef, text="I love you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:04:28,205 [DEBUG] app1.py:1104 - Sending transcription: I love you. (is_final: True)
2024-12-02 16:04:28,209 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:28,210 [DEBUG] app1.py:1031 - Received translation request - Text: 'I love you.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:04:28,211 [DEBUG] app1.py:1042 - Normalized text: 'i love you.'
2024-12-02 16:04:28,211 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 7.319191932678223s
2024-12-02 16:04:28,212 [DEBUG] app1.py:1056 - Checking cache with key: i love you.:es
2024-12-02 16:04:28,212 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:04:28,212 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: te amo.
2024-12-02 16:04:28,213 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:04:28,213 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'te amo.'}
2024-12-02 16:04:28,218 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'te amo.', Language: pt
2024-12-02 16:04:28,219 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3031fad4-08c8-428f-b9a3-534ff4d54993.wav
2024-12-02 16:04:28,221 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:04:28,946 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:04:28,947 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3031fad4-08c8-428f-b9a3-534ff4d54993.wav
2024-12-02 16:04:32,076 [DEBUG] app1.py:1214 - Speech recognizing: i love you
2024-12-02 16:04:32,076 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ced9499936fe4421b4e09034a10749c8, text="i love you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:32,077 [DEBUG] app1.py:1104 - Sending transcription: i love you (is_final: False)
2024-12-02 16:04:32,082 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:32,083 [DEBUG] app1.py:1031 - Received translation request - Text: 'i love you', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:32,083 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:32,681 [INFO] app1.py:1205 - Speech recognized: I love you.
2024-12-02 16:04:32,682 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6ad393e99ef44ed28a589618d0ba5462, text="I love you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:04:32,682 [DEBUG] app1.py:1104 - Sending transcription: I love you. (is_final: True)
2024-12-02 16:04:32,689 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:32,689 [DEBUG] app1.py:1031 - Received translation request - Text: 'I love you.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:04:32,690 [DEBUG] app1.py:1042 - Normalized text: 'i love you.'
2024-12-02 16:04:32,691 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 4.479465007781982s
2024-12-02 16:04:32,691 [DEBUG] app1.py:1056 - Checking cache with key: i love you.:es
2024-12-02 16:04:32,691 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:04:32,692 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: te amo.
2024-12-02 16:04:32,692 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:04:32,692 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'te amo.'}
2024-12-02 16:04:35,981 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:04:35,982 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b964da3fddf642c0a69ac42831aabcbc, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:35,983 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:04:35,988 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:35,989 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:35,989 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:36,179 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:04:36,180 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9618af51fbea4265afa7af84c028c03e, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:36,181 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:04:36,187 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:36,187 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening me', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:36,188 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:36,908 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:04:36,909 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0da701dad0de4de791d2a2457afc036a, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:04:36,910 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:04:36,916 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:36,917 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening me?', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:04:36,918 [DEBUG] app1.py:1042 - Normalized text: 'are you listening me?'
2024-12-02 16:04:36,919 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 4.228304386138916s
2024-12-02 16:04:36,919 [DEBUG] app1.py:1056 - Checking cache with key: are you listening me?:es
2024-12-02 16:04:36,920 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:04:36,920 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Me ests escuchando?
2024-12-02 16:04:36,921 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:04:36,921 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'Me ests escuchando?'}
2024-12-02 16:04:36,928 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Me ests escuchando?', Language: pt
2024-12-02 16:04:36,930 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_80a424c6-ac0d-4a2a-b4b3-5a8bbceccfa4.wav
2024-12-02 16:04:36,931 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:04:37,886 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:04:37,887 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_80a424c6-ac0d-4a2a-b4b3-5a8bbceccfa4.wav
2024-12-02 16:04:46,782 [DEBUG] app1.py:1214 - Speech recognizing: sir
2024-12-02 16:04:46,783 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c7e6a5f36a7d432cb4b3164471412541, text="sir", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:46,784 [DEBUG] app1.py:1104 - Sending transcription: sir (is_final: False)
2024-12-02 16:04:46,792 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:46,793 [DEBUG] app1.py:1031 - Received translation request - Text: 'sir', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:46,794 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:48,490 [DEBUG] app1.py:1214 - Speech recognizing: sir gracias
2024-12-02 16:04:48,491 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2fc66c526bbb42b8b87d32f3c283f20c, text="sir gracias", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:48,492 [DEBUG] app1.py:1104 - Sending transcription: sir gracias (is_final: False)
2024-12-02 16:04:48,497 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:48,497 [DEBUG] app1.py:1031 - Received translation request - Text: 'sir gracias', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:48,498 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:48,681 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:04:50,302 [INFO] app1.py:1205 - Speech recognized: Sir Gracias.
2024-12-02 16:04:50,304 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f09d841baa2a4df0bfd71fdf7e3fa90e, text="Sir Gracias.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:04:50,305 [DEBUG] app1.py:1104 - Sending transcription: Sir Gracias. (is_final: True)
2024-12-02 16:04:50,314 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:50,316 [DEBUG] app1.py:1031 - Received translation request - Text: 'Sir Gracias.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:04:50,317 [DEBUG] app1.py:1042 - Normalized text: 'sir gracias.'
2024-12-02 16:04:50,318 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 13.39828085899353s
2024-12-02 16:04:50,318 [DEBUG] app1.py:1056 - Checking cache with key: sir gracias.:es
2024-12-02 16:04:50,319 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:04:50,319 [INFO] app1.py:933 - Starting translation request - Text: 'sir gracias.', Target language: es
2024-12-02 16:04:50,319 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:04:50,320 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:04:50,320 [DEBUG] app1.py:964 - Request body: [{'text': 'sir gracias.'}]
2024-12-02 16:04:50,576 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:04:50,577 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'es', 'score': 1.0}, 'translations': [{'text': 'sir gracias.', 'to': 'es'}]}]
2024-12-02 16:04:50,578 [DEBUG] app1.py:974 - Extracted translation: sir gracias.
2024-12-02 16:04:50,578 [INFO] app1.py:975 - Translation completed successfully - Original: 'sir gracias.' -> Translation: 'sir gracias.' (es)
2024-12-02 16:04:50,579 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: sir gracias.
2024-12-02 16:04:50,579 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:04:50,579 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'sir gracias.'}
2024-12-02 16:04:50,585 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'sir gracias.', Language: pt
2024-12-02 16:04:50,587 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4bccfa7e-2008-4809-a605-bf76eb719eb6.wav
2024-12-02 16:04:50,588 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:04:51,091 [DEBUG] app1.py:1214 - Speech recognizing: piam
2024-12-02 16:04:51,092 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b10eb247aaa34e1aa186b2568c471d58, text="piam", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:51,092 [DEBUG] app1.py:1104 - Sending transcription: piam (is_final: False)
2024-12-02 16:04:51,098 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:51,099 [DEBUG] app1.py:1031 - Received translation request - Text: 'piam', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:51,100 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:51,231 [DEBUG] app1.py:1214 - Speech recognizing: temo
2024-12-02 16:04:51,232 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e61f3a2e350542d38b8ad8444c35935e, text="temo", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:04:51,232 [DEBUG] app1.py:1104 - Sending transcription: temo (is_final: False)
2024-12-02 16:04:51,235 [INFO] app1.py:1205 - Speech recognized: Temo.
2024-12-02 16:04:51,236 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c02268e195a2489180931294bb39ad34, text="Temo.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:04:51,237 [DEBUG] app1.py:1104 - Sending transcription: Temo. (is_final: True)
2024-12-02 16:04:51,238 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:51,238 [DEBUG] app1.py:1031 - Received translation request - Text: 'temo', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:04:51,240 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:04:51,243 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:04:51,245 [DEBUG] app1.py:1031 - Received translation request - Text: 'Temo.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:04:51,245 [DEBUG] app1.py:1042 - Normalized text: 'temo.'
2024-12-02 16:04:51,246 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 0.9286775588989258s
2024-12-02 16:04:51,246 [DEBUG] app1.py:1050 - Debouncing translation request for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es
2024-12-02 16:04:51,573 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:04:51,573 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4bccfa7e-2008-4809-a605-bf76eb719eb6.wav
2024-12-02 16:05:11,389 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:05:11,391 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=148c64acba044998b5d37aec9a61b0df, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:05:11,392 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:05:18,684 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:05:20,891 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:05:22,912 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:05:23,917 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:05:26,661 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:05:26,797 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:05:26,797 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=00c9e3a4a2624b508bb2d92cf38c9913, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:05:26,798 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:05:27,665 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:05:30,162 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:05:30,162 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a9659cad7e8c4a2cbbad67fe83d8a132, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:30,163 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:05:30,171 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:30,171 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:30,173 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:30,472 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:05:30,472 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1eed54475829488fad4e0b75aa2be500, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:30,473 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:05:30,478 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:30,480 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening me', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:30,481 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:30,661 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:05:31,280 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:05:31,280 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0d46ebddfede4f75af010d091a104981, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:05:31,282 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:05:31,287 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:31,287 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening me?', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:05:31,288 [DEBUG] app1.py:1042 - Normalized text: 'are you listening me?'
2024-12-02 16:05:31,289 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 40.97165513038635s
2024-12-02 16:05:31,290 [DEBUG] app1.py:1056 - Checking cache with key: are you listening me?:es
2024-12-02 16:05:31,290 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:05:31,290 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Me ests escuchando?
2024-12-02 16:05:31,291 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:05:31,291 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'Me ests escuchando?'}
2024-12-02 16:05:31,300 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Me ests escuchando?', Language: pt
2024-12-02 16:05:31,301 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3cf9f19d-e7cb-4d0f-b299-872ca663ba9d.wav
2024-12-02 16:05:31,302 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:05:32,210 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:05:32,211 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3cf9f19d-e7cb-4d0f-b299-872ca663ba9d.wav
2024-12-02 16:05:39,272 [DEBUG] app1.py:1214 - Speech recognizing: may i ask
2024-12-02 16:05:39,273 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d7d6d1a1e4834ea69af97af3580a0232, text="may i ask", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:39,273 [DEBUG] app1.py:1104 - Sending transcription: may i ask (is_final: False)
2024-12-02 16:05:39,280 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:39,281 [DEBUG] app1.py:1031 - Received translation request - Text: 'may i ask', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:39,281 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:39,882 [DEBUG] app1.py:1214 - Speech recognizing: may i ask as
2024-12-02 16:05:39,883 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8769338013d94d7580a1c06586b1ab18, text="may i ask as", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:39,883 [DEBUG] app1.py:1104 - Sending transcription: may i ask as (is_final: False)
2024-12-02 16:05:39,887 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:39,888 [DEBUG] app1.py:1031 - Received translation request - Text: 'may i ask as', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:39,889 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:40,174 [DEBUG] app1.py:1214 - Speech recognizing: may i ask those
2024-12-02 16:05:40,175 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=82a9f68dfcd049a1ab70a556859b8ac8, text="may i ask those", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:40,176 [DEBUG] app1.py:1104 - Sending transcription: may i ask those (is_final: False)
2024-12-02 16:05:40,180 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:40,181 [DEBUG] app1.py:1031 - Received translation request - Text: 'may i ask those', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:40,181 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:40,472 [DEBUG] app1.py:1214 - Speech recognizing: may i ask as K
2024-12-02 16:05:40,472 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fe1e4ba23cb54c9d9736f93e4d9de4cd, text="may i ask as K", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:40,473 [DEBUG] app1.py:1104 - Sending transcription: may i ask as K (is_final: False)
2024-12-02 16:05:40,478 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:40,478 [DEBUG] app1.py:1031 - Received translation request - Text: 'may i ask as K', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:40,480 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:40,579 [DEBUG] app1.py:1214 - Speech recognizing: may i ask as kuchand
2024-12-02 16:05:40,580 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=489ba6e684f148fb9a12d6c87a30fad1, text="may i ask as kuchand", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:40,582 [DEBUG] app1.py:1104 - Sending transcription: may i ask as kuchand (is_final: False)
2024-12-02 16:05:40,589 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:40,592 [DEBUG] app1.py:1031 - Received translation request - Text: 'may i ask as kuchand', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:40,594 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:40,981 [DEBUG] app1.py:1214 - Speech recognizing: may i ask as kuchando
2024-12-02 16:05:40,982 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0d32eeb018464f5db36ec7abe869ae63, text="may i ask as kuchando", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:05:40,983 [DEBUG] app1.py:1104 - Sending transcription: may i ask as kuchando (is_final: False)
2024-12-02 16:05:40,987 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:40,988 [DEBUG] app1.py:1031 - Received translation request - Text: 'may i ask as kuchando', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:05:40,988 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:05:41,103 [INFO] app1.py:1205 - Speech recognized: May I ask those?
2024-12-02 16:05:41,105 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=44e06aa33393428a932b8eafb0e99a6b, text="May I ask those?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:05:41,105 [DEBUG] app1.py:1104 - Sending transcription: May I ask those? (is_final: True)
2024-12-02 16:05:41,110 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:05:41,111 [DEBUG] app1.py:1031 - Received translation request - Text: 'May I ask those?', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:05:41,111 [DEBUG] app1.py:1042 - Normalized text: 'may i ask those?'
2024-12-02 16:05:41,111 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 9.822248935699463s
2024-12-02 16:05:41,112 [DEBUG] app1.py:1056 - Checking cache with key: may i ask those?:es
2024-12-02 16:05:41,112 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:05:41,113 [INFO] app1.py:933 - Starting translation request - Text: 'may i ask those?', Target language: es
2024-12-02 16:05:41,113 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:05:41,115 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:05:41,115 [DEBUG] app1.py:964 - Request body: [{'text': 'may i ask those?'}]
2024-12-02 16:05:41,579 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:05:41,580 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Puedo preguntarles?', 'to': 'es'}]}]
2024-12-02 16:05:41,581 [DEBUG] app1.py:974 - Extracted translation: Puedo preguntarles?
2024-12-02 16:05:41,582 [INFO] app1.py:975 - Translation completed successfully - Original: 'may i ask those?' -> Translation: 'Puedo preguntarles?' (es)
2024-12-02 16:05:41,582 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Puedo preguntarles?
2024-12-02 16:05:41,583 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:05:41,583 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'Puedo preguntarles?'}
2024-12-02 16:05:41,591 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Puedo preguntarles?', Language: pt
2024-12-02 16:05:41,593 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4c02cdbc-aed5-48d0-86ed-b443bbf59ec5.wav
2024-12-02 16:05:41,595 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:05:42,467 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:05:42,468 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4c02cdbc-aed5-48d0-86ed-b443bbf59ec5.wav
2024-12-02 16:05:48,687 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:05:59,755 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:05:59,756 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=603bbca18ec747e6b7c5dc71af89fc50, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:05:59,756 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:06:11,897 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:06:13,905 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:06:14,911 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:06:16,189 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:06:16,190 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a49cbd118a2e4a97a0a3fbf4e55832b6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:06:16,191 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:06:16,927 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:06:17,937 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:06:18,688 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:06:18,717 [DEBUG] app1.py:1214 - Speech recognizing: cosmetus
2024-12-02 16:06:18,717 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9fa67130c7cd4e3c944c90ecbe7287dd, text="cosmetus", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:06:18,718 [DEBUG] app1.py:1104 - Sending transcription: cosmetus (is_final: False)
2024-12-02 16:06:18,726 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:06:18,734 [DEBUG] app1.py:1031 - Received translation request - Text: 'cosmetus', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:06:18,735 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:06:19,917 [DEBUG] app1.py:1214 - Speech recognizing: cosmetus cosmet
2024-12-02 16:06:19,918 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9214343f1def4feeb36f5ad64ab170d0, text="cosmetus cosmet", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:06:19,919 [DEBUG] app1.py:1104 - Sending transcription: cosmetus cosmet (is_final: False)
2024-12-02 16:06:19,923 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:06:19,923 [DEBUG] app1.py:1031 - Received translation request - Text: 'cosmetus cosmet', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:06:19,925 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:06:19,950 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:06:20,011 [DEBUG] app1.py:1214 - Speech recognizing: cosmetus
2024-12-02 16:06:20,011 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c685ba9ed27c4e54939eca3c4d57da83, text="cosmetus", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:06:20,011 [DEBUG] app1.py:1104 - Sending transcription: cosmetus (is_final: False)
2024-12-02 16:06:20,016 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:06:20,016 [DEBUG] app1.py:1031 - Received translation request - Text: 'cosmetus', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:06:20,018 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:06:20,823 [INFO] app1.py:1205 - Speech recognized: Cosmetus.
2024-12-02 16:06:20,824 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f983ff08b72548d68daafd903f7a1ca2, text="Cosmetus.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:06:20,825 [DEBUG] app1.py:1104 - Sending transcription: Cosmetus. (is_final: True)
2024-12-02 16:06:20,829 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:06:20,831 [DEBUG] app1.py:1031 - Received translation request - Text: 'Cosmetus.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:06:20,835 [DEBUG] app1.py:1042 - Normalized text: 'cosmetus.'
2024-12-02 16:06:20,835 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 39.7241325378418s
2024-12-02 16:06:20,838 [DEBUG] app1.py:1056 - Checking cache with key: cosmetus.:es
2024-12-02 16:06:20,838 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:06:20,838 [INFO] app1.py:933 - Starting translation request - Text: 'cosmetus.', Target language: es
2024-12-02 16:06:20,838 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:06:20,838 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:06:20,840 [DEBUG] app1.py:964 - Request body: [{'text': 'cosmetus.'}]
2024-12-02 16:06:20,962 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:06:22,095 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:06:22,095 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.46}, 'translations': [{'text': 'Cosmetus.', 'to': 'es'}]}]
2024-12-02 16:06:22,096 [DEBUG] app1.py:974 - Extracted translation: Cosmetus.
2024-12-02 16:06:22,098 [INFO] app1.py:975 - Translation completed successfully - Original: 'cosmetus.' -> Translation: 'Cosmetus.' (es)
2024-12-02 16:06:22,100 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Cosmetus.
2024-12-02 16:06:22,100 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:06:23,070 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:06:23,073 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'Cosmetus.'}
2024-12-02 16:06:23,106 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Cosmetus.', Language: pt
2024-12-02 16:06:23,106 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_e7d2ca70-2ed2-4f0d-81aa-348ccb78426d.wav
2024-12-02 16:06:23,112 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:06:24,050 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:06:24,052 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_e7d2ca70-2ed2-4f0d-81aa-348ccb78426d.wav
2024-12-02 16:06:41,013 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:06:41,013 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=98b23fd2e66b4810a19a10b977516e8f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:06:41,014 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:06:48,691 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:06:53,420 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:06:55,659 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:06:56,591 [INFO] app1.py:1205 - Speech recognized: Gracias.
2024-12-02 16:06:56,592 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf003f3285874609ba9fe8719e7000aa, text="Gracias.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:06:56,593 [DEBUG] app1.py:1104 - Sending transcription: Gracias. (is_final: True)
2024-12-02 16:06:56,599 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:06:56,600 [DEBUG] app1.py:1031 - Received translation request - Text: 'Gracias.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:06:56,600 [DEBUG] app1.py:1042 - Normalized text: 'gracias.'
2024-12-02 16:06:56,601 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 35.76618194580078s
2024-12-02 16:06:56,602 [DEBUG] app1.py:1056 - Checking cache with key: gracias.:es
2024-12-02 16:06:56,602 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:06:56,603 [INFO] app1.py:933 - Starting translation request - Text: 'gracias.', Target language: es
2024-12-02 16:06:56,603 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:06:56,603 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:06:56,604 [DEBUG] app1.py:964 - Request body: [{'text': 'gracias.'}]
2024-12-02 16:06:56,667 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:06:56,870 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:06:56,871 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'es', 'score': 1.0}, 'translations': [{'text': 'gracias.', 'to': 'es'}]}]
2024-12-02 16:06:56,872 [DEBUG] app1.py:974 - Extracted translation: gracias.
2024-12-02 16:06:56,872 [INFO] app1.py:975 - Translation completed successfully - Original: 'gracias.' -> Translation: 'gracias.' (es)
2024-12-02 16:06:56,873 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: gracias.
2024-12-02 16:06:56,874 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:06:59,648 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:06:59,649 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'gracias.'}
2024-12-02 16:06:59,657 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'gracias.', Language: pt
2024-12-02 16:06:59,658 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_b003de05-d1d1-4b4f-8b9d-161c1d7f8ce3.wav
2024-12-02 16:06:59,659 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:07:00,516 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:07:00,516 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_b003de05-d1d1-4b4f-8b9d-161c1d7f8ce3.wav
2024-12-02 16:07:10,206 [DEBUG] app1.py:1214 - Speech recognizing: ola
2024-12-02 16:07:10,207 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=da3199fa228548d7a9ad97deccde0d3d, text="ola", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:07:10,208 [DEBUG] app1.py:1104 - Sending transcription: ola (is_final: False)
2024-12-02 16:07:10,214 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:07:10,216 [DEBUG] app1.py:1031 - Received translation request - Text: 'ola', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:07:10,216 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:07:11,110 [DEBUG] app1.py:1214 - Speech recognizing: ola te
2024-12-02 16:07:11,110 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ec9a532f3af14e55abd6b4681c469c65, text="ola te", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:07:11,111 [DEBUG] app1.py:1104 - Sending transcription: ola te (is_final: False)
2024-12-02 16:07:11,115 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:07:11,116 [DEBUG] app1.py:1031 - Received translation request - Text: 'ola te', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:07:11,116 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:07:11,203 [DEBUG] app1.py:1214 - Speech recognizing: ola teamo
2024-12-02 16:07:11,203 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0ac987489b0c46f1b6e861c676366919, text="ola teamo", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:07:11,204 [DEBUG] app1.py:1104 - Sending transcription: ola teamo (is_final: False)
2024-12-02 16:07:11,208 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:07:11,209 [DEBUG] app1.py:1031 - Received translation request - Text: 'ola teamo', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:07:11,209 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:07:11,793 [INFO] app1.py:1205 - Speech recognized: Ola Teamo.
2024-12-02 16:07:11,794 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=216d056783d649c8a599066c4aaf4387, text="Ola Teamo.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:07:11,794 [DEBUG] app1.py:1104 - Sending transcription: Ola Teamo. (is_final: True)
2024-12-02 16:07:11,797 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:07:11,798 [DEBUG] app1.py:1031 - Received translation request - Text: 'Ola Teamo.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:07:11,799 [DEBUG] app1.py:1042 - Normalized text: 'ola teamo.'
2024-12-02 16:07:11,799 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 15.198097229003906s
2024-12-02 16:07:11,799 [DEBUG] app1.py:1056 - Checking cache with key: ola teamo.:es
2024-12-02 16:07:11,800 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:07:11,800 [INFO] app1.py:933 - Starting translation request - Text: 'ola teamo.', Target language: es
2024-12-02 16:07:11,801 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:07:11,802 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:07:11,802 [DEBUG] app1.py:964 - Request body: [{'text': 'ola teamo.'}]
2024-12-02 16:07:13,056 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:07:13,057 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.0}, 'translations': [{'text': 'Ola Teamo.', 'to': 'es'}]}]
2024-12-02 16:07:13,057 [DEBUG] app1.py:974 - Extracted translation: Ola Teamo.
2024-12-02 16:07:13,058 [INFO] app1.py:975 - Translation completed successfully - Original: 'ola teamo.' -> Translation: 'Ola Teamo.' (es)
2024-12-02 16:07:13,058 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: Ola Teamo.
2024-12-02 16:07:13,059 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:07:13,059 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'Ola Teamo.'}
2024-12-02 16:07:13,066 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Ola Teamo.', Language: pt
2024-12-02 16:07:13,067 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_be018f49-4f31-45d0-8641-66d5b57a5d80.wav
2024-12-02 16:07:13,069 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:07:13,906 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:07:13,906 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_be018f49-4f31-45d0-8641-66d5b57a5d80.wav
2024-12-02 16:07:18,693 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:07:23,294 [DEBUG] app1.py:1214 - Speech recognizing: gracias
2024-12-02 16:07:23,294 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f75c090bfdf14b30b0e55bc37440d419, text="gracias", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:07:23,295 [DEBUG] app1.py:1104 - Sending transcription: gracias (is_final: False)
2024-12-02 16:07:23,302 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:07:23,303 [DEBUG] app1.py:1031 - Received translation request - Text: 'gracias', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:07:23,303 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:07:25,233 [INFO] app1.py:1205 - Speech recognized: Gracias.
2024-12-02 16:07:25,234 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0be4d06ca3714e47bd4dcd6f32d03992, text="Gracias.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:07:25,234 [DEBUG] app1.py:1104 - Sending transcription: Gracias. (is_final: True)
2024-12-02 16:07:25,239 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:07:25,240 [DEBUG] app1.py:1031 - Received translation request - Text: 'Gracias.', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: True
2024-12-02 16:07:25,240 [DEBUG] app1.py:1042 - Normalized text: 'gracias.'
2024-12-02 16:07:25,241 [DEBUG] app1.py:1048 - Time since last translation for 658f2997-1a74-43f6-b1af-622cc99c8ba6:es: 13.441315412521362s
2024-12-02 16:07:25,241 [DEBUG] app1.py:1056 - Checking cache with key: gracias.:es
2024-12-02 16:07:25,242 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:07:25,242 [DEBUG] app1.py:918 - Sending translation to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: gracias.
2024-12-02 16:07:25,243 [DEBUG] app1.py:925 - Translation sent successfully to client 658f2997-1a74-43f6-b1af-622cc99c8ba6
2024-12-02 16:07:25,243 [DEBUG] app1.py:1144 - Sending message to client 658f2997-1a74-43f6-b1af-622cc99c8ba6: {'type': 'final', 'translation': 'gracias.'}
2024-12-02 16:07:25,251 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'gracias.', Language: pt
2024-12-02 16:07:25,251 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_f72f1866-003e-4919-a5be-8871ced09160.wav
2024-12-02 16:07:25,253 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:07:26,085 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:07:26,086 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_f72f1866-003e-4919-a5be-8871ced09160.wav
2024-12-02 16:07:45,297 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:07:45,297 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0eeac8ba7e584fad9f7f87e0d8cf29d2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:07:45,298 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:07:48,694 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:07:55,562 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:07:57,578 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:07:58,583 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:08:00,384 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:08:00,385 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d91228304f8a4c9a999ce3d3a6d59c6f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:00,385 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:08:00,604 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:08:01,615 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:08:03,623 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:08:04,636 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:08:06,652 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:08:07,279 [DEBUG] app1.py:1214 - Speech recognizing: G
2024-12-02 16:08:07,279 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=330961092a274d35a155793ddf90f9ff, text="G", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:07,280 [DEBUG] app1.py:1104 - Sending transcription: G (is_final: False)
2024-12-02 16:08:07,286 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:08:07,289 [DEBUG] app1.py:1031 - Received translation request - Text: 'G', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:08:07,290 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:08:07,666 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:08:09,683 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:08:10,692 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:08:12,383 [DEBUG] app1.py:1214 - Speech recognizing: let me
2024-12-02 16:08:12,384 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a27ef5e84387483e82ae8213646b2ed3, text="let me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:12,385 [DEBUG] app1.py:1104 - Sending transcription: let me (is_final: False)
2024-12-02 16:08:12,392 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:08:12,393 [DEBUG] app1.py:1031 - Received translation request - Text: 'let me', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:08:12,395 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:08:12,713 [INFO] app1.py:1121 - New translation stream connection for client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, language: es
2024-12-02 16:08:12,774 [DEBUG] app1.py:1214 - Speech recognizing: let me talk
2024-12-02 16:08:12,774 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=54efb3301b154ec98b171935de6bb1c1, text="let me talk", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:12,775 [DEBUG] app1.py:1104 - Sending transcription: let me talk (is_final: False)
2024-12-02 16:08:12,779 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:08:12,781 [DEBUG] app1.py:1031 - Received translation request - Text: 'let me talk', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:08:12,782 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:08:13,674 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with
2024-12-02 16:08:13,674 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=82dca508e1da4e4b94f6dcd3a89c1b4a, text="let me talk with", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:13,675 [DEBUG] app1.py:1104 - Sending transcription: let me talk with (is_final: False)
2024-12-02 16:08:13,679 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:08:13,679 [DEBUG] app1.py:1031 - Received translation request - Text: 'let me talk with', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:08:13,681 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:08:13,719 [WARNING] app1.py:1148 - Client 658f2997-1a74-43f6-b1af-622cc99c8ba6 connection timed out
2024-12-02 16:08:14,281 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my
2024-12-02 16:08:14,282 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1a19ac3b49e34b10baad4c594f93c696, text="let me talk with my", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:14,282 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my (is_final: False)
2024-12-02 16:08:14,286 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:08:14,286 [DEBUG] app1.py:1031 - Received translation request - Text: 'let me talk with my', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:08:14,288 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:08:14,778 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my boys
2024-12-02 16:08:14,778 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=97b08bf6485946e8a4663ba79f7c55bb, text="let me talk with my boys", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:14,779 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my boys (is_final: False)
2024-12-02 16:08:14,783 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:08:14,783 [DEBUG] app1.py:1031 - Received translation request - Text: 'let me talk with my boys', Target: es, Client: 658f2997-1a74-43f6-b1af-622cc99c8ba6, Final: False
2024-12-02 16:08:14,784 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:08:15,983 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my boys trans
2024-12-02 16:08:15,984 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=337c8b6606fd42e195ea399895ce0e9e, text="let me talk with my boys trans", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:15,985 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my boys trans (is_final: False)
2024-12-02 16:08:16,186 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my boys translator
2024-12-02 16:08:16,187 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2a71fae87f47429cad565f06e2adf92e, text="let me talk with my boys translator", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:16,189 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my boys translator (is_final: False)
2024-12-02 16:08:16,683 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my boys translate pune
2024-12-02 16:08:16,684 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=05ad6b783096488eb640f0768892c0fb, text="let me talk with my boys translate pune", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:18,496 [INFO] app1.py:1205 - Speech recognized: Let me talk with my boys, translator.
2024-12-02 16:08:18,496 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e93a1e84b3fa4224b47778d991368174, text="Let me talk with my boys, translator.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:18,697 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6']
2024-12-02 16:08:22,396 [DEBUG] app1.py:1214 - Speech recognizing: OK
2024-12-02 16:08:22,396 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8ae52e976bc34d019704ced7260e6375, text="OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:23,083 [DEBUG] app1.py:1214 - Speech recognizing: OK ah
2024-12-02 16:08:23,085 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ce4de8f46ef433fbb92ec4b4519960b, text="OK ah", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:23,207 [INFO] app1.py:1205 - Speech recognized: OK, ah.
2024-12-02 16:08:23,208 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8100e38e5b3a49ba8aa9cda65666a189, text="OK, ah.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:26,780 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:08:26,781 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0620462978b34d27ae2a3599684f3680, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:27,182 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 16:08:27,183 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=943e40ef9c654f04a1d4ab200bd123f7, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:27,385 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 16:08:27,385 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=995b0c5d1ec34107bb0e4b0bc76cb69e, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:27,990 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 16:08:27,990 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=60c592bc475248e08bb3b30a852f8e26, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:28,152 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:08:28,154 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:08:28,155 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my boys translate pune (is_final: False)
2024-12-02 16:08:28,157 [DEBUG] app1.py:1104 - Sending transcription: Let me talk with my boys, translator. (is_final: True)
2024-12-02 16:08:28,171 [DEBUG] app1.py:1104 - Sending transcription: OK (is_final: False)
2024-12-02 16:08:28,188 [DEBUG] app1.py:1104 - Sending transcription: OK ah (is_final: False)
2024-12-02 16:08:28,206 [DEBUG] app1.py:1104 - Sending transcription: OK, ah. (is_final: True)
2024-12-02 16:08:28,225 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:08:28,234 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 16:08:28,248 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 16:08:28,255 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 16:08:30,085 [DEBUG] app1.py:1214 - Speech recognizing: let me
2024-12-02 16:08:30,086 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=27583736604d4643b33abcbea5135227, text="let me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:30,087 [DEBUG] app1.py:1104 - Sending transcription: let me (is_final: False)
2024-12-02 16:08:30,382 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with
2024-12-02 16:08:30,383 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3cd374b93ecc466cb481df20e7b0d112, text="let me talk with", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:30,384 [DEBUG] app1.py:1104 - Sending transcription: let me talk with (is_final: False)
2024-12-02 16:08:30,474 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my voice
2024-12-02 16:08:30,474 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4de5fa2929774f00abf63b2af6ea156a, text="let me talk with my voice", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:30,475 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my voice (is_final: False)
2024-12-02 16:08:31,783 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my voice translator
2024-12-02 16:08:31,783 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1a16aba73f7b44dc8ad506073659d2e5, text="let me talk with my voice translator", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:31,785 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my voice translator (is_final: False)
2024-12-02 16:08:32,296 [INFO] app1.py:1205 - Speech recognized: Let me talk with my voice translator.
2024-12-02 16:08:32,297 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8e0700e413b145c395be7f970358e687, text="Let me talk with my voice translator.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:32,298 [DEBUG] app1.py:1104 - Sending transcription: Let me talk with my voice translator. (is_final: True)
2024-12-02 16:08:33,973 [DEBUG] app1.py:1214 - Speech recognizing: let me talk
2024-12-02 16:08:33,974 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f058b4f494bb476da4ad0bc83f654543, text="let me talk", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:33,975 [DEBUG] app1.py:1104 - Sending transcription: let me talk (is_final: False)
2024-12-02 16:08:34,473 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with
2024-12-02 16:08:34,473 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5f7dbf292828477a920bf75e6e254f25, text="let me talk with", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:34,474 [DEBUG] app1.py:1104 - Sending transcription: let me talk with (is_final: False)
2024-12-02 16:08:34,985 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with michael
2024-12-02 16:08:34,987 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e059457299444e0881d01521370545e7, text="let me talk with michael", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:34,988 [DEBUG] app1.py:1104 - Sending transcription: let me talk with michael (is_final: False)
2024-12-02 16:08:36,480 [DEBUG] app1.py:1214 - Speech recognizing: let me talk with my voice you better get a guide to refresh
2024-12-02 16:08:36,482 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7ae623cf8cf14948bfee067d0684a0b4, text="let me talk with my voice you better get a guide to refresh", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:36,484 [DEBUG] app1.py:1104 - Sending transcription: let me talk with my voice you better get a guide to refresh (is_final: False)
2024-12-02 16:08:37,801 [INFO] app1.py:1205 - Speech recognized: Let me talk with Michael.
2024-12-02 16:08:37,802 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=57bb17c5f6214becad156643dec72701, text="Let me talk with Michael.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:37,803 [DEBUG] app1.py:1104 - Sending transcription: Let me talk with Michael. (is_final: True)
2024-12-02 16:08:38,857 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:08:38,858 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:08:42,984 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:08:42,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=08ce6607011b4aaf8c7a4fa0ebc2324f, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:42,986 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:08:43,078 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:08:43,079 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4b6333375a304bbd910c7ece13f78399, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:43,080 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:08:45,084 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 16:08:45,085 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f8dee5c9f74447e9a3ee2fd173f8a1d6, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:45,087 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 16:08:45,394 [DEBUG] app1.py:1214 - Speech recognizing: what are
2024-12-02 16:08:45,395 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=320a17033e5d4ab7bdb9767e3f5acc0c, text="what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:45,396 [DEBUG] app1.py:1104 - Sending transcription: what are (is_final: False)
2024-12-02 16:08:45,490 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:08:45,491 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8cfb921404eb4dec942cd5b29e83b59a, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:45,494 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 16:08:46,281 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 16:08:46,282 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da96de17b7614c5bae8474e9d3d9e58a, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:46,284 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 16:08:47,675 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:08:47,675 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=95c1cf9a75fa47cb83d09f15946aeb00, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:47,677 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 16:08:48,618 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: es
2024-12-02 16:08:48,620 [INFO] app1.py:1131 - Creating new client connection: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea
2024-12-02 16:08:48,700 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea']
2024-12-02 16:08:48,972 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 16:08:48,974 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=077bd7760b7e4809910f4ead75c13994, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:48,975 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 16:08:50,577 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:08:50,578 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f3fdba5b00b740698f337338d8e5e708, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:50,579 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 16:08:52,393 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 16:08:52,394 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1a885beb4ef74f38b157bf8333fd737c, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:52,396 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 16:08:56,684 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:08:56,685 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b498878f626645569f64d3d991e170fc, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:08:56,685 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:08:56,778 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:08:56,779 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6a69219a6ee744809a83c7d48b21ceec, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:08:56,781 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:09:00,585 [DEBUG] app1.py:1214 - Speech recognizing: spanish
2024-12-02 16:09:00,586 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=beabb12c5c944bce84bc52cb2f8250c2, text="spanish", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:00,586 [DEBUG] app1.py:1104 - Sending transcription: spanish (is_final: False)
2024-12-02 16:09:01,294 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: pt
2024-12-02 16:09:01,796 [DEBUG] app1.py:1214 - Speech recognizing: spanish guy
2024-12-02 16:09:01,796 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=774f5a5313644257913ae51002bf59b5, text="spanish guy", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:01,797 [DEBUG] app1.py:1104 - Sending transcription: spanish guy (is_final: False)
2024-12-02 16:09:02,390 [DEBUG] app1.py:1214 - Speech recognizing: spanish guy sp
2024-12-02 16:09:02,390 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1904ba4c81b84659b9716af8f4b71209, text="spanish guy sp", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:02,391 [DEBUG] app1.py:1104 - Sending transcription: spanish guy sp (is_final: False)
2024-12-02 16:09:02,484 [DEBUG] app1.py:1214 - Speech recognizing: spanish guy spanish
2024-12-02 16:09:02,485 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4b192fa9eee64087b3c08bb7821ac753, text="spanish guy spanish", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:02,487 [DEBUG] app1.py:1104 - Sending transcription: spanish guy spanish (is_final: False)
2024-12-02 16:09:03,702 [INFO] app1.py:1205 - Speech recognized: Spanish.
2024-12-02 16:09:03,703 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8ced264330bd4636b17e5f87e4a46263, text="Spanish.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:03,703 [DEBUG] app1.py:1104 - Sending transcription: Spanish. (is_final: True)
2024-12-02 16:09:08,886 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:09:08,887 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c26a8f1e5d1f431fbfcf1d79e1035f88, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:08,888 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:09:09,384 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:09:09,385 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=82ce35021ebe4a1ab0b4fb081e938114, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:09,386 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:09:12,987 [DEBUG] app1.py:1214 - Speech recognizing: cometas
2024-12-02 16:09:12,988 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ca1aaec05e6b465a8a639ab4a311adce, text="cometas", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:12,990 [DEBUG] app1.py:1104 - Sending transcription: cometas (is_final: False)
2024-12-02 16:09:13,688 [INFO] app1.py:1205 - Speech recognized: Cometas.
2024-12-02 16:09:13,688 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d492f006f4e9407f8aa26be9f7defde1, text="Cometas.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:13,689 [DEBUG] app1.py:1104 - Sending transcription: Cometas. (is_final: True)
2024-12-02 16:09:14,979 [DEBUG] app1.py:1214 - Speech recognizing: call
2024-12-02 16:09:14,980 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4c9e434689624c21934d93537444ba49, text="call", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:14,981 [DEBUG] app1.py:1104 - Sending transcription: call (is_final: False)
2024-12-02 16:09:16,594 [INFO] app1.py:1205 - Speech recognized: Call.
2024-12-02 16:09:16,595 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a90ccf2b18d64a94928cc5588abe3852, text="Call.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:16,596 [DEBUG] app1.py:1104 - Sending transcription: Call. (is_final: True)
2024-12-02 16:09:18,703 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea']
2024-12-02 16:09:19,484 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:21,378 [DEBUG] app1.py:1214 - Speech recognizing: spanish
2024-12-02 16:09:21,379 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0efb6ee4c3fa442dad2c60e866af4fda, text="spanish", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:21,380 [DEBUG] app1.py:1104 - Sending transcription: spanish (is_final: False)
2024-12-02 16:09:21,661 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: pt
2024-12-02 16:09:22,671 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:23,296 [INFO] app1.py:1205 - Speech recognized: Spanish.
2024-12-02 16:09:23,297 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3d16f6a5ba6942b7a4586c995d51bdfd, text="Spanish.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:23,298 [DEBUG] app1.py:1104 - Sending transcription: Spanish. (is_final: True)
2024-12-02 16:09:25,004 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: pt
2024-12-02 16:09:26,034 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:27,977 [DEBUG] app1.py:1214 - Speech recognizing: hola
2024-12-02 16:09:27,979 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f827d6a6322341d6987f3d2763c2bdd1, text="hola", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:27,980 [DEBUG] app1.py:1104 - Sending transcription: hola (is_final: False)
2024-12-02 16:09:28,055 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: pt
2024-12-02 16:09:29,064 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:29,466 [DEBUG] app1.py:1214 - Speech recognizing: hola translator
2024-12-02 16:09:29,467 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=535b0cb0bddb430aba2988f71921fade, text="hola translator", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:29,467 [DEBUG] app1.py:1104 - Sending transcription: hola translator (is_final: False)
2024-12-02 16:09:29,565 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: es
2024-12-02 16:09:30,571 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:30,706 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:09:30,917 [INFO] app1.py:1205 - Speech recognized: Hola Translator.
2024-12-02 16:09:30,918 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a1a0aa34e6e64bfc831fc266ac610a75, text="Hola Translator.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:30,921 [DEBUG] app1.py:1104 - Sending transcription: Hola Translator. (is_final: True)
2024-12-02 16:09:30,921 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:09:31,073 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: pt
2024-12-02 16:09:31,918 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:09:31,927 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:09:31,935 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: es
2024-12-02 16:09:31,937 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:09:31,989 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:09:32,079 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:32,082 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:09:32,592 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: es
2024-12-02 16:09:32,957 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:33,607 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:35,329 [DEBUG] app1.py:1214 - Speech recognizing: ola
2024-12-02 16:09:35,330 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=168701e4d15443b089be94bc97add333, text="ola", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:35,332 [DEBUG] app1.py:1104 - Sending transcription: ola (is_final: False)
2024-12-02 16:09:35,340 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:09:35,340 [DEBUG] app1.py:1031 - Received translation request - Text: 'ola', Target: es, Client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, Final: False
2024-12-02 16:09:35,343 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:09:35,627 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: es
2024-12-02 16:09:36,635 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:38,653 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: es
2024-12-02 16:09:39,426 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:09:39,427 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ef002f26cbd94d209ec33aa31923d4d3, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:39,428 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 16:09:39,432 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:09:39,433 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, Final: False
2024-12-02 16:09:39,433 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:09:39,656 [WARNING] app1.py:1148 - Client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea connection timed out
2024-12-02 16:09:40,347 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 16:09:40,349 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf75f8ebda7942fca526ab0e57c69fc0, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:40,351 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 16:09:40,358 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:09:40,360 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: es, Client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, Final: True
2024-12-02 16:09:40,362 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 16:09:40,362 [DEBUG] app1.py:1056 - Checking cache with key: hello.:es
2024-12-02 16:09:40,363 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:09:40,363 [DEBUG] app1.py:918 - Sending translation to client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea: Hola.
2024-12-02 16:09:40,363 [DEBUG] app1.py:925 - Translation sent successfully to client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea
2024-12-02 16:09:41,668 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: es
2024-12-02 16:09:41,669 [DEBUG] app1.py:1144 - Sending message to client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 16:09:41,679 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola.', Language: pt
2024-12-02 16:09:41,683 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_5a4c70e6-f177-4387-8487-def4b646bad1.wav
2024-12-02 16:09:41,685 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:09:42,531 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:09:42,531 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_5a4c70e6-f177-4387-8487-def4b646bad1.wav
2024-12-02 16:09:47,220 [DEBUG] app1.py:1214 - Speech recognizing: a little spanish
2024-12-02 16:09:47,221 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=32b58c78b6184578890cd850340ee0ab, text="a little spanish", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:47,223 [DEBUG] app1.py:1104 - Sending transcription: a little spanish (is_final: False)
2024-12-02 16:09:47,231 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:09:47,231 [DEBUG] app1.py:1031 - Received translation request - Text: 'a little spanish', Target: es, Client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, Final: False
2024-12-02 16:09:47,234 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:09:48,707 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea']
2024-12-02 16:09:50,230 [DEBUG] app1.py:1214 - Speech recognizing: thank you
2024-12-02 16:09:50,232 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=55fb4a9167da403e9bc0d67493b95877, text="thank you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:09:50,233 [DEBUG] app1.py:1104 - Sending transcription: thank you (is_final: False)
2024-12-02 16:09:50,241 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:09:50,242 [DEBUG] app1.py:1031 - Received translation request - Text: 'thank you', Target: es, Client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, Final: False
2024-12-02 16:09:50,246 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:09:51,126 [INFO] app1.py:1205 - Speech recognized: Thank you.
2024-12-02 16:09:51,126 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fdc2ab5727b4435db713391e2afada17, text="Thank you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:09:51,127 [DEBUG] app1.py:1104 - Sending transcription: Thank you. (is_final: True)
2024-12-02 16:09:51,130 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:09:51,131 [DEBUG] app1.py:1031 - Received translation request - Text: 'Thank you.', Target: es, Client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, Final: True
2024-12-02 16:09:51,131 [DEBUG] app1.py:1042 - Normalized text: 'thank you.'
2024-12-02 16:09:51,134 [DEBUG] app1.py:1048 - Time since last translation for cc697dd5-1301-43eb-82ab-5e1efdd7e4ea:es: 10.77164340019226s
2024-12-02 16:09:51,134 [DEBUG] app1.py:1056 - Checking cache with key: thank you.:es
2024-12-02 16:09:51,134 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:09:51,134 [INFO] app1.py:933 - Starting translation request - Text: 'thank you.', Target language: es
2024-12-02 16:09:51,136 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:09:51,137 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:09:51,138 [DEBUG] app1.py:964 - Request body: [{'text': 'thank you.'}]
2024-12-02 16:09:51,448 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:09:51,449 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Gracias.', 'to': 'es'}]}]
2024-12-02 16:09:51,449 [DEBUG] app1.py:974 - Extracted translation: Gracias.
2024-12-02 16:09:51,450 [INFO] app1.py:975 - Translation completed successfully - Original: 'thank you.' -> Translation: 'Gracias.' (es)
2024-12-02 16:09:51,451 [DEBUG] app1.py:918 - Sending translation to client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea: Gracias.
2024-12-02 16:09:51,452 [DEBUG] app1.py:925 - Translation sent successfully to client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea
2024-12-02 16:09:51,452 [DEBUG] app1.py:1144 - Sending message to client cc697dd5-1301-43eb-82ab-5e1efdd7e4ea: {'type': 'final', 'translation': 'Gracias.'}
2024-12-02 16:09:51,461 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Gracias.', Language: pt
2024-12-02 16:09:51,466 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_66e47f11-d6b5-45b5-9af3-8f8640ed6c3f.wav
2024-12-02 16:09:51,471 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:09:52,319 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:09:52,320 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_66e47f11-d6b5-45b5-9af3-8f8640ed6c3f.wav
2024-12-02 16:09:59,754 [INFO] app1.py:1121 - New translation stream connection for client: cc697dd5-1301-43eb-82ab-5e1efdd7e4ea, language: pt
2024-12-02 16:10:01,078 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:10:01,300 [INFO] app1.py:1205 - Speech recognized: Churu.
2024-12-02 16:10:01,301 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=356905d51f87424aa65b8a4277d3ca81, text="Churu.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:10:01,303 [DEBUG] app1.py:1104 - Sending transcription: Churu. (is_final: True)
2024-12-02 16:10:01,303 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:10:05,973 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:10:05,992 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:10:05,994 [INFO] app1.py:1121 - New translation stream connection for client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, language: pt
2024-12-02 16:10:05,998 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:10:06,007 [INFO] app1.py:1131 - Creating new client connection: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7
2024-12-02 16:10:06,063 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:10:06,146 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:10:08,813 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:10:08,813 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bae4767ea1f641eea2fb3bee2a2b11ee, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:08,814 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:10:08,823 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:08,825 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: False
2024-12-02 16:10:08,827 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:10:10,618 [DEBUG] app1.py:1214 - Speech recognizing: hi integr
2024-12-02 16:10:10,619 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=78addcae620f4465831366088db250ad, text="hi integr", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:10,621 [DEBUG] app1.py:1104 - Sending transcription: hi integr (is_final: False)
2024-12-02 16:10:10,626 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:10,627 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi integr', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: False
2024-12-02 16:10:10,628 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:10:10,711 [DEBUG] app1.py:1214 - Speech recognizing: hi integrate
2024-12-02 16:10:10,712 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9081f805a2114027841773e084f28c2b, text="hi integrate", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:10,712 [DEBUG] app1.py:1104 - Sending transcription: hi integrate (is_final: False)
2024-12-02 16:10:10,717 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:10,718 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi integrate', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: False
2024-12-02 16:10:10,718 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:10:12,535 [INFO] app1.py:1205 - Speech recognized: Hi integrate.
2024-12-02 16:10:12,537 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e9b7afa7a28e49f2a61a02036718eb4d, text="Hi integrate.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:10:12,538 [DEBUG] app1.py:1104 - Sending transcription: Hi integrate. (is_final: True)
2024-12-02 16:10:12,544 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:12,544 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi integrate.', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: True
2024-12-02 16:10:12,547 [DEBUG] app1.py:1042 - Normalized text: 'hi integrate.'
2024-12-02 16:10:12,547 [DEBUG] app1.py:1056 - Checking cache with key: hi integrate.:pt
2024-12-02 16:10:12,548 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:10:12,549 [INFO] app1.py:933 - Starting translation request - Text: 'hi integrate.', Target language: pt
2024-12-02 16:10:12,549 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:10:12,551 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 16:10:12,552 [DEBUG] app1.py:964 - Request body: [{'text': 'hi integrate.'}]
2024-12-02 16:10:13,802 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:10:13,804 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.8}, 'translations': [{'text': 'oi integrar.', 'to': 'pt'}]}]
2024-12-02 16:10:13,805 [DEBUG] app1.py:974 - Extracted translation: oi integrar.
2024-12-02 16:10:13,806 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi integrate.' -> Translation: 'oi integrar.' (pt)
2024-12-02 16:10:13,808 [DEBUG] app1.py:918 - Sending translation to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7: oi integrar.
2024-12-02 16:10:13,809 [DEBUG] app1.py:925 - Translation sent successfully to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7
2024-12-02 16:10:13,809 [DEBUG] app1.py:1144 - Sending message to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7: {'type': 'final', 'translation': 'oi integrar.'}
2024-12-02 16:10:13,820 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'oi integrar.', Language: pt
2024-12-02 16:10:13,821 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_e2b5e2c3-5395-431b-9cbe-7d2a992e0f7c.wav
2024-12-02 16:10:13,822 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:10:14,681 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:10:14,683 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_e2b5e2c3-5395-431b-9cbe-7d2a992e0f7c.wav
2024-12-02 16:10:18,710 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7']
2024-12-02 16:10:21,319 [DEBUG] app1.py:1214 - Speech recognizing: kiwil
2024-12-02 16:10:21,320 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d06e541a87674ecc87d14a41e2b42b33, text="kiwil", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:21,323 [DEBUG] app1.py:1104 - Sending transcription: kiwil (is_final: False)
2024-12-02 16:10:21,361 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:21,365 [DEBUG] app1.py:1031 - Received translation request - Text: 'kiwil', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: False
2024-12-02 16:10:21,366 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:10:26,112 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:10:26,112 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7ec100a63a2546c28652df1cb3e7dc91, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:26,112 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 16:10:26,116 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:26,117 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: False
2024-12-02 16:10:26,121 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:10:26,221 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:10:26,221 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=363ac700ba9e496abb4c5b9395c182f2, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:26,222 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:10:26,226 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:26,227 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: False
2024-12-02 16:10:26,227 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:10:28,087 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 16:10:28,088 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=95e497d2dab341608ae37b6a26064d02, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:10:28,090 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 16:10:28,098 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:28,099 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening?', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: True
2024-12-02 16:10:28,100 [DEBUG] app1.py:1042 - Normalized text: 'are you listening?'
2024-12-02 16:10:28,100 [DEBUG] app1.py:1048 - Time since last translation for ad7df895-1a53-4766-8bdc-ae5c0bf12ae7:pt: 15.552537441253662s
2024-12-02 16:10:28,101 [DEBUG] app1.py:1056 - Checking cache with key: are you listening?:pt
2024-12-02 16:10:28,101 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:10:28,102 [INFO] app1.py:933 - Starting translation request - Text: 'are you listening?', Target language: pt
2024-12-02 16:10:28,103 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:10:28,103 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 16:10:28,103 [DEBUG] app1.py:964 - Request body: [{'text': 'are you listening?'}]
2024-12-02 16:10:28,810 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:10:28,810 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Voc est ouvindo?', 'to': 'pt'}]}]
2024-12-02 16:10:28,811 [DEBUG] app1.py:974 - Extracted translation: Voc est ouvindo?
2024-12-02 16:10:28,811 [INFO] app1.py:975 - Translation completed successfully - Original: 'are you listening?' -> Translation: 'Voc est ouvindo?' (pt)
2024-12-02 16:10:28,812 [DEBUG] app1.py:918 - Sending translation to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7: Voc est ouvindo?
2024-12-02 16:10:28,812 [DEBUG] app1.py:925 - Translation sent successfully to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7
2024-12-02 16:10:28,812 [DEBUG] app1.py:1144 - Sending message to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7: {'type': 'final', 'translation': 'Voc est ouvindo?'}
2024-12-02 16:10:28,820 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Voc est ouvindo?', Language: pt
2024-12-02 16:10:28,840 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d4d59187-2fb1-4bd8-aada-23fd5cff3816.wav
2024-12-02 16:10:28,841 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:10:29,793 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:10:29,795 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d4d59187-2fb1-4bd8-aada-23fd5cff3816.wav
2024-12-02 16:10:37,732 [DEBUG] app1.py:1214 - Speech recognizing: to
2024-12-02 16:10:37,734 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=339edb93723345099521dd01faf7ae26, text="to", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:37,736 [DEBUG] app1.py:1104 - Sending transcription: to (is_final: False)
2024-12-02 16:10:37,745 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:37,748 [DEBUG] app1.py:1031 - Received translation request - Text: 'to', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: False
2024-12-02 16:10:37,748 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:10:39,524 [INFO] app1.py:1205 - Speech recognized: To.
2024-12-02 16:10:39,525 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dfa74546a9334e778200b0987feb806a, text="To.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:10:39,526 [DEBUG] app1.py:1104 - Sending transcription: To. (is_final: True)
2024-12-02 16:10:39,530 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:10:39,532 [DEBUG] app1.py:1031 - Received translation request - Text: 'To.', Target: pt, Client: ad7df895-1a53-4766-8bdc-ae5c0bf12ae7, Final: True
2024-12-02 16:10:39,532 [DEBUG] app1.py:1042 - Normalized text: 'to.'
2024-12-02 16:10:39,532 [DEBUG] app1.py:1048 - Time since last translation for ad7df895-1a53-4766-8bdc-ae5c0bf12ae7:pt: 11.431794881820679s
2024-12-02 16:10:39,533 [DEBUG] app1.py:1056 - Checking cache with key: to.:pt
2024-12-02 16:10:39,533 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:10:39,533 [INFO] app1.py:933 - Starting translation request - Text: 'to.', Target language: pt
2024-12-02 16:10:39,534 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:10:39,534 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 16:10:39,534 [DEBUG] app1.py:964 - Request body: [{'text': 'to.'}]
2024-12-02 16:10:40,746 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:10:40,747 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'Para.', 'to': 'pt'}]}]
2024-12-02 16:10:40,749 [DEBUG] app1.py:974 - Extracted translation: Para.
2024-12-02 16:10:40,750 [INFO] app1.py:975 - Translation completed successfully - Original: 'to.' -> Translation: 'Para.' (pt)
2024-12-02 16:10:40,751 [DEBUG] app1.py:918 - Sending translation to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7: Para.
2024-12-02 16:10:40,752 [DEBUG] app1.py:925 - Translation sent successfully to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7
2024-12-02 16:10:40,754 [DEBUG] app1.py:1144 - Sending message to client ad7df895-1a53-4766-8bdc-ae5c0bf12ae7: {'type': 'final', 'translation': 'Para.'}
2024-12-02 16:10:40,763 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Para.', Language: pt
2024-12-02 16:10:40,769 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_b815dd12-79c2-4fbc-8b3e-e9144909da63.wav
2024-12-02 16:10:40,771 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:10:41,531 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:10:41,532 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_b815dd12-79c2-4fbc-8b3e-e9144909da63.wav
2024-12-02 16:10:46,347 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:10:46,523 [DEBUG] app1.py:1214 - Speech recognizing: the
2024-12-02 16:10:46,524 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=63bb5dfee9144af0acb0618cd85931e5, text="the", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:10:46,526 [DEBUG] app1.py:1104 - Sending transcription: the (is_final: False)
2024-12-02 16:10:46,531 [INFO] app1.py:1205 - Speech recognized: The.
2024-12-02 16:10:46,533 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=062268e26ddc4171b2481125b909ea11, text="The.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:10:46,534 [DEBUG] app1.py:1104 - Sending transcription: The. (is_final: True)
2024-12-02 16:10:46,535 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:10:48,715 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7']
2024-12-02 16:11:18,716 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7']
2024-12-02 16:11:48,719 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7']
2024-12-02 16:11:49,463 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:11:49,623 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:11:49,723 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:11:52,386 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:11:52,387 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ded54639a8214d66ba729bb70a9248f9, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:52,481 [DEBUG] app1.py:1214 - Speech recognizing: hello rahul
2024-12-02 16:11:52,481 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=caf00c0e7c5b4627897260030083f15b, text="hello rahul", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:52,884 [DEBUG] app1.py:1214 - Speech recognizing: hello rahul how
2024-12-02 16:11:52,885 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=24400cdb9ab04ec8a5292372b51ad711, text="hello rahul how", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:52,982 [DEBUG] app1.py:1214 - Speech recognizing: hello rahul how are you
2024-12-02 16:11:52,983 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7fbc310f7bde4446bef01dec2b67fb02, text="hello rahul how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:53,292 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:11:53,294 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:11:53,305 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 16:11:53,307 [DEBUG] app1.py:1104 - Sending transcription: hello rahul (is_final: False)
2024-12-02 16:11:53,311 [DEBUG] app1.py:1104 - Sending transcription: hello rahul how (is_final: False)
2024-12-02 16:11:53,315 [DEBUG] app1.py:1104 - Sending transcription: hello rahul how are you (is_final: False)
2024-12-02 16:11:54,226 [INFO] app1.py:1205 - Speech recognized: Hello, Rahul, how are you?
2024-12-02 16:11:54,227 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b1510f9fad144c9e96ae6cf86a9a707f, text="Hello, Rahul, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:11:54,228 [DEBUG] app1.py:1104 - Sending transcription: Hello, Rahul, how are you? (is_final: True)
2024-12-02 16:11:55,564 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:11:55,565 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f671f6e9a4214464b1cd8cb3cca3df37, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:55,566 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 16:11:57,388 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 16:11:57,389 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=94300b27a9ad4ba7b678e8d3222d08e5, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:11:57,389 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 16:11:59,172 [DEBUG] app1.py:1214 - Speech recognizing: i am
2024-12-02 16:11:59,173 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=28fd9794e07a4932a9545b7789562ef2, text="i am", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:59,175 [DEBUG] app1.py:1104 - Sending transcription: i am (is_final: False)
2024-12-02 16:11:59,375 [DEBUG] app1.py:1214 - Speech recognizing: i am pastor
2024-12-02 16:11:59,376 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=797cc0be0f294ff1b538ee024aacc9dc, text="i am pastor", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:59,377 [DEBUG] app1.py:1104 - Sending transcription: i am pastor (is_final: False)
2024-12-02 16:11:59,977 [DEBUG] app1.py:1214 - Speech recognizing: i am pastor akhil
2024-12-02 16:11:59,979 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=02a1abfd99fa40bd9075d22d757f09a3, text="i am pastor akhil", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:11:59,980 [DEBUG] app1.py:1104 - Sending transcription: i am pastor akhil (is_final: False)
2024-12-02 16:12:01,624 [INFO] app1.py:1205 - Speech recognized: I am Pastor Akhil.
2024-12-02 16:12:01,625 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a61df5ce0c5b463395360198431f900a, text="I am Pastor Akhil.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:01,627 [DEBUG] app1.py:1104 - Sending transcription: I am Pastor Akhil. (is_final: True)
2024-12-02 16:12:03,569 [DEBUG] app1.py:1214 - Speech recognizing: are you intense
2024-12-02 16:12:03,569 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bdde85966b1640ad9e444a5a62777f14, text="are you intense", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:03,571 [DEBUG] app1.py:1104 - Sending transcription: are you intense (is_final: False)
2024-12-02 16:12:04,270 [DEBUG] app1.py:1214 - Speech recognizing: are you intense rebecca
2024-12-02 16:12:04,271 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7960396d4bbe4f26adafc41727d8e394, text="are you intense rebecca", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:04,273 [DEBUG] app1.py:1104 - Sending transcription: are you intense rebecca (is_final: False)
2024-12-02 16:12:04,671 [DEBUG] app1.py:1214 - Speech recognizing: are you intense
2024-12-02 16:12:04,673 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7cf67257a3b74234829d9f72aeb3542b, text="are you intense", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:04,675 [DEBUG] app1.py:1104 - Sending transcription: are you intense (is_final: False)
2024-12-02 16:12:05,306 [INFO] app1.py:1205 - Speech recognized: Are you intense?
2024-12-02 16:12:05,308 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d3bedb49a32a44bfb78639e5d84ad5b7, text="Are you intense?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:05,310 [DEBUG] app1.py:1104 - Sending transcription: Are you intense? (is_final: True)
2024-12-02 16:12:06,774 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:12:06,774 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c4d76e0b434b4d23b42b91c6ce47381f, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:06,775 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 16:12:08,002 [DEBUG] app1.py:1214 - Speech recognizing: are you in
2024-12-02 16:12:08,003 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=495dd110e91a4280956505686bcbb343, text="are you in", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:08,003 [DEBUG] app1.py:1104 - Sending transcription: are you in (is_final: False)
2024-12-02 16:12:08,870 [DEBUG] app1.py:1214 - Speech recognizing: are you in what are
2024-12-02 16:12:08,871 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=db629650b201481ab9f74bc36c33bb0c, text="are you in what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:08,873 [DEBUG] app1.py:1104 - Sending transcription: are you in what are (is_final: False)
2024-12-02 16:12:08,982 [DEBUG] app1.py:1214 - Speech recognizing: are you in what are you speaking
2024-12-02 16:12:08,982 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0270169f3cc74d51a838b88a9a9a63df, text="are you in what are you speaking", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:08,984 [DEBUG] app1.py:1104 - Sending transcription: are you in what are you speaking (is_final: False)
2024-12-02 16:12:10,086 [INFO] app1.py:1205 - Speech recognized: Are you in? What are you speaking?
2024-12-02 16:12:10,086 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b29d2a75e91b4e249b439cb0de0dedb8, text="Are you in? What are you speaking?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:10,087 [DEBUG] app1.py:1104 - Sending transcription: Are you in? What are you speaking? (is_final: True)
2024-12-02 16:12:11,473 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:12:11,474 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bc43cb472d394656865053d370d3d60c, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:11,474 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 16:12:12,078 [DEBUG] app1.py:1214 - Speech recognizing: are you in
2024-12-02 16:12:12,079 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c11a9af0e5de47b1b106aa6242282008, text="are you in", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:12,079 [DEBUG] app1.py:1104 - Sending transcription: are you in (is_final: False)
2024-12-02 16:12:12,131 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:12:12,405 [DEBUG] app1.py:1214 - Speech recognizing: are you in what are you
2024-12-02 16:12:12,405 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3f06a45f8cc341b6895dad970748813c, text="are you in what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:12,406 [DEBUG] app1.py:1104 - Sending transcription: are you in what are you (is_final: False)
2024-12-02 16:12:12,421 [INFO] app1.py:1205 - Speech recognized: Are you in? What are you?
2024-12-02 16:12:12,422 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=edc0f87cde304b4b8203d4101adb27e2, text="Are you in? What are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:12,422 [DEBUG] app1.py:1104 - Sending transcription: Are you in? What are you? (is_final: True)
2024-12-02 16:12:12,422 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:12:15,182 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:12:15,191 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:12:15,192 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:12:15,199 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:12:15,200 [INFO] app1.py:1131 - Creating new client connection: 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:12:15,261 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:12:15,353 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:12:18,722 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:12:19,322 [DEBUG] app1.py:1214 - Speech recognizing: hey mr
2024-12-02 16:12:19,323 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c0508b617a444de8b6857d4dc06268c9, text="hey mr", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:19,324 [DEBUG] app1.py:1104 - Sending transcription: hey mr (is_final: False)
2024-12-02 16:12:19,332 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:19,333 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey mr', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:19,336 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:19,816 [DEBUG] app1.py:1214 - Speech recognizing: hey mr rahul how are you
2024-12-02 16:12:19,816 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e8b0333f2e2b46f08de0f1219e58139b, text="hey mr rahul how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:19,818 [DEBUG] app1.py:1104 - Sending transcription: hey mr rahul how are you (is_final: False)
2024-12-02 16:12:19,821 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:19,822 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey mr rahul how are you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:19,823 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:20,829 [INFO] app1.py:1205 - Speech recognized: Hey, Mr. Rahul, how are you?
2024-12-02 16:12:20,829 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=844de47ddd87432bbbc98036b6a5d6f1, text="Hey, Mr. Rahul, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:20,835 [DEBUG] app1.py:1104 - Sending transcription: Hey, Mr. Rahul, how are you? (is_final: True)
2024-12-02 16:12:20,841 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:20,842 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hey, Mr. Rahul, how are you?', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:12:20,843 [DEBUG] app1.py:1042 - Normalized text: 'hey, mr. rahul, how are you?'
2024-12-02 16:12:20,843 [DEBUG] app1.py:1056 - Checking cache with key: hey, mr. rahul, how are you?:es
2024-12-02 16:12:20,844 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:12:20,844 [INFO] app1.py:933 - Starting translation request - Text: 'hey, mr. rahul, how are you?', Target language: es
2024-12-02 16:12:20,844 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:12:20,853 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:12:20,853 [DEBUG] app1.py:964 - Request body: [{'text': 'hey, mr. rahul, how are you?'}]
2024-12-02 16:12:21,193 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:12:21,194 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola, Sr. Rahul, cmo est?', 'to': 'es'}]}]
2024-12-02 16:12:21,195 [DEBUG] app1.py:974 - Extracted translation: Hola, Sr. Rahul, cmo est?
2024-12-02 16:12:21,196 [INFO] app1.py:975 - Translation completed successfully - Original: 'hey, mr. rahul, how are you?' -> Translation: 'Hola, Sr. Rahul, cmo est?' (es)
2024-12-02 16:12:21,197 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Hola, Sr. Rahul, cmo est?
2024-12-02 16:12:21,198 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:12:21,198 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Hola, Sr. Rahul, cmo est?'}
2024-12-02 16:12:21,207 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola, Sr. Rahul, cmo est?', Language: es
2024-12-02 16:12:21,274 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0bf004a0-7881-43a2-a7b7-3b7750c791a3.wav
2024-12-02 16:12:21,297 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:12:22,252 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:12:22,253 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0bf004a0-7881-43a2-a7b7-3b7750c791a3.wav
2024-12-02 16:12:24,006 [DEBUG] app1.py:1214 - Speech recognizing: hola
2024-12-02 16:12:24,006 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=09e640381ee14a088a0096446efa5597, text="hola", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:24,007 [DEBUG] app1.py:1104 - Sending transcription: hola (is_final: False)
2024-12-02 16:12:24,011 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:24,013 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:24,015 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:25,203 [DEBUG] app1.py:1214 - Speech recognizing: hola com
2024-12-02 16:12:25,205 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c707c46b51934547a2d8289d9cfa0b0e, text="hola com", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:25,206 [DEBUG] app1.py:1104 - Sending transcription: hola com (is_final: False)
2024-12-02 16:12:25,214 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:25,215 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola com', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:25,218 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:25,309 [DEBUG] app1.py:1214 - Speech recognizing: hola como esta
2024-12-02 16:12:25,309 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=de71a2fd61bc4cc8bf3414c0c80aaee1, text="hola como esta", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:25,310 [DEBUG] app1.py:1104 - Sending transcription: hola como esta (is_final: False)
2024-12-02 16:12:25,314 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:25,315 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola como esta', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:25,316 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:25,743 [INFO] app1.py:1205 - Speech recognized: Hola como estas.
2024-12-02 16:12:25,744 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=19e0bc241478439fb7819ed2048b53f7, text="Hola como estas.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:25,745 [DEBUG] app1.py:1104 - Sending transcription: Hola como estas. (is_final: True)
2024-12-02 16:12:25,750 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:25,751 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hola como estas.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:12:25,751 [DEBUG] app1.py:1042 - Normalized text: 'hola como estas.'
2024-12-02 16:12:25,751 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 4.907445192337036s
2024-12-02 16:12:25,752 [DEBUG] app1.py:1056 - Checking cache with key: hola como estas.:es
2024-12-02 16:12:25,752 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:12:25,753 [INFO] app1.py:933 - Starting translation request - Text: 'hola como estas.', Target language: es
2024-12-02 16:12:25,753 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:12:25,754 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:12:25,754 [DEBUG] app1.py:964 - Request body: [{'text': 'hola como estas.'}]
2024-12-02 16:12:26,065 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:12:26,066 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'es', 'score': 1.0}, 'translations': [{'text': 'hola como estas.', 'to': 'es'}]}]
2024-12-02 16:12:26,067 [DEBUG] app1.py:974 - Extracted translation: hola como estas.
2024-12-02 16:12:26,067 [INFO] app1.py:975 - Translation completed successfully - Original: 'hola como estas.' -> Translation: 'hola como estas.' (es)
2024-12-02 16:12:26,069 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: hola como estas.
2024-12-02 16:12:26,069 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:12:26,069 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'hola como estas.'}
2024-12-02 16:12:26,074 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'hola como estas.', Language: es
2024-12-02 16:12:26,076 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_bc5cc0c2-8bf6-4099-94d4-54bc2e81d603.wav
2024-12-02 16:12:26,084 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:12:26,817 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 16:12:26,818 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=58a59574036240b981395137b2681b26, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:26,819 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 16:12:26,823 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:26,823 [DEBUG] app1.py:1031 - Received translation request - Text: 'what', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:26,825 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:26,987 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:12:26,988 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_bc5cc0c2-8bf6-4099-94d4-54bc2e81d603.wav
2024-12-02 16:12:27,111 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:12:27,111 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0757c975140746dc82cf09a698bc6e82, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:27,112 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 16:12:27,117 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:27,117 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are you doing', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:27,118 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:28,416 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing i am
2024-12-02 16:12:28,417 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c55e5f1e6a5c4205a6da3f72680bfa6b, text="what are you doing i am", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:28,418 [DEBUG] app1.py:1104 - Sending transcription: what are you doing i am (is_final: False)
2024-12-02 16:12:28,423 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:28,425 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are you doing i am', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:28,426 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:29,317 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing i am i am here
2024-12-02 16:12:29,318 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f277a7dc51004d72aac0c86dbe191bfd, text="what are you doing i am i am here", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:29,319 [DEBUG] app1.py:1104 - Sending transcription: what are you doing i am i am here (is_final: False)
2024-12-02 16:12:29,324 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:29,324 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are you doing i am i am here', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:29,325 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:30,033 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing i am i am here for you
2024-12-02 16:12:30,034 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ba51df935434392b9808dcd638ad8c1, text="what are you doing i am i am here for you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:30,035 [DEBUG] app1.py:1104 - Sending transcription: what are you doing i am i am here for you (is_final: False)
2024-12-02 16:12:30,039 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:30,039 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are you doing i am i am here for you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:30,040 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:31,744 [INFO] app1.py:1205 - Speech recognized: What are you doing? I am. I am here for you.
2024-12-02 16:12:31,745 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9680fdb078e145ee8cd5de95f0b33286, text="What are you doing? I am. I am here for you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:31,746 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? I am. I am here for you. (is_final: True)
2024-12-02 16:12:31,754 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:31,756 [DEBUG] app1.py:1031 - Received translation request - Text: 'What are you doing? I am. I am here for you.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:12:31,757 [DEBUG] app1.py:1042 - Normalized text: 'what are you doing? i am. i am here for you.'
2024-12-02 16:12:31,757 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 6.006440162658691s
2024-12-02 16:12:31,758 [DEBUG] app1.py:1056 - Checking cache with key: what are you doing? i am. i am here for you.:es
2024-12-02 16:12:31,758 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:12:31,759 [INFO] app1.py:933 - Starting translation request - Text: 'what are you doing? i am. i am here for you.', Target language: es
2024-12-02 16:12:31,759 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:12:31,759 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:12:31,760 [DEBUG] app1.py:964 - Request body: [{'text': 'what are you doing? i am. i am here for you.'}]
2024-12-02 16:12:32,107 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:12:32,108 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Qu ests haciendo? Soy yo. Estoy aqu para ti.', 'to': 'es'}]}]
2024-12-02 16:12:32,108 [DEBUG] app1.py:974 - Extracted translation: Qu ests haciendo? Soy yo. Estoy aqu para ti.
2024-12-02 16:12:32,109 [INFO] app1.py:975 - Translation completed successfully - Original: 'what are you doing? i am. i am here for you.' -> Translation: 'Qu ests haciendo? Soy yo. Estoy aqu para ti.' (es)
2024-12-02 16:12:32,110 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Qu ests haciendo? Soy yo. Estoy aqu para ti.
2024-12-02 16:12:32,110 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:12:32,110 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Qu ests haciendo? Soy yo. Estoy aqu para ti.'}
2024-12-02 16:12:32,117 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Qu ests haciendo? Soy yo. Estoy aqu para ti.', Language: es
2024-12-02 16:12:32,123 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_6968ac81-4acb-42fb-8d0f-ebee7aec7b4f.wav
2024-12-02 16:12:32,124 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:12:33,079 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:12:33,080 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_6968ac81-4acb-42fb-8d0f-ebee7aec7b4f.wav
2024-12-02 16:12:37,128 [INFO] app1.py:1205 - Speech recognized: N.
2024-12-02 16:12:37,129 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d5d09f0f51ab4acbbb5b7590b3ace4a8, text="N.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:37,130 [DEBUG] app1.py:1104 - Sending transcription: N. (is_final: True)
2024-12-02 16:12:37,138 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:37,140 [DEBUG] app1.py:1031 - Received translation request - Text: 'N.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:12:37,141 [DEBUG] app1.py:1042 - Normalized text: 'n.'
2024-12-02 16:12:37,142 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 5.384875774383545s
2024-12-02 16:12:37,142 [DEBUG] app1.py:1056 - Checking cache with key: n.:es
2024-12-02 16:12:37,142 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:12:37,143 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: n.
2024-12-02 16:12:37,143 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:12:37,143 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'n.'}
2024-12-02 16:12:40,114 [DEBUG] app1.py:1214 - Speech recognizing: tum
2024-12-02 16:12:40,114 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=da5b08092168479384ddbb29f50a27c3, text="tum", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:40,116 [DEBUG] app1.py:1104 - Sending transcription: tum (is_final: False)
2024-12-02 16:12:40,121 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:40,121 [DEBUG] app1.py:1031 - Received translation request - Text: 'tum', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:40,123 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:40,315 [DEBUG] app1.py:1214 - Speech recognizing: tum kya
2024-12-02 16:12:40,315 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0688ca2c68c141998095dada83db5a3f, text="tum kya", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:40,316 [DEBUG] app1.py:1104 - Sending transcription: tum kya (is_final: False)
2024-12-02 16:12:40,321 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:40,321 [DEBUG] app1.py:1031 - Received translation request - Text: 'tum kya', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:40,323 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:40,704 [DEBUG] app1.py:1214 - Speech recognizing: tum kya kar
2024-12-02 16:12:40,705 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c1486927ce9d4222a369275268669595, text="tum kya kar", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:40,706 [DEBUG] app1.py:1104 - Sending transcription: tum kya kar (is_final: False)
2024-12-02 16:12:40,710 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:40,711 [DEBUG] app1.py:1031 - Received translation request - Text: 'tum kya kar', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:40,712 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:40,815 [DEBUG] app1.py:1214 - Speech recognizing: tum kya karte
2024-12-02 16:12:40,816 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2e9d1416f72944e796ff14721f977ed5, text="tum kya karte", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:40,817 [DEBUG] app1.py:1104 - Sending transcription: tum kya karte (is_final: False)
2024-12-02 16:12:40,821 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:40,821 [DEBUG] app1.py:1031 - Received translation request - Text: 'tum kya karte', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:40,821 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:41,018 [DEBUG] app1.py:1214 - Speech recognizing: tum kya karte ho
2024-12-02 16:12:41,019 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8ad3c2ad40bb4df59039332eac46fdbf, text="tum kya karte ho", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:41,020 [DEBUG] app1.py:1104 - Sending transcription: tum kya karte ho (is_final: False)
2024-12-02 16:12:41,025 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:41,026 [DEBUG] app1.py:1031 - Received translation request - Text: 'tum kya karte ho', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:41,027 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:41,422 [INFO] app1.py:1205 - Speech recognized: Tum kya karte ho.
2024-12-02 16:12:41,423 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d27e50045a38499c938aa2f8af1d1e64, text="Tum kya karte ho.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:41,424 [DEBUG] app1.py:1104 - Sending transcription: Tum kya karte ho. (is_final: True)
2024-12-02 16:12:41,428 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:41,428 [DEBUG] app1.py:1031 - Received translation request - Text: 'Tum kya karte ho.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:12:41,432 [DEBUG] app1.py:1042 - Normalized text: 'tum kya karte ho.'
2024-12-02 16:12:41,433 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 4.291074991226196s
2024-12-02 16:12:41,434 [DEBUG] app1.py:1056 - Checking cache with key: tum kya karte ho.:es
2024-12-02 16:12:41,434 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:12:41,435 [INFO] app1.py:933 - Starting translation request - Text: 'tum kya karte ho.', Target language: es
2024-12-02 16:12:41,436 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:12:41,437 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:12:41,437 [DEBUG] app1.py:964 - Request body: [{'text': 'tum kya karte ho.'}]
2024-12-02 16:12:41,775 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:12:41,844 [DEBUG] app1.py:974 - Extracted translation: A qu te dedicas?
2024-12-02 16:12:41,844 [INFO] app1.py:975 - Translation completed successfully - Original: 'tum kya karte ho.' -> Translation: 'A qu te dedicas?' (es)
2024-12-02 16:12:41,845 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: A qu te dedicas?
2024-12-02 16:12:41,846 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:12:41,846 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'A qu te dedicas?'}
2024-12-02 16:12:41,859 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'A qu te dedicas?', Language: es
2024-12-02 16:12:41,860 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d1e8fcc4-3160-4296-b0de-1c7fb966f0b9.wav
2024-12-02 16:12:41,862 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:12:42,677 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:12:42,678 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d1e8fcc4-3160-4296-b0de-1c7fb966f0b9.wav
2024-12-02 16:12:46,397 [DEBUG] app1.py:1214 - Speech recognizing: S
2024-12-02 16:12:46,398 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=096cd087f96845c29fe918f3bf0d9b9d, text="S", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:46,398 [DEBUG] app1.py:1104 - Sending transcription: S (is_final: False)
2024-12-02 16:12:46,405 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:46,406 [DEBUG] app1.py:1031 - Received translation request - Text: 'S', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:46,407 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:46,802 [DEBUG] app1.py:1214 - Speech recognizing: E copy
2024-12-02 16:12:46,804 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6fd0a71d7da242eca2c4357ccbf32ae4, text="E copy", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:46,804 [DEBUG] app1.py:1104 - Sending transcription: E copy (is_final: False)
2024-12-02 16:12:46,808 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:46,809 [DEBUG] app1.py:1031 - Received translation request - Text: 'E copy', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:46,810 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:47,004 [DEBUG] app1.py:1214 - Speech recognizing: E copy paste
2024-12-02 16:12:47,005 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=693fac3bf4d54360bed44bd1b919435d, text="E copy paste", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:12:47,005 [DEBUG] app1.py:1104 - Sending transcription: E copy paste (is_final: False)
2024-12-02 16:12:47,009 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:47,010 [DEBUG] app1.py:1031 - Received translation request - Text: 'E copy paste', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:12:47,011 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:12:47,830 [INFO] app1.py:1205 - Speech recognized: E Copy paste.
2024-12-02 16:12:47,830 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e3aef5e6f47c476983ca2928a2343910, text="E Copy paste.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:12:47,831 [DEBUG] app1.py:1104 - Sending transcription: E Copy paste. (is_final: True)
2024-12-02 16:12:47,834 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:12:47,835 [DEBUG] app1.py:1031 - Received translation request - Text: 'E Copy paste.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:12:47,836 [DEBUG] app1.py:1042 - Normalized text: 'e copy paste.'
2024-12-02 16:12:47,837 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 6.40439772605896s
2024-12-02 16:12:47,837 [DEBUG] app1.py:1056 - Checking cache with key: e copy paste.:es
2024-12-02 16:12:47,838 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:12:47,838 [INFO] app1.py:933 - Starting translation request - Text: 'e copy paste.', Target language: es
2024-12-02 16:12:47,839 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:12:47,843 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:12:47,846 [DEBUG] app1.py:964 - Request body: [{'text': 'e copy paste.'}]
2024-12-02 16:12:48,413 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:12:48,413 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'it', 'score': 0.78}, 'translations': [{'text': 'y copiar y pegar.', 'to': 'es'}]}]
2024-12-02 16:12:48,414 [DEBUG] app1.py:974 - Extracted translation: y copiar y pegar.
2024-12-02 16:12:48,414 [INFO] app1.py:975 - Translation completed successfully - Original: 'e copy paste.' -> Translation: 'y copiar y pegar.' (es)
2024-12-02 16:12:48,415 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: y copiar y pegar.
2024-12-02 16:12:48,415 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:12:48,415 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'y copiar y pegar.'}
2024-12-02 16:12:48,451 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'y copiar y pegar.', Language: es
2024-12-02 16:12:48,453 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_757c18c0-c033-4082-8eed-0d2736711b12.wav
2024-12-02 16:12:48,471 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:12:48,725 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:12:49,342 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:12:49,343 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_757c18c0-c033-4082-8eed-0d2736711b12.wav
2024-12-02 16:13:01,006 [DEBUG] app1.py:1214 - Speech recognizing: spanish to
2024-12-02 16:13:01,006 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=22e51f0c340d44648f5217f499716076, text="spanish to", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:01,007 [DEBUG] app1.py:1104 - Sending transcription: spanish to (is_final: False)
2024-12-02 16:13:01,014 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:01,015 [DEBUG] app1.py:1031 - Received translation request - Text: 'spanish to', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:01,016 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:01,191 [DEBUG] app1.py:1214 - Speech recognizing: spanish to hindi
2024-12-02 16:13:01,192 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dabc1f4e54f24b6d941b4f675138545a, text="spanish to hindi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:01,192 [DEBUG] app1.py:1104 - Sending transcription: spanish to hindi (is_final: False)
2024-12-02 16:13:01,196 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:01,197 [DEBUG] app1.py:1031 - Received translation request - Text: 'spanish to hindi', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:01,197 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:05,000 [DEBUG] app1.py:1214 - Speech recognizing: mar
2024-12-02 16:13:05,000 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6a44c2a513694f81bf8b16fd30c8522b, text="mar", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:05,000 [DEBUG] app1.py:1104 - Sending transcription: mar (is_final: False)
2024-12-02 16:13:05,005 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:05,006 [DEBUG] app1.py:1031 - Received translation request - Text: 'mar', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:05,007 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:05,296 [DEBUG] app1.py:1214 - Speech recognizing: marini
2024-12-02 16:13:05,297 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a0720fe5eab941c4bf05ca1ec5d30880, text="marini", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:05,298 [DEBUG] app1.py:1104 - Sending transcription: marini (is_final: False)
2024-12-02 16:13:05,302 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:05,303 [DEBUG] app1.py:1031 - Received translation request - Text: 'marini', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:05,305 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:05,595 [DEBUG] app1.py:1214 - Speech recognizing: marine vulgarity
2024-12-02 16:13:05,596 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d19b09b865c94d979994f00c044c3220, text="marine vulgarity", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:05,597 [DEBUG] app1.py:1104 - Sending transcription: marine vulgarity (is_final: False)
2024-12-02 16:13:05,604 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:05,605 [DEBUG] app1.py:1031 - Received translation request - Text: 'marine vulgarity', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:05,606 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:05,951 [INFO] app1.py:1205 - Speech recognized: Marini will get.
2024-12-02 16:13:05,953 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a712a44f43904dcd8e47b36ba345d22c, text="Marini will get.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:13:05,954 [DEBUG] app1.py:1104 - Sending transcription: Marini will get. (is_final: True)
2024-12-02 16:13:05,957 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:05,957 [DEBUG] app1.py:1031 - Received translation request - Text: 'Marini will get.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:13:05,958 [DEBUG] app1.py:1042 - Normalized text: 'marini will get.'
2024-12-02 16:13:05,958 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 18.120601654052734s
2024-12-02 16:13:05,959 [DEBUG] app1.py:1056 - Checking cache with key: marini will get.:es
2024-12-02 16:13:05,962 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:13:05,963 [INFO] app1.py:933 - Starting translation request - Text: 'marini will get.', Target language: es
2024-12-02 16:13:05,969 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:13:05,970 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:13:05,970 [DEBUG] app1.py:964 - Request body: [{'text': 'marini will get.'}]
2024-12-02 16:13:06,493 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:13:06,494 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Marini lo conseguir.', 'to': 'es'}]}]
2024-12-02 16:13:06,495 [DEBUG] app1.py:974 - Extracted translation: Marini lo conseguir.
2024-12-02 16:13:06,496 [INFO] app1.py:975 - Translation completed successfully - Original: 'marini will get.' -> Translation: 'Marini lo conseguir.' (es)
2024-12-02 16:13:06,497 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Marini lo conseguir.
2024-12-02 16:13:06,498 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:13:06,498 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Marini lo conseguir.'}
2024-12-02 16:13:06,505 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Marini lo conseguir.', Language: es
2024-12-02 16:13:06,509 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_49537648-bd09-4fa5-81b2-1ff121c6b327.wav
2024-12-02 16:13:06,521 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:13:07,353 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:13:07,354 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_49537648-bd09-4fa5-81b2-1ff121c6b327.wav
2024-12-02 16:13:07,617 [DEBUG] app1.py:1214 - Speech recognizing: bike athol
2024-12-02 16:13:07,618 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3f3bb328c0e94ac8b88e9980634c6815, text="bike athol", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:07,619 [DEBUG] app1.py:1104 - Sending transcription: bike athol (is_final: False)
2024-12-02 16:13:07,629 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:07,630 [DEBUG] app1.py:1031 - Received translation request - Text: 'bike athol', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:07,631 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:07,912 [DEBUG] app1.py:1214 - Speech recognizing: bike atholotha
2024-12-02 16:13:07,912 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3a3ab87d01314acaaa0c367a82d0a100, text="bike atholotha", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:07,913 [DEBUG] app1.py:1104 - Sending transcription: bike atholotha (is_final: False)
2024-12-02 16:13:07,917 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:07,917 [DEBUG] app1.py:1031 - Received translation request - Text: 'bike atholotha', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:07,919 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:08,208 [DEBUG] app1.py:1214 - Speech recognizing: bike atholotha and
2024-12-02 16:13:08,209 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e5f28f2580e942e78822a5b0373dd531, text="bike atholotha and", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:08,210 [DEBUG] app1.py:1104 - Sending transcription: bike atholotha and (is_final: False)
2024-12-02 16:13:08,215 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:08,215 [DEBUG] app1.py:1031 - Received translation request - Text: 'bike atholotha and', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:08,216 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:08,316 [DEBUG] app1.py:1214 - Speech recognizing: bike atholotha and spanish
2024-12-02 16:13:08,317 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=34e4632fea264e0b9acdc064212761ed, text="bike atholotha and spanish", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:08,319 [DEBUG] app1.py:1104 - Sending transcription: bike atholotha and spanish (is_final: False)
2024-12-02 16:13:08,323 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:08,325 [DEBUG] app1.py:1031 - Received translation request - Text: 'bike atholotha and spanish', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:08,325 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:08,503 [DEBUG] app1.py:1214 - Speech recognizing: bike atholotha and spanish man
2024-12-02 16:13:08,503 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3f210535bf314538a481c6e85d8d573d, text="bike atholotha and spanish man", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:08,506 [DEBUG] app1.py:1104 - Sending transcription: bike atholotha and spanish man (is_final: False)
2024-12-02 16:13:08,511 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:08,511 [DEBUG] app1.py:1031 - Received translation request - Text: 'bike atholotha and spanish man', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:08,511 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:10,163 [INFO] app1.py:1205 - Speech recognized: Bike athletes and Spanish men.
2024-12-02 16:13:10,165 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7420fd99c89d42e4b477a9768dbad389, text="Bike athletes and Spanish men.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:13:10,166 [DEBUG] app1.py:1104 - Sending transcription: Bike athletes and Spanish men. (is_final: True)
2024-12-02 16:13:10,170 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:10,170 [DEBUG] app1.py:1031 - Received translation request - Text: 'Bike athletes and Spanish men.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:13:10,171 [DEBUG] app1.py:1042 - Normalized text: 'bike athletes and spanish men.'
2024-12-02 16:13:10,171 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 4.213195323944092s
2024-12-02 16:13:10,171 [DEBUG] app1.py:1056 - Checking cache with key: bike athletes and spanish men.:es
2024-12-02 16:13:10,171 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:13:10,173 [INFO] app1.py:933 - Starting translation request - Text: 'bike athletes and spanish men.', Target language: es
2024-12-02 16:13:10,173 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:13:10,173 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:13:10,174 [DEBUG] app1.py:964 - Request body: [{'text': 'bike athletes and spanish men.'}]
2024-12-02 16:13:10,469 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:13:10,470 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Atletas de ciclismo y hombres espaoles.', 'to': 'es'}]}]
2024-12-02 16:13:10,472 [DEBUG] app1.py:974 - Extracted translation: Atletas de ciclismo y hombres espaoles.
2024-12-02 16:13:10,472 [INFO] app1.py:975 - Translation completed successfully - Original: 'bike athletes and spanish men.' -> Translation: 'Atletas de ciclismo y hombres espaoles.' (es)
2024-12-02 16:13:10,473 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Atletas de ciclismo y hombres espaoles.
2024-12-02 16:13:10,474 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:13:10,474 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Atletas de ciclismo y hombres espaoles.'}
2024-12-02 16:13:10,478 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Atletas de ciclismo y hombres espaoles.', Language: es
2024-12-02 16:13:10,481 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ba73cbea-654e-48c1-af8d-a875b2f10b86.wav
2024-12-02 16:13:10,484 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:13:11,423 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:13:11,423 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ba73cbea-654e-48c1-af8d-a875b2f10b86.wav
2024-12-02 16:13:13,304 [DEBUG] app1.py:1214 - Speech recognizing: at later
2024-12-02 16:13:13,305 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8e6786ca6fe1442c908975186d37fc9a, text="at later", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:13,306 [DEBUG] app1.py:1104 - Sending transcription: at later (is_final: False)
2024-12-02 16:13:13,313 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:13,314 [DEBUG] app1.py:1031 - Received translation request - Text: 'at later', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:13,314 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:13,491 [DEBUG] app1.py:1214 - Speech recognizing: at latest
2024-12-02 16:13:13,492 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e53caf54c8784059a430c1cacff3b81a, text="at latest", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:13,493 [DEBUG] app1.py:1104 - Sending transcription: at latest (is_final: False)
2024-12-02 16:13:13,497 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:13,498 [DEBUG] app1.py:1031 - Received translation request - Text: 'at latest', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:13,498 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:15,423 [INFO] app1.py:1205 - Speech recognized: At latest.
2024-12-02 16:13:15,423 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=57204e30925e48428a08dca8a96253a9, text="At latest.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:13:15,424 [DEBUG] app1.py:1104 - Sending transcription: At latest. (is_final: True)
2024-12-02 16:13:15,429 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:15,429 [DEBUG] app1.py:1031 - Received translation request - Text: 'At latest.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:13:15,430 [DEBUG] app1.py:1042 - Normalized text: 'at latest.'
2024-12-02 16:13:15,431 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 5.259600877761841s
2024-12-02 16:13:15,443 [DEBUG] app1.py:1056 - Checking cache with key: at latest.:es
2024-12-02 16:13:15,450 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:13:15,451 [INFO] app1.py:933 - Starting translation request - Text: 'at latest.', Target language: es
2024-12-02 16:13:15,452 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:13:15,453 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:13:15,453 [DEBUG] app1.py:964 - Request body: [{'text': 'at latest.'}]
2024-12-02 16:13:15,980 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:13:15,981 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'a ms tardar.', 'to': 'es'}]}]
2024-12-02 16:13:15,981 [DEBUG] app1.py:974 - Extracted translation: a ms tardar.
2024-12-02 16:13:15,983 [INFO] app1.py:975 - Translation completed successfully - Original: 'at latest.' -> Translation: 'a ms tardar.' (es)
2024-12-02 16:13:15,984 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: a ms tardar.
2024-12-02 16:13:15,985 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:13:15,985 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'a ms tardar.'}
2024-12-02 16:13:15,994 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'a ms tardar.', Language: es
2024-12-02 16:13:15,997 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ec75b9ea-7f1b-4518-b2c8-388aa8c05c8e.wav
2024-12-02 16:13:15,998 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:13:16,883 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:13:16,884 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ec75b9ea-7f1b-4518-b2c8-388aa8c05c8e.wav
2024-12-02 16:13:18,727 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:13:19,690 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:13:19,691 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c482fe6be32e4ca18ba4693e2ba26cae, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:19,691 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 16:13:19,698 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:19,700 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:19,702 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:19,895 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:13:19,896 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=27a3eac23aa44f0da4358c06967cf61a, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:19,897 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:13:19,902 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:19,903 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening me', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:19,903 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:20,597 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:13:20,598 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=825cfd0451a346f2b6f339d102012295, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:13:20,599 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:13:20,602 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:20,603 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening me?', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:13:20,603 [DEBUG] app1.py:1042 - Normalized text: 'are you listening me?'
2024-12-02 16:13:20,604 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 5.173391819000244s
2024-12-02 16:13:20,604 [DEBUG] app1.py:1056 - Checking cache with key: are you listening me?:es
2024-12-02 16:13:20,606 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:13:20,606 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Me ests escuchando?
2024-12-02 16:13:20,607 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:13:20,607 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Me ests escuchando?'}
2024-12-02 16:13:20,615 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Me ests escuchando?', Language: es
2024-12-02 16:13:20,626 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_de4b76a3-729c-4511-90f7-4aef1eb10fae.wav
2024-12-02 16:13:20,627 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:13:21,419 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:13:21,419 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_de4b76a3-729c-4511-90f7-4aef1eb10fae.wav
2024-12-02 16:13:33,008 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chand
2024-12-02 16:13:33,009 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=270dbf3b0d8045b5a1da48767248597e, text="chandu chu chand", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:33,010 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chand (is_final: False)
2024-12-02 16:13:33,018 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:33,019 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chand', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:33,021 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:33,217 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chandu
2024-12-02 16:13:33,231 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=510fc6848a5146cf8d06687ed431d35e, text="chandu chu chandu", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:33,233 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chandu (is_final: False)
2024-12-02 16:13:33,238 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:33,239 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chandu', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:33,240 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:34,917 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chandu chand
2024-12-02 16:13:34,919 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bba7ee72fea04150803bf4670dc8edb3, text="chandu chu chandu chand", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:34,920 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chandu chand (is_final: False)
2024-12-02 16:13:34,925 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:34,925 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chandu chand', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:34,926 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:35,229 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chandu kochand
2024-12-02 16:13:35,230 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=031b04bf8bc84384b76677bac0ac1ac3, text="chandu chu chandu kochand", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:35,232 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chandu kochand (is_final: False)
2024-12-02 16:13:35,237 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:35,237 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chandu kochand', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:35,238 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:35,507 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chandu chandu
2024-12-02 16:13:35,508 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ec7cec82a394534aa014ad5191fea43, text="chandu chu chandu chandu", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:35,509 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chandu chandu (is_final: False)
2024-12-02 16:13:35,514 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:35,515 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chandu chandu', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:35,516 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:37,513 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chandu chandu kochand
2024-12-02 16:13:37,514 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a87ee9bd421c412890fca4f088deb7cc, text="chandu chu chandu chandu kochand", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:37,515 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chandu chandu kochand (is_final: False)
2024-12-02 16:13:37,520 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:37,521 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chandu chandu kochand', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:37,523 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:37,715 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chandu chandu kochando
2024-12-02 16:13:37,716 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=05bb1e645f3b475c9b810d60d4808415, text="chandu chu chandu chandu kochando", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:37,718 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chandu chandu kochando (is_final: False)
2024-12-02 16:13:37,722 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:37,723 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chandu chandu kochando', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:37,724 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:39,318 [DEBUG] app1.py:1214 - Speech recognizing: chandu chu chandu chandu kochando are
2024-12-02 16:13:39,319 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5d2621bb78ff4d21b737bd434489d526, text="chandu chu chandu chandu kochando are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:39,320 [DEBUG] app1.py:1104 - Sending transcription: chandu chu chandu chandu kochando are (is_final: False)
2024-12-02 16:13:39,326 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:39,327 [DEBUG] app1.py:1031 - Received translation request - Text: 'chandu chu chandu chandu kochando are', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:39,327 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:39,440 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:13:39,441 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ca0bda70dfa14741b5263161e34989fc, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:39,442 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 16:13:39,446 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:39,447 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:39,449 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:39,503 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:13:39,503 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f82632cd23f54806b62ca1c05e72da71, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:39,504 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:13:39,508 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:39,508 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:39,509 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:39,611 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:13:39,611 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=83afca95277843828948c89088a3b28f, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:39,612 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:13:39,616 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:39,617 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening me', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:39,617 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:40,868 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:13:40,868 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b337064828cd454ebdc0aca416ab4cdf, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:13:40,869 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:13:40,873 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:40,874 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening me?', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:13:40,875 [DEBUG] app1.py:1042 - Normalized text: 'are you listening me?'
2024-12-02 16:13:40,875 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 20.2710862159729s
2024-12-02 16:13:40,875 [DEBUG] app1.py:1056 - Checking cache with key: are you listening me?:es
2024-12-02 16:13:40,876 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:13:40,876 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Me ests escuchando?
2024-12-02 16:13:40,877 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:13:40,877 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Me ests escuchando?'}
2024-12-02 16:13:47,608 [DEBUG] app1.py:1214 - Speech recognizing: hi are you
2024-12-02 16:13:47,609 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=82c09837db1e4414861e7f686d745350, text="hi are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:47,611 [DEBUG] app1.py:1104 - Sending transcription: hi are you (is_final: False)
2024-12-02 16:13:47,619 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:47,620 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi are you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:47,621 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:47,700 [DEBUG] app1.py:1214 - Speech recognizing: hi are you listen
2024-12-02 16:13:47,700 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=74279b9b6f7e4c129f4785a5c661c37e, text="hi are you listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:47,703 [DEBUG] app1.py:1104 - Sending transcription: hi are you listen (is_final: False)
2024-12-02 16:13:47,707 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:47,708 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi are you listen', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:47,708 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:47,794 [DEBUG] app1.py:1214 - Speech recognizing: hi are you listening
2024-12-02 16:13:47,794 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8399ddacc87644189f8b490eea3d081b, text="hi are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:47,795 [DEBUG] app1.py:1104 - Sending transcription: hi are you listening (is_final: False)
2024-12-02 16:13:47,800 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:47,800 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi are you listening', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:47,801 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:48,202 [DEBUG] app1.py:1214 - Speech recognizing: hi are you listening me
2024-12-02 16:13:48,215 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f129941e9c014047aa9f7e60588cd767, text="hi are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:48,216 [DEBUG] app1.py:1104 - Sending transcription: hi are you listening me (is_final: False)
2024-12-02 16:13:48,221 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:48,221 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi are you listening me', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:48,221 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:48,431 [INFO] app1.py:1205 - Speech recognized: Hi, are you listening me?
2024-12-02 16:13:48,432 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2d9aafa4f1e34db5b74e28fe7cbecf6b, text="Hi, are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:13:48,433 [DEBUG] app1.py:1104 - Sending transcription: Hi, are you listening me? (is_final: True)
2024-12-02 16:13:48,437 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:48,437 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, are you listening me?', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:13:48,438 [DEBUG] app1.py:1042 - Normalized text: 'hi, are you listening me?'
2024-12-02 16:13:48,438 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 7.562807559967041s
2024-12-02 16:13:48,439 [DEBUG] app1.py:1056 - Checking cache with key: hi, are you listening me?:es
2024-12-02 16:13:48,439 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:13:48,439 [INFO] app1.py:933 - Starting translation request - Text: 'hi, are you listening me?', Target language: es
2024-12-02 16:13:48,439 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:13:48,440 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:13:48,440 [DEBUG] app1.py:964 - Request body: [{'text': 'hi, are you listening me?'}]
2024-12-02 16:13:48,730 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:13:48,760 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:13:48,761 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola, me ests escuchando?', 'to': 'es'}]}]
2024-12-02 16:13:48,761 [DEBUG] app1.py:974 - Extracted translation: Hola, me ests escuchando?
2024-12-02 16:13:48,762 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi, are you listening me?' -> Translation: 'Hola, me ests escuchando?' (es)
2024-12-02 16:13:48,762 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Hola, me ests escuchando?
2024-12-02 16:13:48,763 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:13:48,763 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Hola, me ests escuchando?'}
2024-12-02 16:13:48,769 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola, me ests escuchando?', Language: es
2024-12-02 16:13:48,770 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ff29bbd9-3d99-427d-b66c-4a7e7e7b6f37.wav
2024-12-02 16:13:48,771 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:13:49,625 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:13:49,625 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ff29bbd9-3d99-427d-b66c-4a7e7e7b6f37.wav
2024-12-02 16:13:51,301 [DEBUG] app1.py:1214 - Speech recognizing: hola
2024-12-02 16:13:51,303 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1f9b13a72e7f4749a0212e9a070368b3, text="hola", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:51,303 [DEBUG] app1.py:1104 - Sending transcription: hola (is_final: False)
2024-12-02 16:13:51,307 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:51,308 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:51,309 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:52,513 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 16:13:52,513 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=07b06049e1d04674b36e954156d00172, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:52,514 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 16:13:52,519 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:52,521 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:52,521 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:54,111 [DEBUG] app1.py:1214 - Speech recognizing: hola is that is good channel are you
2024-12-02 16:13:54,112 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a3ef2b770a9b4d6b813b57b89e3b31af, text="hola is that is good channel are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:54,112 [DEBUG] app1.py:1104 - Sending transcription: hola is that is good channel are you (is_final: False)
2024-12-02 16:13:54,120 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:54,120 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola is that is good channel are you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:54,121 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:54,405 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana are you
2024-12-02 16:13:54,407 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=650e695db6374f79b42995567e0c8b51, text="hey cortana are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:54,409 [DEBUG] app1.py:1104 - Sending transcription: hey cortana are you (is_final: False)
2024-12-02 16:13:54,419 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:54,421 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana are you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:54,422 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:54,513 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:13:54,514 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=59e6d049071d426391a1525cc654a345, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:54,515 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:13:54,519 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:54,519 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:54,520 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:54,715 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana are you listening me
2024-12-02 16:13:54,716 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=67e1923fdfff47b58741ec2958736ab8, text="hey cortana are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:54,716 [DEBUG] app1.py:1104 - Sending transcription: hey cortana are you listening me (is_final: False)
2024-12-02 16:13:54,719 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:54,720 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana are you listening me', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:54,721 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:13:55,415 [INFO] app1.py:1205 - Speech recognized: Hey Cortana, are you listening me?
2024-12-02 16:13:55,415 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=471c30ca1d4c45809e3632cc2aeb7320, text="Hey Cortana, are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:13:55,416 [DEBUG] app1.py:1104 - Sending transcription: Hey Cortana, are you listening me? (is_final: True)
2024-12-02 16:13:55,420 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:55,421 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hey Cortana, are you listening me?', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:13:55,423 [DEBUG] app1.py:1042 - Normalized text: 'hey cortana, are you listening me?'
2024-12-02 16:13:55,423 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 6.985269069671631s
2024-12-02 16:13:55,424 [DEBUG] app1.py:1056 - Checking cache with key: hey cortana, are you listening me?:es
2024-12-02 16:13:55,425 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:13:55,425 [INFO] app1.py:933 - Starting translation request - Text: 'hey cortana, are you listening me?', Target language: es
2024-12-02 16:13:55,425 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:13:55,425 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:13:55,427 [DEBUG] app1.py:964 - Request body: [{'text': 'hey cortana, are you listening me?'}]
2024-12-02 16:13:55,726 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:13:55,727 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola Cortana, me ests escuchando?', 'to': 'es'}]}]
2024-12-02 16:13:55,727 [DEBUG] app1.py:974 - Extracted translation: Hola Cortana, me ests escuchando?
2024-12-02 16:13:55,729 [INFO] app1.py:975 - Translation completed successfully - Original: 'hey cortana, are you listening me?' -> Translation: 'Hola Cortana, me ests escuchando?' (es)
2024-12-02 16:13:55,730 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Hola Cortana, me ests escuchando?
2024-12-02 16:13:55,731 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:13:55,731 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Hola Cortana, me ests escuchando?'}
2024-12-02 16:13:55,740 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola Cortana, me ests escuchando?', Language: es
2024-12-02 16:13:55,742 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_8729b904-e131-4291-8a1f-66189562c987.wav
2024-12-02 16:13:55,752 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:13:56,640 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:13:56,641 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_8729b904-e131-4291-8a1f-66189562c987.wav
2024-12-02 16:13:58,703 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 16:13:58,704 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1fd2e9b8d44946ab9d739edb989eff0e, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:13:58,704 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 16:13:58,709 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:13:58,710 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:13:58,711 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:14,111 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:14:14,113 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=50c2f5aed85d499ab1b98d3cdf5a303b, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:14,114 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:14:14,131 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:14,132 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:14,133 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:15,956 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:14:15,957 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8447a07b47eb4a84b1e00b0b45ff2b85, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:14:15,959 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:14:15,964 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:15,965 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:14:15,966 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 16:14:15,966 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 20.542445421218872s
2024-12-02 16:14:15,967 [DEBUG] app1.py:1056 - Checking cache with key: hi.:es
2024-12-02 16:14:15,967 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:14:15,968 [INFO] app1.py:933 - Starting translation request - Text: 'hi.', Target language: es
2024-12-02 16:14:15,968 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:14:15,969 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:14:15,969 [DEBUG] app1.py:964 - Request body: [{'text': 'hi.'}]
2024-12-02 16:14:16,227 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:14:16,228 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'hola.', 'to': 'es'}]}]
2024-12-02 16:14:16,229 [DEBUG] app1.py:974 - Extracted translation: hola.
2024-12-02 16:14:16,229 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi.' -> Translation: 'hola.' (es)
2024-12-02 16:14:16,230 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: hola.
2024-12-02 16:14:16,231 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:14:16,231 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'hola.'}
2024-12-02 16:14:16,237 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'hola.', Language: es
2024-12-02 16:14:16,237 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_e340114e-2eb7-42ab-ad6f-70b5808ac5f0.wav
2024-12-02 16:14:16,239 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:14:16,993 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:14:16,993 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_e340114e-2eb7-42ab-ad6f-70b5808ac5f0.wav
2024-12-02 16:14:17,011 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:14:17,012 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=48f376f79f33432cb22f7b44bd149021, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:17,013 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:14:17,018 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:17,019 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:17,019 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:18,519 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:14:18,519 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aaeac622e36a467aa88e6eef7fda8e39, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:14:18,520 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:14:18,526 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:18,526 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:14:18,527 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 16:14:18,527 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 2.561453104019165s
2024-12-02 16:14:18,529 [DEBUG] app1.py:1056 - Checking cache with key: hi.:es
2024-12-02 16:14:18,529 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:14:18,530 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: hola.
2024-12-02 16:14:18,530 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:14:18,530 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'hola.'}
2024-12-02 16:14:18,732 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:14:21,513 [DEBUG] app1.py:1214 - Speech recognizing: thank you
2024-12-02 16:14:21,514 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=250d71f863c749e39bbab618daf7f57c, text="thank you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:21,516 [DEBUG] app1.py:1104 - Sending transcription: thank you (is_final: False)
2024-12-02 16:14:21,535 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:21,540 [DEBUG] app1.py:1031 - Received translation request - Text: 'thank you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:21,542 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:22,394 [INFO] app1.py:1205 - Speech recognized: Thank you.
2024-12-02 16:14:22,395 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=57768a2b095447d9a6f4d85dc776b32e, text="Thank you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:14:22,396 [DEBUG] app1.py:1104 - Sending transcription: Thank you. (is_final: True)
2024-12-02 16:14:22,401 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:22,402 [DEBUG] app1.py:1031 - Received translation request - Text: 'Thank you.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:14:22,403 [DEBUG] app1.py:1042 - Normalized text: 'thank you.'
2024-12-02 16:14:22,403 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 3.8754775524139404s
2024-12-02 16:14:22,403 [DEBUG] app1.py:1056 - Checking cache with key: thank you.:es
2024-12-02 16:14:22,404 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:14:22,404 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Gracias.
2024-12-02 16:14:22,405 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:14:22,405 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Gracias.'}
2024-12-02 16:14:22,411 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Gracias.', Language: es
2024-12-02 16:14:22,412 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_c944e5a6-ccd9-4bbf-b22f-9c9f45fc0aad.wav
2024-12-02 16:14:22,413 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:14:23,169 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:14:23,170 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_c944e5a6-ccd9-4bbf-b22f-9c9f45fc0aad.wav
2024-12-02 16:14:27,310 [DEBUG] app1.py:1214 - Speech recognizing: how
2024-12-02 16:14:27,311 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a6295047a0a945dc99e0b23531bb20fc, text="how", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:27,312 [DEBUG] app1.py:1104 - Sending transcription: how (is_final: False)
2024-12-02 16:14:27,319 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:27,320 [DEBUG] app1.py:1031 - Received translation request - Text: 'how', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:27,320 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:27,405 [DEBUG] app1.py:1214 - Speech recognizing: how are
2024-12-02 16:14:27,405 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0ad8c39bab714da18279b6d0ae499887, text="how are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:27,406 [DEBUG] app1.py:1104 - Sending transcription: how are (is_final: False)
2024-12-02 16:14:27,411 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:27,411 [DEBUG] app1.py:1031 - Received translation request - Text: 'how are', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:27,412 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:27,531 [DEBUG] app1.py:1214 - Speech recognizing: how are you
2024-12-02 16:14:27,531 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=333372fef0714e17a6553a05898c1261, text="how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:27,532 [DEBUG] app1.py:1104 - Sending transcription: how are you (is_final: False)
2024-12-02 16:14:27,536 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:27,537 [DEBUG] app1.py:1031 - Received translation request - Text: 'how are you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:27,538 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:28,122 [INFO] app1.py:1205 - Speech recognized: How are you?
2024-12-02 16:14:28,123 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f37951211a6f4249ba61a4c656a4667e, text="How are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:14:28,124 [DEBUG] app1.py:1104 - Sending transcription: How are you? (is_final: True)
2024-12-02 16:14:28,129 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:28,129 [DEBUG] app1.py:1031 - Received translation request - Text: 'How are you?', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:14:28,130 [DEBUG] app1.py:1042 - Normalized text: 'how are you?'
2024-12-02 16:14:28,130 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 5.727323055267334s
2024-12-02 16:14:28,130 [DEBUG] app1.py:1056 - Checking cache with key: how are you?:es
2024-12-02 16:14:28,131 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:14:28,132 [INFO] app1.py:933 - Starting translation request - Text: 'how are you?', Target language: es
2024-12-02 16:14:28,132 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:14:28,133 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:14:28,133 [DEBUG] app1.py:964 - Request body: [{'text': 'how are you?'}]
2024-12-02 16:14:28,400 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:14:28,401 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Cmo ests?', 'to': 'es'}]}]
2024-12-02 16:14:28,402 [DEBUG] app1.py:974 - Extracted translation: Cmo ests?
2024-12-02 16:14:28,402 [INFO] app1.py:975 - Translation completed successfully - Original: 'how are you?' -> Translation: 'Cmo ests?' (es)
2024-12-02 16:14:28,403 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Cmo ests?
2024-12-02 16:14:28,404 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:14:28,404 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Cmo ests?'}
2024-12-02 16:14:28,410 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Cmo ests?', Language: es
2024-12-02 16:14:28,411 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d58281f3-42c3-49df-8193-4cb1cb5c4156.wav
2024-12-02 16:14:28,414 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:14:29,241 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:14:29,241 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_d58281f3-42c3-49df-8193-4cb1cb5c4156.wav
2024-12-02 16:14:35,216 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:14:35,217 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bfce4bcc03dc48529d0c260b57084cef, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:35,217 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:14:35,224 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:35,224 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:35,225 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:35,715 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:14:35,715 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=867015b3c00d4a03be4e33d902f82095, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:14:35,716 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:14:35,721 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:35,721 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening me', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:14:35,722 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:14:36,522 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:14:36,523 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8499651402314f7cb0df196adc0142b6, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:14:36,524 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:14:36,530 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:36,530 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening me?', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:14:36,532 [DEBUG] app1.py:1042 - Normalized text: 'are you listening me?'
2024-12-02 16:14:36,532 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 8.401801824569702s
2024-12-02 16:14:36,533 [DEBUG] app1.py:1056 - Checking cache with key: are you listening me?:es
2024-12-02 16:14:36,533 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:14:36,534 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Me ests escuchando?
2024-12-02 16:14:36,534 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:14:36,534 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Me ests escuchando?'}
2024-12-02 16:14:36,541 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Me ests escuchando?', Language: es
2024-12-02 16:14:36,542 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_f375e596-be42-40c9-8234-0e07e2694ae7.wav
2024-12-02 16:14:36,544 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:14:37,376 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:14:37,377 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_f375e596-be42-40c9-8234-0e07e2694ae7.wav
2024-12-02 16:14:48,735 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:14:54,033 [INFO] app1.py:1205 - Speech recognized: 2000 and 18.
2024-12-02 16:14:54,033 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=59990d9a4ffb495099c0cec02f03575c, text="2000 and 18.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:14:54,034 [DEBUG] app1.py:1104 - Sending transcription: 2000 and 18. (is_final: True)
2024-12-02 16:14:54,040 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:14:54,041 [DEBUG] app1.py:1031 - Received translation request - Text: '2000 and 18.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:14:54,042 [DEBUG] app1.py:1042 - Normalized text: '2000 and 18.'
2024-12-02 16:14:54,043 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 17.51113748550415s
2024-12-02 16:14:54,044 [DEBUG] app1.py:1056 - Checking cache with key: 2000 and 18.:es
2024-12-02 16:14:54,044 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 16:14:54,045 [INFO] app1.py:933 - Starting translation request - Text: '2000 and 18.', Target language: es
2024-12-02 16:14:54,045 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 16:14:54,045 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 16:14:54,046 [DEBUG] app1.py:964 - Request body: [{'text': '2000 and 18.'}]
2024-12-02 16:14:54,352 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 16:14:54,353 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': '2000 y 18.', 'to': 'es'}]}]
2024-12-02 16:14:54,354 [DEBUG] app1.py:974 - Extracted translation: 2000 y 18.
2024-12-02 16:14:54,355 [INFO] app1.py:975 - Translation completed successfully - Original: '2000 and 18.' -> Translation: '2000 y 18.' (es)
2024-12-02 16:14:54,356 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: 2000 y 18.
2024-12-02 16:14:54,357 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:14:54,357 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': '2000 y 18.'}
2024-12-02 16:14:54,366 [INFO] app1.py:1274 - Speech synthesis requested - Text: '2000 y 18.', Language: es
2024-12-02 16:14:54,374 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_93f5f2c7-5aac-486a-8e6c-62e2d08b00cd.wav
2024-12-02 16:14:54,377 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:14:55,245 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:14:55,246 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_93f5f2c7-5aac-486a-8e6c-62e2d08b00cd.wav
2024-12-02 16:15:02,136 [DEBUG] app1.py:1214 - Speech recognizing: thank you
2024-12-02 16:15:02,136 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fd1430ee3ec54df09565fe2aa15ce143, text="thank you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:02,137 [DEBUG] app1.py:1104 - Sending transcription: thank you (is_final: False)
2024-12-02 16:15:02,143 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:15:02,144 [DEBUG] app1.py:1031 - Received translation request - Text: 'thank you', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:15:02,145 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:15:02,151 [INFO] app1.py:1205 - Speech recognized: Thank you.
2024-12-02 16:15:02,153 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0d105f9145fe4693aa5014ceb4356d96, text="Thank you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:15:02,154 [DEBUG] app1.py:1104 - Sending transcription: Thank you. (is_final: True)
2024-12-02 16:15:02,159 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:15:02,159 [DEBUG] app1.py:1031 - Received translation request - Text: 'Thank you.', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: True
2024-12-02 16:15:02,160 [DEBUG] app1.py:1042 - Normalized text: 'thank you.'
2024-12-02 16:15:02,160 [DEBUG] app1.py:1048 - Time since last translation for 9c112104-1955-4a9a-9379-234276cdf84f:es: 8.117117166519165s
2024-12-02 16:15:02,161 [DEBUG] app1.py:1056 - Checking cache with key: thank you.:es
2024-12-02 16:15:02,161 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 16:15:02,161 [DEBUG] app1.py:918 - Sending translation to client 9c112104-1955-4a9a-9379-234276cdf84f: Gracias.
2024-12-02 16:15:02,162 [DEBUG] app1.py:925 - Translation sent successfully to client 9c112104-1955-4a9a-9379-234276cdf84f
2024-12-02 16:15:02,162 [DEBUG] app1.py:1144 - Sending message to client 9c112104-1955-4a9a-9379-234276cdf84f: {'type': 'final', 'translation': 'Gracias.'}
2024-12-02 16:15:02,191 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Gracias.', Language: es
2024-12-02 16:15:02,192 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_7df07557-4515-45c0-a8a3-65decf43d503.wav
2024-12-02 16:15:02,194 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 16:15:03,060 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 16:15:03,061 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_7df07557-4515-45c0-a8a3-65decf43d503.wav
2024-12-02 16:15:18,737 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:15:22,222 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:15:22,223 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bdcf4fd6e4294568a5d356078b410149, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:15:22,224 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:15:32,440 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:15:34,653 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:15:35,658 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:15:37,428 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:15:37,429 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=02a68763faa346088bdb35d2462ae3b2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:15:37,429 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:15:38,660 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:15:39,664 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:15:40,504 [DEBUG] app1.py:1214 - Speech recognizing: is it is
2024-12-02 16:15:40,505 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3674feea8e5e45bb9516d3ad0a78825f, text="is it is", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:40,505 [DEBUG] app1.py:1104 - Sending transcription: is it is (is_final: False)
2024-12-02 16:15:40,512 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:15:40,512 [DEBUG] app1.py:1031 - Received translation request - Text: 'is it is', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:15:40,513 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:15:40,813 [DEBUG] app1.py:1214 - Speech recognizing: is it is activity
2024-12-02 16:15:40,814 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=682c92cd164d48398b1f891ccf994429, text="is it is activity", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:40,814 [DEBUG] app1.py:1104 - Sending transcription: is it is activity (is_final: False)
2024-12-02 16:15:40,822 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:15:40,822 [DEBUG] app1.py:1031 - Received translation request - Text: 'is it is activity', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:15:40,823 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:15:41,128 [DEBUG] app1.py:1214 - Speech recognizing: is it is activity a magnet
2024-12-02 16:15:41,134 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3a4bbd80e8b7459f978d181f9862c0e8, text="is it is activity a magnet", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:41,137 [DEBUG] app1.py:1104 - Sending transcription: is it is activity a magnet (is_final: False)
2024-12-02 16:15:41,141 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 16:15:41,144 [DEBUG] app1.py:1031 - Received translation request - Text: 'is it is activity a magnet', Target: es, Client: 9c112104-1955-4a9a-9379-234276cdf84f, Final: False
2024-12-02 16:15:41,145 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 16:15:41,719 [DEBUG] app1.py:1214 - Speech recognizing: is it is activity a magnet is active
2024-12-02 16:15:41,719 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=815b518cc31a4044b50d9c4cd867e774, text="is it is activity a magnet is active", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:41,720 [DEBUG] app1.py:1104 - Sending transcription: is it is activity a magnet is active (is_final: False)
2024-12-02 16:15:42,654 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:15:43,426 [DEBUG] app1.py:1214 - Speech recognizing: is it is activity a magnet is active trans
2024-12-02 16:15:43,429 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=55f6299d075c4339bcbc06abbefde80b, text="is it is activity a magnet is active trans", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:43,438 [DEBUG] app1.py:1104 - Sending transcription: is it is activity a magnet is active trans (is_final: False)
2024-12-02 16:15:43,664 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:15:43,713 [DEBUG] app1.py:1214 - Speech recognizing: is it is activity a magnet is active transgender
2024-12-02 16:15:43,714 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=978eeca59c7c4409a59fd66a65ad8bc7, text="is it is activity a magnet is active transgender", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:45,546 [INFO] app1.py:1205 - Speech recognized: Is activity a magnet? Is active transgender?
2024-12-02 16:15:45,547 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=afb851741f744b0d994796c28b0d5cc9, text="Is activity a magnet? Is active transgender?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:15:46,653 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:15:47,666 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:15:48,739 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:15:50,653 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:15:51,664 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:15:52,702 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:15:52,703 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d7ddb4fbfff44b0ebe4f5f44ee98a1bb, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:54,247 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:15:54,248 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4ea757fb8467428f84b87fb1027a8f40, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:15:54,632 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:15:54,633 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=26eb4eadbf9844aba9952702ea17ec63, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:54,650 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:15:55,659 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:15:56,420 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:15:56,420 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bd1ac702b8fd4b14a8113d3547974b27, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:15:58,194 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:15:58,195 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=842dae1476ba4eb0aca735d411ed7647, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:58,395 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:15:58,395 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fa71865b01a745df914b874881637589, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:15:58,665 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:15:59,500 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:15:59,501 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=57dd389f1d884821b563ecacc06b91f2, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:15:59,668 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:16:02,669 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:16:03,675 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:16:05,685 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:16:06,699 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:16:08,723 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:16:09,728 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:16:10,678 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:16:10,876 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:16:11,748 [INFO] app1.py:1121 - New translation stream connection for client: 9c112104-1955-4a9a-9379-234276cdf84f, language: es
2024-12-02 16:16:12,760 [WARNING] app1.py:1148 - Client 9c112104-1955-4a9a-9379-234276cdf84f connection timed out
2024-12-02 16:16:18,742 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:16:23,340 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:16:23,360 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:16:23,362 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:16:23,362 [DEBUG] app1.py:1104 - Sending transcription: is it is activity a magnet is active transgender (is_final: False)
2024-12-02 16:16:23,364 [DEBUG] app1.py:1104 - Sending transcription: Is activity a magnet? Is active transgender? (is_final: True)
2024-12-02 16:16:23,391 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:16:23,402 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:16:23,451 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:16:23,457 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:16:23,471 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 16:16:23,473 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:16:23,486 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:16:23,547 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:16:23,635 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:16:25,398 [DEBUG] app1.py:1214 - Speech recognizing: is activity
2024-12-02 16:16:25,400 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=38e8068c70df4c72bc0028959f75f2c3, text="is activity", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:25,401 [DEBUG] app1.py:1104 - Sending transcription: is activity (is_final: False)
2024-12-02 16:16:26,687 [DEBUG] app1.py:1214 - Speech recognizing: is activity imagined
2024-12-02 16:16:26,688 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b1cd998725bb41b8b90b1709406499ed, text="is activity imagined", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:26,691 [DEBUG] app1.py:1104 - Sending transcription: is activity imagined (is_final: False)
2024-12-02 16:16:28,490 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:16:28,490 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=100a6b3bb3eb480aa91ab35cbd0e6640, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:28,491 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 16:16:28,583 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:16:28,584 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=42c0b42abec048829ea6d349ac59b3a8, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:28,584 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:16:28,789 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:16:28,790 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f8fe0c44fb5549ecb91be885d11442cb, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:28,792 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:16:29,616 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:16:29,617 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=35d98b765db5472fa9168d53496bbf6c, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:16:29,619 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:16:39,686 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:16:39,687 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc63489faf7547ce8762608046bd05b8, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:39,689 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:16:40,383 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:16:40,384 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=866f099f7a174fb9a7bc832bacddf559, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:40,386 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:16:40,909 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:16:40,911 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=44c4d7fa63d04bfa95dd6a89aa18a735, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:16:40,913 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:16:46,197 [DEBUG] app1.py:1214 - Speech recognizing: now i'm
2024-12-02 16:16:46,198 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9e758b225b004a729ec73a6e45e959d7, text="now i'm", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:46,198 [DEBUG] app1.py:1104 - Sending transcription: now i'm (is_final: False)
2024-12-02 16:16:47,286 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to win
2024-12-02 16:16:47,287 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2e995155aa02465fb8279ccb761e0c5d, text="now i'm going to win", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:47,287 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to win (is_final: False)
2024-12-02 16:16:48,113 [INFO] app1.py:1205 - Speech recognized: Now I'm going to.
2024-12-02 16:16:48,114 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=be0c8bb4e3c2400591186281d3e9f189, text="Now I'm going to.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:16:48,115 [DEBUG] app1.py:1104 - Sending transcription: Now I'm going to. (is_final: True)
2024-12-02 16:16:48,745 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:16:49,677 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going
2024-12-02 16:16:49,678 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ea603f3a9774b428adee034a58fe4c0, text="now i'm going", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:49,680 [DEBUG] app1.py:1104 - Sending transcription: now i'm going (is_final: False)
2024-12-02 16:16:50,082 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to
2024-12-02 16:16:50,082 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=301203c5679e4a83a5cb7d85f399d111, text="now i'm going to", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:50,083 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to (is_final: False)
2024-12-02 16:16:51,978 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to are you listening me
2024-12-02 16:16:51,979 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=006106c997a34d32b2537bd3179a80b1, text="now i'm going to are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:51,980 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to are you listening me (is_final: False)
2024-12-02 16:16:52,913 [INFO] app1.py:1205 - Speech recognized: Now I'm going to Are you listening me?
2024-12-02 16:16:52,914 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fd09b76465604492a364a35b272caa08, text="Now I'm going to Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:16:52,916 [DEBUG] app1.py:1104 - Sending transcription: Now I'm going to Are you listening me? (is_final: True)
2024-12-02 16:16:54,276 [DEBUG] app1.py:1214 - Speech recognizing: now
2024-12-02 16:16:54,277 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce525eae62984683b7c726a5db5eb1ed, text="now", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:54,278 [DEBUG] app1.py:1104 - Sending transcription: now (is_final: False)
2024-12-02 16:16:54,588 [DEBUG] app1.py:1214 - Speech recognizing: now i
2024-12-02 16:16:54,589 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=157727ee189f4205a45a67fca891fcfc, text="now i", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:54,590 [DEBUG] app1.py:1104 - Sending transcription: now i (is_final: False)
2024-12-02 16:16:54,681 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going
2024-12-02 16:16:54,681 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ae5e79c07b4a4a5fb5363e6b7f640370, text="now i'm going", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:54,682 [DEBUG] app1.py:1104 - Sending transcription: now i'm going (is_final: False)
2024-12-02 16:16:54,995 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to
2024-12-02 16:16:54,996 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=83901fbdcb10438aabd50013544d778f, text="now i'm going to", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:54,997 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to (is_final: False)
2024-12-02 16:16:55,289 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to are you listening
2024-12-02 16:16:55,289 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c7cedab30f214a7386bde0c2d2b48d8e, text="now i'm going to are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:55,291 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to are you listening (is_final: False)
2024-12-02 16:16:56,409 [INFO] app1.py:1205 - Speech recognized: Now I'm going to Are you listening?
2024-12-02 16:16:56,410 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1eb2731141f248249b5771f593af8575, text="Now I'm going to Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:16:56,411 [DEBUG] app1.py:1104 - Sending transcription: Now I'm going to Are you listening? (is_final: True)
2024-12-02 16:16:57,782 [DEBUG] app1.py:1214 - Speech recognizing: are you just
2024-12-02 16:16:57,783 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f99fbbcbc01c431b96dbe1497af35284, text="are you just", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:57,784 [DEBUG] app1.py:1104 - Sending transcription: are you just (is_final: False)
2024-12-02 16:16:58,390 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going
2024-12-02 16:16:58,391 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7414806bb30d47418ca3fdf723275ecb, text="now i'm going", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:58,393 [DEBUG] app1.py:1104 - Sending transcription: now i'm going (is_final: False)
2024-12-02 16:16:58,690 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to are you listening
2024-12-02 16:16:58,692 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6c136c84c9a1406eb7e91a2243a196e3, text="now i'm going to are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:16:58,693 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to are you listening (is_final: False)
2024-12-02 16:17:00,289 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to are you listening can you tell me
2024-12-02 16:17:00,290 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=11e130ba08c7479ca9526124db7400cd, text="now i'm going to are you listening can you tell me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:00,292 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to are you listening can you tell me (is_final: False)
2024-12-02 16:17:02,032 [INFO] app1.py:1205 - Speech recognized: Now I'm going to Are you listening? Can you tell me?
2024-12-02 16:17:02,032 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1e0444932ae4455da7328e992ef776ed, text="Now I'm going to Are you listening? Can you tell me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:02,034 [DEBUG] app1.py:1104 - Sending transcription: Now I'm going to Are you listening? Can you tell me? (is_final: True)
2024-12-02 16:17:03,703 [DEBUG] app1.py:1214 - Speech recognizing: now i'm
2024-12-02 16:17:03,705 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2cac9099a1f849b2a1e7ab534059c5b2, text="now i'm", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:03,706 [DEBUG] app1.py:1104 - Sending transcription: now i'm (is_final: False)
2024-12-02 16:17:03,982 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going
2024-12-02 16:17:03,982 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=39e4ebf21c9b47f39f290b990d0813b9, text="now i'm going", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:03,983 [DEBUG] app1.py:1104 - Sending transcription: now i'm going (is_final: False)
2024-12-02 16:17:04,339 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to
2024-12-02 16:17:04,340 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d4ed6f0f23fd49c49f3b7200d22bebdf, text="now i'm going to", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:04,342 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to (is_final: False)
2024-12-02 16:17:04,684 [DEBUG] app1.py:1214 - Speech recognizing: now i'm going to want to listen
2024-12-02 16:17:04,684 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e5e9d4c7d7e044449d6127ed22bacd51, text="now i'm going to want to listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:04,687 [DEBUG] app1.py:1104 - Sending transcription: now i'm going to want to listen (is_final: False)
2024-12-02 16:17:06,848 [INFO] app1.py:1205 - Speech recognized: Now I'm going to want to listen.
2024-12-02 16:17:06,849 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c5bc40ed4f3b4bec80b0bd838da56552, text="Now I'm going to want to listen.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:06,851 [DEBUG] app1.py:1104 - Sending transcription: Now I'm going to want to listen. (is_final: True)
2024-12-02 16:17:07,919 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 16:17:07,919 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=223f71ea7b7e47f5893d1df9d7c0cdc6, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:07,921 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 16:17:08,090 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:17:08,091 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7992e0d133134504b58f9b3907c5fe65, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:08,092 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 16:17:09,196 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 16:17:09,198 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bc3bf47d72c24fc49871098c7d9cf86e, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:09,198 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 16:17:10,705 [DEBUG] app1.py:1214 - Speech recognizing: ippa mudiyaatha
2024-12-02 16:17:10,706 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=314548dcc7254497bf452916a1ad0eff, text="ippa mudiyaatha", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:10,708 [DEBUG] app1.py:1104 - Sending transcription: ippa mudiyaatha (is_final: False)
2024-12-02 16:17:10,892 [DEBUG] app1.py:1214 - Speech recognizing: ippa mudiyaatha var
2024-12-02 16:17:10,894 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b4319ea69e894fd0af92f2bee89437ca, text="ippa mudiyaatha var", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:10,895 [DEBUG] app1.py:1104 - Sending transcription: ippa mudiyaatha var (is_final: False)
2024-12-02 16:17:11,016 [DEBUG] app1.py:1214 - Speech recognizing: ippa mudiyaatha vara
2024-12-02 16:17:11,016 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=62f110337a194a3ca465a098c376a7ac, text="ippa mudiyaatha vara", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:11,017 [DEBUG] app1.py:1104 - Sending transcription: ippa mudiyaatha vara (is_final: False)
2024-12-02 16:17:11,201 [DEBUG] app1.py:1214 - Speech recognizing: ippa mudiyaatha varuvaar
2024-12-02 16:17:11,202 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=214f27c521cc4720b3a9cf64685c38a5, text="ippa mudiyaatha varuvaar", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:11,202 [DEBUG] app1.py:1104 - Sending transcription: ippa mudiyaatha varuvaar (is_final: False)
2024-12-02 16:17:11,532 [INFO] app1.py:1205 - Speech recognized: Ippa Mudiyaatha varuvaar.
2024-12-02 16:17:11,533 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c9a05649f4f647719b8d34a23b5a1cdc, text="Ippa Mudiyaatha varuvaar.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:11,535 [DEBUG] app1.py:1104 - Sending transcription: Ippa Mudiyaatha varuvaar. (is_final: True)
2024-12-02 16:17:18,747 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f']
2024-12-02 16:17:19,455 [INFO] app1.py:1121 - New translation stream connection for client: 2d93488d-dfc0-421c-b185-5d03c01bec66, language: es
2024-12-02 16:17:19,456 [INFO] app1.py:1131 - Creating new client connection: 2d93488d-dfc0-421c-b185-5d03c01bec66
2024-12-02 16:17:29,307 [DEBUG] app1.py:1214 - Speech recognizing: intelligent layer
2024-12-02 16:17:29,308 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=da9c2b9fe362461f9be7f02898b3dbcd, text="intelligent layer", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:30,321 [INFO] app1.py:1205 - Speech recognized: Intelligent layer.
2024-12-02 16:17:30,322 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a970ea6d45ee454e80bfdb6531316ebf, text="Intelligent layer.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:33,190 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:17:33,191 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=54c50de0d99f4ba3ae8e36c0641dd332, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:34,491 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 16:17:34,491 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=53f006137cbc47fabe9a5c6b7b026533, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:34,784 [DEBUG] app1.py:1214 - Speech recognizing: hi what are
2024-12-02 16:17:34,785 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d2a18b4e18b4b8d9a7bb94fb99fb384, text="hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:34,894 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 16:17:34,895 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6be702e2968c47f1a69c7aa9fa912ed9, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:35,003 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 16:17:35,004 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4a9a644e65424f8a97eab47aba99d2b6, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:35,042 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:17:35,045 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:17:35,046 [DEBUG] app1.py:1104 - Sending transcription: intelligent layer (is_final: False)
2024-12-02 16:17:35,062 [DEBUG] app1.py:1104 - Sending transcription: Intelligent layer. (is_final: True)
2024-12-02 16:17:35,112 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:17:35,152 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 16:17:35,164 [DEBUG] app1.py:1104 - Sending transcription: hi what are (is_final: False)
2024-12-02 16:17:35,178 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 16:17:35,180 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 16:17:36,786 [DEBUG] app1.py:1214 - Speech recognizing: intelligent
2024-12-02 16:17:36,787 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bf9b1df0427d4810b3113b97a434c298, text="intelligent", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:36,787 [DEBUG] app1.py:1104 - Sending transcription: intelligent (is_final: False)
2024-12-02 16:17:37,285 [DEBUG] app1.py:1214 - Speech recognizing: intelligent layer
2024-12-02 16:17:37,286 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b20c94bca8f4d2a9596595f2e8434d6, text="intelligent layer", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:37,288 [DEBUG] app1.py:1104 - Sending transcription: intelligent layer (is_final: False)
2024-12-02 16:17:39,347 [INFO] app1.py:1205 - Speech recognized: Intelligent layer.
2024-12-02 16:17:39,347 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9e4bbd23b390405d813cfbc9072ac6db, text="Intelligent layer.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:39,348 [DEBUG] app1.py:1104 - Sending transcription: Intelligent layer. (is_final: True)
2024-12-02 16:17:47,906 [DEBUG] app1.py:1214 - Speech recognizing: on my chain is gambling EK
2024-12-02 16:17:47,907 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=88f6d6c669274ce488c1c535b3bbfc8e, text="on my chain is gambling EK", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:47,909 [DEBUG] app1.py:1104 - Sending transcription: on my chain is gambling EK (is_final: False)
2024-12-02 16:17:48,200 [DEBUG] app1.py:1214 - Speech recognizing: on my chain is gambling EK will
2024-12-02 16:17:48,202 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=30d0831e4682478daa44d39f97b3f528, text="on my chain is gambling EK will", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:48,204 [DEBUG] app1.py:1104 - Sending transcription: on my chain is gambling EK will (is_final: False)
2024-12-02 16:17:48,292 [DEBUG] app1.py:1214 - Speech recognizing: OK we'll
2024-12-02 16:17:48,293 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f35b2776d6d14cceb6579b3b440b80b6, text="OK we'll", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:48,293 [DEBUG] app1.py:1104 - Sending transcription: OK we'll (is_final: False)
2024-12-02 16:17:48,606 [DEBUG] app1.py:1214 - Speech recognizing: OK we'll open up
2024-12-02 16:17:48,607 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8f4cf8c0d3674238b9869f04a39ba2f4, text="OK we'll open up", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:48,609 [DEBUG] app1.py:1104 - Sending transcription: OK we'll open up (is_final: False)
2024-12-02 16:17:48,749 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f', '2d93488d-dfc0-421c-b185-5d03c01bec66']
2024-12-02 16:17:48,994 [DEBUG] app1.py:1214 - Speech recognizing: OK we'll open up that
2024-12-02 16:17:48,994 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d816c6745d346b09e46768d40ad173b, text="OK we'll open up that", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:48,996 [DEBUG] app1.py:1104 - Sending transcription: OK we'll open up that (is_final: False)
2024-12-02 16:17:49,102 [DEBUG] app1.py:1214 - Speech recognizing: OK we'll open up
2024-12-02 16:17:49,103 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=64ab77493d864782b8557841d085631c, text="OK we'll open up", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:49,105 [DEBUG] app1.py:1104 - Sending transcription: OK we'll open up (is_final: False)
2024-12-02 16:17:50,822 [INFO] app1.py:1205 - Speech recognized: OK, we'll open up.
2024-12-02 16:17:50,822 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=597886a2457f4676853b2a228409dcf1, text="OK, we'll open up.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:50,823 [DEBUG] app1.py:1104 - Sending transcription: OK, we'll open up. (is_final: True)
2024-12-02 16:17:52,192 [DEBUG] app1.py:1214 - Speech recognizing: OK
2024-12-02 16:17:52,193 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c60dd4850bd24b72a08c34728b71bfcd, text="OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:52,194 [DEBUG] app1.py:1104 - Sending transcription: OK (is_final: False)
2024-12-02 16:17:53,208 [INFO] app1.py:1205 - Speech recognized: OK.
2024-12-02 16:17:53,210 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b900c3a7fbea4d8bbd77bc49c9067d36, text="OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:53,210 [DEBUG] app1.py:1104 - Sending transcription: OK. (is_final: True)
2024-12-02 16:17:56,300 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:17:56,301 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aa259940f07a4bae9adfc8bf6406bbfc, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:56,302 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:17:56,410 [DEBUG] app1.py:1214 - Speech recognizing: hi termin
2024-12-02 16:17:56,417 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=79000de81fdd4d7587bca5dbabee643d, text="hi termin", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:56,420 [DEBUG] app1.py:1104 - Sending transcription: hi termin (is_final: False)
2024-12-02 16:17:56,499 [DEBUG] app1.py:1214 - Speech recognizing: hi terminal
2024-12-02 16:17:56,500 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7efe1e217c71491493a6e13300d86868, text="hi terminal", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:56,500 [DEBUG] app1.py:1104 - Sending transcription: hi terminal (is_final: False)
2024-12-02 16:17:57,435 [INFO] app1.py:1205 - Speech recognized: Hi Terminal TV.
2024-12-02 16:17:57,437 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9f57f0d1f831419d982c6ccd1c3fff7e, text="Hi Terminal TV.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:57,438 [DEBUG] app1.py:1104 - Sending transcription: Hi Terminal TV. (is_final: True)
2024-12-02 16:17:59,186 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:17:59,188 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a0bbf8ffed284484acc26aa07dfb85ae, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:17:59,189 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:17:59,482 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:17:59,483 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e569ccf7e5db467588441e4492df8e1f, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:17:59,484 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:18:01,086 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:18:01,087 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=70273c9dab9a4b8ea9475039b3ad13d8, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:01,087 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:18:01,491 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:18:01,493 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fd44de4b94644327960348a9d5da822a, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:01,494 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:18:02,613 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:18:02,614 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=86fe35cec13841c8bbc99e25d365b171, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:18:02,616 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:18:03,886 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:18:03,887 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6e3a960c577740e4bde8d6336a480785, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:03,888 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 16:18:05,195 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:18:05,196 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=818eb9fda596479d8f70b231333c1197, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:05,197 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 16:18:05,505 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:18:05,507 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=709140cf427f4ba4b774d91eec35d827, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:18:05,508 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 16:18:06,884 [DEBUG] app1.py:1214 - Speech recognizing: what are
2024-12-02 16:18:06,885 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b48bea9a8e3d49e2976fb2bd7fc4d6b9, text="what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:06,886 [DEBUG] app1.py:1104 - Sending transcription: what are (is_final: False)
2024-12-02 16:18:07,086 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:18:07,087 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c3161c5fc70947fc95d867054558e9eb, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:07,088 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 16:18:08,496 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 16:18:08,498 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1aa7c0c8797f4154801f1204d2d1eaef, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:18:08,498 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 16:18:09,783 [DEBUG] app1.py:1214 - Speech recognizing: what are you
2024-12-02 16:18:09,784 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ebcdc3a09fec49e181fd52ab7c7bf089, text="what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:09,785 [DEBUG] app1.py:1104 - Sending transcription: what are you (is_final: False)
2024-12-02 16:18:10,186 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:18:10,187 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7604904a91b64718b143c6590f3acc4d, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:10,189 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 16:18:12,009 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 16:18:12,010 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3572d152b09548528573c4a8b2bbc4b0, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:18:12,011 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 16:18:13,392 [DEBUG] app1.py:1214 - Speech recognizing: thank you
2024-12-02 16:18:13,393 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2e25018468eb4aafadfa8373e8ca5865, text="thank you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:13,394 [DEBUG] app1.py:1104 - Sending transcription: thank you (is_final: False)
2024-12-02 16:18:14,215 [INFO] app1.py:1205 - Speech recognized: Thank you.
2024-12-02 16:18:14,216 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=55a94e7dae8a4b478284906743913aaa, text="Thank you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:18:14,217 [DEBUG] app1.py:1104 - Sending transcription: Thank you. (is_final: True)
2024-12-02 16:18:15,984 [DEBUG] app1.py:1214 - Speech recognizing: thank you
2024-12-02 16:18:15,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9282097dcb9402f8422a01e605de650, text="thank you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:18:15,986 [DEBUG] app1.py:1104 - Sending transcription: thank you (is_final: False)
2024-12-02 16:18:16,388 [INFO] app1.py:1205 - Speech recognized: Thank you.
2024-12-02 16:18:16,388 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=15baa421c78b4828840bb912e2ac0acb, text="Thank you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:18:16,389 [DEBUG] app1.py:1104 - Sending transcription: Thank you. (is_final: True)
2024-12-02 16:18:16,857 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:18:17,101 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:18:18,752 [INFO] app1.py:898 - Active clients: ['295d61aa-6936-467c-bb1d-8b07951a8543', 'dfff3259-8802-40bf-b5af-a30fb9321a5d', '5d729144-bfe2-4c24-8a55-f2cf1ca7e5dc', 'd9f0bfec-df8f-4a05-ba9b-129af61b114a', '29f82839-12f3-4d63-a0cb-4c0ab67e39de', 'f80826cc-6b48-4732-8c37-b486d19dc8d1', 'c20100b0-4860-4dd6-91cf-b286e69cb563', 'aaa7967e-bdf5-4a9f-aa6e-cd361c8c2dc5', '72605ad0-02ec-43d6-9d83-45aa2000f04f', '10200d57-8db3-458d-923f-f3916c12eb96', '658f2997-1a74-43f6-b1af-622cc99c8ba6', 'cc697dd5-1301-43eb-82ab-5e1efdd7e4ea', 'ad7df895-1a53-4766-8bdc-ae5c0bf12ae7', '9c112104-1955-4a9a-9379-234276cdf84f', '2d93488d-dfc0-421c-b185-5d03c01bec66']
