2024-12-02 13:12:36,210 [INFO] app1.py:898 - Active clients: []
2024-12-02 13:12:36,213 [INFO] app1.py:1402 - Starting Flask application
2024-12-02 13:12:36,214 [INFO] app1.py:1405 - Starting with Waitress server on http://127.0.0.1:4585
2024-12-02 13:12:45,866 [INFO] app1.py:1018 - Join live page requested
2024-12-02 13:12:46,788 [INFO] app1.py:1013 - Go live page requested
2024-12-02 13:12:48,532 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 13:12:48,686 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 13:12:48,829 [INFO] app1.py:1240 - Audio stream started
2024-12-02 13:12:50,183 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:12:50,184 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:12:51,636 [DEBUG] app1.py:1214 - Speech recognizing: hi hello
2024-12-02 13:12:51,637 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ecec2335b560412f8592ba4e6c4b8811, text="hi hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:51,638 [DEBUG] app1.py:1104 - Sending transcription: hi hello (is_final: False)
2024-12-02 13:12:52,331 [DEBUG] app1.py:1214 - Speech recognizing: hi hello how are
2024-12-02 13:12:52,332 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a891afde74964a20bbc95a00b7794459, text="hi hello how are", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:52,333 [DEBUG] app1.py:1104 - Sending transcription: hi hello how are (is_final: False)
2024-12-02 13:12:52,737 [DEBUG] app1.py:1214 - Speech recognizing: hi hello how are you
2024-12-02 13:12:52,737 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4abb054f340945b29e2a135f8e3c4233, text="hi hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:52,738 [DEBUG] app1.py:1104 - Sending transcription: hi hello how are you (is_final: False)
2024-12-02 13:12:52,846 [DEBUG] app1.py:1214 - Speech recognizing: hi hello how are you what
2024-12-02 13:12:52,847 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5f409045a46c49c4b4866fe9f1c03dbd, text="hi hello how are you what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:52,848 [DEBUG] app1.py:1104 - Sending transcription: hi hello how are you what (is_final: False)
2024-12-02 13:12:53,249 [DEBUG] app1.py:1214 - Speech recognizing: hi hello how are you what are you doing
2024-12-02 13:12:53,250 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=11c1a1efdeb94d36b83fc585b7e001f5, text="hi hello how are you what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:53,251 [DEBUG] app1.py:1104 - Sending transcription: hi hello how are you what are you doing (is_final: False)
2024-12-02 13:12:53,891 [INFO] app1.py:1205 - Speech recognized: Hi, hello. How are you? What are you doing?
2024-12-02 13:12:53,892 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da26a62e351a4c41b869634b6fe06d6d, text="Hi, hello. How are you? What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:12:53,893 [DEBUG] app1.py:1104 - Sending transcription: Hi, hello. How are you? What are you doing? (is_final: True)
2024-12-02 13:12:56,287 [DEBUG] app1.py:1214 - Speech recognizing: hi hello
2024-12-02 13:12:56,288 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=39837d71448c4390be3c483bebf01bde, text="hi hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:56,289 [DEBUG] app1.py:1104 - Sending transcription: hi hello (is_final: False)
2024-12-02 13:12:56,299 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:12:56,301 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi hello', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:12:56,302 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:12:56,303 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: es
2024-12-02 13:12:56,306 [INFO] app1.py:1131 - Creating new client connection: 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:12:56,552 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 13:12:56,553 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=86fc8cfe662a4dd8929fe66e6fe7a97f, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:56,554 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 13:12:56,559 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:12:56,560 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:12:56,562 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:12:56,765 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 13:12:56,767 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8d8328c808d34536bd6e77b3ee5a9463, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:12:56,768 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 13:12:56,773 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:12:56,774 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:12:56,775 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 13:12:56,776 [DEBUG] app1.py:1056 - Checking cache with key: hello.:es
2024-12-02 13:12:56,776 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:12:56,776 [INFO] app1.py:933 - Starting translation request - Text: 'hello.', Target language: es
2024-12-02 13:12:56,796 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:12:56,797 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:12:56,799 [DEBUG] app1.py:964 - Request body: [{'text': 'hello.'}]
2024-12-02 13:12:57,351 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:12:57,352 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola.', 'to': 'es'}]}]
2024-12-02 13:12:57,354 [DEBUG] app1.py:974 - Extracted translation: Hola.
2024-12-02 13:12:57,356 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello.' -> Translation: 'Hola.' (es)
2024-12-02 13:12:57,357 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: Hola.
2024-12-02 13:12:57,359 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:12:57,359 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 13:12:57,364 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola.', Language: es
2024-12-02 13:12:57,365 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4d08e425-42b5-45f3-a3a8-f7769ba81244.wav
2024-12-02 13:12:57,376 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:12:58,325 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:12:58,327 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4d08e425-42b5-45f3-a3a8-f7769ba81244.wav
2024-12-02 13:12:59,650 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:12:59,652 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=015e47fe13e6473c85e55ea8d82e93d8, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:12:59,654 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:12:59,660 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:12:59,660 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:12:59,662 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:12:59,756 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 13:12:59,757 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3d4640926ad748d196dacc18aba2b894, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:12:59,759 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 13:12:59,763 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:12:59,764 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:12:59,765 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 13:12:59,765 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 2.988516330718994s
2024-12-02 13:12:59,766 [DEBUG] app1.py:1056 - Checking cache with key: hi.:es
2024-12-02 13:12:59,767 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:12:59,767 [INFO] app1.py:933 - Starting translation request - Text: 'hi.', Target language: es
2024-12-02 13:12:59,767 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:12:59,768 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:12:59,768 [DEBUG] app1.py:964 - Request body: [{'text': 'hi.'}]
2024-12-02 13:13:01,012 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:13:01,013 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'hola.', 'to': 'es'}]}]
2024-12-02 13:13:01,014 [DEBUG] app1.py:974 - Extracted translation: hola.
2024-12-02 13:13:01,014 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi.' -> Translation: 'hola.' (es)
2024-12-02 13:13:01,015 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: hola.
2024-12-02 13:13:01,016 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:01,016 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'hola.'}
2024-12-02 13:13:01,020 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'hola.', Language: es
2024-12-02 13:13:01,021 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_745e99bf-70ab-4d88-9041-1be187f94a49.wav
2024-12-02 13:13:01,024 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:13:01,148 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 13:13:01,149 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b8a7e5faa56a4a9eaa5d38890a1a424f, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:01,149 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 13:13:01,154 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:01,155 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:01,156 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:01,896 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:13:01,897 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_745e99bf-70ab-4d88-9041-1be187f94a49.wav
2024-12-02 13:13:01,958 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 13:13:01,958 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=69f8da16000b47c3979a86b184a7e22a, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:01,960 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 13:13:01,963 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:01,964 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:01,965 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 13:13:01,965 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 2.200559377670288s
2024-12-02 13:13:01,965 [DEBUG] app1.py:1056 - Checking cache with key: hello.:es
2024-12-02 13:13:01,966 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 13:13:01,966 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: Hola.
2024-12-02 13:13:01,966 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:01,966 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 13:13:06,215 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:13:06,962 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:13:06,963 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1844455d413143f89336b83af8d68257, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:06,964 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:13:06,967 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:06,968 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:06,968 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:07,989 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 13:13:07,989 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6676982a1e6241ed91559f62431d67c5, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:07,991 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 13:13:07,994 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:07,995 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:07,995 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 13:13:07,995 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 6.0298871994018555s
2024-12-02 13:13:07,996 [DEBUG] app1.py:1056 - Checking cache with key: hi.:es
2024-12-02 13:13:07,997 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 13:13:07,997 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: hola.
2024-12-02 13:13:07,997 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:07,997 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'hola.'}
2024-12-02 13:13:09,650 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 13:13:09,651 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=06d5851ef37c4073ad4ff141280bcecc, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:09,651 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 13:13:09,655 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:09,655 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:09,656 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:10,460 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 13:13:10,460 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=42a57b38997c41ea9521c524fb4c6d0f, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:10,461 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 13:13:10,464 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:10,464 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:10,465 [DEBUG] app1.py:1042 - Normalized text: 'hello.'
2024-12-02 13:13:10,466 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 2.4705398082733154s
2024-12-02 13:13:10,467 [DEBUG] app1.py:1056 - Checking cache with key: hello.:es
2024-12-02 13:13:10,467 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 13:13:10,467 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: Hola.
2024-12-02 13:13:10,467 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:10,468 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'Hola.'}
2024-12-02 13:13:10,472 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola.', Language: es
2024-12-02 13:13:10,474 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ab0608eb-9565-458f-a5f4-db3643925180.wav
2024-12-02 13:13:10,475 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:13:11,326 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:13:11,326 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_ab0608eb-9565-458f-a5f4-db3643925180.wav
2024-12-02 13:13:12,242 [DEBUG] app1.py:1214 - Speech recognizing: what are
2024-12-02 13:13:12,242 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fcc14d13490e40bcb4328de87b92c0dc, text="what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:12,244 [DEBUG] app1.py:1104 - Sending transcription: what are (is_final: False)
2024-12-02 13:13:12,247 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:12,248 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:12,248 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:12,634 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 13:13:12,635 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eb2dab37f96142b9a2167fbf6278e6cb, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:12,635 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 13:13:12,639 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:12,639 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are you doing', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:12,641 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:13,271 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 13:13:13,273 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5b3444b2062e46d0884c78b42dd570c3, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:13,274 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 13:13:13,278 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:13,279 [DEBUG] app1.py:1031 - Received translation request - Text: 'What are you doing?', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:13,280 [DEBUG] app1.py:1042 - Normalized text: 'what are you doing?'
2024-12-02 13:13:13,284 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 2.81794810295105s
2024-12-02 13:13:13,285 [DEBUG] app1.py:1056 - Checking cache with key: what are you doing?:es
2024-12-02 13:13:13,285 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:13:13,286 [INFO] app1.py:933 - Starting translation request - Text: 'what are you doing?', Target language: es
2024-12-02 13:13:13,286 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:13:13,287 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:13:13,287 [DEBUG] app1.py:964 - Request body: [{'text': 'what are you doing?'}]
2024-12-02 13:13:14,520 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:13:14,523 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.98}, 'translations': [{'text': '¿Qué estás haciendo?', 'to': 'es'}]}]
2024-12-02 13:13:14,524 [DEBUG] app1.py:974 - Extracted translation: ¿Qué estás haciendo?
2024-12-02 13:13:14,525 [INFO] app1.py:975 - Translation completed successfully - Original: 'what are you doing?' -> Translation: '¿Qué estás haciendo?' (es)
2024-12-02 13:13:14,526 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: ¿Qué estás haciendo?
2024-12-02 13:13:14,527 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:14,527 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': '¿Qué estás haciendo?'}
2024-12-02 13:13:14,535 [INFO] app1.py:1274 - Speech synthesis requested - Text: '¿Qué estás haciendo?', Language: es
2024-12-02 13:13:14,535 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_802bb74e-cca8-4c86-9273-46489c4920c4.wav
2024-12-02 13:13:14,537 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:13:15,464 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:13:15,465 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_802bb74e-cca8-4c86-9273-46489c4920c4.wav
2024-12-02 13:13:21,854 [DEBUG] app1.py:1214 - Speech recognizing: thanks
2024-12-02 13:13:21,855 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4553af7a8d3048d486aefd5fc7ea3169, text="thanks", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:21,855 [DEBUG] app1.py:1104 - Sending transcription: thanks (is_final: False)
2024-12-02 13:13:21,860 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:21,860 [DEBUG] app1.py:1031 - Received translation request - Text: 'thanks', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:21,860 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:22,941 [INFO] app1.py:1205 - Speech recognized: Thanks.
2024-12-02 13:13:22,942 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cc198bdb2010484bae28a760dee69c1a, text="Thanks.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:22,942 [DEBUG] app1.py:1104 - Sending transcription: Thanks. (is_final: True)
2024-12-02 13:13:22,946 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:22,946 [DEBUG] app1.py:1031 - Received translation request - Text: 'Thanks.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:22,947 [DEBUG] app1.py:1042 - Normalized text: 'thanks.'
2024-12-02 13:13:22,947 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 9.663333654403687s
2024-12-02 13:13:22,947 [DEBUG] app1.py:1056 - Checking cache with key: thanks.:es
2024-12-02 13:13:22,948 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:13:22,948 [INFO] app1.py:933 - Starting translation request - Text: 'thanks.', Target language: es
2024-12-02 13:13:22,948 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:13:22,948 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:13:22,949 [DEBUG] app1.py:964 - Request body: [{'text': 'thanks.'}]
2024-12-02 13:13:23,233 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:13:23,234 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'gracias.', 'to': 'es'}]}]
2024-12-02 13:13:23,235 [DEBUG] app1.py:974 - Extracted translation: gracias.
2024-12-02 13:13:23,235 [INFO] app1.py:975 - Translation completed successfully - Original: 'thanks.' -> Translation: 'gracias.' (es)
2024-12-02 13:13:23,236 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: gracias.
2024-12-02 13:13:23,237 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:23,237 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'gracias.'}
2024-12-02 13:13:23,242 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'gracias.', Language: es
2024-12-02 13:13:23,244 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0588eea7-76e4-4a2c-8b57-987712946b33.wav
2024-12-02 13:13:23,245 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:13:24,483 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:13:24,484 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0588eea7-76e4-4a2c-8b57-987712946b33.wav
2024-12-02 13:13:36,216 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:13:36,841 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 13:13:36,842 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=454112fbe50246358e58554f9698c8f9, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:36,842 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 13:13:36,847 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:36,848 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening me', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:36,848 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:37,496 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 13:13:37,497 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cc961eae66614ebb81ec1b25b0a09f66, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:37,498 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 13:13:37,502 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:37,503 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening me?', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:37,503 [DEBUG] app1.py:1042 - Normalized text: 'are you listening me?'
2024-12-02 13:13:37,503 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 14.555744171142578s
2024-12-02 13:13:37,504 [DEBUG] app1.py:1056 - Checking cache with key: are you listening me?:es
2024-12-02 13:13:37,504 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:13:37,504 [INFO] app1.py:933 - Starting translation request - Text: 'are you listening me?', Target language: es
2024-12-02 13:13:37,506 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:13:37,506 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:13:37,506 [DEBUG] app1.py:964 - Request body: [{'text': 'are you listening me?'}]
2024-12-02 13:13:38,878 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:13:38,880 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': '¿Me estás escuchando?', 'to': 'es'}]}]
2024-12-02 13:13:38,881 [DEBUG] app1.py:974 - Extracted translation: ¿Me estás escuchando?
2024-12-02 13:13:38,882 [INFO] app1.py:975 - Translation completed successfully - Original: 'are you listening me?' -> Translation: '¿Me estás escuchando?' (es)
2024-12-02 13:13:38,884 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: ¿Me estás escuchando?
2024-12-02 13:13:38,885 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:38,885 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': '¿Me estás escuchando?'}
2024-12-02 13:13:38,890 [INFO] app1.py:1274 - Speech synthesis requested - Text: '¿Me estás escuchando?', Language: es
2024-12-02 13:13:38,891 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_437747ad-162e-4ad3-ad58-28233c89ed86.wav
2024-12-02 13:13:38,892 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:13:39,070 [DEBUG] app1.py:1214 - Speech recognizing: MP3
2024-12-02 13:13:39,071 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a6f4a424eb0c4325bfd1b9644bdacab3, text="MP3", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:39,073 [DEBUG] app1.py:1104 - Sending transcription: MP3 (is_final: False)
2024-12-02 13:13:39,077 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:39,077 [DEBUG] app1.py:1031 - Received translation request - Text: 'MP3', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:39,078 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:39,579 [DEBUG] app1.py:1214 - Speech recognizing: MP3 kalave
2024-12-02 13:13:39,580 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2566fa4425724ef59ac3d88a8e4a60ef, text="MP3 kalave", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:39,582 [DEBUG] app1.py:1104 - Sending transcription: MP3 kalave (is_final: False)
2024-12-02 13:13:39,586 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:39,587 [DEBUG] app1.py:1031 - Received translation request - Text: 'MP3 kalave', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:39,588 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:39,859 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:13:39,860 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_437747ad-162e-4ad3-ad58-28233c89ed86.wav
2024-12-02 13:13:39,986 [DEBUG] app1.py:1214 - Speech recognizing: MP3 kalaviya magp
2024-12-02 13:13:39,987 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=50dd194b47f5467080b1e184d17c3ce0, text="MP3 kalaviya magp", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:39,989 [DEBUG] app1.py:1104 - Sending transcription: MP3 kalaviya magp (is_final: False)
2024-12-02 13:13:39,993 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:39,994 [DEBUG] app1.py:1031 - Received translation request - Text: 'MP3 kalaviya magp', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:39,996 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:40,375 [DEBUG] app1.py:1214 - Speech recognizing: MP3 kalaviya magpa
2024-12-02 13:13:40,375 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b46cbe5455024def8f503522a683121a, text="MP3 kalaviya magpa", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:40,376 [DEBUG] app1.py:1104 - Sending transcription: MP3 kalaviya magpa (is_final: False)
2024-12-02 13:13:40,379 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:40,380 [DEBUG] app1.py:1031 - Received translation request - Text: 'MP3 kalaviya magpa', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:40,380 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:41,877 [INFO] app1.py:1205 - Speech recognized: MP3 Kalaviya Magpa.
2024-12-02 13:13:41,877 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a1d03c57f6f643e884c925544363d01e, text="MP3 Kalaviya Magpa.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:41,878 [DEBUG] app1.py:1104 - Sending transcription: MP3 Kalaviya Magpa. (is_final: True)
2024-12-02 13:13:41,882 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:41,882 [DEBUG] app1.py:1031 - Received translation request - Text: 'MP3 Kalaviya Magpa.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:41,882 [DEBUG] app1.py:1042 - Normalized text: 'mp3 kalaviya magpa.'
2024-12-02 13:13:41,884 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 4.3809120655059814s
2024-12-02 13:13:41,884 [DEBUG] app1.py:1056 - Checking cache with key: mp3 kalaviya magpa.:es
2024-12-02 13:13:41,884 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:13:41,885 [INFO] app1.py:933 - Starting translation request - Text: 'mp3 kalaviya magpa.', Target language: es
2024-12-02 13:13:41,885 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:13:41,885 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:13:41,886 [DEBUG] app1.py:964 - Request body: [{'text': 'mp3 kalaviya magpa.'}]
2024-12-02 13:13:42,245 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:13:42,247 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'fil', 'score': 0.78}, 'translations': [{'text': 'MP3 Kalaviya Magpa.', 'to': 'es'}]}]
2024-12-02 13:13:42,249 [DEBUG] app1.py:974 - Extracted translation: MP3 Kalaviya Magpa.
2024-12-02 13:13:42,249 [INFO] app1.py:975 - Translation completed successfully - Original: 'mp3 kalaviya magpa.' -> Translation: 'MP3 Kalaviya Magpa.' (es)
2024-12-02 13:13:42,254 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: MP3 Kalaviya Magpa.
2024-12-02 13:13:42,255 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:42,257 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'MP3 Kalaviya Magpa.'}
2024-12-02 13:13:42,267 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'MP3 Kalaviya Magpa.', Language: es
2024-12-02 13:13:42,269 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_aa6f5ee1-7ce4-4f33-9160-a3addc0d6de6.wav
2024-12-02 13:13:42,271 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:13:42,580 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: pt
2024-12-02 13:13:43,306 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:13:43,307 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_aa6f5ee1-7ce4-4f33-9160-a3addc0d6de6.wav
2024-12-02 13:13:44,537 [DEBUG] app1.py:1214 - Speech recognizing: no other questions
2024-12-02 13:13:44,538 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fdcf3bdda7c545d9baee969255821f7b, text="no other questions", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:44,540 [DEBUG] app1.py:1104 - Sending transcription: no other questions (is_final: False)
2024-12-02 13:13:44,544 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:44,545 [DEBUG] app1.py:1031 - Received translation request - Text: 'no other questions', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:44,545 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:46,371 [INFO] app1.py:1205 - Speech recognized: No other questions.
2024-12-02 13:13:46,372 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=54ecfe223c6c4329a538f1511aac8a75, text="No other questions.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:46,372 [DEBUG] app1.py:1104 - Sending transcription: No other questions. (is_final: True)
2024-12-02 13:13:46,377 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:46,378 [DEBUG] app1.py:1031 - Received translation request - Text: 'No other questions.', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:46,378 [DEBUG] app1.py:1042 - Normalized text: 'no other questions.'
2024-12-02 13:13:46,379 [DEBUG] app1.py:1056 - Checking cache with key: no other questions.:pt
2024-12-02 13:13:46,379 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:13:46,379 [INFO] app1.py:933 - Starting translation request - Text: 'no other questions.', Target language: pt
2024-12-02 13:13:46,379 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:13:46,380 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:13:46,380 [DEBUG] app1.py:964 - Request body: [{'text': 'no other questions.'}]
2024-12-02 13:13:47,674 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:13:47,674 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Sem outras perguntas.', 'to': 'pt'}]}]
2024-12-02 13:13:47,676 [DEBUG] app1.py:974 - Extracted translation: Sem outras perguntas.
2024-12-02 13:13:47,676 [INFO] app1.py:975 - Translation completed successfully - Original: 'no other questions.' -> Translation: 'Sem outras perguntas.' (pt)
2024-12-02 13:13:47,677 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: Sem outras perguntas.
2024-12-02 13:13:47,677 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:47,677 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'Sem outras perguntas.'}
2024-12-02 13:13:47,681 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Sem outras perguntas.', Language: pt
2024-12-02 13:13:47,682 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_eb0505d4-1bac-4ef5-9b95-e574a0eca4ba.wav
2024-12-02 13:13:47,684 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:13:47,742 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 13:13:47,743 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=26a8813afd1844b1b6ab564b13ff6c49, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:47,744 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 13:13:47,748 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:47,748 [DEBUG] app1.py:1031 - Received translation request - Text: 'what', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:47,749 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:48,052 [DEBUG] app1.py:1214 - Speech recognizing: what are
2024-12-02 13:13:48,053 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5eeab131bc6b442e8d67f4d16e0f966d, text="what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:48,054 [DEBUG] app1.py:1104 - Sending transcription: what are (is_final: False)
2024-12-02 13:13:48,058 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:48,058 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:48,059 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:48,142 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 13:13:48,144 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=33f3dee97abb40cc8f1e707a7e7b7140, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:48,145 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 13:13:48,149 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:48,149 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are you doing', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:13:48,149 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:13:48,594 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:13:48,594 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_eb0505d4-1bac-4ef5-9b95-e574a0eca4ba.wav
2024-12-02 13:13:48,937 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 13:13:48,939 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=87802cc3682c48d0901108c0204edbc2, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:48,940 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 13:13:48,944 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:13:48,945 [DEBUG] app1.py:1031 - Received translation request - Text: 'What are you doing?', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:13:48,945 [DEBUG] app1.py:1042 - Normalized text: 'what are you doing?'
2024-12-02 13:13:48,946 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:pt: 2.5683705806732178s
2024-12-02 13:13:48,946 [DEBUG] app1.py:1056 - Checking cache with key: what are you doing?:pt
2024-12-02 13:13:48,947 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:13:48,947 [INFO] app1.py:933 - Starting translation request - Text: 'what are you doing?', Target language: pt
2024-12-02 13:13:48,947 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:13:48,949 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:13:48,949 [DEBUG] app1.py:964 - Request body: [{'text': 'what are you doing?'}]
2024-12-02 13:13:49,225 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:13:49,227 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.98}, 'translations': [{'text': 'O que é que está a fazer?', 'to': 'pt'}]}]
2024-12-02 13:13:49,228 [DEBUG] app1.py:974 - Extracted translation: O que é que está a fazer?
2024-12-02 13:13:49,229 [INFO] app1.py:975 - Translation completed successfully - Original: 'what are you doing?' -> Translation: 'O que é que está a fazer?' (pt)
2024-12-02 13:13:49,231 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: O que é que está a fazer?
2024-12-02 13:13:49,233 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:13:49,233 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'O que é que está a fazer?'}
2024-12-02 13:13:54,136 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:13:54,136 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d42057fa46b4109a092869eb6005865, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:54,137 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:13:54,461 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 13:13:54,462 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e214a1ffcf8b4eeca5952b5372acda27, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:54,464 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 13:13:54,538 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:13:54,539 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=65e4971f48f540a0992e4ecb353c2aaf, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:54,539 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 13:13:54,646 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:13:54,646 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6e914dc96c6240a6b6b7aa18476775e5, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:13:54,647 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:13:56,650 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 13:13:56,651 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d529d3b3f9784832882826bcba59eef2, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:13:56,652 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 13:14:04,748 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:14:04,749 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0abb19cd2604471595dd0db40e1d3de2, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:04,752 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:14:06,218 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:14:06,552 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 13:14:06,553 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa6b62e99fec4b63a55b68363e1fa1c6, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:14:06,554 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 13:14:17,103 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 13:14:17,104 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ff0e13d1de043e5a021f7fafc0df3c3, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:17,106 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 13:14:18,731 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 13:14:18,731 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=901b3439338e4514ae9ae0ef9345404c, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:14:18,732 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 13:14:27,850 [DEBUG] app1.py:1214 - Speech recognizing: english
2024-12-02 13:14:27,851 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e9fe3a8c29264f2b9fa0de911203ad53, text="english", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:27,853 [DEBUG] app1.py:1104 - Sending transcription: english (is_final: False)
2024-12-02 13:14:29,641 [INFO] app1.py:1205 - Speech recognized: English.
2024-12-02 13:14:29,642 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=708af9a3f0754a5482e155c01a47a74d, text="English.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:14:29,642 [DEBUG] app1.py:1104 - Sending transcription: English. (is_final: True)
2024-12-02 13:14:36,220 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:14:36,742 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:14:36,743 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9c143b51d2ad40ad8c68cf86ddffbfcf, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:36,743 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:14:38,253 [DEBUG] app1.py:1214 - Speech recognizing: hi i
2024-12-02 13:14:38,254 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7e85bc8d06ae436da93785eba27d5f2f, text="hi i", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:38,256 [DEBUG] app1.py:1104 - Sending transcription: hi i (is_final: False)
2024-12-02 13:14:38,344 [DEBUG] app1.py:1214 - Speech recognizing: hi iluk
2024-12-02 13:14:38,345 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6623db95d1c44831b764d29f2042da9b, text="hi iluk", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:38,346 [DEBUG] app1.py:1104 - Sending transcription: hi iluk (is_final: False)
2024-12-02 13:14:38,638 [DEBUG] app1.py:1214 - Speech recognizing: hi ilukandra
2024-12-02 13:14:38,639 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d5513853250943259b14c8cdd717d91f, text="hi ilukandra", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:38,641 [DEBUG] app1.py:1104 - Sending transcription: hi ilukandra (is_final: False)
2024-12-02 13:14:38,961 [DEBUG] app1.py:1214 - Speech recognizing: hi ilukandra vashtra
2024-12-02 13:14:38,961 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=98d4fda33c914eaf92694a3a88bb1c17, text="hi ilukandra vashtra", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:38,962 [DEBUG] app1.py:1104 - Sending transcription: hi ilukandra vashtra (is_final: False)
2024-12-02 13:14:39,447 [DEBUG] app1.py:1214 - Speech recognizing: hi ilukandra vastra ind
2024-12-02 13:14:39,447 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=13e52fb1d924438eb2b35612e451811a, text="hi ilukandra vastra ind", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:39,447 [DEBUG] app1.py:1104 - Sending transcription: hi ilukandra vastra ind (is_final: False)
2024-12-02 13:14:39,836 [DEBUG] app1.py:1214 - Speech recognizing: hi ilukandra vashtra indra
2024-12-02 13:14:39,837 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d37926a5bd8d48bb8b805c05327a21ad, text="hi ilukandra vashtra indra", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:39,838 [DEBUG] app1.py:1104 - Sending transcription: hi ilukandra vashtra indra (is_final: False)
2024-12-02 13:14:39,945 [DEBUG] app1.py:1214 - Speech recognizing: hi ilukandra vashtra indra vashtra
2024-12-02 13:14:39,946 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=98d1187ab0b14c738cb2fa309e9d7ced, text="hi ilukandra vashtra indra vashtra", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:39,947 [DEBUG] app1.py:1104 - Sending transcription: hi ilukandra vashtra indra vashtra (is_final: False)
2024-12-02 13:14:41,759 [INFO] app1.py:1205 - Speech recognized: Hi Ilukandra Vashtra. Indra Vashtra.
2024-12-02 13:14:41,760 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1f31b1539e36414980f5ed48030de231, text="Hi Ilukandra Vashtra. Indra Vashtra.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:14:41,760 [DEBUG] app1.py:1104 - Sending transcription: Hi Ilukandra Vashtra. Indra Vashtra. (is_final: True)
2024-12-02 13:14:45,957 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: pt
2024-12-02 13:14:46,963 [WARNING] app1.py:1148 - Client 71b562af-3aa2-4bbf-b66b-3513c9caa661 connection timed out
2024-12-02 13:14:48,982 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: pt
2024-12-02 13:14:49,991 [WARNING] app1.py:1148 - Client 71b562af-3aa2-4bbf-b66b-3513c9caa661 connection timed out
2024-12-02 13:14:50,260 [DEBUG] app1.py:1214 - Speech recognizing: action
2024-12-02 13:14:50,274 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2a8366e5883644ac952f0ae1884037dd, text="action", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:50,276 [DEBUG] app1.py:1104 - Sending transcription: action (is_final: False)
2024-12-02 13:14:50,281 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:14:50,281 [DEBUG] app1.py:1031 - Received translation request - Text: 'action', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:14:50,282 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:14:50,522 [DEBUG] app1.py:1214 - Speech recognizing: action lost
2024-12-02 13:14:50,524 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7fc67238453146c792e1be542a8d86c0, text="action lost", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:50,525 [DEBUG] app1.py:1104 - Sending transcription: action lost (is_final: False)
2024-12-02 13:14:50,530 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:14:50,531 [DEBUG] app1.py:1031 - Received translation request - Text: 'action lost', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:14:50,531 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:14:52,010 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: pt
2024-12-02 13:14:52,430 [INFO] app1.py:1205 - Speech recognized: Action lost.
2024-12-02 13:14:52,431 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b2b6d0d246054bcf96a88c9a6bd5a6f7, text="Action lost.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:14:52,432 [DEBUG] app1.py:1104 - Sending transcription: Action lost. (is_final: True)
2024-12-02 13:14:52,437 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:14:52,437 [DEBUG] app1.py:1031 - Received translation request - Text: 'Action lost.', Target: pt, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:14:52,438 [DEBUG] app1.py:1042 - Normalized text: 'action lost.'
2024-12-02 13:14:52,438 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:pt: 63.4921236038208s
2024-12-02 13:14:52,440 [DEBUG] app1.py:1056 - Checking cache with key: action lost.:pt
2024-12-02 13:14:52,440 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:14:52,441 [INFO] app1.py:933 - Starting translation request - Text: 'action lost.', Target language: pt
2024-12-02 13:14:52,441 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:14:52,441 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:14:52,442 [DEBUG] app1.py:964 - Request body: [{'text': 'action lost.'}]
2024-12-02 13:14:53,019 [WARNING] app1.py:1148 - Client 71b562af-3aa2-4bbf-b66b-3513c9caa661 connection timed out
2024-12-02 13:14:53,305 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: es
2024-12-02 13:14:53,671 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:14:53,671 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.9}, 'translations': [{'text': 'ação perdida.', 'to': 'pt'}]}]
2024-12-02 13:14:53,673 [DEBUG] app1.py:974 - Extracted translation: ação perdida.
2024-12-02 13:14:53,674 [INFO] app1.py:975 - Translation completed successfully - Original: 'action lost.' -> Translation: 'ação perdida.' (pt)
2024-12-02 13:14:53,675 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: ação perdida.
2024-12-02 13:14:53,676 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:14:53,676 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'ação perdida.'}
2024-12-02 13:14:53,680 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'ação perdida.', Language: es
2024-12-02 13:14:53,681 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_b5f3a3b8-9c92-4531-94e3-d9a0156eba49.wav
2024-12-02 13:14:53,682 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:14:54,605 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:14:54,606 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_b5f3a3b8-9c92-4531-94e3-d9a0156eba49.wav
2024-12-02 13:14:55,025 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: pt
2024-12-02 13:14:55,047 [DEBUG] app1.py:1214 - Speech recognizing: terminal
2024-12-02 13:14:55,048 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=619b0ba7eb464143bf2ccb1d95643470, text="terminal", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:55,049 [DEBUG] app1.py:1104 - Sending transcription: terminal (is_final: False)
2024-12-02 13:14:55,059 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:14:55,060 [DEBUG] app1.py:1031 - Received translation request - Text: 'terminal', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:14:55,060 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:14:55,634 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:14:55,635 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a7d89c0608b547f39552035fc21db89c, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:14:55,636 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:14:55,640 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:14:55,640 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:14:55,641 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:14:57,158 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 13:14:57,160 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=64e458d7750144c78e42933cd37cbdb7, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:14:57,161 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 13:14:57,165 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:14:57,166 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:14:57,166 [DEBUG] app1.py:1042 - Normalized text: 'hi.'
2024-12-02 13:14:57,166 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 75.2824444770813s
2024-12-02 13:14:57,168 [DEBUG] app1.py:1056 - Checking cache with key: hi.:es
2024-12-02 13:14:57,168 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 13:14:57,168 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: hola.
2024-12-02 13:14:57,168 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:14:57,168 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'hola.'}
2024-12-02 13:14:57,172 [INFO] app1.py:1152 - Client 71b562af-3aa2-4bbf-b66b-3513c9caa661 disconnected
2024-12-02 13:14:58,061 [ERROR] app1.py:1157 - Error in translation stream for client 71b562af-3aa2-4bbf-b66b-3513c9caa661: '71b562af-3aa2-4bbf-b66b-3513c9caa661'
2024-12-02 13:15:00,073 [INFO] app1.py:1121 - New translation stream connection for client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, language: pt
2024-12-02 13:15:00,074 [INFO] app1.py:1131 - Creating new client connection: 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:15:01,426 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 13:15:01,427 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c73c91f9223f467eb2cec9ff875b70cb, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:01,429 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 13:15:01,434 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:01,434 [DEBUG] app1.py:1031 - Received translation request - Text: 'what are you doing', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:15:01,435 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:15:03,243 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 13:15:03,244 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=59307d70178845b6aba340b83d628b38, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:03,244 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 13:15:03,248 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:03,249 [DEBUG] app1.py:1031 - Received translation request - Text: 'What are you doing?', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:15:03,250 [DEBUG] app1.py:1042 - Normalized text: 'what are you doing?'
2024-12-02 13:15:03,250 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 6.083688497543335s
2024-12-02 13:15:03,250 [DEBUG] app1.py:1056 - Checking cache with key: what are you doing?:es
2024-12-02 13:15:03,251 [DEBUG] app1.py:1059 - Translation found in recent cache
2024-12-02 13:15:03,251 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: ¿Qué estás haciendo?
2024-12-02 13:15:03,252 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:15:03,252 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': '¿Qué estás haciendo?'}
2024-12-02 13:15:03,258 [INFO] app1.py:1274 - Speech synthesis requested - Text: '¿Qué estás haciendo?', Language: es
2024-12-02 13:15:03,260 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4627dd75-66d5-4e96-8267-524676a2641d.wav
2024-12-02 13:15:03,262 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:15:04,125 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:15:04,125 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_4627dd75-66d5-4e96-8267-524676a2641d.wav
2024-12-02 13:15:06,221 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:15:13,829 [DEBUG] app1.py:1214 - Speech recognizing: success
2024-12-02 13:15:13,829 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ad8d024f9cf54423bb901f0cb4580d70, text="success", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:13,829 [DEBUG] app1.py:1104 - Sending transcription: success (is_final: False)
2024-12-02 13:15:13,834 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:13,835 [DEBUG] app1.py:1031 - Received translation request - Text: 'success', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:15:13,836 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:15:14,262 [DEBUG] app1.py:1214 - Speech recognizing: successfully
2024-12-02 13:15:14,264 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=60e5805df75942d4a6ef40d734bc3150, text="successfully", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:14,264 [DEBUG] app1.py:1104 - Sending transcription: successfully (is_final: False)
2024-12-02 13:15:14,268 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:14,268 [DEBUG] app1.py:1031 - Received translation request - Text: 'successfully', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:15:14,269 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:15:16,065 [INFO] app1.py:1205 - Speech recognized: Successfully.
2024-12-02 13:15:16,066 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7856a145ab80451f89e81970c682355b, text="Successfully.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:16,068 [DEBUG] app1.py:1104 - Sending transcription: Successfully. (is_final: True)
2024-12-02 13:15:16,076 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:16,077 [DEBUG] app1.py:1031 - Received translation request - Text: 'Successfully.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:15:16,078 [DEBUG] app1.py:1042 - Normalized text: 'successfully.'
2024-12-02 13:15:16,079 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 12.828372716903687s
2024-12-02 13:15:16,079 [DEBUG] app1.py:1056 - Checking cache with key: successfully.:es
2024-12-02 13:15:16,080 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:15:16,081 [INFO] app1.py:933 - Starting translation request - Text: 'successfully.', Target language: es
2024-12-02 13:15:16,082 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:15:16,084 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:15:16,085 [DEBUG] app1.py:964 - Request body: [{'text': 'successfully.'}]
2024-12-02 13:15:17,028 [DEBUG] app1.py:1214 - Speech recognizing: as
2024-12-02 13:15:17,028 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8d8c0b21ca1843f3b41a86a69d9963a0, text="as", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:17,029 [DEBUG] app1.py:1104 - Sending transcription: as (is_final: False)
2024-12-02 13:15:17,035 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:17,035 [DEBUG] app1.py:1031 - Received translation request - Text: 'as', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:15:17,036 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:15:17,291 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:15:17,292 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'exitosamente.', 'to': 'es'}]}]
2024-12-02 13:15:17,292 [DEBUG] app1.py:974 - Extracted translation: exitosamente.
2024-12-02 13:15:17,293 [INFO] app1.py:975 - Translation completed successfully - Original: 'successfully.' -> Translation: 'exitosamente.' (es)
2024-12-02 13:15:17,294 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: exitosamente.
2024-12-02 13:15:17,294 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:15:17,294 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'exitosamente.'}
2024-12-02 13:15:17,298 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'exitosamente.', Language: es
2024-12-02 13:15:17,299 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0877d5cb-7c25-4253-88f6-14897f17566d.wav
2024-12-02 13:15:17,300 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:15:17,431 [DEBUG] app1.py:1214 - Speech recognizing: as in ticket
2024-12-02 13:15:17,432 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ffef04b6f7c46d8b050d266fa5ea8aa, text="as in ticket", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:17,433 [DEBUG] app1.py:1104 - Sending transcription: as in ticket (is_final: False)
2024-12-02 13:15:17,438 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:17,439 [DEBUG] app1.py:1031 - Received translation request - Text: 'as in ticket', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:15:17,440 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:15:17,661 [INFO] app1.py:1205 - Speech recognized: As in ticket.
2024-12-02 13:15:17,662 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cb12a9fb6e254f3596a64323cbe69d90, text="As in ticket.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:17,663 [DEBUG] app1.py:1104 - Sending transcription: As in ticket. (is_final: True)
2024-12-02 13:15:17,668 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:17,668 [DEBUG] app1.py:1031 - Received translation request - Text: 'As in ticket.', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: True
2024-12-02 13:15:17,669 [DEBUG] app1.py:1042 - Normalized text: 'as in ticket.'
2024-12-02 13:15:17,669 [DEBUG] app1.py:1048 - Time since last translation for 71b562af-3aa2-4bbf-b66b-3513c9caa661:es: 1.5907588005065918s
2024-12-02 13:15:17,670 [DEBUG] app1.py:1056 - Checking cache with key: as in ticket.:es
2024-12-02 13:15:17,671 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:15:17,672 [INFO] app1.py:933 - Starting translation request - Text: 'as in ticket.', Target language: es
2024-12-02 13:15:17,672 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:15:17,673 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:15:17,673 [DEBUG] app1.py:964 - Request body: [{'text': 'as in ticket.'}]
2024-12-02 13:15:17,983 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:15:17,984 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'como en el billete.', 'to': 'es'}]}]
2024-12-02 13:15:17,985 [DEBUG] app1.py:974 - Extracted translation: como en el billete.
2024-12-02 13:15:17,986 [INFO] app1.py:975 - Translation completed successfully - Original: 'as in ticket.' -> Translation: 'como en el billete.' (es)
2024-12-02 13:15:17,987 [DEBUG] app1.py:918 - Sending translation to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: como en el billete.
2024-12-02 13:15:17,988 [DEBUG] app1.py:925 - Translation sent successfully to client 71b562af-3aa2-4bbf-b66b-3513c9caa661
2024-12-02 13:15:17,989 [DEBUG] app1.py:1144 - Sending message to client 71b562af-3aa2-4bbf-b66b-3513c9caa661: {'type': 'final', 'translation': 'como en el billete.'}
2024-12-02 13:15:18,533 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:15:18,534 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0877d5cb-7c25-4253-88f6-14897f17566d.wav
2024-12-02 13:15:20,027 [DEBUG] app1.py:1214 - Speech recognizing: the API
2024-12-02 13:15:20,027 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=12ff7c71432e4ccc88dfa932c572d7fa, text="the API", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:20,028 [DEBUG] app1.py:1104 - Sending transcription: the API (is_final: False)
2024-12-02 13:15:20,033 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:15:20,034 [DEBUG] app1.py:1031 - Received translation request - Text: 'the API', Target: es, Client: 71b562af-3aa2-4bbf-b66b-3513c9caa661, Final: False
2024-12-02 13:15:20,035 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:15:22,373 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 13:15:22,427 [DEBUG] app1.py:1214 - Speech recognizing: API
2024-12-02 13:15:22,428 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ee887a1ed85e4b30960fb058dbe1efbc, text="API", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:22,428 [DEBUG] app1.py:1104 - Sending transcription: API (is_final: False)
2024-12-02 13:15:22,584 [INFO] app1.py:1205 - Speech recognized: API.
2024-12-02 13:15:22,585 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=124169dc742445ee9461b6697d441d3f, text="API.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:22,586 [DEBUG] app1.py:1104 - Sending transcription: API. (is_final: True)
2024-12-02 13:15:22,586 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 13:15:28,952 [INFO] app1.py:1013 - Go live page requested
2024-12-02 13:15:30,572 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 13:15:30,701 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 13:15:30,822 [INFO] app1.py:1240 - Audio stream started
2024-12-02 13:15:36,222 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:15:46,160 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:15:46,160 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=257253f4d13f4583a267e0785eda2871, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:47,978 [DEBUG] app1.py:1214 - Speech recognizing: R
2024-12-02 13:15:47,979 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e1b73d7076c14605a44bdc126e869ec4, text="R", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:48,276 [DEBUG] app1.py:1214 - Speech recognizing: ruk
2024-12-02 13:15:48,277 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=719ba84d0bfd4f379a269c2ed410e458, text="ruk", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:48,369 [DEBUG] app1.py:1214 - Speech recognizing: ruku yadav
2024-12-02 13:15:48,369 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a8d012190e6842118fcb974f6aa1f74a, text="ruku yadav", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:48,976 [DEBUG] app1.py:1214 - Speech recognizing: ruku yadav rook
2024-12-02 13:15:48,977 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e212341d95724cc2951577ec66330b7d, text="ruku yadav rook", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:49,177 [DEBUG] app1.py:1214 - Speech recognizing: ruku yadav rookie ireland
2024-12-02 13:15:49,177 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=23e834bd2b06458b9bb469a4c4b77a47, text="ruku yadav rookie ireland", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:49,767 [DEBUG] app1.py:1214 - Speech recognizing: ruku yadav rookie ireland ad
2024-12-02 13:15:49,768 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ee83e21581c143bf849321b0e1187e89, text="ruku yadav rookie ireland ad", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:49,876 [DEBUG] app1.py:1214 - Speech recognizing: ruku yadav rookie ireland aruviya
2024-12-02 13:15:49,877 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cdb6c9a1e90f4cfa9d3ba31db337f1e6, text="ruku yadav rookie ireland aruviya", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:50,388 [INFO] app1.py:1205 - Speech recognized: Rookie Ireland Aduhya.
2024-12-02 13:15:50,389 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7a9a1dac807c4ce7b405586f20b19466, text="Rookie Ireland Aduhya.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:52,452 [DEBUG] app1.py:1214 - Speech recognizing: her voice
2024-12-02 13:15:52,453 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7322b458cdc0450394ecfb2ffd6519e3, text="her voice", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:52,745 [DEBUG] app1.py:1214 - Speech recognizing: her voice is
2024-12-02 13:15:52,745 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e523f891e9fe456ab8aadca978429acd, text="her voice is", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:53,753 [DEBUG] app1.py:1214 - Speech recognizing: her voice is for EK gape jahaanara
2024-12-02 13:15:53,754 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=45bb17a399e548d3ad387252a218b0ef, text="her voice is for EK gape jahaanara", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:53,955 [DEBUG] app1.py:1214 - Speech recognizing: her voice is for EK gape jahaanara oh
2024-12-02 13:15:53,956 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c88c764dd4ec4e69b8ba6ef5a14ed8c2, text="her voice is for EK gape jahaanara oh", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:54,353 [DEBUG] app1.py:1214 - Speech recognizing: her voice is oh that's
2024-12-02 13:15:54,353 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=44731941c27d4e51a30e50f00f51ff09, text="her voice is oh that's", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:54,653 [DEBUG] app1.py:1214 - Speech recognizing: her voice is oh that's the window
2024-12-02 13:15:54,655 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=29415b0ef8984f3babe970766304362e, text="her voice is oh that's the window", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:15:56,933 [INFO] app1.py:1205 - Speech recognized: Her voice is Oh, that's the window.
2024-12-02 13:15:56,934 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=51dc209e297c4bcf9a4b7573a10adfe4, text="Her voice is Oh, that's the window.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:58,159 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 13:15:58,436 [INFO] app1.py:1205 - Speech recognized: Stop.
2024-12-02 13:15:58,437 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0db70f6ef26e4b78b6e1e3f3847830ee, text="Stop.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:15:58,439 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 13:16:06,230 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:16:36,240 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:17:06,242 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:17:22,399 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 13:17:22,552 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 13:17:22,647 [INFO] app1.py:1240 - Audio stream started
2024-12-02 13:17:24,415 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:17:24,417 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=af0412f3095b45f5870e6c029f346628, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:24,615 [DEBUG] app1.py:1214 - Speech recognizing: hi what are
2024-12-02 13:17:24,616 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=becd48a496df457688f496759e1f8a7c, text="hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:25,020 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:17:25,021 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f2d218f104fd4fcf9b115229eb0b34fb, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:25,641 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 13:17:25,642 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=41b05dfded4241f7a0f32421b806455c, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:17:35,407 [DEBUG] app1.py:1214 - Speech recognizing: hey hi
2024-12-02 13:17:35,408 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fa7c03dc1df3466ebaf0de15800d246d, text="hey hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:35,422 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 13:17:35,423 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ffaf3070e7b74114830d5eddfa4e74ad, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:17:36,244 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:17:46,413 [DEBUG] app1.py:1214 - Speech recognizing: mmm
2024-12-02 13:17:46,413 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=04c6fc7640ff49a19cf049658859c7ce, text="mmm", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:47,019 [DEBUG] app1.py:1214 - Speech recognizing: mmm did you
2024-12-02 13:17:47,020 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=55b198d3aa4c43a09ad4732fb7145c3a, text="mmm did you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:47,721 [DEBUG] app1.py:1214 - Speech recognizing: mmm did you get in the
2024-12-02 13:17:47,722 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7e83587fcb3d4cfab25c55ae5259d8c2, text="mmm did you get in the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:49,618 [DEBUG] app1.py:1214 - Speech recognizing: mmm did you get in the ruku
2024-12-02 13:17:49,618 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=89f189628fe04ee19376650951d0b06e, text="mmm did you get in the ruku", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:50,218 [DEBUG] app1.py:1214 - Speech recognizing: mmm did you get in the ruku thingya
2024-12-02 13:17:50,218 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6bc6971919594ea6bfd040fe091bc4ba, text="mmm did you get in the ruku thingya", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:50,515 [DEBUG] app1.py:1214 - Speech recognizing: mmm did you get in the
2024-12-02 13:17:50,516 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=42fcf07db17b4079b18d0df8ffe33742, text="mmm did you get in the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:52,211 [DEBUG] app1.py:1214 - Speech recognizing: mmm did you get in the local
2024-12-02 13:17:52,212 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9f38826567a14a36bdeb7f65430acaaf, text="mmm did you get in the local", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:54,064 [INFO] app1.py:1205 - Speech recognized: MMM did you get in the?
2024-12-02 13:17:54,065 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f1e37215ad0c4754832318a97c39890b, text="MMM did you get in the?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:17:58,507 [DEBUG] app1.py:1214 - Speech recognizing: broad
2024-12-02 13:17:58,508 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eca3da805a3a4ca7af8cd16fcb76757d, text="broad", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:59,099 [DEBUG] app1.py:1214 - Speech recognizing: broadcaster
2024-12-02 13:17:59,100 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9e88abc9f647426399259dcf8955125d, text="broadcaster", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:17:59,706 [DEBUG] app1.py:1214 - Speech recognizing: broadcaster of
2024-12-02 13:17:59,707 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f5ac89680c1d4c9ebe7be6a3c2ed777d, text="broadcaster of", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:02,848 [INFO] app1.py:1205 - Speech recognized: Broadcaster of.
2024-12-02 13:18:02,849 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7fef9b84cfff4155b21e0eb0b8c2ca3d, text="Broadcaster of.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:18:06,245 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:18:07,519 [INFO] app1.py:1018 - Join live page requested
2024-12-02 13:18:09,905 [INFO] app1.py:1018 - Join live page requested
2024-12-02 13:18:12,126 [DEBUG] app1.py:1214 - Speech recognizing: a joint
2024-12-02 13:18:12,127 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8cbd6fd0a3cf43e2b5938058b70fb95e, text="a joint", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:12,516 [DEBUG] app1.py:1214 - Speech recognizing: a joint live
2024-12-02 13:18:12,516 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9e284dddac19424b92aac24b29c59561, text="a joint live", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:14,243 [INFO] app1.py:1205 - Speech recognized: Joined live.
2024-12-02 13:18:14,244 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e08002676e5e4f67a582fa075a304a25, text="Joined live.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:18:15,510 [INFO] app1.py:1013 - Go live page requested
2024-12-02 13:18:21,649 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:18:21,649 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ed2390bb4d34dc1a24473a4e3cae11a, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:21,849 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:18:21,850 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8f39ccbe26a44c6e862843e27e593c84, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:22,145 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:18:22,146 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0db9140d0812491a9904ffe9249dab83, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:23,048 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 13:18:23,049 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=83ffb28628464961957df62e7bfc20fa, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:18:29,526 [DEBUG] app1.py:1214 - Speech recognizing: 20
2024-12-02 13:18:29,527 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1b42a902747943209c17381cbbd430a0, text="20", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:29,919 [DEBUG] app1.py:1214 - Speech recognizing: 20 talker
2024-12-02 13:18:29,919 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1b75c638b08b4d058fcde2976bdf6091, text="20 talker", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:30,039 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 13:18:30,213 [DEBUG] app1.py:1214 - Speech recognizing: 20 talker stalker
2024-12-02 13:18:30,213 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3a927116aa854c14988571cff4c128d3, text="20 talker stalker", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:18:30,228 [INFO] app1.py:1205 - Speech recognized: 20 Talker Stalker.
2024-12-02 13:18:30,228 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1a56b3f18cd649abb12a1c538de17066, text="20 Talker Stalker.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:18:30,230 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 13:18:36,247 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:19:06,247 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:19:36,249 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:20:06,259 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:20:36,261 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:21:06,262 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:21:36,264 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:22:06,285 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:22:36,289 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:23:06,292 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:23:36,293 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:24:06,294 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:24:36,297 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:25:06,299 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:25:36,301 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:26:06,302 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:26:36,303 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:27:06,304 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:27:36,306 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:28:06,307 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:28:36,309 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:29:06,311 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:29:36,313 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:30:04,532 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 13:30:04,548 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:30:04,552 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:30:04,563 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:30:04,698 [DEBUG] app1.py:1104 - Sending transcription: R (is_final: False)
2024-12-02 13:30:04,747 [DEBUG] app1.py:1104 - Sending transcription: ruk (is_final: False)
2024-12-02 13:30:04,798 [DEBUG] app1.py:1104 - Sending transcription: ruku yadav (is_final: False)
2024-12-02 13:30:04,841 [DEBUG] app1.py:1104 - Sending transcription: ruku yadav rook (is_final: False)
2024-12-02 13:30:04,841 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 13:30:04,842 [DEBUG] app1.py:1104 - Sending transcription: ruku yadav rookie ireland (is_final: False)
2024-12-02 13:30:04,843 [DEBUG] app1.py:1104 - Sending transcription: ruku yadav rookie ireland ad (is_final: False)
2024-12-02 13:30:04,845 [DEBUG] app1.py:1104 - Sending transcription: ruku yadav rookie ireland aruviya (is_final: False)
2024-12-02 13:30:04,846 [DEBUG] app1.py:1104 - Sending transcription: Rookie Ireland Aduhya. (is_final: True)
2024-12-02 13:30:04,865 [DEBUG] app1.py:1104 - Sending transcription: her voice (is_final: False)
2024-12-02 13:30:04,912 [DEBUG] app1.py:1104 - Sending transcription: her voice is (is_final: False)
2024-12-02 13:30:04,929 [DEBUG] app1.py:1104 - Sending transcription: her voice is for EK gape jahaanara (is_final: False)
2024-12-02 13:30:04,945 [DEBUG] app1.py:1104 - Sending transcription: her voice is for EK gape jahaanara oh (is_final: False)
2024-12-02 13:30:04,956 [DEBUG] app1.py:1104 - Sending transcription: her voice is oh that's (is_final: False)
2024-12-02 13:30:04,963 [DEBUG] app1.py:1104 - Sending transcription: her voice is oh that's the window (is_final: False)
2024-12-02 13:30:04,976 [DEBUG] app1.py:1104 - Sending transcription: Her voice is Oh, that's the window. (is_final: True)
2024-12-02 13:30:04,992 [DEBUG] app1.py:1104 - Sending transcription: Stop. (is_final: True)
2024-12-02 13:30:05,000 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:30:05,023 [DEBUG] app1.py:1104 - Sending transcription: hi what are (is_final: False)
2024-12-02 13:30:05,026 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:30:05,040 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 13:30:05,057 [DEBUG] app1.py:1104 - Sending transcription: hey hi (is_final: False)
2024-12-02 13:30:05,060 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 13:30:05,091 [DEBUG] app1.py:1104 - Sending transcription: mmm (is_final: False)
2024-12-02 13:30:05,123 [DEBUG] app1.py:1104 - Sending transcription: mmm did you (is_final: False)
2024-12-02 13:30:05,124 [INFO] app1.py:1240 - Audio stream started
2024-12-02 13:30:05,138 [DEBUG] app1.py:1104 - Sending transcription: mmm did you get in the (is_final: False)
2024-12-02 13:30:05,146 [DEBUG] app1.py:1104 - Sending transcription: mmm did you get in the ruku (is_final: False)
2024-12-02 13:30:05,161 [DEBUG] app1.py:1104 - Sending transcription: mmm did you get in the ruku thingya (is_final: False)
2024-12-02 13:30:05,166 [DEBUG] app1.py:1104 - Sending transcription: mmm did you get in the (is_final: False)
2024-12-02 13:30:05,178 [DEBUG] app1.py:1104 - Sending transcription: mmm did you get in the local (is_final: False)
2024-12-02 13:30:05,180 [DEBUG] app1.py:1104 - Sending transcription: MMM did you get in the? (is_final: True)
2024-12-02 13:30:05,181 [DEBUG] app1.py:1104 - Sending transcription: broad (is_final: False)
2024-12-02 13:30:05,190 [DEBUG] app1.py:1104 - Sending transcription: broadcaster (is_final: False)
2024-12-02 13:30:05,195 [DEBUG] app1.py:1104 - Sending transcription: broadcaster of (is_final: False)
2024-12-02 13:30:05,198 [DEBUG] app1.py:1104 - Sending transcription: Broadcaster of. (is_final: True)
2024-12-02 13:30:05,214 [DEBUG] app1.py:1104 - Sending transcription: a joint (is_final: False)
2024-12-02 13:30:05,226 [DEBUG] app1.py:1104 - Sending transcription: a joint live (is_final: False)
2024-12-02 13:30:05,241 [DEBUG] app1.py:1104 - Sending transcription: Joined live. (is_final: True)
2024-12-02 13:30:05,241 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:30:05,249 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 13:30:05,258 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:30:05,274 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 13:30:05,279 [DEBUG] app1.py:1104 - Sending transcription: 20 (is_final: False)
2024-12-02 13:30:05,293 [DEBUG] app1.py:1104 - Sending transcription: 20 talker (is_final: False)
2024-12-02 13:30:05,296 [DEBUG] app1.py:1104 - Sending transcription: 20 talker stalker (is_final: False)
2024-12-02 13:30:05,297 [DEBUG] app1.py:1104 - Sending transcription: 20 Talker Stalker. (is_final: True)
2024-12-02 13:30:06,315 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661']
2024-12-02 13:30:13,682 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:30:13,683 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=db49be42673f4127b7e886df016a6877, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:13,683 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 13:30:13,994 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:30:13,995 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=310bcf8f278c4571851c81198b37b9a2, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:13,997 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:30:14,826 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 13:30:14,828 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=745ea6a3a29d48fa8edc4bd8a73425bd, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:14,828 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 13:30:21,412 [DEBUG] app1.py:1214 - Speech recognizing: portugues
2024-12-02 13:30:21,412 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fcafbe09a8b64c9488b1abf4e7135136, text="portugues", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:21,413 [DEBUG] app1.py:1104 - Sending transcription: portugues (is_final: False)
2024-12-02 13:30:21,707 [DEBUG] app1.py:1214 - Speech recognizing: portuguese
2024-12-02 13:30:21,707 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3d7dddd4fe114a06b89a5204aa4e581e, text="portuguese", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:21,707 [DEBUG] app1.py:1104 - Sending transcription: portuguese (is_final: False)
2024-12-02 13:30:23,214 [INFO] app1.py:1205 - Speech recognized: Portuguese.
2024-12-02 13:30:23,215 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=326b411487944c5b85d19821794244e6, text="Portuguese.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:23,215 [DEBUG] app1.py:1104 - Sending transcription: Portuguese. (is_final: True)
2024-12-02 13:30:24,985 [DEBUG] app1.py:1214 - Speech recognizing: portuguese
2024-12-02 13:30:24,986 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7663708a3f3540cd8698ec1e94a8ae08, text="portuguese", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:24,986 [DEBUG] app1.py:1104 - Sending transcription: portuguese (is_final: False)
2024-12-02 13:30:26,818 [INFO] app1.py:1205 - Speech recognized: Portuguese.
2024-12-02 13:30:26,822 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=827d2bd1441f4b8ba5f6b0873cc68673, text="Portuguese.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:26,830 [DEBUG] app1.py:1104 - Sending transcription: Portuguese. (is_final: True)
2024-12-02 13:30:30,086 [DEBUG] app1.py:1214 - Speech recognizing: portuguese
2024-12-02 13:30:30,097 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d25f093f0b23419fb3e7d2c90035c0c0, text="portuguese", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:31,918 [INFO] app1.py:1205 - Speech recognized: Portuguese.
2024-12-02 13:30:31,919 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e2aaf5e7ff4c4cc38ed6f41af5a6d105, text="Portuguese.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:33,360 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:30:33,365 [INFO] app1.py:1121 - New translation stream connection for client: 0f70942e-eefa-4efb-83f1-115edcc18149, language: pt
2024-12-02 13:30:33,369 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:30:33,371 [INFO] app1.py:1131 - Creating new client connection: 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:30:33,371 [DEBUG] app1.py:1104 - Sending transcription: portuguese (is_final: False)
2024-12-02 13:30:33,377 [DEBUG] app1.py:1104 - Sending transcription: Portuguese. (is_final: True)
2024-12-02 13:30:33,412 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:33,413 [DEBUG] app1.py:1031 - Received translation request - Text: 'Portuguese.', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:30:33,414 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:33,414 [DEBUG] app1.py:1042 - Normalized text: 'portuguese.'
2024-12-02 13:30:33,414 [DEBUG] app1.py:1031 - Received translation request - Text: 'portuguese', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:33,415 [DEBUG] app1.py:1056 - Checking cache with key: portuguese.:pt
2024-12-02 13:30:33,415 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:33,415 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:30:33,449 [INFO] app1.py:933 - Starting translation request - Text: 'portuguese.', Target language: pt
2024-12-02 13:30:33,465 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:30:33,465 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:30:33,466 [DEBUG] app1.py:964 - Request body: [{'text': 'portuguese.'}]
2024-12-02 13:30:34,017 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:30:34,019 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'Português.', 'to': 'pt'}]}]
2024-12-02 13:30:34,020 [DEBUG] app1.py:974 - Extracted translation: Português.
2024-12-02 13:30:34,021 [INFO] app1.py:975 - Translation completed successfully - Original: 'portuguese.' -> Translation: 'Português.' (pt)
2024-12-02 13:30:34,024 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: Português.
2024-12-02 13:30:34,025 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:30:34,025 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'Português.'}
2024-12-02 13:30:35,898 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:30:35,899 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=82f2e8b1432d4983acdc6ab7d50edbba, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:35,899 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:30:35,909 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:35,909 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:35,910 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:36,085 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:30:36,086 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cb302bef3bf54b8d93035df4c2a9f855, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:36,087 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 13:30:36,092 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:36,094 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:36,095 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:36,316 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:30:36,490 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:30:36,491 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9944e74373e34f10a53763de559e5916, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:36,492 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:30:36,498 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:36,499 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you doing', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:36,500 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:37,611 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 13:30:37,612 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ba806092e7964bb38dfa46c6007dd8b5, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:37,612 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 13:30:37,616 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:37,617 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, what are you doing?', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:30:37,619 [DEBUG] app1.py:1042 - Normalized text: 'hi, what are you doing?'
2024-12-02 13:30:37,620 [DEBUG] app1.py:1048 - Time since last translation for 0f70942e-eefa-4efb-83f1-115edcc18149:pt: 4.204424619674683s
2024-12-02 13:30:37,621 [DEBUG] app1.py:1056 - Checking cache with key: hi, what are you doing?:pt
2024-12-02 13:30:37,625 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:30:37,626 [INFO] app1.py:933 - Starting translation request - Text: 'hi, what are you doing?', Target language: pt
2024-12-02 13:30:37,626 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:30:37,627 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:30:37,627 [DEBUG] app1.py:964 - Request body: [{'text': 'hi, what are you doing?'}]
2024-12-02 13:30:38,852 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:30:38,853 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'Oi, o que você está fazendo?', 'to': 'pt'}]}]
2024-12-02 13:30:38,853 [DEBUG] app1.py:974 - Extracted translation: Oi, o que você está fazendo?
2024-12-02 13:30:38,854 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi, what are you doing?' -> Translation: 'Oi, o que você está fazendo?' (pt)
2024-12-02 13:30:38,854 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: Oi, o que você está fazendo?
2024-12-02 13:30:38,854 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:30:38,854 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'Oi, o que você está fazendo?'}
2024-12-02 13:30:41,787 [DEBUG] app1.py:1214 - Speech recognizing: mulheri
2024-12-02 13:30:41,788 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f8faf8cf51b54c7897f1b4d41b7eaa8f, text="mulheri", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:41,788 [DEBUG] app1.py:1104 - Sending transcription: mulheri (is_final: False)
2024-12-02 13:30:41,796 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:41,798 [DEBUG] app1.py:1031 - Received translation request - Text: 'mulheri', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:41,801 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:42,096 [DEBUG] app1.py:1214 - Speech recognizing: muller in
2024-12-02 13:30:42,096 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fb8905fe761342a1b32993ecb15983a9, text="muller in", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:42,097 [DEBUG] app1.py:1104 - Sending transcription: muller in (is_final: False)
2024-12-02 13:30:42,101 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:42,111 [DEBUG] app1.py:1031 - Received translation request - Text: 'muller in', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:42,113 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:42,393 [DEBUG] app1.py:1214 - Speech recognizing: muller in gulay
2024-12-02 13:30:42,393 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9e5d6d03113d4210a0d516d712815771, text="muller in gulay", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:42,394 [DEBUG] app1.py:1104 - Sending transcription: muller in gulay (is_final: False)
2024-12-02 13:30:42,397 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:42,397 [DEBUG] app1.py:1031 - Received translation request - Text: 'muller in gulay', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:42,398 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:42,796 [DEBUG] app1.py:1214 - Speech recognizing: muller in gulayani
2024-12-02 13:30:42,797 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b96ef0c14ac6428284d60b3edaa569fa, text="muller in gulayani", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:42,798 [DEBUG] app1.py:1104 - Sending transcription: muller in gulayani (is_final: False)
2024-12-02 13:30:42,804 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:42,805 [DEBUG] app1.py:1031 - Received translation request - Text: 'muller in gulayani', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:42,810 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:42,990 [DEBUG] app1.py:1214 - Speech recognizing: muller in gulayanima
2024-12-02 13:30:43,015 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d0e7b963dec4038ab0f0d6a3ae86a69, text="muller in gulayanima", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:43,041 [DEBUG] app1.py:1104 - Sending transcription: muller in gulayanima (is_final: False)
2024-12-02 13:30:43,074 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:43,075 [DEBUG] app1.py:1031 - Received translation request - Text: 'muller in gulayanima', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:43,075 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:43,409 [DEBUG] app1.py:1214 - Speech recognizing: muller in gulayanima likhi taini
2024-12-02 13:30:43,411 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=91fc43addaed436f83e6c917bd5bb025, text="muller in gulayanima likhi taini", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:43,413 [DEBUG] app1.py:1104 - Sending transcription: muller in gulayanima likhi taini (is_final: False)
2024-12-02 13:30:43,426 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:43,427 [DEBUG] app1.py:1031 - Received translation request - Text: 'muller in gulayanima likhi taini', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:43,428 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:44,684 [DEBUG] app1.py:1214 - Speech recognizing: muller in gulayanima likhi taini bul
2024-12-02 13:30:44,685 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e2f60f6f6b8e4db19ef4cd0582057324, text="muller in gulayanima likhi taini bul", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:44,685 [DEBUG] app1.py:1104 - Sending transcription: muller in gulayanima likhi taini bul (is_final: False)
2024-12-02 13:30:44,688 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:44,690 [DEBUG] app1.py:1031 - Received translation request - Text: 'muller in gulayanima likhi taini bul', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:44,690 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:44,994 [DEBUG] app1.py:1214 - Speech recognizing: muller in gulayanima likhi taini bulani
2024-12-02 13:30:44,994 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=15c66214f85d4cf7acfc2b26b8d63495, text="muller in gulayanima likhi taini bulani", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:44,995 [DEBUG] app1.py:1104 - Sending transcription: muller in gulayanima likhi taini bulani (is_final: False)
2024-12-02 13:30:44,999 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:45,000 [DEBUG] app1.py:1031 - Received translation request - Text: 'muller in gulayanima likhi taini bulani', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:45,000 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:46,844 [INFO] app1.py:1205 - Speech recognized: Muller in Gulayanima likhi taini.
2024-12-02 13:30:46,845 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ec1514bbdf794c29b389a298e74a4baa, text="Muller in Gulayanima likhi taini.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:46,847 [DEBUG] app1.py:1104 - Sending transcription: Muller in Gulayanima likhi taini. (is_final: True)
2024-12-02 13:30:46,854 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:46,854 [DEBUG] app1.py:1031 - Received translation request - Text: 'Muller in Gulayanima likhi taini.', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:30:46,858 [DEBUG] app1.py:1042 - Normalized text: 'muller in gulayanima likhi taini.'
2024-12-02 13:30:46,860 [DEBUG] app1.py:1048 - Time since last translation for 0f70942e-eefa-4efb-83f1-115edcc18149:pt: 9.241300821304321s
2024-12-02 13:30:46,860 [DEBUG] app1.py:1056 - Checking cache with key: muller in gulayanima likhi taini.:pt
2024-12-02 13:30:46,860 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:30:46,861 [INFO] app1.py:933 - Starting translation request - Text: 'muller in gulayanima likhi taini.', Target language: pt
2024-12-02 13:30:46,861 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:30:46,863 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:30:46,863 [DEBUG] app1.py:964 - Request body: [{'text': 'muller in gulayanima likhi taini.'}]
2024-12-02 13:30:47,303 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:30:47,413 [DEBUG] app1.py:974 - Extracted translation: Ela não escreveu Muller em Gulayanima.
2024-12-02 13:30:47,414 [INFO] app1.py:975 - Translation completed successfully - Original: 'muller in gulayanima likhi taini.' -> Translation: 'Ela não escreveu Muller em Gulayanima.' (pt)
2024-12-02 13:30:47,414 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: Ela não escreveu Muller em Gulayanima.
2024-12-02 13:30:47,415 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:30:47,415 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'Ela não escreveu Muller em Gulayanima.'}
2024-12-02 13:30:50,898 [INFO] app1.py:1205 - Speech recognized: Goes to India.
2024-12-02 13:30:50,899 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9981d1cc6f7e44f084bb2f7e1f4f58f0, text="Goes to India.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:50,900 [DEBUG] app1.py:1104 - Sending transcription: Goes to India. (is_final: True)
2024-12-02 13:30:50,907 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:50,907 [DEBUG] app1.py:1031 - Received translation request - Text: 'Goes to India.', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:30:50,916 [DEBUG] app1.py:1042 - Normalized text: 'goes to india.'
2024-12-02 13:30:50,918 [DEBUG] app1.py:1048 - Time since last translation for 0f70942e-eefa-4efb-83f1-115edcc18149:pt: 4.0562827587127686s
2024-12-02 13:30:50,920 [DEBUG] app1.py:1056 - Checking cache with key: goes to india.:pt
2024-12-02 13:30:50,923 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:30:50,923 [INFO] app1.py:933 - Starting translation request - Text: 'goes to india.', Target language: pt
2024-12-02 13:30:50,924 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:30:50,924 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:30:50,924 [DEBUG] app1.py:964 - Request body: [{'text': 'goes to india.'}]
2024-12-02 13:30:51,218 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:30:51,220 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'vai para a Índia.', 'to': 'pt'}]}]
2024-12-02 13:30:51,221 [DEBUG] app1.py:974 - Extracted translation: vai para a Índia.
2024-12-02 13:30:51,222 [INFO] app1.py:975 - Translation completed successfully - Original: 'goes to india.' -> Translation: 'vai para a Índia.' (pt)
2024-12-02 13:30:51,223 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: vai para a Índia.
2024-12-02 13:30:51,224 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:30:51,224 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'vai para a Índia.'}
2024-12-02 13:30:56,726 [DEBUG] app1.py:1214 - Speech recognizing: mulashi glam waiya enakku teriya APA continue
2024-12-02 13:30:56,728 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a6eb00dae85a4e4795092baec285e266, text="mulashi glam waiya enakku teriya APA continue", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:56,730 [DEBUG] app1.py:1104 - Sending transcription: mulashi glam waiya enakku teriya APA continue (is_final: False)
2024-12-02 13:30:56,744 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:56,745 [DEBUG] app1.py:1031 - Received translation request - Text: 'mulashi glam waiya enakku teriya APA continue', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:56,745 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:57,020 [DEBUG] app1.py:1214 - Speech recognizing: mulashi glam waiya enakku teriya APA continue run
2024-12-02 13:30:57,021 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=169dc32d34164c36baaeafbf0bc5c08d, text="mulashi glam waiya enakku teriya APA continue run", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:57,022 [DEBUG] app1.py:1104 - Sending transcription: mulashi glam waiya enakku teriya APA continue run (is_final: False)
2024-12-02 13:30:57,026 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:57,027 [DEBUG] app1.py:1031 - Received translation request - Text: 'mulashi glam waiya enakku teriya APA continue run', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:57,027 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:57,114 [DEBUG] app1.py:1214 - Speech recognizing: mulashi glam waiya enakku teriya APA continue run K
2024-12-02 13:30:57,114 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c903737743c0494cbad98b6e315dd615, text="mulashi glam waiya enakku teriya APA continue run K", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:57,120 [DEBUG] app1.py:1104 - Sending transcription: mulashi glam waiya enakku teriya APA continue run K (is_final: False)
2024-12-02 13:30:57,123 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:57,125 [DEBUG] app1.py:1031 - Received translation request - Text: 'mulashi glam waiya enakku teriya APA continue run K', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:57,125 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:57,409 [DEBUG] app1.py:1214 - Speech recognizing: mmm mmm
2024-12-02 13:30:57,410 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c5df831e6fe5495fae85cdd1136cb9c2, text="mmm mmm", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:30:57,411 [DEBUG] app1.py:1104 - Sending transcription: mmm mmm (is_final: False)
2024-12-02 13:30:57,415 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:57,415 [DEBUG] app1.py:1031 - Received translation request - Text: 'mmm mmm', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:30:57,417 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:30:59,244 [INFO] app1.py:1205 - Speech recognized: MMM MMM.
2024-12-02 13:30:59,244 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7da12e89692f40938d4cf872e8509204, text="MMM MMM.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:30:59,245 [DEBUG] app1.py:1104 - Sending transcription: MMM MMM. (is_final: True)
2024-12-02 13:30:59,249 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:30:59,250 [DEBUG] app1.py:1031 - Received translation request - Text: 'MMM MMM.', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:30:59,257 [DEBUG] app1.py:1042 - Normalized text: 'mmm mmm.'
2024-12-02 13:30:59,259 [DEBUG] app1.py:1048 - Time since last translation for 0f70942e-eefa-4efb-83f1-115edcc18149:pt: 8.34282112121582s
2024-12-02 13:30:59,260 [DEBUG] app1.py:1056 - Checking cache with key: mmm mmm.:pt
2024-12-02 13:30:59,260 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:30:59,261 [INFO] app1.py:933 - Starting translation request - Text: 'mmm mmm.', Target language: pt
2024-12-02 13:30:59,261 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:30:59,262 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:30:59,262 [DEBUG] app1.py:964 - Request body: [{'text': 'mmm mmm.'}]
2024-12-02 13:31:00,544 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:31:00,545 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.86}, 'translations': [{'text': 'mmm mmm.', 'to': 'pt'}]}]
2024-12-02 13:31:00,546 [DEBUG] app1.py:974 - Extracted translation: mmm mmm.
2024-12-02 13:31:00,547 [INFO] app1.py:975 - Translation completed successfully - Original: 'mmm mmm.' -> Translation: 'mmm mmm.' (pt)
2024-12-02 13:31:00,548 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: mmm mmm.
2024-12-02 13:31:00,548 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:31:00,548 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'mmm mmm.'}
2024-12-02 13:31:06,319 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:31:13,083 [DEBUG] app1.py:1214 - Speech recognizing: only other equipment
2024-12-02 13:31:13,084 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f50c125b690c46d58b4bf06597dcb52c, text="only other equipment", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:13,086 [DEBUG] app1.py:1104 - Sending transcription: only other equipment (is_final: False)
2024-12-02 13:31:13,096 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:31:13,097 [DEBUG] app1.py:1031 - Received translation request - Text: 'only other equipment', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:31:13,098 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:31:14,891 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:31:14,892 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6c8d43d0602d41bca547f0f0c919c6d2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:31:14,893 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:31:15,684 [DEBUG] app1.py:1214 - Speech recognizing: continue
2024-12-02 13:31:15,701 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=41764fdcd2d0402a88647dafb111a5f4, text="continue", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:15,702 [DEBUG] app1.py:1104 - Sending transcription: continue (is_final: False)
2024-12-02 13:31:15,707 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:31:15,708 [DEBUG] app1.py:1031 - Received translation request - Text: 'continue', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:31:15,709 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:31:17,512 [INFO] app1.py:1205 - Speech recognized: Continue.
2024-12-02 13:31:17,513 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=064f028d94134a40a02e61af455bdfa4, text="Continue.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:31:17,513 [DEBUG] app1.py:1104 - Sending transcription: Continue. (is_final: True)
2024-12-02 13:31:17,517 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:31:17,518 [DEBUG] app1.py:1031 - Received translation request - Text: 'Continue.', Target: pt, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:31:17,519 [DEBUG] app1.py:1042 - Normalized text: 'continue.'
2024-12-02 13:31:17,522 [DEBUG] app1.py:1048 - Time since last translation for 0f70942e-eefa-4efb-83f1-115edcc18149:pt: 18.26337957382202s
2024-12-02 13:31:17,525 [DEBUG] app1.py:1056 - Checking cache with key: continue.:pt
2024-12-02 13:31:17,525 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:31:17,525 [INFO] app1.py:933 - Starting translation request - Text: 'continue.', Target language: pt
2024-12-02 13:31:17,526 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:31:17,526 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'pt-BR'}
2024-12-02 13:31:17,526 [DEBUG] app1.py:964 - Request body: [{'text': 'continue.'}]
2024-12-02 13:31:18,053 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:31:18,054 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.77}, 'translations': [{'text': 'continuar.', 'to': 'pt'}]}]
2024-12-02 13:31:18,054 [DEBUG] app1.py:974 - Extracted translation: continuar.
2024-12-02 13:31:18,055 [INFO] app1.py:975 - Translation completed successfully - Original: 'continue.' -> Translation: 'continuar.' (pt)
2024-12-02 13:31:18,056 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: continuar.
2024-12-02 13:31:18,057 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:31:18,058 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'continuar.'}
2024-12-02 13:31:22,456 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 13:31:22,655 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 13:31:24,913 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 13:31:24,930 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:31:24,932 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:31:24,995 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 13:31:25,089 [INFO] app1.py:1240 - Audio stream started
2024-12-02 13:31:27,446 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:31:27,447 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a8c92fcfbb5f4e93bf6673c65250222e, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:27,448 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 13:31:27,649 [DEBUG] app1.py:1214 - Speech recognizing: hi what are
2024-12-02 13:31:27,650 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=44d7abb03c8c4fef93e172afe75cf636, text="hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:27,651 [DEBUG] app1.py:1104 - Sending transcription: hi what are (is_final: False)
2024-12-02 13:31:27,742 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:31:27,742 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=badac2c7103d4ccc99c2439a8ade5592, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:27,743 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:31:29,052 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you
2024-12-02 13:31:29,053 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ba1972699ba4d0084af624729253f60, text="hi what are you doing are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:29,054 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you (is_final: False)
2024-12-02 13:31:29,346 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you listening
2024-12-02 13:31:29,347 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=15628d22481844a7baac69fe11f57fdd, text="hi what are you doing are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:29,348 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you listening (is_final: False)
2024-12-02 13:31:29,657 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing are you listening me
2024-12-02 13:31:29,658 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d47d4ad7fa7844b78de17b21b24ac740, text="hi what are you doing are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:29,658 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing are you listening me (is_final: False)
2024-12-02 13:31:30,186 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing? Are you listening me?
2024-12-02 13:31:30,188 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fe8eb196f1354c918858469521ce6300, text="Hi, what are you doing? Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:31:30,188 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? Are you listening me? (is_final: True)
2024-12-02 13:31:32,249 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 13:31:32,249 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cdf4550420104d30b70c5bc8453ff306, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:32,250 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 13:31:32,543 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:31:32,544 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cd9ef40a899444cdaf78172ed96425ad, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:32,545 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:31:33,165 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 13:31:33,166 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c08479d0baea4303b23454a8c08a24cd, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:31:33,166 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 13:31:34,158 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 13:31:34,159 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=84d73a411a664f118b12e4c43468bb27, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:34,160 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 13:31:35,466 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here
2024-12-02 13:31:35,466 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4d4fb41614de49c094db3936e8d7d35d, text="are you listening here", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:35,467 [DEBUG] app1.py:1104 - Sending transcription: are you listening here (is_final: False)
2024-12-02 13:31:36,320 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:31:36,663 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently
2024-12-02 13:31:36,664 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=992d06b1a26b4d9d91be1c15f87d6f16, text="are you listening here apparently", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:36,665 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently (is_final: False)
2024-12-02 13:31:37,751 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here
2024-12-02 13:31:37,752 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0fc43647d64d45668d0025e106442b5d, text="are you listening here", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:37,753 [DEBUG] app1.py:1104 - Sending transcription: are you listening here (is_final: False)
2024-12-02 13:31:37,952 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently
2024-12-02 13:31:37,953 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=61896f4452a64fa88f1f525207b04361, text="are you listening here apparently", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:37,953 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently (is_final: False)
2024-12-02 13:31:38,358 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently stevielle
2024-12-02 13:31:38,359 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aa692f3e4f174fd7b157a0d747389b9b, text="are you listening here apparently stevielle", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:38,359 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently stevielle (is_final: False)
2024-12-02 13:31:38,677 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently stevielle vaughn
2024-12-02 13:31:38,677 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=34ef29f7f5634746894795e25d84787d, text="are you listening here apparently stevielle vaughn", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:38,678 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently stevielle vaughn (is_final: False)
2024-12-02 13:31:38,929 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently stevielle vaughan
2024-12-02 13:31:38,938 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ac3f0a7934df4d9abe5367cc9d43732b, text="are you listening here apparently stevielle vaughan", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:38,945 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently stevielle vaughan (is_final: False)
2024-12-02 13:31:38,994 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently stevielle vaughn kinjal
2024-12-02 13:31:38,995 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1824bed2b11b479f9d9b00eeb3b07e32, text="are you listening here apparently stevielle vaughn kinjal", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:38,997 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently stevielle vaughn kinjal (is_final: False)
2024-12-02 13:31:40,259 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently stevielle vaughn kinjal bhakti
2024-12-02 13:31:40,260 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bfe9247f15b24195bed47b6f1f414452, text="are you listening here apparently stevielle vaughn kinjal bhakti", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:40,262 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently stevielle vaughn kinjal bhakti (is_final: False)
2024-12-02 13:31:40,461 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently stevielle vaughn kinjal bhakti mar
2024-12-02 13:31:40,463 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8790ddf0e4034fe4b0e1d8b73d3ec3ec, text="are you listening here apparently stevielle vaughn kinjal bhakti mar", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:40,465 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently stevielle vaughn kinjal bhakti mar (is_final: False)
2024-12-02 13:31:40,553 [DEBUG] app1.py:1214 - Speech recognizing: are you listening here apparently stevielle vaughn kinjal bhakti margaret
2024-12-02 13:31:40,555 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bea2ba853c2544faa943da4b634e1d07, text="are you listening here apparently stevielle vaughn kinjal bhakti margaret", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:40,557 [DEBUG] app1.py:1104 - Sending transcription: are you listening here apparently stevielle vaughn kinjal bhakti margaret (is_final: False)
2024-12-02 13:31:42,383 [INFO] app1.py:1205 - Speech recognized: Are you listening here? Apparently. Stevielle Vaughn, Kinjal Bhakti, Margaret.
2024-12-02 13:31:42,384 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9ffe664793ca40d9a6ea54361b7e9710, text="Are you listening here? Apparently. Stevielle Vaughn, Kinjal Bhakti, Margaret.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:31:42,385 [DEBUG] app1.py:1104 - Sending transcription: Are you listening here? Apparently. Stevielle Vaughn, Kinjal Bhakti, Margaret. (is_final: True)
2024-12-02 13:31:47,943 [DEBUG] app1.py:1214 - Speech recognizing: simply
2024-12-02 13:31:47,943 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=889d637d1175496383efe9f612b86473, text="simply", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:47,945 [DEBUG] app1.py:1104 - Sending transcription: simply (is_final: False)
2024-12-02 13:31:48,334 [DEBUG] app1.py:1214 - Speech recognizing: simply punya
2024-12-02 13:31:48,335 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d7e4b675c22a49659438cab220c2366e, text="simply punya", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:48,336 [DEBUG] app1.py:1104 - Sending transcription: simply punya (is_final: False)
2024-12-02 13:31:48,533 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD
2024-12-02 13:31:48,534 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8bb025708aab440c8f24482f7a742733, text="sindhi unneeded PHD", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:48,534 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD (is_final: False)
2024-12-02 13:31:49,249 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP
2024-12-02 13:31:49,249 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=53dc14ae0c094e5d83761f272b196139, text="sindhi unneeded PHD in FPP", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:49,249 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP (is_final: False)
2024-12-02 13:31:49,636 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP pay
2024-12-02 13:31:49,636 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e386ff7ec22b414796edf65c591719b1, text="sindhi unneeded PHD in FPP pay", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:49,636 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP pay (is_final: False)
2024-12-02 13:31:49,838 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP payload
2024-12-02 13:31:49,839 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e1ffc5b519804784b4c2889897acadca, text="sindhi unneeded PHD in FPP payload", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:49,840 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP payload (is_final: False)
2024-12-02 13:31:50,532 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP payloading
2024-12-02 13:31:50,532 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a7c841ec1a5c4f6ab717d9a03eb1f6b2, text="sindhi unneeded PHD in FPP payloading", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:50,533 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP payloading (is_final: False)
2024-12-02 13:31:50,839 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP payloading with
2024-12-02 13:31:50,839 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bb071d60f8354df79ff4771edd484487, text="sindhi unneeded PHD in FPP payloading with", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:50,840 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP payloading with (is_final: False)
2024-12-02 13:31:51,538 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP payloading with nikita
2024-12-02 13:31:51,539 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6bec745aadcd4e4b840722ac334dab1e, text="sindhi unneeded PHD in FPP payloading with nikita", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:51,539 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP payloading with nikita (is_final: False)
2024-12-02 13:31:52,146 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP payloading with nikita chennai
2024-12-02 13:31:52,147 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=675e0053fa0a49b48fbeb658ec53bf3f, text="sindhi unneeded PHD in FPP payloading with nikita chennai", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:52,149 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP payloading with nikita chennai (is_final: False)
2024-12-02 13:31:52,443 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP payloading with nikhil tejani
2024-12-02 13:31:52,444 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce0690b2889c4234bc02e4487b7164bd, text="sindhi unneeded PHD in FPP payloading with nikhil tejani", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:52,446 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP payloading with nikhil tejani (is_final: False)
2024-12-02 13:31:52,846 [DEBUG] app1.py:1214 - Speech recognizing: sindhi unneeded PHD in FPP payloading with nikhil
2024-12-02 13:31:52,847 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c2082116f8b64845999860496506746e, text="sindhi unneeded PHD in FPP payloading with nikhil", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:31:52,848 [DEBUG] app1.py:1104 - Sending transcription: sindhi unneeded PHD in FPP payloading with nikhil (is_final: False)
2024-12-02 13:31:54,304 [INFO] app1.py:1205 - Speech recognized: Sindhi unneeded PhD and payloading with Nikhil.
2024-12-02 13:31:54,305 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c5c5f59e9c974600bce59d88df394f89, text="Sindhi unneeded PhD and payloading with Nikhil.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:31:54,306 [DEBUG] app1.py:1104 - Sending transcription: Sindhi unneeded PhD and payloading with Nikhil. (is_final: True)
2024-12-02 13:32:06,322 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:32:14,473 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:32:14,473 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=26b0b25cd3b243c89e658bd44d7c828b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:14,474 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:32:16,653 [DEBUG] app1.py:1214 - Speech recognizing: this is speech
2024-12-02 13:32:16,653 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2202167461f84cd48fa294bc532a4d7a, text="this is speech", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:16,654 [DEBUG] app1.py:1104 - Sending transcription: this is speech (is_final: False)
2024-12-02 13:32:17,148 [DEBUG] app1.py:1214 - Speech recognizing: this is speech a synth
2024-12-02 13:32:17,148 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7e47e13b384a483c87664a0ce63536cd, text="this is speech a synth", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:17,149 [DEBUG] app1.py:1104 - Sending transcription: this is speech a synth (is_final: False)
2024-12-02 13:32:17,550 [DEBUG] app1.py:1214 - Speech recognizing: this is speech a synthesis
2024-12-02 13:32:17,551 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fdd2a215e52247b0838389c84d2c29c4, text="this is speech a synthesis", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:17,552 [DEBUG] app1.py:1104 - Sending transcription: this is speech a synthesis (is_final: False)
2024-12-02 13:32:17,955 [DEBUG] app1.py:1214 - Speech recognizing: this is speech a synthesis speech
2024-12-02 13:32:17,956 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9c2147ebb5bd49b6955b4374573790d7, text="this is speech a synthesis speech", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:17,957 [DEBUG] app1.py:1104 - Sending transcription: this is speech a synthesis speech (is_final: False)
2024-12-02 13:32:19,794 [INFO] app1.py:1205 - Speech recognized: This is speech synthesis speech.
2024-12-02 13:32:19,794 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b339b28231624684be6626c2da9b6a2b, text="This is speech synthesis speech.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:19,795 [DEBUG] app1.py:1104 - Sending transcription: This is speech synthesis speech. (is_final: True)
2024-12-02 13:32:29,074 [INFO] app1.py:1205 - Speech recognized: Open Mahakaali.
2024-12-02 13:32:29,075 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eb45f197c1224ec9a7fe0fbb8d12f365, text="Open Mahakaali.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:29,075 [DEBUG] app1.py:1104 - Sending transcription: Open Mahakaali. (is_final: True)
2024-12-02 13:32:30,445 [DEBUG] app1.py:1214 - Speech recognizing: open
2024-12-02 13:32:30,445 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8c3af6a7a00e4f03a6153c538099395d, text="open", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:30,446 [DEBUG] app1.py:1104 - Sending transcription: open (is_final: False)
2024-12-02 13:32:30,943 [DEBUG] app1.py:1214 - Speech recognizing: open one
2024-12-02 13:32:30,945 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c3f9fe405e1b4daeabb03318e392bef3, text="open one", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:30,946 [DEBUG] app1.py:1104 - Sending transcription: open one (is_final: False)
2024-12-02 13:32:31,037 [DEBUG] app1.py:1214 - Speech recognizing: open one hand
2024-12-02 13:32:31,037 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e9f2fab1dd8c402ca9411499bf5330d3, text="open one hand", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:31,038 [DEBUG] app1.py:1104 - Sending transcription: open one hand (is_final: False)
2024-12-02 13:32:31,347 [DEBUG] app1.py:1214 - Speech recognizing: open one hand fil
2024-12-02 13:32:31,347 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ab88d070935a4cf69c4628deaca46074, text="open one hand fil", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:31,347 [DEBUG] app1.py:1104 - Sending transcription: open one hand fil (is_final: False)
2024-12-02 13:32:31,439 [DEBUG] app1.py:1214 - Speech recognizing: open one hand filing
2024-12-02 13:32:31,440 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ad5f9b3574f495eb8db1ac5b3ce775d, text="open one hand filing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:31,441 [DEBUG] app1.py:1104 - Sending transcription: open one hand filing (is_final: False)
2024-12-02 13:32:31,736 [DEBUG] app1.py:1214 - Speech recognizing: open my hands on
2024-12-02 13:32:31,736 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=70612f1c22104f41be8e6e0b2c913ba4, text="open my hands on", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:31,737 [DEBUG] app1.py:1104 - Sending transcription: open my hands on (is_final: False)
2024-12-02 13:32:31,860 [INFO] app1.py:1205 - Speech recognized: Open one hand filing 4.
2024-12-02 13:32:31,860 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0628741ae97e41f1a5db0527854740d3, text="Open one hand filing 4.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:31,861 [DEBUG] app1.py:1104 - Sending transcription: Open one hand filing 4. (is_final: True)
2024-12-02 13:32:36,254 [DEBUG] app1.py:1214 - Speech recognizing: why are you
2024-12-02 13:32:36,255 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1194c659233441e8838f1d33ccb40199, text="why are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:36,256 [DEBUG] app1.py:1104 - Sending transcription: why are you (is_final: False)
2024-12-02 13:32:36,323 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:32:36,552 [DEBUG] app1.py:1214 - Speech recognizing: why are you opening
2024-12-02 13:32:36,553 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5dc557cce4a6447184bd4142ff430fd3, text="why are you opening", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:36,553 [DEBUG] app1.py:1104 - Sending transcription: why are you opening (is_final: False)
2024-12-02 13:32:37,174 [INFO] app1.py:1205 - Speech recognized: Why are you opening?
2024-12-02 13:32:37,175 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3f927d69fdac43098cbb16332f737aaf, text="Why are you opening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:37,176 [DEBUG] app1.py:1104 - Sending transcription: Why are you opening? (is_final: True)
2024-12-02 13:32:40,127 [DEBUG] app1.py:1214 - Speech recognizing: just
2024-12-02 13:32:40,127 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f8b2eadef1084d389fb458b01718171e, text="just", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:40,128 [DEBUG] app1.py:1104 - Sending transcription: just (is_final: False)
2024-12-02 13:32:40,828 [DEBUG] app1.py:1214 - Speech recognizing: just tell me
2024-12-02 13:32:40,829 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a5c5ee4bc4a143cd9deef793d20c22db, text="just tell me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:40,829 [DEBUG] app1.py:1104 - Sending transcription: just tell me (is_final: False)
2024-12-02 13:32:41,030 [DEBUG] app1.py:1214 - Speech recognizing: just tell me now
2024-12-02 13:32:41,031 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9af62830a08240c7aa9f0def97613bfc, text="just tell me now", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:41,032 [DEBUG] app1.py:1104 - Sending transcription: just tell me now (is_final: False)
2024-12-02 13:32:41,401 [INFO] app1.py:1205 - Speech recognized: Just tell me now.
2024-12-02 13:32:41,402 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5d90ad61ccb74391b515441ba7b67f90, text="Just tell me now.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:41,402 [DEBUG] app1.py:1104 - Sending transcription: Just tell me now. (is_final: True)
2024-12-02 13:32:48,527 [DEBUG] app1.py:1214 - Speech recognizing: join
2024-12-02 13:32:48,528 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8cc791342f784362804f828d5f464829, text="join", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:48,528 [DEBUG] app1.py:1104 - Sending transcription: join (is_final: False)
2024-12-02 13:32:48,837 [DEBUG] app1.py:1214 - Speech recognizing: join live
2024-12-02 13:32:48,837 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=408fe50a7db445d3bb37ef4d4b54e0d9, text="join live", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:48,837 [DEBUG] app1.py:1104 - Sending transcription: join live (is_final: False)
2024-12-02 13:32:49,130 [DEBUG] app1.py:1214 - Speech recognizing: join live ceremony
2024-12-02 13:32:49,130 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8467a2244e884157ae7e7ddc8d923b8b, text="join live ceremony", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:49,132 [DEBUG] app1.py:1104 - Sending transcription: join live ceremony (is_final: False)
2024-12-02 13:32:50,094 [INFO] app1.py:1205 - Speech recognized: Join live ceremony era.
2024-12-02 13:32:50,096 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6622aed3a53b4b17b2a12b594b6bc360, text="Join live ceremony era.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:50,097 [DEBUG] app1.py:1104 - Sending transcription: Join live ceremony era. (is_final: True)
2024-12-02 13:32:51,450 [DEBUG] app1.py:1214 - Speech recognizing: join
2024-12-02 13:32:51,450 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=21c84677b7264145b25a805da20e3b6c, text="join", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:51,451 [DEBUG] app1.py:1104 - Sending transcription: join (is_final: False)
2024-12-02 13:32:51,746 [DEBUG] app1.py:1214 - Speech recognizing: join live
2024-12-02 13:32:51,746 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bd346b162c804e2185f4d969a9d94ac9, text="join live", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:51,747 [DEBUG] app1.py:1104 - Sending transcription: join live (is_final: False)
2024-12-02 13:32:52,259 [INFO] app1.py:1205 - Speech recognized: Join live.
2024-12-02 13:32:52,259 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9eab83c5f43a4efca14ef9901eb5122e, text="Join live.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:52,259 [DEBUG] app1.py:1104 - Sending transcription: Join live. (is_final: True)
2024-12-02 13:32:54,053 [DEBUG] app1.py:1214 - Speech recognizing: host
2024-12-02 13:32:54,055 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce106d18b17e4f31ab4fc871ad086308, text="host", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:54,056 [DEBUG] app1.py:1104 - Sending transcription: host (is_final: False)
2024-12-02 13:32:54,257 [DEBUG] app1.py:1214 - Speech recognizing: post
2024-12-02 13:32:54,258 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=729241ff73a746fbb93d99931ba246f5, text="post", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:54,260 [DEBUG] app1.py:1104 - Sending transcription: post (is_final: False)
2024-12-02 13:32:54,549 [DEBUG] app1.py:1214 - Speech recognizing: hosts look close to uday
2024-12-02 13:32:54,550 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8ac716b967ac4b498dde6dcbd25b1808, text="hosts look close to uday", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:54,551 [DEBUG] app1.py:1104 - Sending transcription: hosts look close to uday (is_final: False)
2024-12-02 13:32:54,640 [DEBUG] app1.py:1214 - Speech recognizing: hosts look close to udayan
2024-12-02 13:32:54,640 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a885c1ca85f048a8aecb495e2431ac08, text="hosts look close to udayan", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:54,641 [DEBUG] app1.py:1104 - Sending transcription: hosts look close to udayan (is_final: False)
2024-12-02 13:32:54,951 [DEBUG] app1.py:1214 - Speech recognizing: hosts look close to udayan ghost
2024-12-02 13:32:54,951 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9e9789767dc24b93966e3cb92d533908, text="hosts look close to udayan ghost", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:54,952 [DEBUG] app1.py:1104 - Sending transcription: hosts look close to udayan ghost (is_final: False)
2024-12-02 13:32:55,761 [INFO] app1.py:1205 - Speech recognized: Hosts look close to Udayan ghost.
2024-12-02 13:32:55,762 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3cf01fc3cfcd44a091152bc5cc3dcfcc, text="Hosts look close to Udayan ghost.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:32:55,763 [DEBUG] app1.py:1104 - Sending transcription: Hosts look close to Udayan ghost. (is_final: True)
2024-12-02 13:32:58,338 [DEBUG] app1.py:1214 - Speech recognizing: who's
2024-12-02 13:32:58,339 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6dc30b8d879848da84f344e84bcab31a, text="who's", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:58,339 [DEBUG] app1.py:1104 - Sending transcription: who's (is_final: False)
2024-12-02 13:32:58,931 [DEBUG] app1.py:1214 - Speech recognizing: who's to do you know
2024-12-02 13:32:58,932 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3a60278fe8464ae6906fa5b0c4f93b2c, text="who's to do you know", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:32:58,952 [DEBUG] app1.py:1104 - Sending transcription: who's to do you know (is_final: False)
2024-12-02 13:33:00,078 [DEBUG] app1.py:1214 - Speech recognizing: who's to do you know if the
2024-12-02 13:33:00,079 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e1079e44a86545ef9aefdaadf483a826, text="who's to do you know if the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:00,079 [DEBUG] app1.py:1104 - Sending transcription: who's to do you know if the (is_final: False)
2024-12-02 13:33:01,332 [DEBUG] app1.py:1214 - Speech recognizing: who's to do you know if the joint live
2024-12-02 13:33:01,333 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2938736add79446fbaceee624b07eabe, text="who's to do you know if the joint live", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:01,334 [DEBUG] app1.py:1104 - Sending transcription: who's to do you know if the joint live (is_final: False)
2024-12-02 13:33:01,532 [DEBUG] app1.py:1214 - Speech recognizing: who's to do you know if the joint live ceremony
2024-12-02 13:33:01,532 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=738219be728a47b79dd2a756ad806912, text="who's to do you know if the joint live ceremony", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:01,533 [DEBUG] app1.py:1104 - Sending transcription: who's to do you know if the joint live ceremony (is_final: False)
2024-12-02 13:33:02,546 [DEBUG] app1.py:1214 - Speech recognizing: who's to do you know if the joint live ceremony joined
2024-12-02 13:33:02,547 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f043b003ddc944abba45caffde5c777f, text="who's to do you know if the joint live ceremony joined", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:02,547 [DEBUG] app1.py:1104 - Sending transcription: who's to do you know if the joint live ceremony joined (is_final: False)
2024-12-02 13:33:02,843 [DEBUG] app1.py:1214 - Speech recognizing: who's to do you know if the joint live ceremony joined live ceremony
2024-12-02 13:33:02,844 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d0e6e2d88c324061ba50b1178e2b867e, text="who's to do you know if the joint live ceremony joined live ceremony", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:02,845 [DEBUG] app1.py:1104 - Sending transcription: who's to do you know if the joint live ceremony joined live ceremony (is_final: False)
2024-12-02 13:33:03,823 [INFO] app1.py:1205 - Speech recognized: Who's to do you know if the joint live ceremony joined live ceremony?
2024-12-02 13:33:03,824 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7dc0d154c5a1470980b4d65ec70b5663, text="Who's to do you know if the joint live ceremony joined live ceremony?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:03,824 [DEBUG] app1.py:1104 - Sending transcription: Who's to do you know if the joint live ceremony joined live ceremony? (is_final: True)
2024-12-02 13:33:05,925 [DEBUG] app1.py:1214 - Speech recognizing: any
2024-12-02 13:33:05,927 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0ae7853a41684c778b018657e88200e4, text="any", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:05,928 [DEBUG] app1.py:1104 - Sending transcription: any (is_final: False)
2024-12-02 13:33:06,324 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:33:06,533 [DEBUG] app1.py:1214 - Speech recognizing: any other general
2024-12-02 13:33:06,534 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc68aedc62a641d2aebc43c773129b99, text="any other general", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:06,535 [DEBUG] app1.py:1104 - Sending transcription: any other general (is_final: False)
2024-12-02 13:33:07,140 [DEBUG] app1.py:1214 - Speech recognizing: any other general sensitive
2024-12-02 13:33:07,141 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d0339a991f2a45c4aff56aa9677986ba, text="any other general sensitive", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:07,142 [DEBUG] app1.py:1104 - Sending transcription: any other general sensitive (is_final: False)
2024-12-02 13:33:07,433 [DEBUG] app1.py:1214 - Speech recognizing: any other general sensitive speech
2024-12-02 13:33:07,434 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a20e139e14144b2b9585d962f53f4eec, text="any other general sensitive speech", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:07,434 [DEBUG] app1.py:1104 - Sending transcription: any other general sensitive speech (is_final: False)
2024-12-02 13:33:08,026 [DEBUG] app1.py:1214 - Speech recognizing: any other general sensitive speech is either
2024-12-02 13:33:08,027 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=06c0270c641b4fb7aeb933436b6a4f12, text="any other general sensitive speech is either", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:08,028 [DEBUG] app1.py:1104 - Sending transcription: any other general sensitive speech is either (is_final: False)
2024-12-02 13:33:09,136 [DEBUG] app1.py:1214 - Speech recognizing: any other general sensitive speech is either arity
2024-12-02 13:33:09,137 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=81f3507fd29c422792e281233fdd885d, text="any other general sensitive speech is either arity", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:09,137 [DEBUG] app1.py:1104 - Sending transcription: any other general sensitive speech is either arity (is_final: False)
2024-12-02 13:33:10,035 [DEBUG] app1.py:1214 - Speech recognizing: any other general sensitive speech is either arity API
2024-12-02 13:33:10,036 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5cab735e4dbc40ab9eeb042baca2f60c, text="any other general sensitive speech is either arity API", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:10,036 [DEBUG] app1.py:1104 - Sending transcription: any other general sensitive speech is either arity API (is_final: False)
2024-12-02 13:33:11,030 [DEBUG] app1.py:1214 - Speech recognizing: any other general sensitive speech is either arity API kilo
2024-12-02 13:33:11,030 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9a9cd0f4a3074fae873f7ffab4c46968, text="any other general sensitive speech is either arity API kilo", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:11,031 [DEBUG] app1.py:1104 - Sending transcription: any other general sensitive speech is either arity API kilo (is_final: False)
2024-12-02 13:33:11,232 [DEBUG] app1.py:1214 - Speech recognizing: any other general sensitive speech is either arity API kilo closed
2024-12-02 13:33:11,233 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ecba1ebed08e4649b634a9069f7f7771, text="any other general sensitive speech is either arity API kilo closed", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:11,233 [DEBUG] app1.py:1104 - Sending transcription: any other general sensitive speech is either arity API kilo closed (is_final: False)
2024-12-02 13:33:11,915 [INFO] app1.py:1205 - Speech recognized: Any other general sensitive speech? Is either API closed?
2024-12-02 13:33:11,916 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=23e99e82e7024c9ebf76adfcd536701b, text="Any other general sensitive speech? Is either API closed?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:11,917 [DEBUG] app1.py:1104 - Sending transcription: Any other general sensitive speech? Is either API closed? (is_final: True)
2024-12-02 13:33:13,532 [DEBUG] app1.py:1214 - Speech recognizing: i'm i'm not any
2024-12-02 13:33:13,532 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=57a6c2094b51460fa68b0b0f4d03680c, text="i'm i'm not any", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:13,533 [DEBUG] app1.py:1104 - Sending transcription: i'm i'm not any (is_final: False)
2024-12-02 13:33:13,734 [DEBUG] app1.py:1214 - Speech recognizing: i'm i'm not gonna
2024-12-02 13:33:13,735 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=004b3ccc2ad0474e9d8dfd859bbdbfc0, text="i'm i'm not gonna", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:13,736 [DEBUG] app1.py:1104 - Sending transcription: i'm i'm not gonna (is_final: False)
2024-12-02 13:33:14,244 [DEBUG] app1.py:1214 - Speech recognizing: i'm i'm not
2024-12-02 13:33:14,245 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8c8cdfb86dfb466ca799a50ae7a8edc6, text="i'm i'm not", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:14,245 [DEBUG] app1.py:1104 - Sending transcription: i'm i'm not (is_final: False)
2024-12-02 13:33:16,386 [INFO] app1.py:1205 - Speech recognized: I'm. I'm not.
2024-12-02 13:33:16,388 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a40b53bed25b4f33863403eba48c2054, text="I'm. I'm not.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:16,407 [DEBUG] app1.py:1104 - Sending transcription: I'm. I'm not. (is_final: True)
2024-12-02 13:33:22,923 [DEBUG] app1.py:1214 - Speech recognizing: synth
2024-12-02 13:33:22,923 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b228606e1f140e8b54b29f3f1c1157f, text="synth", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:22,942 [DEBUG] app1.py:1104 - Sending transcription: synth (is_final: False)
2024-12-02 13:33:23,325 [DEBUG] app1.py:1214 - Speech recognizing: synthesis
2024-12-02 13:33:23,326 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4f5a653d0cea458d90e7c158da2201a5, text="synthesis", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:23,327 [DEBUG] app1.py:1104 - Sending transcription: synthesis (is_final: False)
2024-12-02 13:33:24,236 [INFO] app1.py:1205 - Speech recognized: Synthesis.
2024-12-02 13:33:24,237 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=788a6703449d455ea04001946fd6240c, text="Synthesis.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:24,238 [DEBUG] app1.py:1104 - Sending transcription: Synthesis. (is_final: True)
2024-12-02 13:33:36,326 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:33:39,752 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 13:33:40,025 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:33:40,026 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3b96c795fe0e413ba34df8a5fddd3838, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:40,027 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 13:33:41,874 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 13:33:41,883 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:33:41,885 [INFO] app1.py:1121 - New translation stream connection for client: 0f70942e-eefa-4efb-83f1-115edcc18149, language: es
2024-12-02 13:33:41,892 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:33:41,896 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:33:41,964 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 13:33:42,059 [INFO] app1.py:1240 - Audio stream started
2024-12-02 13:33:42,897 [WARNING] app1.py:1148 - Client 0f70942e-eefa-4efb-83f1-115edcc18149 connection timed out
2024-12-02 13:33:43,426 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:33:43,426 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5b839a8c8c224cbd84d57c9c2d46e75a, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:43,428 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 13:33:43,434 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:43,435 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:33:43,436 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:33:43,799 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 13:33:43,799 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e022d1c593a341baaa15d6600544ab4c, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:43,800 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 13:33:43,804 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:43,805 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:33:43,806 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:33:43,998 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:33:43,999 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=356f5cb308664059b8c64d2cf25783cc, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:44,001 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:33:44,009 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:44,014 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you doing', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:33:44,018 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:33:44,744 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 13:33:44,745 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f7cf8aed4ab54b308f9fae5af391c9b4, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:44,747 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 13:33:44,753 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:44,754 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, what are you doing?', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:33:44,758 [DEBUG] app1.py:1042 - Normalized text: 'hi, what are you doing?'
2024-12-02 13:33:44,759 [DEBUG] app1.py:1056 - Checking cache with key: hi, what are you doing?:es
2024-12-02 13:33:44,761 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:33:44,763 [INFO] app1.py:933 - Starting translation request - Text: 'hi, what are you doing?', Target language: es
2024-12-02 13:33:44,763 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:33:44,763 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:33:44,763 [DEBUG] app1.py:964 - Request body: [{'text': 'hi, what are you doing?'}]
2024-12-02 13:33:44,917 [INFO] app1.py:1121 - New translation stream connection for client: 0f70942e-eefa-4efb-83f1-115edcc18149, language: es
2024-12-02 13:33:45,298 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:33:45,299 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': '¿hola, qué está haciendo?', 'to': 'es'}]}]
2024-12-02 13:33:45,300 [DEBUG] app1.py:974 - Extracted translation: ¿hola, qué está haciendo?
2024-12-02 13:33:45,301 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi, what are you doing?' -> Translation: '¿hola, qué está haciendo?' (es)
2024-12-02 13:33:45,303 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: ¿hola, qué está haciendo?
2024-12-02 13:33:45,303 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:33:45,303 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': '¿hola, qué está haciendo?'}
2024-12-02 13:33:45,315 [INFO] app1.py:1274 - Speech synthesis requested - Text: '¿hola, qué está haciendo?', Language: es
2024-12-02 13:33:45,315 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_01695b91-42e9-4b7e-8112-a97c2c6ece20.wav
2024-12-02 13:33:45,315 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:33:46,243 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:33:46,244 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_01695b91-42e9-4b7e-8112-a97c2c6ece20.wav
2024-12-02 13:33:47,896 [DEBUG] app1.py:1214 - Speech recognizing: hola
2024-12-02 13:33:47,897 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bc9b5d3c630946dbaa95d24e484c3231, text="hola", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:47,898 [DEBUG] app1.py:1104 - Sending transcription: hola (is_final: False)
2024-12-02 13:33:47,907 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:47,909 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:33:47,910 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:33:48,504 [DEBUG] app1.py:1214 - Speech recognizing: hola gustaf
2024-12-02 13:33:48,505 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ac0a9f8a41d444e4aaf604b2dfbdd8ee, text="hola gustaf", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:48,505 [DEBUG] app1.py:1104 - Sending transcription: hola gustaf (is_final: False)
2024-12-02 13:33:48,512 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:48,513 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola gustaf', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:33:48,515 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:33:48,897 [DEBUG] app1.py:1214 - Speech recognizing: hola gustafiano
2024-12-02 13:33:48,898 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=68413ad9c1244546a92c5435d58b9cd5, text="hola gustafiano", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:48,900 [DEBUG] app1.py:1104 - Sending transcription: hola gustafiano (is_final: False)
2024-12-02 13:33:48,904 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:48,905 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola gustafiano', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:33:48,906 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:33:50,740 [INFO] app1.py:1205 - Speech recognized: Hola, Gustavo.
2024-12-02 13:33:50,741 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0ceccf4de08b4af2b63c921db2bdedf7, text="Hola, Gustavo.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:50,741 [DEBUG] app1.py:1104 - Sending transcription: Hola, Gustavo. (is_final: True)
2024-12-02 13:33:50,745 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:50,745 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hola, Gustavo.', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:33:50,746 [DEBUG] app1.py:1042 - Normalized text: 'hola, gustavo.'
2024-12-02 13:33:50,746 [DEBUG] app1.py:1048 - Time since last translation for 0f70942e-eefa-4efb-83f1-115edcc18149:es: 5.987126350402832s
2024-12-02 13:33:50,749 [DEBUG] app1.py:1056 - Checking cache with key: hola, gustavo.:es
2024-12-02 13:33:50,751 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:33:50,751 [INFO] app1.py:933 - Starting translation request - Text: 'hola, gustavo.', Target language: es
2024-12-02 13:33:50,756 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:33:50,758 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:33:50,758 [DEBUG] app1.py:964 - Request body: [{'text': 'hola, gustavo.'}]
2024-12-02 13:33:51,989 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:33:51,990 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'es', 'score': 1.0}, 'translations': [{'text': 'hola, gustavo.', 'to': 'es'}]}]
2024-12-02 13:33:51,991 [DEBUG] app1.py:974 - Extracted translation: hola, gustavo.
2024-12-02 13:33:51,992 [INFO] app1.py:975 - Translation completed successfully - Original: 'hola, gustavo.' -> Translation: 'hola, gustavo.' (es)
2024-12-02 13:33:51,993 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: hola, gustavo.
2024-12-02 13:33:51,993 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:33:51,993 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'hola, gustavo.'}
2024-12-02 13:33:52,002 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'hola, gustavo.', Language: es
2024-12-02 13:33:52,015 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_879dc005-932f-470b-9255-a4486fd00bdc.wav
2024-12-02 13:33:52,017 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:33:52,127 [DEBUG] app1.py:1214 - Speech recognizing: yeah we can integrate
2024-12-02 13:33:52,127 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=30d8d57875ab4e8c9c073a0ad083507e, text="yeah we can integrate", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:33:52,128 [DEBUG] app1.py:1104 - Sending transcription: yeah we can integrate (is_final: False)
2024-12-02 13:33:52,134 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:52,134 [DEBUG] app1.py:1031 - Received translation request - Text: 'yeah we can integrate', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: False
2024-12-02 13:33:52,134 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 13:33:52,874 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:33:52,875 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_879dc005-932f-470b-9255-a4486fd00bdc.wav
2024-12-02 13:33:53,931 [INFO] app1.py:1205 - Speech recognized: Yeah, we can integrate.
2024-12-02 13:33:53,932 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f6e366f67a81453fbc3e404bc2a1f7f2, text="Yeah, we can integrate.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:33:53,932 [DEBUG] app1.py:1104 - Sending transcription: Yeah, we can integrate. (is_final: True)
2024-12-02 13:33:53,938 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 13:33:53,939 [DEBUG] app1.py:1031 - Received translation request - Text: 'Yeah, we can integrate.', Target: es, Client: 0f70942e-eefa-4efb-83f1-115edcc18149, Final: True
2024-12-02 13:33:53,939 [DEBUG] app1.py:1042 - Normalized text: 'yeah, we can integrate.'
2024-12-02 13:33:53,941 [DEBUG] app1.py:1048 - Time since last translation for 0f70942e-eefa-4efb-83f1-115edcc18149:es: 3.1945202350616455s
2024-12-02 13:33:53,942 [DEBUG] app1.py:1056 - Checking cache with key: yeah, we can integrate.:es
2024-12-02 13:33:53,943 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 13:33:53,943 [INFO] app1.py:933 - Starting translation request - Text: 'yeah, we can integrate.', Target language: es
2024-12-02 13:33:53,944 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 13:33:53,944 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 13:33:53,945 [DEBUG] app1.py:964 - Request body: [{'text': 'yeah, we can integrate.'}]
2024-12-02 13:33:55,212 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 13:33:55,212 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Sí, podemos integrarnos.', 'to': 'es'}]}]
2024-12-02 13:33:55,214 [DEBUG] app1.py:974 - Extracted translation: Sí, podemos integrarnos.
2024-12-02 13:33:55,214 [INFO] app1.py:975 - Translation completed successfully - Original: 'yeah, we can integrate.' -> Translation: 'Sí, podemos integrarnos.' (es)
2024-12-02 13:33:55,214 [DEBUG] app1.py:918 - Sending translation to client 0f70942e-eefa-4efb-83f1-115edcc18149: Sí, podemos integrarnos.
2024-12-02 13:33:55,215 [DEBUG] app1.py:925 - Translation sent successfully to client 0f70942e-eefa-4efb-83f1-115edcc18149
2024-12-02 13:33:55,215 [DEBUG] app1.py:1144 - Sending message to client 0f70942e-eefa-4efb-83f1-115edcc18149: {'type': 'final', 'translation': 'Sí, podemos integrarnos.'}
2024-12-02 13:33:55,220 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Sí, podemos integrarnos.', Language: es
2024-12-02 13:33:55,229 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_53ed0868-7268-4a0c-af09-03c2c37709c1.wav
2024-12-02 13:33:55,233 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 13:33:56,171 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 13:33:56,172 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_53ed0868-7268-4a0c-af09-03c2c37709c1.wav
2024-12-02 13:34:06,327 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:34:14,126 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:34:14,127 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ee7252ab33184c82b7a372ae430e458a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:34:14,127 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:34:29,172 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:34:29,172 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=612f9adace654018bbbbdc03efb57dfb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:34:36,329 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:34:44,443 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:34:44,444 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=730010bb977d48ca8edbe4d9f09cd301, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:35:01,719 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 13:35:01,724 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0ca204f3add248c4bba595202a1df93a, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:35:06,331 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:35:08,025 [DEBUG] app1.py:1214 - Speech recognizing: i don't know
2024-12-02 13:35:08,027 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3ffebec05f04495a9a97ccf30834d277, text="i don't know", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:09,651 [INFO] app1.py:1205 - Speech recognized: I don't know.
2024-12-02 13:35:09,652 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dc1345b6041847119d05572624bbaf40, text="I don't know.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:35:13,550 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:35:13,551 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c87edd76691f45d4b402647b84bca44e, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:15,441 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 13:35:15,442 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c5ef0f004fef42a0865fa7f77914ba5b, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:35:15,551 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 13:35:15,552 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=599915aef204459f96e53d398bd4a986, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:16,543 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 13:35:16,544 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0419623ad9a949bdbef31b99e7111321, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:35:19,912 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:35:19,912 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ad4d161e24ea4922a56b035e51cfddba, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:20,625 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 13:35:20,626 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=74e0731f64b64f33ba40bc1ef741739e, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:21,013 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 13:35:21,014 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d030410a4a0439b8790180c4d7f8f03, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:22,112 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing is
2024-12-02 13:35:22,113 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6fa4417d56054069a229f5932d4201ba, text="hi what are you doing is", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:22,519 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing is that happening
2024-12-02 13:35:22,532 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7830c4c62cce4d6ea25ad4410116069d, text="hi what are you doing is that happening", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:24,225 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing is that happening something
2024-12-02 13:35:24,226 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6e06041adc704a4481535b0f00f2321a, text="hi what are you doing is that happening something", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:24,814 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing is that happening something or not
2024-12-02 13:35:24,815 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=216fe7ed015c45d98f599da7d2cb92b7, text="hi what are you doing is that happening something or not", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:35:25,141 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing? Is that happening something or not?
2024-12-02 13:35:25,141 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2a4fe4f5de80497cb9f1c6a185c78c9f, text="Hi, what are you doing? Is that happening something or not?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:35:36,333 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:35:40,529 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:35:40,530 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=90e94304b2684c20a8bd9035746ddfdc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:36:00,157 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:36:00,157 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fa361b76091b42d69ef4baef371a4261, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:36:02,707 [DEBUG] app1.py:1214 - Speech recognizing: he had
2024-12-02 13:36:02,708 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f771b70ed7964da6a3fc4a3ff770f622, text="he had", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:04,114 [INFO] app1.py:1205 - Speech recognized: He had.
2024-12-02 13:36:04,115 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e14ba27740074ccc9c66fdc472180656, text="He had.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:36:06,334 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:36:07,413 [DEBUG] app1.py:1214 - Speech recognizing: hit up the roof
2024-12-02 13:36:07,414 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=adb654f3e33340ab9667e22b59252f3b, text="hit up the roof", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:07,817 [DEBUG] app1.py:1214 - Speech recognizing: hit up the room
2024-12-02 13:36:07,837 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=421c046ba30643eebcc933a67bf9a75f, text="hit up the room", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:07,938 [DEBUG] app1.py:1214 - Speech recognizing: hit up the roof
2024-12-02 13:36:07,939 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ea69fcd3096a43bf8bbdfc04a6e82fbc, text="hit up the roof", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:08,016 [DEBUG] app1.py:1214 - Speech recognizing: hit up the room contractor
2024-12-02 13:36:08,017 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=69c3a18dd47b4583ab5c9de7fb2c522f, text="hit up the room contractor", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:09,942 [DEBUG] app1.py:1214 - Speech recognizing: hit up the roof root
2024-12-02 13:36:09,972 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5c946d5eb25e4f5799c8c7d105c8de62, text="hit up the roof root", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:11,564 [INFO] app1.py:1205 - Speech recognized: The.
2024-12-02 13:36:11,565 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=65ca2f71446a4fcf9aa8af1e8378159a, text="The.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:36:31,704 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:36:31,705 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=638344a3cf0747e396ad98202d6dc81a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:36:36,335 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:36:46,926 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:36:46,927 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e6cccbd285294184b77f978d977ce938, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:36:48,121 [DEBUG] app1.py:1214 - Speech recognizing: depository
2024-12-02 13:36:48,123 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=765067cb93bd4ff19512efad7ccee300, text="depository", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:48,417 [DEBUG] app1.py:1214 - Speech recognizing: depository root
2024-12-02 13:36:48,417 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fc3e9f2dbb224abeb1743e50cabe9215, text="depository root", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:48,621 [DEBUG] app1.py:1214 - Speech recognizing: depository route directory
2024-12-02 13:36:48,622 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4218a1df5463499fa89d720a1002bb08, text="depository route directory", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:49,413 [DEBUG] app1.py:1214 - Speech recognizing: depository root directory folder
2024-12-02 13:36:49,414 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=46204cd6003b4967aff63d790b6369c4, text="depository root directory folder", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:49,633 [DEBUG] app1.py:1214 - Speech recognizing: depository route directory
2024-12-02 13:36:49,635 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=31020db0d814426b9164d399b60a1742, text="depository route directory", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:50,320 [DEBUG] app1.py:1214 - Speech recognizing: depository root directory folder
2024-12-02 13:36:50,321 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=385269dc5c9c4b268437b7584712ec45, text="depository root directory folder", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:51,021 [DEBUG] app1.py:1214 - Speech recognizing: depository root directory in a folder
2024-12-02 13:36:51,022 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aa234c1c12314d7094023a9ae43f5fb9, text="depository root directory in a folder", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:36:52,822 [INFO] app1.py:1205 - Speech recognized: Depository root directory in a folder.
2024-12-02 13:36:52,823 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=192f4e84e14f4f8ea2dd473bfff3f3b7, text="Depository root directory in a folder.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:36:55,807 [DEBUG] app1.py:1214 - Speech recognizing: copy
2024-12-02 13:36:55,808 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ccb3c5400a614098955acd66c246dbff, text="copy", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:05,121 [DEBUG] app1.py:1214 - Speech recognizing: kanji me
2024-12-02 13:37:05,122 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a57001ccf9d04a94b69f2def1fdef1e1, text="kanji me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:05,214 [DEBUG] app1.py:1214 - Speech recognizing: kanchi male
2024-12-02 13:37:05,215 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b5ce7eddbbf64eb1b7552998df8dff6c, text="kanchi male", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:06,336 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:37:07,604 [DEBUG] app1.py:1214 - Speech recognizing: begin pachhd
2024-12-02 13:37:07,605 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=81c35d53d1724d1c94135b0d9b74620b, text="begin pachhd", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:07,714 [DEBUG] app1.py:1214 - Speech recognizing: begin pachhdi
2024-12-02 13:37:07,715 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9b4d6e6d01e648f3bc047c3b8f37b263, text="begin pachhdi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:08,305 [DEBUG] app1.py:1214 - Speech recognizing: begin pachhdi mein lagi
2024-12-02 13:37:08,305 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=570f0ce1db6e457ab985bd047646fa47, text="begin pachhdi mein lagi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:10,124 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:37:10,124 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5be244beb53140f18c2be9d29896697d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:37:14,128 [DEBUG] app1.py:1214 - Speech recognizing: credentials
2024-12-02 13:37:14,130 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ac10c5ae189f4070b8d38f149fe857ea, text="credentials", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:14,532 [DEBUG] app1.py:1214 - Speech recognizing: credentials of
2024-12-02 13:37:14,533 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ed92b3d717d4c13b1c638a10172f3e2, text="credentials of", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:16,338 [INFO] app1.py:1205 - Speech recognized: Credentials of.
2024-12-02 13:37:16,339 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=724e0eb304fd42a3a2c40dfdc13cff8c, text="Credentials of.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:37:17,343 [DEBUG] app1.py:1214 - Speech recognizing: failed
2024-12-02 13:37:17,344 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=79861b61745e4df8924fcad858ba84aa, text="failed", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:17,642 [DEBUG] app1.py:1214 - Speech recognizing: failed to
2024-12-02 13:37:17,643 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7fb97074cd5046f2bcc8f566a930c91c, text="failed to", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:17,732 [DEBUG] app1.py:1214 - Speech recognizing: failed to deploy
2024-12-02 13:37:17,732 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=135651146fa2474995ca3416e5da981a, text="failed to deploy", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:19,533 [INFO] app1.py:1205 - Speech recognized: Failed to deploy.
2024-12-02 13:37:19,534 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=54cf0fde834d44adac13a1e3e80905a1, text="Failed to deploy.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:37:23,114 [DEBUG] app1.py:1214 - Speech recognizing: is successfully uploaded and deployed
2024-12-02 13:37:23,115 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=149a7d9a22b6483c8a18d63b44a8d077, text="is successfully uploaded and deployed", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:23,515 [DEBUG] app1.py:1214 - Speech recognizing: is successfully uploaded and deployed react
2024-12-02 13:37:23,517 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=323bdee410ed4509913e56e620b4bb42, text="is successfully uploaded and deployed react", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:23,714 [DEBUG] app1.py:1214 - Speech recognizing: is successfully uploaded and deployed reactor
2024-12-02 13:37:23,715 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a653046615524b85a4af2f0a1e5b474b, text="is successfully uploaded and deployed reactor", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:24,817 [DEBUG] app1.py:1214 - Speech recognizing: is successfully uploaded and deployed reactor deploy
2024-12-02 13:37:24,818 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a23897f8acad4e009b92e83c16976825, text="is successfully uploaded and deployed reactor deploy", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:26,652 [INFO] app1.py:1205 - Speech recognized: Successfully deployed reactor deploy.
2024-12-02 13:37:26,653 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1503285c9f67496e9dd23397dcd35ac0, text="Successfully deployed reactor deploy.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:37:34,402 [INFO] app1.py:1205 - Speech recognized: Ed.
2024-12-02 13:37:34,403 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e8fcb5be2e314f25a09b1fc5b3846629, text="Ed.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:37:35,613 [DEBUG] app1.py:1214 - Speech recognizing: is
2024-12-02 13:37:35,614 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=687f3c527be249589ab2a48e50eabfd4, text="is", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:36,012 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in
2024-12-02 13:37:36,013 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=065690d55e2c484db1ba429c4dcb22db, text="is the file name in", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:36,309 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the
2024-12-02 13:37:36,310 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e91c9d975fa44b11b251096d7a88a1ad, text="is the file name in the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:36,339 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:37:36,708 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the yahoo
2024-12-02 13:37:36,709 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=356fa3951a0a44e1b03ce8fbae5a5e8c, text="is the file name in the yahoo", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:37,345 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the yahoo can you
2024-12-02 13:37:37,347 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=377784feabf2454d890596241e01b36a, text="is the file name in the yahoo can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:37,611 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the yahoo can you file
2024-12-02 13:37:37,612 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b3963cd32f72418aa6edb871dc5e6544, text="is the file name in the yahoo can you file", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:37,921 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the yahoo can you find me
2024-12-02 13:37:37,922 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c49e0002f0494fe6b6676507555366f1, text="is the file name in the yahoo can you find me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:38,216 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the yahoo can you find me the root
2024-12-02 13:37:38,218 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c23c9802fe7c40d5845bc2dc647c6c9a, text="is the file name in the yahoo can you find me the root", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:38,619 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the yahoo can you file me a route directory
2024-12-02 13:37:38,620 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5d96d09883f84f67b9b665c8c4356b40, text="is the file name in the yahoo can you file me a route directory", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:38,804 [DEBUG] app1.py:1214 - Speech recognizing: is the file name in the yahoo can you find me the root directory correct
2024-12-02 13:37:38,805 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=91502719021046bbab8334f1f490d2a1, text="is the file name in the yahoo can you find me the root directory correct", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:37:39,533 [INFO] app1.py:1205 - Speech recognized: Is the file name in the Yahoo? Can you find me the root directory correct?
2024-12-02 13:37:39,535 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e0b413f8253943dca60113a02b88ecd8, text="Is the file name in the Yahoo? Can you find me the root directory correct?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:37:58,913 [DEBUG] app1.py:1214 - Speech recognizing: PHP
2024-12-02 13:37:58,914 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7d15e477a7c0487ba803b240f6acd678, text="PHP", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:00,432 [DEBUG] app1.py:1214 - Speech recognizing: PHP's
2024-12-02 13:38:00,433 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=52837807f3e4459c8e63b17c30896416, text="PHP's", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:00,446 [INFO] app1.py:1205 - Speech recognized: PHP.
2024-12-02 13:38:00,447 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1bb9566e13624bc4a190724d36072d06, text="PHP.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:38:02,112 [DEBUG] app1.py:1214 - Speech recognizing: and in the
2024-12-02 13:38:02,113 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4b5e8cfb314c4c30a40df00775dd4b12, text="and in the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:02,422 [DEBUG] app1.py:1214 - Speech recognizing: and in the dinner
2024-12-02 13:38:02,423 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3cc240a83ce549e78abef8d5f96e2048, text="and in the dinner", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:02,827 [DEBUG] app1.py:1214 - Speech recognizing: and in the dinner in order
2024-12-02 13:38:02,828 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2b9f10b901734e209be3eec338fada90, text="and in the dinner in order", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:03,016 [DEBUG] app1.py:1214 - Speech recognizing: and in the dinner in order to get
2024-12-02 13:38:03,017 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=70dd92a9d9394eac8d92531d6293206e, text="and in the dinner in order to get", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:03,725 [DEBUG] app1.py:1214 - Speech recognizing: and in the dinner in order to get anything
2024-12-02 13:38:03,727 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dea248362a60401f8cdae81331a13833, text="and in the dinner in order to get anything", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:04,115 [DEBUG] app1.py:1214 - Speech recognizing: and in the dinner in order to get anything in
2024-12-02 13:38:04,116 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=455aba6890364a29bdcdb0d4d80b3b92, text="and in the dinner in order to get anything in", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:05,997 [INFO] app1.py:1205 - Speech recognized: In order to get anything in.
2024-12-02 13:38:05,998 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0609170c293248faa7d9e779240b3d5e, text="In order to get anything in.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:38:06,340 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:38:11,737 [DEBUG] app1.py:1214 - Speech recognizing: the
2024-12-02 13:38:11,738 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3d036385a8664835bef036b518ee22e1, text="the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:13,837 [INFO] app1.py:1205 - Speech recognized: The.
2024-12-02 13:38:13,838 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=067349c9a97a48f3a32552ac1d349833, text="The.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:38:17,537 [DEBUG] app1.py:1214 - Speech recognizing: python
2024-12-02 13:38:17,538 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eb0a19c5745a4dbea047c7ac524a97ee, text="python", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:17,739 [DEBUG] app1.py:1214 - Speech recognizing: python code
2024-12-02 13:38:17,740 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=480bfff76ffa427b8703aef7298aae30, text="python code", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:18,144 [DEBUG] app1.py:1214 - Speech recognizing: python code live
2024-12-02 13:38:18,145 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ad686d55a3354612a36ac448adc2a4fe, text="python code live", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:19,637 [DEBUG] app1.py:1214 - Speech recognizing: python code live live
2024-12-02 13:38:19,638 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=35ba0cfb6f914323a3693e62ea98ab6b, text="python code live live", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:21,537 [INFO] app1.py:1205 - Speech recognized: Python code live.
2024-12-02 13:38:21,538 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a4054b5bf2ce46ed8ba4e11168708ae4, text="Python code live.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:38:25,030 [DEBUG] app1.py:1214 - Speech recognizing: how can i
2024-12-02 13:38:25,030 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a9e00f3ca0ba441198e704db0a3c830d, text="how can i", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:25,340 [DEBUG] app1.py:1214 - Speech recognizing: how can i get
2024-12-02 13:38:25,341 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4d6b037ec1f24cef928163abf19942d7, text="how can i get", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:26,770 [INFO] app1.py:1205 - Speech recognized: How can I get?
2024-12-02 13:38:26,772 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fd9f2b2abe024468b3d4ed0be427a48b, text="How can I get?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:38:29,037 [DEBUG] app1.py:1214 - Speech recognizing: he can
2024-12-02 13:38:29,038 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fdc921f654934156999ae2a77ceab20f, text="he can", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:29,236 [DEBUG] app1.py:1214 - Speech recognizing: E congress
2024-12-02 13:38:29,237 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=839a6b0f71fe4feaa913c735b8d2161b, text="E congress", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:29,330 [DEBUG] app1.py:1214 - Speech recognizing: E congresswoman
2024-12-02 13:38:29,331 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=887ceda8fa764e6b9ecde5573530aaa3, text="E congresswoman", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:29,827 [DEBUG] app1.py:1214 - Speech recognizing: E congresswoman unif
2024-12-02 13:38:29,828 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a1350a04bb7940bb99465d04e621a162, text="E congresswoman unif", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:29,933 [DEBUG] app1.py:1214 - Speech recognizing: E congresswoman unifensive
2024-12-02 13:38:29,935 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d6b7afde75d8417a83ebcb99d9844e4b, text="E congresswoman unifensive", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:30,436 [DEBUG] app1.py:1214 - Speech recognizing: E congresswoman unifensively
2024-12-02 13:38:30,437 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8381cad972e4451ca05edd61a04b13bd, text="E congresswoman unifensively", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:38:30,901 [INFO] app1.py:1205 - Speech recognized: E Congresswoman Unifensive Year.
2024-12-02 13:38:30,903 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=851c868c1bdf4257888ee35656094b40, text="E Congresswoman Unifensive Year.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:38:36,343 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:38:51,258 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:38:51,260 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0a5bcc52f1ad4386b76cc3dc56581285, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:39:06,298 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:39:06,299 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da033079841d46188e9422ac90571145, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:39:06,344 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:39:21,498 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:39:21,499 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=662b34b916734831ac88546c6d4587d5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:39:36,346 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:39:36,673 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:39:36,674 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b755571192bb4bd98f7b7ba6283b7081, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:39:41,450 [DEBUG] app1.py:1214 - Speech recognizing: sanjay
2024-12-02 13:39:41,450 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bca5a5aed9ae4f258b40edaeab5e85af, text="sanjay", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:41,715 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubg
2024-12-02 13:39:41,716 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=034e3afc0d834f68b142380ff5892876, text="sanjeev pubg", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:41,916 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubjira
2024-12-02 13:39:41,917 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=51140ed1f12244a085a4d0ba8a957411, text="sanjeev pubjira", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:42,209 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubjira is
2024-12-02 13:39:42,210 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ca74c72815546e99fb0b7cb28391170, text="sanjeev pubjira is", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:42,317 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubjira is only
2024-12-02 13:39:42,318 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=806bfd603aec4b34962fef94d5fb6515, text="sanjeev pubjira is only", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:42,614 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubjira is only when
2024-12-02 13:39:42,615 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=05cd5a624ddb43d5ba4c1bdfdad3a23e, text="sanjeev pubjira is only when", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:42,720 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubjira is only when the
2024-12-02 13:39:42,721 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=39a04f459dc14a6eb24be7a199ead6ab, text="sanjeev pubjira is only when the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:42,815 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubjira is only when the hacker
2024-12-02 13:39:42,816 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d03dfed0efce457f8c0e31647bcfc2f0, text="sanjeev pubjira is only when the hacker", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:43,221 [DEBUG] app1.py:1214 - Speech recognizing: sanjeev pubjira is only when the hiker and the
2024-12-02 13:39:43,223 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b592fcb9c28b48b3a9270eb443144c08, text="sanjeev pubjira is only when the hiker and the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:39:44,858 [INFO] app1.py:1205 - Speech recognized: Sanjeev Pubjira is only when the hacker.
2024-12-02 13:39:44,860 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8e21d64497e74abcac428cb2b728dcb7, text="Sanjeev Pubjira is only when the hacker.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:40:05,027 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:40:05,028 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f6c61d67af2a40ef88323b3dbcfd0ed1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:40:06,356 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:40:20,221 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:40:20,222 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=77e87d66d3f2419fb81eaa01d7ab0cbe, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:40:23,333 [DEBUG] app1.py:1214 - Speech recognizing: add
2024-12-02 13:40:23,333 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c27af1b44423451d93ebc5cbb82097dd, text="add", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:24,527 [DEBUG] app1.py:1214 - Speech recognizing: add this
2024-12-02 13:40:24,528 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a185cb4bbae24abab3e9b88da462b75e, text="add this", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:25,629 [DEBUG] app1.py:1214 - Speech recognizing: add this for
2024-12-02 13:40:25,630 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ddb0dd0a8e9d4a30ab16450d2b79dc75, text="add this for", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:25,833 [DEBUG] app1.py:1214 - Speech recognizing: add this for ahmedabad
2024-12-02 13:40:25,835 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=01b8c495dcc14cb08ec88f11c863cd6c, text="add this for ahmedabad", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:26,533 [DEBUG] app1.py:1214 - Speech recognizing: add this for aye mazda bachelor
2024-12-02 13:40:26,534 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=034fd57ff45947d5acceee4f2458949c, text="add this for aye mazda bachelor", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:26,937 [DEBUG] app1.py:1214 - Speech recognizing: add this for aye mazda bachelor building
2024-12-02 13:40:26,939 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8da60cc35b9841839d54c848622672b8, text="add this for aye mazda bachelor building", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:27,432 [DEBUG] app1.py:1214 - Speech recognizing: add this for aye mazda bachelor building into
2024-12-02 13:40:27,434 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=020e7d94a38044d2b492b7b492ed9d45, text="add this for aye mazda bachelor building into", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:27,524 [DEBUG] app1.py:1214 - Speech recognizing: add this for aye mazda bachelor building integrality
2024-12-02 13:40:27,525 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f8f80dd5760c432097826b61ac288e61, text="add this for aye mazda bachelor building integrality", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:35,330 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:40:35,331 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=334c29d0af864e26b5950d946c9755e3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:40:36,380 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:40:36,965 [DEBUG] app1.py:1214 - Speech recognizing: the seven
2024-12-02 13:40:36,966 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0a3ec283d96043518622de6f40676be3, text="the seven", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:37,170 [DEBUG] app1.py:1214 - Speech recognizing: the seven develop
2024-12-02 13:40:37,171 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=229865d34e73410eb9ee08149d2ce858, text="the seven develop", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:37,668 [DEBUG] app1.py:1214 - Speech recognizing: the seven develop puzzle
2024-12-02 13:40:37,670 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ff1227eb460d4568b71b37237064a39a, text="the seven develop puzzle", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:37,872 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao
2024-12-02 13:40:37,873 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b778dafd74224219b67f63dbd2ddc3c2, text="the seven developing ki ki ki liao", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:39,069 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao me
2024-12-02 13:40:39,070 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cb5aac63db404c948da6cadd7840a17b, text="the seven developing ki ki ki liao me", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:39,518 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao mei you
2024-12-02 13:40:39,520 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=14a7171e35d649e396af29de28cd796e, text="the seven developing ki ki ki liao mei you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:40,071 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao mei you starting
2024-12-02 13:40:40,072 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f1af4bf4b6c5407abcb181952eefcf96, text="the seven developing ki ki ki liao mei you starting", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:40,472 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao mei you starting pujini
2024-12-02 13:40:40,473 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=622842552ce34e0eaf572b61ab17ee96, text="the seven developing ki ki ki liao mei you starting pujini", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:41,472 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao mei you starting pujini starting
2024-12-02 13:40:41,473 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=20595be0cf014fa6bf1fec7f340e529c, text="the seven developing ki ki ki liao mei you starting pujini starting", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:41,775 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao mei you starting pujini ki
2024-12-02 13:40:41,776 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=839601ec5d1643038c4244a4f6749437, text="the seven developing ki ki ki liao mei you starting pujini ki", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:42,273 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao mei you starting pujini starting
2024-12-02 13:40:42,274 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3371411f895742a592909c744659c256, text="the seven developing ki ki ki liao mei you starting pujini starting", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:43,971 [DEBUG] app1.py:1214 - Speech recognizing: the seven developing ki ki ki liao mei you starting pujini starting school
2024-12-02 13:40:43,972 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=78167ad7ae1a4c9180792d49eefdb66b, text="the seven developing ki ki ki liao mei you starting pujini starting school", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:40:45,916 [INFO] app1.py:1205 - Speech recognized: The seven developing Ki Ki liao Mei you starting school.
2024-12-02 13:40:45,918 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0e32e827788443698edb728b65769bee, text="The seven developing Ki Ki liao Mei you starting school.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:40:53,521 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:40:53,521 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a60a2b5bdea44606aa08a1d5a04cb693, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:41:06,381 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:41:13,059 [DEBUG] app1.py:1214 - Speech recognizing: two BHK builder
2024-12-02 13:41:13,060 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3983cc5eb3854e96b2ee9c719537c707, text="two BHK builder", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:14,646 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 13:41:14,647 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a04acaa8601140c7962d4faeb67446a8, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:41:17,258 [DEBUG] app1.py:1214 - Speech recognizing: floor
2024-12-02 13:41:17,260 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aadd65c1ab22464cbda552381ca9f206, text="floor", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:17,351 [INFO] app1.py:1205 - Speech recognized: Floor 1.
2024-12-02 13:41:17,351 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=80eb66e6ee6b4d88b983762f7a944509, text="Floor 1.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:41:19,343 [DEBUG] app1.py:1214 - Speech recognizing: new delhi
2024-12-02 13:41:19,344 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ec448a9862eb4b5cbdd3321043f5037a, text="new delhi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:19,843 [DEBUG] app1.py:1214 - Speech recognizing: new delhi in the
2024-12-02 13:41:19,844 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e7dd920ea9f149a083232cfc830ec91b, text="new delhi in the", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:20,043 [DEBUG] app1.py:1214 - Speech recognizing: new delhi in the mardin
2024-12-02 13:41:20,044 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=54197cb8de1642229667ed0814927194, text="new delhi in the mardin", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:20,340 [DEBUG] app1.py:1214 - Speech recognizing: new delhi in the mardini
2024-12-02 13:41:20,341 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f662a88be7a448d99d872f111fad5974, text="new delhi in the mardini", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:21,041 [DEBUG] app1.py:1214 - Speech recognizing: new delhi in the mardi gras
2024-12-02 13:41:21,042 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=643ade71c04d4321b652b66a41bca3f8, text="new delhi in the mardi gras", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:22,874 [INFO] app1.py:1205 - Speech recognized: New Delhi in the Mardi Gras.
2024-12-02 13:41:22,876 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a283b2752f5b4209bf6a7631673384b9, text="New Delhi in the Mardi Gras.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:41:25,164 [DEBUG] app1.py:1214 - Speech recognizing: movie kathakali
2024-12-02 13:41:25,165 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b3e4eab14aa84786af1ad3233be0a0f2, text="movie kathakali", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:27,373 [DEBUG] app1.py:1214 - Speech recognizing: tune into
2024-12-02 13:41:27,374 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=671b10bec6d5498697d5702f8588188a, text="tune into", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:27,573 [DEBUG] app1.py:1214 - Speech recognizing: tune into thandiwe
2024-12-02 13:41:27,573 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=70295e8e121c41fa8818d90c5e25497a, text="tune into thandiwe", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:27,672 [DEBUG] app1.py:1214 - Speech recognizing: tune into thandiwe shopping
2024-12-02 13:41:27,672 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7f8d15f062984b348d7f325a911daabd, text="tune into thandiwe shopping", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:27,982 [DEBUG] app1.py:1214 - Speech recognizing: tune into thandiwe shopping kitut
2024-12-02 13:41:27,983 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ce3b9812897435da0a75c57457fa200, text="tune into thandiwe shopping kitut", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:28,280 [DEBUG] app1.py:1214 - Speech recognizing: tune into thandiwe shopping kituto
2024-12-02 13:41:28,280 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0e892883e2a04419b66a65f3423ca6ee, text="tune into thandiwe shopping kituto", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:28,669 [DEBUG] app1.py:1214 - Speech recognizing: tune into thandiwe shopping kituto ginje
2024-12-02 13:41:28,670 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=740270d0da5d40a8ba8769fdf1083da5, text="tune into thandiwe shopping kituto ginje", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:29,430 [INFO] app1.py:1205 - Speech recognized: Tune into Thandiwe shopping kituto ginje Haji.
2024-12-02 13:41:29,431 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=336de9cb6d4845619ddcd3492d2969ea, text="Tune into Thandiwe shopping kituto ginje Haji.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:41:36,383 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:41:37,194 [DEBUG] app1.py:1214 - Speech recognizing: game and show beginning
2024-12-02 13:41:37,195 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a752fdec98184b90865d1b7aee6326d4, text="game and show beginning", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:41:49,538 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:41:49,539 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=97f2fa05a28e4e34ab7cd6e42b3fe3c4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:42:04,873 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:42:04,874 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=77546c5e8dae41ddadbbb495ee1e256a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:42:06,385 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:42:08,602 [DEBUG] app1.py:1214 - Speech recognizing: repair
2024-12-02 13:42:08,603 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bf98615c671b42abba506030acaf4326, text="repair", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:10,453 [INFO] app1.py:1205 - Speech recognized: Repair.
2024-12-02 13:42:10,454 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=04d0dd7c90cf4ecc87fc48f7127c66d3, text="Repair.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:42:17,519 [DEBUG] app1.py:1214 - Speech recognizing: 20°
2024-12-02 13:42:17,519 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=698a0499aa9843c596ab6d1aa172f420, text="20°", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:17,812 [DEBUG] app1.py:1214 - Speech recognizing: 20° function
2024-12-02 13:42:17,813 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=97b920d30bfb4b139733395eb87e9897, text="20° function", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:17,919 [DEBUG] app1.py:1214 - Speech recognizing: two degree functional
2024-12-02 13:42:17,920 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cb49920b9a5e433a90d7802970ee21f4, text="two degree functional", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:18,135 [DEBUG] app1.py:1214 - Speech recognizing: 20° functionality
2024-12-02 13:42:18,148 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=35022d67b3ef40fc828613b47cf8f45d, text="20° functionality", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:18,712 [DEBUG] app1.py:1214 - Speech recognizing: 20° functionality storage
2024-12-02 13:42:18,713 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ae7167d3cab44f2585bccf5f83842803, text="20° functionality storage", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:18,822 [DEBUG] app1.py:1214 - Speech recognizing: 20° functionality storage in
2024-12-02 13:42:18,823 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ac52f7067d349a580f476b80e2b7764, text="20° functionality storage in", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:19,415 [DEBUG] app1.py:1214 - Speech recognizing: 20° functionality
2024-12-02 13:42:19,416 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9fd6a5dcec0b413ebdf1c705e19c5902, text="20° functionality", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:20,470 [INFO] app1.py:1205 - Speech recognized: 20° functionality.
2024-12-02 13:42:20,472 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=700959ca2edf4553b96b77a049d9ece6, text="20° functionality.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:42:22,914 [DEBUG] app1.py:1214 - Speech recognizing: music key
2024-12-02 13:42:22,915 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0a7a00ef531649359aa4106d7a713079, text="music key", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:23,319 [DEBUG] app1.py:1214 - Speech recognizing: music key changes
2024-12-02 13:42:23,320 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=06f66fbb4129401da1d715aaf8e793a4, text="music key changes", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:23,910 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did
2024-12-02 13:42:23,912 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d50b81df055a4e6d893319920ce14d1e, text="music key changes and did", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:24,623 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys
2024-12-02 13:42:24,623 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=95aeb01a214c4a8f8eb3b221b65560a5, text="music key changes and did boys", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:24,826 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys syn
2024-12-02 13:42:24,826 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=294a4bf248c448a4b91773770c795a78, text="music key changes and did boys syn", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:24,918 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis
2024-12-02 13:42:24,919 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cfdecbad888545cf87f471920b15283a, text="music key changes and did boys synthesis", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:25,321 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis function
2024-12-02 13:42:25,322 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6fd45370ae6c4398a999cf559408dcff, text="music key changes and did boys synthesis function", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:25,523 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality
2024-12-02 13:42:25,525 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2b922965a0da4331b9d67ca43526d70c, text="music key changes and did boys synthesis functionality", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:26,115 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore
2024-12-02 13:42:26,117 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2feb655952c94f17aa35f32ae0095538, text="music key changes and did boys synthesis functionality restore", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:26,520 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both
2024-12-02 13:42:26,521 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0e54779b106d41be8de7a409c6f90025, text="music key changes and did boys synthesis functionality restore both", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:26,819 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system
2024-12-02 13:42:26,820 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c424729ce3043a6a6e6a5e1a2160d91, text="music key changes and did boys synthesis functionality restore both system", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:27,114 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices
2024-12-02 13:42:27,115 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=78098485a5b141819092a86820b153bc, text="music key changes and did boys synthesis functionality restore both system voices", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:27,814 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices and
2024-12-02 13:42:27,814 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ffd3f577c6624bdcbf742808aa0ac824, text="music key changes and did boys synthesis functionality restore both system voices and", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:28,059 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices and SCOT
2024-12-02 13:42:28,084 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d57f2c2dabac4e9e9327530cb5145aae, text="music key changes and did boys synthesis functionality restore both system voices and SCOT", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:28,422 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices and SCOTTP
2024-12-02 13:42:28,424 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b042deca78934d418fc2038dc7826280, text="music key changes and did boys synthesis functionality restore both system voices and SCOTTP", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:28,515 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS
2024-12-02 13:42:28,515 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6d6bf249e38e482a9a165904efc16be8, text="music key changes and did boys synthesis functionality restore both system voices and SCOTTPS", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:29,118 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implement
2024-12-02 13:42:29,118 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a7ba9b36093b40e28de6dcd0e1ef2e62, text="music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implement", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:29,824 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implemented
2024-12-02 13:42:29,825 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d2a1926b0444488b9e7b13bcee599a3a, text="music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implemented", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:30,020 [DEBUG] app1.py:1214 - Speech recognizing: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implemented time
2024-12-02 13:42:30,020 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=53f3c23e6bed4658b6ac50cb372a1df0, text="music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implemented time", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:31,979 [INFO] app1.py:1205 - Speech recognized: Music key changes and did boys synthesis functionality restore both system voices and SOTTPS implemented time.
2024-12-02 13:42:31,979 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6705f775ac7e4543bb8f478faa2ec8cf, text="Music key changes and did boys synthesis functionality restore both system voices and SOTTPS implemented time.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:42:36,387 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:42:41,598 [DEBUG] app1.py:1214 - Speech recognizing: PVT
2024-12-02 13:42:41,599 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=66dfffad74944bd2916503efe2e61cce, text="PVT", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:42,002 [DEBUG] app1.py:1214 - Speech recognizing: PVT club
2024-12-02 13:42:42,003 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d63a2a8746de4fa7b0f49494e5426e1c, text="PVT club", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:43,813 [INFO] app1.py:1205 - Speech recognized: Pvt. Club.
2024-12-02 13:42:43,815 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f504ef68645848feaa5311234e15762d, text="Pvt. Club.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:42:49,902 [DEBUG] app1.py:1214 - Speech recognizing: cancel
2024-12-02 13:42:49,902 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=037a3f421b284708b9e9b423e5f4fadb, text="cancel", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:42:50,213 [INFO] app1.py:1205 - Speech recognized: Cancel.
2024-12-02 13:42:50,214 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=10fabfa832314ffa93468ec9f1d10177, text="Cancel.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:42:53,813 [INFO] app1.py:1205 - Speech recognized: Why?
2024-12-02 13:42:53,814 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fcdf1b4095474bc687546a27fb102480, text="Why?", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:43:06,389 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:43:10,905 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:43:10,906 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6c239c4791454245a23382aa6a2b6896, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:43:29,012 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:43:29,013 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d25cce9f16dc43adbcae4d1e47c63764, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:43:35,715 [DEBUG] app1.py:1214 - Speech recognizing: join
2024-12-02 13:43:35,716 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=de38dafec74b4c35a678d823c5afe276, text="join", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:35,916 [DEBUG] app1.py:1214 - Speech recognizing: join live record
2024-12-02 13:43:35,917 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a806f1a4640349c3aaf51384e1ebf2c8, text="join live record", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:36,391 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:43:37,826 [INFO] app1.py:1205 - Speech recognized: Join live record.
2024-12-02 13:43:37,827 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e4617685d21748f3b7c6b7fccfd2cb08, text="Join live record.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:43:40,104 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 13:43:40,105 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 13:43:40,105 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,106 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,107 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 13:43:40,107 [DEBUG] app1.py:1104 - Sending transcription: i don't know (is_final: False)
2024-12-02 13:43:40,113 [DEBUG] app1.py:1104 - Sending transcription: I don't know. (is_final: True)
2024-12-02 13:43:40,116 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:43:40,120 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 13:43:40,121 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 13:43:40,122 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 13:43:40,137 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:43:40,140 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 13:43:40,148 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 13:43:40,152 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing is (is_final: False)
2024-12-02 13:43:40,155 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing is that happening (is_final: False)
2024-12-02 13:43:40,156 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing is that happening something (is_final: False)
2024-12-02 13:43:40,166 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing is that happening something or not (is_final: False)
2024-12-02 13:43:40,173 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? Is that happening something or not? (is_final: True)
2024-12-02 13:43:40,179 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,190 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,191 [DEBUG] app1.py:1104 - Sending transcription: he had (is_final: False)
2024-12-02 13:43:40,202 [DEBUG] app1.py:1104 - Sending transcription: He had. (is_final: True)
2024-12-02 13:43:40,204 [DEBUG] app1.py:1104 - Sending transcription: hit up the roof (is_final: False)
2024-12-02 13:43:40,207 [DEBUG] app1.py:1104 - Sending transcription: hit up the room (is_final: False)
2024-12-02 13:43:40,208 [DEBUG] app1.py:1104 - Sending transcription: hit up the roof (is_final: False)
2024-12-02 13:43:40,211 [DEBUG] app1.py:1104 - Sending transcription: hit up the room contractor (is_final: False)
2024-12-02 13:43:40,235 [DEBUG] app1.py:1104 - Sending transcription: hit up the roof root (is_final: False)
2024-12-02 13:43:40,237 [DEBUG] app1.py:1104 - Sending transcription: The. (is_final: True)
2024-12-02 13:43:40,238 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,239 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,240 [DEBUG] app1.py:1104 - Sending transcription: depository (is_final: False)
2024-12-02 13:43:40,248 [DEBUG] app1.py:1104 - Sending transcription: depository root (is_final: False)
2024-12-02 13:43:40,251 [DEBUG] app1.py:1104 - Sending transcription: depository route directory (is_final: False)
2024-12-02 13:43:40,251 [DEBUG] app1.py:1104 - Sending transcription: depository root directory folder (is_final: False)
2024-12-02 13:43:40,253 [DEBUG] app1.py:1104 - Sending transcription: depository route directory (is_final: False)
2024-12-02 13:43:40,254 [DEBUG] app1.py:1104 - Sending transcription: depository root directory folder (is_final: False)
2024-12-02 13:43:40,255 [DEBUG] app1.py:1104 - Sending transcription: depository root directory in a folder (is_final: False)
2024-12-02 13:43:40,256 [DEBUG] app1.py:1104 - Sending transcription: Depository root directory in a folder. (is_final: True)
2024-12-02 13:43:40,267 [DEBUG] app1.py:1104 - Sending transcription: copy (is_final: False)
2024-12-02 13:43:40,269 [DEBUG] app1.py:1104 - Sending transcription: kanji me (is_final: False)
2024-12-02 13:43:40,270 [DEBUG] app1.py:1104 - Sending transcription: kanchi male (is_final: False)
2024-12-02 13:43:40,272 [DEBUG] app1.py:1104 - Sending transcription: begin pachhd (is_final: False)
2024-12-02 13:43:40,275 [DEBUG] app1.py:1104 - Sending transcription: begin pachhdi (is_final: False)
2024-12-02 13:43:40,284 [DEBUG] app1.py:1104 - Sending transcription: begin pachhdi mein lagi (is_final: False)
2024-12-02 13:43:40,287 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,291 [DEBUG] app1.py:1104 - Sending transcription: credentials (is_final: False)
2024-12-02 13:43:40,295 [DEBUG] app1.py:1104 - Sending transcription: credentials of (is_final: False)
2024-12-02 13:43:40,297 [DEBUG] app1.py:1104 - Sending transcription: Credentials of. (is_final: True)
2024-12-02 13:43:40,301 [DEBUG] app1.py:1104 - Sending transcription: failed (is_final: False)
2024-12-02 13:43:40,302 [DEBUG] app1.py:1104 - Sending transcription: failed to (is_final: False)
2024-12-02 13:43:40,304 [DEBUG] app1.py:1104 - Sending transcription: failed to deploy (is_final: False)
2024-12-02 13:43:40,306 [DEBUG] app1.py:1104 - Sending transcription: Failed to deploy. (is_final: True)
2024-12-02 13:43:40,307 [DEBUG] app1.py:1104 - Sending transcription: is successfully uploaded and deployed (is_final: False)
2024-12-02 13:43:40,308 [DEBUG] app1.py:1104 - Sending transcription: is successfully uploaded and deployed react (is_final: False)
2024-12-02 13:43:40,312 [DEBUG] app1.py:1104 - Sending transcription: is successfully uploaded and deployed reactor (is_final: False)
2024-12-02 13:43:40,320 [DEBUG] app1.py:1104 - Sending transcription: is successfully uploaded and deployed reactor deploy (is_final: False)
2024-12-02 13:43:40,321 [DEBUG] app1.py:1104 - Sending transcription: Successfully deployed reactor deploy. (is_final: True)
2024-12-02 13:43:40,322 [DEBUG] app1.py:1104 - Sending transcription: Ed. (is_final: True)
2024-12-02 13:43:40,323 [DEBUG] app1.py:1104 - Sending transcription: is (is_final: False)
2024-12-02 13:43:40,331 [DEBUG] app1.py:1104 - Sending transcription: is the file name in (is_final: False)
2024-12-02 13:43:40,336 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the (is_final: False)
2024-12-02 13:43:40,337 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the yahoo (is_final: False)
2024-12-02 13:43:40,339 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the yahoo can you (is_final: False)
2024-12-02 13:43:40,341 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the yahoo can you file (is_final: False)
2024-12-02 13:43:40,351 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the yahoo can you find me (is_final: False)
2024-12-02 13:43:40,352 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the yahoo can you find me the root (is_final: False)
2024-12-02 13:43:40,355 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the yahoo can you file me a route directory (is_final: False)
2024-12-02 13:43:40,357 [DEBUG] app1.py:1104 - Sending transcription: is the file name in the yahoo can you find me the root directory correct (is_final: False)
2024-12-02 13:43:40,365 [DEBUG] app1.py:1104 - Sending transcription: Is the file name in the Yahoo? Can you find me the root directory correct? (is_final: True)
2024-12-02 13:43:40,366 [DEBUG] app1.py:1104 - Sending transcription: PHP (is_final: False)
2024-12-02 13:43:40,366 [DEBUG] app1.py:1104 - Sending transcription: PHP's (is_final: False)
2024-12-02 13:43:40,368 [DEBUG] app1.py:1104 - Sending transcription: PHP. (is_final: True)
2024-12-02 13:43:40,370 [DEBUG] app1.py:1104 - Sending transcription: and in the (is_final: False)
2024-12-02 13:43:40,371 [DEBUG] app1.py:1104 - Sending transcription: and in the dinner (is_final: False)
2024-12-02 13:43:40,373 [DEBUG] app1.py:1104 - Sending transcription: and in the dinner in order (is_final: False)
2024-12-02 13:43:40,373 [DEBUG] app1.py:1104 - Sending transcription: and in the dinner in order to get (is_final: False)
2024-12-02 13:43:40,374 [DEBUG] app1.py:1104 - Sending transcription: and in the dinner in order to get anything (is_final: False)
2024-12-02 13:43:40,380 [DEBUG] app1.py:1104 - Sending transcription: and in the dinner in order to get anything in (is_final: False)
2024-12-02 13:43:40,386 [DEBUG] app1.py:1104 - Sending transcription: In order to get anything in. (is_final: True)
2024-12-02 13:43:40,390 [DEBUG] app1.py:1104 - Sending transcription: the (is_final: False)
2024-12-02 13:43:40,391 [DEBUG] app1.py:1104 - Sending transcription: The. (is_final: True)
2024-12-02 13:43:40,391 [DEBUG] app1.py:1104 - Sending transcription: python (is_final: False)
2024-12-02 13:43:40,396 [DEBUG] app1.py:1104 - Sending transcription: python code (is_final: False)
2024-12-02 13:43:40,398 [DEBUG] app1.py:1104 - Sending transcription: python code live (is_final: False)
2024-12-02 13:43:40,403 [DEBUG] app1.py:1104 - Sending transcription: python code live live (is_final: False)
2024-12-02 13:43:40,405 [DEBUG] app1.py:1104 - Sending transcription: Python code live. (is_final: True)
2024-12-02 13:43:40,406 [DEBUG] app1.py:1104 - Sending transcription: how can i (is_final: False)
2024-12-02 13:43:40,407 [DEBUG] app1.py:1104 - Sending transcription: how can i get (is_final: False)
2024-12-02 13:43:40,407 [DEBUG] app1.py:1104 - Sending transcription: How can I get? (is_final: True)
2024-12-02 13:43:40,418 [DEBUG] app1.py:1104 - Sending transcription: he can (is_final: False)
2024-12-02 13:43:40,419 [DEBUG] app1.py:1104 - Sending transcription: E congress (is_final: False)
2024-12-02 13:43:40,420 [DEBUG] app1.py:1104 - Sending transcription: E congresswoman (is_final: False)
2024-12-02 13:43:40,420 [DEBUG] app1.py:1104 - Sending transcription: E congresswoman unif (is_final: False)
2024-12-02 13:43:40,422 [DEBUG] app1.py:1104 - Sending transcription: E congresswoman unifensive (is_final: False)
2024-12-02 13:43:40,424 [DEBUG] app1.py:1104 - Sending transcription: E congresswoman unifensively (is_final: False)
2024-12-02 13:43:40,425 [DEBUG] app1.py:1104 - Sending transcription: E Congresswoman Unifensive Year. (is_final: True)
2024-12-02 13:43:40,435 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,437 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,439 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,440 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,440 [DEBUG] app1.py:1104 - Sending transcription: sanjay (is_final: False)
2024-12-02 13:43:40,441 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubg (is_final: False)
2024-12-02 13:43:40,446 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubjira (is_final: False)
2024-12-02 13:43:40,451 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubjira is (is_final: False)
2024-12-02 13:43:40,469 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubjira is only (is_final: False)
2024-12-02 13:43:40,470 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubjira is only when (is_final: False)
2024-12-02 13:43:40,472 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubjira is only when the (is_final: False)
2024-12-02 13:43:40,473 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubjira is only when the hacker (is_final: False)
2024-12-02 13:43:40,474 [DEBUG] app1.py:1104 - Sending transcription: sanjeev pubjira is only when the hiker and the (is_final: False)
2024-12-02 13:43:40,483 [DEBUG] app1.py:1104 - Sending transcription: Sanjeev Pubjira is only when the hacker. (is_final: True)
2024-12-02 13:43:40,484 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,491 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,491 [DEBUG] app1.py:1104 - Sending transcription: add (is_final: False)
2024-12-02 13:43:40,492 [DEBUG] app1.py:1104 - Sending transcription: add this (is_final: False)
2024-12-02 13:43:40,502 [DEBUG] app1.py:1104 - Sending transcription: add this for (is_final: False)
2024-12-02 13:43:40,503 [DEBUG] app1.py:1104 - Sending transcription: add this for ahmedabad (is_final: False)
2024-12-02 13:43:40,504 [DEBUG] app1.py:1104 - Sending transcription: add this for aye mazda bachelor (is_final: False)
2024-12-02 13:43:40,506 [DEBUG] app1.py:1104 - Sending transcription: add this for aye mazda bachelor building (is_final: False)
2024-12-02 13:43:40,508 [DEBUG] app1.py:1104 - Sending transcription: add this for aye mazda bachelor building into (is_final: False)
2024-12-02 13:43:40,519 [DEBUG] app1.py:1104 - Sending transcription: add this for aye mazda bachelor building integrality (is_final: False)
2024-12-02 13:43:40,524 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,531 [DEBUG] app1.py:1104 - Sending transcription: the seven (is_final: False)
2024-12-02 13:43:40,533 [DEBUG] app1.py:1104 - Sending transcription: the seven develop (is_final: False)
2024-12-02 13:43:40,537 [DEBUG] app1.py:1104 - Sending transcription: the seven develop puzzle (is_final: False)
2024-12-02 13:43:40,539 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao (is_final: False)
2024-12-02 13:43:40,539 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao me (is_final: False)
2024-12-02 13:43:40,540 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao mei you (is_final: False)
2024-12-02 13:43:40,542 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao mei you starting (is_final: False)
2024-12-02 13:43:40,542 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao mei you starting pujini (is_final: False)
2024-12-02 13:43:40,550 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao mei you starting pujini starting (is_final: False)
2024-12-02 13:43:40,551 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao mei you starting pujini ki (is_final: False)
2024-12-02 13:43:40,552 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao mei you starting pujini starting (is_final: False)
2024-12-02 13:43:40,553 [DEBUG] app1.py:1104 - Sending transcription: the seven developing ki ki ki liao mei you starting pujini starting school (is_final: False)
2024-12-02 13:43:40,556 [DEBUG] app1.py:1104 - Sending transcription: The seven developing Ki Ki liao Mei you starting school. (is_final: True)
2024-12-02 13:43:40,556 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,558 [DEBUG] app1.py:1104 - Sending transcription: two BHK builder (is_final: False)
2024-12-02 13:43:40,566 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 13:43:40,567 [DEBUG] app1.py:1104 - Sending transcription: floor (is_final: False)
2024-12-02 13:43:40,568 [DEBUG] app1.py:1104 - Sending transcription: Floor 1. (is_final: True)
2024-12-02 13:43:40,571 [DEBUG] app1.py:1104 - Sending transcription: new delhi (is_final: False)
2024-12-02 13:43:40,572 [DEBUG] app1.py:1104 - Sending transcription: new delhi in the (is_final: False)
2024-12-02 13:43:40,573 [DEBUG] app1.py:1104 - Sending transcription: new delhi in the mardin (is_final: False)
2024-12-02 13:43:40,574 [DEBUG] app1.py:1104 - Sending transcription: new delhi in the mardini (is_final: False)
2024-12-02 13:43:40,575 [DEBUG] app1.py:1104 - Sending transcription: new delhi in the mardi gras (is_final: False)
2024-12-02 13:43:40,583 [DEBUG] app1.py:1104 - Sending transcription: New Delhi in the Mardi Gras. (is_final: True)
2024-12-02 13:43:40,583 [DEBUG] app1.py:1104 - Sending transcription: movie kathakali (is_final: False)
2024-12-02 13:43:40,586 [DEBUG] app1.py:1104 - Sending transcription: tune into (is_final: False)
2024-12-02 13:43:40,587 [DEBUG] app1.py:1104 - Sending transcription: tune into thandiwe (is_final: False)
2024-12-02 13:43:40,588 [DEBUG] app1.py:1104 - Sending transcription: tune into thandiwe shopping (is_final: False)
2024-12-02 13:43:40,590 [DEBUG] app1.py:1104 - Sending transcription: tune into thandiwe shopping kitut (is_final: False)
2024-12-02 13:43:40,590 [DEBUG] app1.py:1104 - Sending transcription: tune into thandiwe shopping kituto (is_final: False)
2024-12-02 13:43:40,591 [DEBUG] app1.py:1104 - Sending transcription: tune into thandiwe shopping kituto ginje (is_final: False)
2024-12-02 13:43:40,592 [DEBUG] app1.py:1104 - Sending transcription: Tune into Thandiwe shopping kituto ginje Haji. (is_final: True)
2024-12-02 13:43:40,600 [DEBUG] app1.py:1104 - Sending transcription: game and show beginning (is_final: False)
2024-12-02 13:43:40,601 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,602 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,602 [DEBUG] app1.py:1104 - Sending transcription: repair (is_final: False)
2024-12-02 13:43:40,606 [DEBUG] app1.py:1104 - Sending transcription: Repair. (is_final: True)
2024-12-02 13:43:40,607 [DEBUG] app1.py:1104 - Sending transcription: 20° (is_final: False)
2024-12-02 13:43:40,615 [DEBUG] app1.py:1104 - Sending transcription: 20° function (is_final: False)
2024-12-02 13:43:40,616 [DEBUG] app1.py:1104 - Sending transcription: two degree functional (is_final: False)
2024-12-02 13:43:40,619 [DEBUG] app1.py:1104 - Sending transcription: 20° functionality (is_final: False)
2024-12-02 13:43:40,620 [DEBUG] app1.py:1104 - Sending transcription: 20° functionality storage (is_final: False)
2024-12-02 13:43:40,621 [DEBUG] app1.py:1104 - Sending transcription: 20° functionality storage in (is_final: False)
2024-12-02 13:43:40,623 [DEBUG] app1.py:1104 - Sending transcription: 20° functionality (is_final: False)
2024-12-02 13:43:40,624 [DEBUG] app1.py:1104 - Sending transcription: 20° functionality. (is_final: True)
2024-12-02 13:43:40,631 [DEBUG] app1.py:1104 - Sending transcription: music key (is_final: False)
2024-12-02 13:43:40,632 [DEBUG] app1.py:1104 - Sending transcription: music key changes (is_final: False)
2024-12-02 13:43:40,633 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did (is_final: False)
2024-12-02 13:43:40,638 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys (is_final: False)
2024-12-02 13:43:40,640 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys syn (is_final: False)
2024-12-02 13:43:40,640 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis (is_final: False)
2024-12-02 13:43:40,641 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis function (is_final: False)
2024-12-02 13:43:40,648 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality (is_final: False)
2024-12-02 13:43:40,650 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore (is_final: False)
2024-12-02 13:43:40,674 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both (is_final: False)
2024-12-02 13:43:40,675 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system (is_final: False)
2024-12-02 13:43:40,690 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices (is_final: False)
2024-12-02 13:43:40,692 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices and (is_final: False)
2024-12-02 13:43:40,700 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices and SCOT (is_final: False)
2024-12-02 13:43:40,701 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices and SCOTTP (is_final: False)
2024-12-02 13:43:40,703 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS (is_final: False)
2024-12-02 13:43:40,706 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implement (is_final: False)
2024-12-02 13:43:40,707 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implemented (is_final: False)
2024-12-02 13:43:40,707 [DEBUG] app1.py:1104 - Sending transcription: music key changes and did boys synthesis functionality restore both system voices and SCOTTPS implemented time (is_final: False)
2024-12-02 13:43:40,716 [DEBUG] app1.py:1104 - Sending transcription: Music key changes and did boys synthesis functionality restore both system voices and SOTTPS implemented time. (is_final: True)
2024-12-02 13:43:40,718 [DEBUG] app1.py:1104 - Sending transcription: PVT (is_final: False)
2024-12-02 13:43:40,718 [DEBUG] app1.py:1104 - Sending transcription: PVT club (is_final: False)
2024-12-02 13:43:40,719 [DEBUG] app1.py:1104 - Sending transcription: Pvt. Club. (is_final: True)
2024-12-02 13:43:40,723 [DEBUG] app1.py:1104 - Sending transcription: cancel (is_final: False)
2024-12-02 13:43:40,724 [DEBUG] app1.py:1104 - Sending transcription: Cancel. (is_final: True)
2024-12-02 13:43:40,725 [DEBUG] app1.py:1104 - Sending transcription: Why? (is_final: True)
2024-12-02 13:43:40,731 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,732 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 13:43:40,734 [DEBUG] app1.py:1104 - Sending transcription: join (is_final: False)
2024-12-02 13:43:40,739 [DEBUG] app1.py:1104 - Sending transcription: join live record (is_final: False)
2024-12-02 13:43:40,740 [DEBUG] app1.py:1104 - Sending transcription: Join live record. (is_final: True)
2024-12-02 13:43:43,718 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:43:43,718 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=990b4a8455474149ba509c139de58de5, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:43,719 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:43:44,309 [DEBUG] app1.py:1214 - Speech recognizing: hi hi
2024-12-02 13:43:44,309 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=27105b5451164c0387ba51b2dd0ff0ce, text="hi hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:44,310 [DEBUG] app1.py:1104 - Sending transcription: hi hi (is_final: False)
2024-12-02 13:43:44,617 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 13:43:44,618 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=29ca825aeba14d629dc5c5ba09503019, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:44,618 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 13:43:45,207 [DEBUG] app1.py:1214 - Speech recognizing: hi hi hi
2024-12-02 13:43:45,207 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9cb4c977c39d4f3ba119c7a31347c9e0, text="hi hi hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:45,208 [DEBUG] app1.py:1104 - Sending transcription: hi hi hi (is_final: False)
2024-12-02 13:43:46,013 [DEBUG] app1.py:1214 - Speech recognizing: hi hi hi language
2024-12-02 13:43:46,014 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1230300620e046a8a19b4d6d81ea17ac, text="hi hi hi language", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:46,015 [DEBUG] app1.py:1104 - Sending transcription: hi hi hi language (is_final: False)
2024-12-02 13:43:46,917 [DEBUG] app1.py:1214 - Speech recognizing: hi hi hi language translate
2024-12-02 13:43:46,918 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fe0c59d8f4114ea0ae5b4994d0e293e4, text="hi hi hi language translate", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:46,918 [DEBUG] app1.py:1104 - Sending transcription: hi hi hi language translate (is_final: False)
2024-12-02 13:43:48,739 [INFO] app1.py:1205 - Speech recognized: Hi, hi hi, language translate.
2024-12-02 13:43:48,740 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d21765ffc1ec43afadfb726208134331, text="Hi, hi hi, language translate.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:43:48,742 [DEBUG] app1.py:1104 - Sending transcription: Hi, hi hi, language translate. (is_final: True)
2024-12-02 13:43:49,829 [DEBUG] app1.py:1214 - Speech recognizing: hindi
2024-12-02 13:43:49,829 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6be853677519461e9f70587d1dc84c72, text="hindi", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:43:49,830 [DEBUG] app1.py:1104 - Sending transcription: hindi (is_final: False)
2024-12-02 13:44:01,609 [DEBUG] app1.py:1214 - Speech recognizing: english
2024-12-02 13:44:01,610 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce678cb735554f7888efc85fb8926a0e, text="english", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:01,611 [DEBUG] app1.py:1104 - Sending transcription: english (is_final: False)
2024-12-02 13:44:04,128 [INFO] app1.py:1205 - Speech recognized: English.
2024-12-02 13:44:04,128 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=67dff92fda4449659b979e689837171b, text="English.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:44:04,130 [DEBUG] app1.py:1104 - Sending transcription: English. (is_final: True)
2024-12-02 13:44:06,393 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:44:15,423 [DEBUG] app1.py:1214 - Speech recognizing: request vijay
2024-12-02 13:44:15,423 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8e02602a1e6a431da6d1427e1ffb831d, text="request vijay", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:16,014 [DEBUG] app1.py:1214 - Speech recognizing: but a quiz
2024-12-02 13:44:16,015 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dd283c87552e469c9dd63197b421b7df, text="but a quiz", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:16,125 [DEBUG] app1.py:1214 - Speech recognizing: but a quiz project
2024-12-02 13:44:16,126 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=62e8f8a2a7df400582a34667299fd0ec, text="but a quiz project", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:16,421 [DEBUG] app1.py:1214 - Speech recognizing: but a quiz vijayan pichla project
2024-12-02 13:44:16,421 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=104995f667794392b1698e898185808c, text="but a quiz vijayan pichla project", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:16,623 [DEBUG] app1.py:1214 - Speech recognizing: but a quiz vijayan pichla project an
2024-12-02 13:44:16,624 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3718a38f155a4138ba7a5e82375e3543, text="but a quiz vijayan pichla project an", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:16,716 [DEBUG] app1.py:1214 - Speech recognizing: but a quiz vijayan pichla project
2024-12-02 13:44:16,717 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fa7e71670d5b4c4f8605fea7d3e35471, text="but a quiz vijayan pichla project", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:18,521 [INFO] app1.py:1205 - Speech recognized: But a quiz Vijayan Pichla project.
2024-12-02 13:44:18,522 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bd524dda3db44a6e9fade5babcae92c1, text="But a quiz Vijayan Pichla project.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:44:26,908 [DEBUG] app1.py:1214 - Speech recognizing: indian
2024-12-02 13:44:26,909 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=37bffdbaa0694a7dbade1052177bc411, text="indian", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:44:28,818 [INFO] app1.py:1205 - Speech recognized: Indian.
2024-12-02 13:44:28,819 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0823a0c58d0e4d7b8826e828d1cf8485, text="Indian.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:44:36,394 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:44:49,027 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 13:44:49,028 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c9108fc2a7c240cd8f90b6a0d22a3427, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:45:01,718 [DEBUG] app1.py:1214 - Speech recognizing: thank you
2024-12-02 13:45:01,719 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dd269802e3144ce98c605971d9a53416, text="thank you", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:03,527 [INFO] app1.py:1205 - Speech recognized: Thank you.
2024-12-02 13:45:03,528 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c448325ee28342929bad9f66df9ad91c, text="Thank you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:45:06,395 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:45:17,698 [DEBUG] app1.py:1214 - Speech recognizing: today
2024-12-02 13:45:17,699 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=453c14ae2fea486a8375bc0439011f84, text="today", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:17,899 [DEBUG] app1.py:1214 - Speech recognizing: today nigeria
2024-12-02 13:45:17,900 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b1c9afaf61a4db7a372c38e68912fdb, text="today nigeria", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:19,207 [DEBUG] app1.py:1214 - Speech recognizing: today nigeria bang
2024-12-02 13:45:19,208 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=91f0dacc76004ae1b6bff2bdf08bd556, text="today nigeria bang", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:19,596 [DEBUG] app1.py:1214 - Speech recognizing: could the nigerian bangor regions
2024-12-02 13:45:19,598 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d6caab61afef4576bf87f372def1d90d, text="could the nigerian bangor regions", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:19,798 [DEBUG] app1.py:1214 - Speech recognizing: today nigeria's
2024-12-02 13:45:19,798 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d20930c427fe4aa69d0805b49b756722, text="today nigeria's", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:20,200 [DEBUG] app1.py:1214 - Speech recognizing: could the nigerian bangor regions
2024-12-02 13:45:20,201 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=efb5708b645e45e0901402ec646c997c, text="could the nigerian bangor regions", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:20,496 [DEBUG] app1.py:1214 - Speech recognizing: today nigeria banguri jasper
2024-12-02 13:45:20,497 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b0d0be6f63a545b4ab7340fa9cb16c7d, text="today nigeria banguri jasper", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:20,901 [DEBUG] app1.py:1214 - Speech recognizing: today nigeria banguri jasleen krishnamo
2024-12-02 13:45:20,902 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d1410fd4db62472492d837290fa959b4, text="today nigeria banguri jasleen krishnamo", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:21,104 [DEBUG] app1.py:1214 - Speech recognizing: today nigeria banguri jasleen krishnamoorth
2024-12-02 13:45:21,105 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e04a2f080abe446ea985a98e49143d18, text="today nigeria banguri jasleen krishnamoorth", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:21,806 [DEBUG] app1.py:1214 - Speech recognizing: today nigeria banguri jasleen krishnamoorthy
2024-12-02 13:45:21,807 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=315be417f8dd4293bf0a306dd3545d12, text="today nigeria banguri jasleen krishnamoorthy", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:22,801 [INFO] app1.py:1205 - Speech recognized: Today Nigeria. Banguri, Jasleen Krishnamoorth.
2024-12-02 13:45:22,802 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e976d87ca5224e089272b790422d813d, text="Today Nigeria. Banguri, Jasleen Krishnamoorth.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:45:35,296 [DEBUG] app1.py:1214 - Speech recognizing: go to
2024-12-02 13:45:35,296 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4bcc5795847a4235a042645b3945fc88, text="go to", reason=ResultReason.RecognizingSpeech)
2024-12-02 13:45:36,397 [INFO] app1.py:898 - Active clients: ['71b562af-3aa2-4bbf-b66b-3513c9caa661', '0f70942e-eefa-4efb-83f1-115edcc18149']
2024-12-02 13:45:38,439 [INFO] app1.py:1205 - Speech recognized: Go to.
2024-12-02 13:45:38,440 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e4fd48e1db104782aa0e5622ac21b81d, text="Go to.", reason=ResultReason.RecognizedSpeech)
2024-12-02 13:45:48,818 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 13:45:48,818 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9336e530e8114452b2c4be78528dc581, text="Play.", reason=ResultReason.RecognizedSpeech)
