2024-12-02 16:41:32,630 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:41:32,635 [INFO] app1.py:1402 - Starting Flask application
2024-12-02 16:41:32,636 [INFO] app1.py:1405 - Starting with Waitress server on http://127.0.0.1:4585
2024-12-02 16:41:40,601 [INFO] app1.py:1018 - Join live page requested
2024-12-02 16:41:41,368 [INFO] app1.py:1013 - Go live page requested
2024-12-02 16:41:51,222 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:41:51,375 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:41:51,548 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:41:53,795 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:41:53,795 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9d92d672586144f18529ac18f3322496, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:41:54,028 [DEBUG] app1.py:1214 - Speech recognizing: hello how are
2024-12-02 16:41:54,028 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e29ca251b18c4875a9e490aa2fbf12fd, text="hello how are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:41:54,339 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 16:41:54,340 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=549c3c2c140748d4a763887d09d585bb, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:41:54,963 [INFO] app1.py:1205 - Speech recognized: Hello, how are you?
2024-12-02 16:41:54,963 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a65f4b69b4894a6e980ce715d9393e60, text="Hello, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:01,541 [DEBUG] app1.py:1214 - Speech recognizing: show me
2024-12-02 16:42:01,541 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dbfc079e18c24aaeaacda8da265a7a96, text="show me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:02,636 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:42:03,177 [INFO] app1.py:1205 - Speech recognized: Show me.
2024-12-02 16:42:03,177 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9a006c2a0b8c43c7a4d4912c3711b2b0, text="Show me.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:14,713 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:42:14,903 [DEBUG] app1.py:1214 - Speech recognizing: IPL 2019
2024-12-02 16:42:14,903 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6318de53bcb345b39a891490ce88e80b, text="IPL 2019", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:14,937 [INFO] app1.py:1205 - Speech recognized: IPL 2019.
2024-12-02 16:42:14,937 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b787db785c0740308b9c7e9deeabfd5f, text="IPL 2019.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:14,937 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:42:15,485 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:42:15,612 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:42:15,786 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:42:17,663 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:42:17,664 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=86aabcb8cf2f406da3e77e1483e00450, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:18,270 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:42:18,270 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2daf79dd615d4cf2b0a392b0665e57c0, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:21,338 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:42:21,340 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:42:21,341 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 16:42:21,343 [DEBUG] app1.py:1104 - Sending transcription: hello how are (is_final: False)
2024-12-02 16:42:21,344 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 16:42:21,353 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? (is_final: True)
2024-12-02 16:42:21,356 [DEBUG] app1.py:1104 - Sending transcription: show me (is_final: False)
2024-12-02 16:42:21,357 [DEBUG] app1.py:1104 - Sending transcription: Show me. (is_final: True)
2024-12-02 16:42:21,365 [DEBUG] app1.py:1104 - Sending transcription: IPL 2019 (is_final: False)
2024-12-02 16:42:21,372 [DEBUG] app1.py:1104 - Sending transcription: IPL 2019. (is_final: True)
2024-12-02 16:42:21,373 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:42:21,374 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:42:26,269 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:42:26,269 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=344ed0f5c5404492b55398942136a53e, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:26,270 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:42:26,658 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:42:26,658 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0799336899d54d65a77d7719595644ab, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:26,659 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:42:31,078 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:42:31,078 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bec92b62e2b94340ba2f07cd4073ca08, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:31,079 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 16:42:31,778 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 16:42:31,778 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=704661b73ded4e13b6790dece290611d, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:31,779 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 16:42:32,637 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:42:35,107 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:42:45,160 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:42:48,975 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:42:49,136 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:42:49,263 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:42:51,218 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:42:51,218 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=06c56c99f7b045a4874c49290a47b24d, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:51,905 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:42:51,907 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c07bd03eef634c208e6707ce21f51a01, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:52,635 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:42:52,635 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=05f30094f1ce4d0eaf092d75201a226d, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:53,705 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 16:42:53,709 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=561e1648ebc34c62a9e3db47da07a9ee, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:42:55,487 [DEBUG] app1.py:1214 - Speech recognizing: angela
2024-12-02 16:42:55,489 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=81c5817defbe414fad208dd3fbd9a07d, text="angela", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:42:55,692 [DEBUG] app1.py:1214 - Speech recognizing: enjoy the sunika
2024-12-02 16:42:55,692 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b8d2434e1f0a4d17a60fa2df581469b3, text="enjoy the sunika", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:02,491 [DEBUG] app1.py:1214 - Speech recognizing: live
2024-12-02 16:43:02,491 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0eab77e3934648ddb321c8ecbc737091, text="live", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:02,638 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:43:13,914 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:43:13,914 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5806962b50ff4ca3879948429d512972, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:43:18,996 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 16:43:18,996 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=de6060ea055f440d81e60e40761cfd24, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:20,295 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana join live
2024-12-02 16:43:20,295 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=267c73851acd448990f0c64152ff7eb8, text="hey cortana join live", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:20,600 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:43:20,601 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:43:20,602 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:43:20,607 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana join live salman khan
2024-12-02 16:43:20,612 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:43:20,647 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4d570b6dd20543ea8e8508adca7ca898, text="hey cortana join live salman khan", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:20,648 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 16:43:20,675 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 16:43:20,678 [DEBUG] app1.py:1104 - Sending transcription: angela (is_final: False)
2024-12-02 16:43:20,679 [DEBUG] app1.py:1104 - Sending transcription: enjoy the sunika (is_final: False)
2024-12-02 16:43:20,679 [DEBUG] app1.py:1104 - Sending transcription: live (is_final: False)
2024-12-02 16:43:20,680 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:43:20,688 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 16:43:20,690 [DEBUG] app1.py:1104 - Sending transcription: hey cortana join live (is_final: False)
2024-12-02 16:43:20,691 [DEBUG] app1.py:1104 - Sending transcription: hey cortana join live salman khan (is_final: False)
2024-12-02 16:43:27,393 [DEBUG] app1.py:1214 - Speech recognizing: EK kundli yeh parlavna
2024-12-02 16:43:27,394 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0f2d689e747b405690ef93670f3864dc, text="EK kundli yeh parlavna", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:27,395 [DEBUG] app1.py:1104 - Sending transcription: EK kundli yeh parlavna (is_final: False)
2024-12-02 16:43:29,209 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:43:29,210 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7c514f7acb6841209320abb23d1e077b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:43:29,211 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:43:32,640 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:43:36,628 [DEBUG] app1.py:1214 - Speech recognizing: mezmo meadow court tom anna API ki jaan karthik kas
2024-12-02 16:43:36,629 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b56d901c597a46eea693d2c3fa8654ce, text="mezmo meadow court tom anna API ki jaan karthik kas", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:36,630 [DEBUG] app1.py:1104 - Sending transcription: mezmo meadow court tom anna API ki jaan karthik kas (is_final: False)
2024-12-02 16:43:36,830 [DEBUG] app1.py:1214 - Speech recognizing: mezmo meadow court tom anna API ki jaan karthik kashtam
2024-12-02 16:43:36,832 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1c02f66e7515476c87bb8009449ecd99, text="mezmo meadow court tom anna API ki jaan karthik kashtam", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:36,833 [DEBUG] app1.py:1104 - Sending transcription: mezmo meadow court tom anna API ki jaan karthik kashtam (is_final: False)
2024-12-02 16:43:38,135 [DEBUG] app1.py:1214 - Speech recognizing: mezmo meadow court tom anna API ki jaan
2024-12-02 16:43:38,135 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=39c542ccfffd42e9ba83b0e32c2d8711, text="mezmo meadow court tom anna API ki jaan", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:38,137 [DEBUG] app1.py:1104 - Sending transcription: mezmo meadow court tom anna API ki jaan (is_final: False)
2024-12-02 16:43:44,422 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:43:44,423 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=df5c5c761cf14f49b33f964bbfe65263, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:43:44,424 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:43:47,407 [DEBUG] app1.py:1214 - Speech recognizing: lewis arvind
2024-12-02 16:43:47,407 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bd04364788604b8ab1160f00eefe6d10, text="lewis arvind", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:47,408 [DEBUG] app1.py:1104 - Sending transcription: lewis arvind (is_final: False)
2024-12-02 16:43:47,593 [DEBUG] app1.py:1214 - Speech recognizing: lewis arvind kejriwal
2024-12-02 16:43:47,595 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=581cdbccb7314c87b406399fea86ea6e, text="lewis arvind kejriwal", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:47,596 [DEBUG] app1.py:1104 - Sending transcription: lewis arvind kejriwal (is_final: False)
2024-12-02 16:43:48,447 [INFO] app1.py:1205 - Speech recognized: Lewis, Arvind Kejriwal.
2024-12-02 16:43:48,448 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=328771cdf3a64363a2f7e33b42e066d9, text="Lewis, Arvind Kejriwal.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:43:48,448 [DEBUG] app1.py:1104 - Sending transcription: Lewis, Arvind Kejriwal. (is_final: True)
2024-12-02 16:43:51,214 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't
2024-12-02 16:43:51,216 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=912a4c3743b64d6ea44befb4398a9967, text="this wasn't", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:51,217 [DEBUG] app1.py:1104 - Sending transcription: this wasn't (is_final: False)
2024-12-02 16:43:51,415 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't really
2024-12-02 16:43:51,415 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3e57ee2d578d46969d38e112af6bc490, text="this wasn't really", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:51,416 [DEBUG] app1.py:1104 - Sending transcription: this wasn't really (is_final: False)
2024-12-02 16:43:52,519 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't very long it is
2024-12-02 16:43:52,520 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f044276667744008926d4af873d1d65d, text="this wasn't very long it is", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:52,521 [DEBUG] app1.py:1104 - Sending transcription: this wasn't very long it is (is_final: False)
2024-12-02 16:43:52,707 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't very long it is su
2024-12-02 16:43:52,708 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=878e6b0359f44773a9558fad29b54bd7, text="this wasn't very long it is su", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:52,710 [DEBUG] app1.py:1104 - Sending transcription: this wasn't very long it is su (is_final: False)
2024-12-02 16:43:52,814 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't very long it is sumika and
2024-12-02 16:43:52,815 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0121b75e7c084bb4a7dfe32b4c958a7c, text="this wasn't very long it is sumika and", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:52,816 [DEBUG] app1.py:1104 - Sending transcription: this wasn't very long it is sumika and (is_final: False)
2024-12-02 16:43:53,218 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't very long it is sumika and igbinos
2024-12-02 16:43:53,219 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c7fe9d18dad4491b8a4de6ea68a559a8, text="this wasn't very long it is sumika and igbinos", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:53,220 [DEBUG] app1.py:1104 - Sending transcription: this wasn't very long it is sumika and igbinos (is_final: False)
2024-12-02 16:43:53,811 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't very long it is sumika and igby nostalgia
2024-12-02 16:43:53,813 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c27bb39e0724ae89def08b49dc4ef3b, text="this wasn't very long it is sumika and igby nostalgia", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:53,814 [DEBUG] app1.py:1104 - Sending transcription: this wasn't very long it is sumika and igby nostalgia (is_final: False)
2024-12-02 16:43:54,725 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't very long it is sumika and igbinos day it is
2024-12-02 16:43:54,726 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1bb3673c74c04c948bf0f11dc47afd0f, text="this wasn't very long it is sumika and igbinos day it is", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:54,728 [DEBUG] app1.py:1104 - Sending transcription: this wasn't very long it is sumika and igbinos day it is (is_final: False)
2024-12-02 16:43:55,316 [DEBUG] app1.py:1214 - Speech recognizing: this wasn't very long it is sumika and igby nostalgia it is a styling
2024-12-02 16:43:55,318 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d91a97ac6a3f49518b48fcc59884a549, text="this wasn't very long it is sumika and igby nostalgia it is a styling", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:55,318 [DEBUG] app1.py:1104 - Sending transcription: this wasn't very long it is sumika and igby nostalgia it is a styling (is_final: False)
2024-12-02 16:43:57,177 [INFO] app1.py:1205 - Speech recognized: This wasn't very long. It is Sumika and Igbinos day. It is a styling.
2024-12-02 16:43:57,178 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6ee742e2d80f427ea55391a2ef91d2fa, text="This wasn't very long. It is Sumika and Igbinos day. It is a styling.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:43:57,179 [DEBUG] app1.py:1104 - Sending transcription: This wasn't very long. It is Sumika and Igbinos day. It is a styling. (is_final: True)
2024-12-02 16:43:57,936 [DEBUG] app1.py:1214 - Speech recognizing: hamilton
2024-12-02 16:43:57,936 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0f733c7aa5344c418009d03dd8023e54, text="hamilton", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:57,937 [DEBUG] app1.py:1104 - Sending transcription: hamilton (is_final: False)
2024-12-02 16:43:58,230 [DEBUG] app1.py:1214 - Speech recognizing: is
2024-12-02 16:43:58,231 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=24cfc8778aa744e1be9168fdd7eb2bad, text="is", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:58,231 [DEBUG] app1.py:1104 - Sending transcription: is (is_final: False)
2024-12-02 16:43:58,432 [DEBUG] app1.py:1214 - Speech recognizing: is chill
2024-12-02 16:43:58,432 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1df564d6640b4d6e9c057b67d64dbc45, text="is chill", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:58,433 [DEBUG] app1.py:1104 - Sending transcription: is chill (is_final: False)
2024-12-02 16:43:58,526 [DEBUG] app1.py:1214 - Speech recognizing: is chilling
2024-12-02 16:43:58,526 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2e08d2d2dbe349f7a3f692ce4f76b809, text="is chilling", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:58,527 [DEBUG] app1.py:1104 - Sending transcription: is chilling (is_final: False)
2024-12-02 16:43:59,537 [DEBUG] app1.py:1214 - Speech recognizing: is chilling kucho
2024-12-02 16:43:59,537 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=effefa8029704592ad7da2e51cd633a2, text="is chilling kucho", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:59,538 [DEBUG] app1.py:1104 - Sending transcription: is chilling kucho (is_final: False)
2024-12-02 16:43:59,630 [DEBUG] app1.py:1214 - Speech recognizing: is chilling
2024-12-02 16:43:59,630 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a396972cb8894a1c841ec971f1b10719, text="is chilling", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:43:59,631 [DEBUG] app1.py:1104 - Sending transcription: is chilling (is_final: False)
2024-12-02 16:44:00,125 [DEBUG] app1.py:1214 - Speech recognizing: hamilton is a chillingham
2024-12-02 16:44:00,125 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce0cb71a19584ffeb3f17e575651cc12, text="hamilton is a chillingham", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:00,127 [DEBUG] app1.py:1104 - Sending transcription: hamilton is a chillingham (is_final: False)
2024-12-02 16:44:02,041 [INFO] app1.py:1205 - Speech recognized: Is chilling.
2024-12-02 16:44:02,042 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2fc6c8a44f414f479412c8667e5cb9fa, text="Is chilling.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:44:02,043 [DEBUG] app1.py:1104 - Sending transcription: Is chilling. (is_final: True)
2024-12-02 16:44:02,641 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:44:02,804 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:44:02,805 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=afaaed38d03b41fdbc7139c9d18963a2, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:02,806 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 16:44:02,911 [DEBUG] app1.py:1214 - Speech recognizing: hello how are
2024-12-02 16:44:02,913 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=63e664dd5a224118b5e549cfbdc237b2, text="hello how are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:02,914 [DEBUG] app1.py:1104 - Sending transcription: hello how are (is_final: False)
2024-12-02 16:44:03,004 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 16:44:03,005 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=291448935cfc40249bf7fe0628782b94, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:03,005 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 16:44:04,309 [INFO] app1.py:1205 - Speech recognized: Hello, how are you?
2024-12-02 16:44:04,309 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cc6614167d134162a316ac7cc14cc001, text="Hello, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:44:04,310 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? (is_final: True)
2024-12-02 16:44:24,514 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:44:24,514 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2e43a546d443448f8daa11f1195ea87e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:44:24,516 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 16:44:26,127 [DEBUG] app1.py:1214 - Speech recognizing: key component
2024-12-02 16:44:26,130 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1fad065b96504755aa086a9a9f5e9dee, text="key component", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:26,130 [DEBUG] app1.py:1104 - Sending transcription: key component (is_final: False)
2024-12-02 16:44:27,916 [INFO] app1.py:1205 - Speech recognized: Key component.
2024-12-02 16:44:27,917 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8eb07ba886eb4373a75f86fe4054b0dd, text="Key component.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:44:27,917 [DEBUG] app1.py:1104 - Sending transcription: Key component. (is_final: True)
2024-12-02 16:44:28,025 [DEBUG] app1.py:1214 - Speech recognizing: compon
2024-12-02 16:44:28,025 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a54a3ab04d3243e6865851af3866a4cf, text="compon", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:28,026 [DEBUG] app1.py:1104 - Sending transcription: compon (is_final: False)
2024-12-02 16:44:28,118 [DEBUG] app1.py:1214 - Speech recognizing: component
2024-12-02 16:44:28,118 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6f9f3d95c93646e3bde9d983abdaf25c, text="component", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:28,119 [DEBUG] app1.py:1104 - Sending transcription: component (is_final: False)
2024-12-02 16:44:30,124 [INFO] app1.py:1205 - Speech recognized: Component.
2024-12-02 16:44:30,125 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa61a6ed8b4c4fc59fb11edbdb7b1bf3, text="Component.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:44:30,126 [DEBUG] app1.py:1104 - Sending transcription: Component. (is_final: True)
2024-12-02 16:44:32,642 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:44:44,118 [DEBUG] app1.py:1214 - Speech recognizing: ORU dhuniva
2024-12-02 16:44:44,119 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e44b462de42c4706b2d317cc4a3f24a0, text="ORU dhuniva", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:44,120 [DEBUG] app1.py:1104 - Sending transcription: ORU dhuniva (is_final: False)
2024-12-02 16:44:44,705 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul
2024-12-02 16:44:44,705 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d8926436c28044acb0da0f6430cfca4a, text="urdu niwa abdul", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:44,706 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul (is_final: False)
2024-12-02 16:44:44,799 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai
2024-12-02 16:44:44,800 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a99bcb01d7724de1969c40ead809ebcb, text="urdu niwa abdul mai", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:44,801 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai (is_final: False)
2024-12-02 16:44:45,000 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke
2024-12-02 16:44:45,001 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cf81361e8d5546aca4b69a17628a3e12, text="urdu niwa abdul mai ke", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:45,002 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke (is_final: False)
2024-12-02 16:44:45,310 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bul
2024-12-02 16:44:45,311 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=855e45f533f04798be8ec23efb7b08ec, text="urdu niwa abdul mai ke bul", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:45,311 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bul (is_final: False)
2024-12-02 16:44:45,405 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bulan naan
2024-12-02 16:44:45,406 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=36839f1db17a49318fede3485568b72e, text="urdu niwa abdul mai ke bulan naan", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:45,406 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bulan naan (is_final: False)
2024-12-02 16:44:45,498 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bulan dahi ch
2024-12-02 16:44:45,499 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=24b3833b43f14fb49fab12f6e8124608, text="urdu niwa abdul mai ke bulan dahi ch", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:45,499 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bulan dahi ch (is_final: False)
2024-12-02 16:44:45,607 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bulan naan jalan
2024-12-02 16:44:45,608 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=227d75362be44dfa8939efd5314a182c, text="urdu niwa abdul mai ke bulan naan jalan", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:45,611 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bulan naan jalan (is_final: False)
2024-12-02 16:44:45,902 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bulan naan jalan D
2024-12-02 16:44:45,905 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=06d79b5c6aa142f1869178c853572eff, text="urdu niwa abdul mai ke bulan naan jalan D", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:45,906 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bulan naan jalan D (is_final: False)
2024-12-02 16:44:46,011 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bulan naan jalan dua
2024-12-02 16:44:46,012 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7235ff928eed49889c145b0efc1c71af, text="urdu niwa abdul mai ke bulan naan jalan dua", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:46,014 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bulan naan jalan dua (is_final: False)
2024-12-02 16:44:46,910 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bulan naan jalan dua bola sani
2024-12-02 16:44:46,910 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=083ea72e945c4e02a8ba15de04f0b4e0, text="urdu niwa abdul mai ke bulan naan jalan dua bola sani", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:46,911 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bulan naan jalan dua bola sani (is_final: False)
2024-12-02 16:44:47,301 [DEBUG] app1.py:1214 - Speech recognizing: urdu niwa abdul mai ke bulan naan jalan dua saniya
2024-12-02 16:44:47,301 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a23b7618d2c44f1d97b95e5d80296c41, text="urdu niwa abdul mai ke bulan naan jalan dua saniya", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:47,302 [DEBUG] app1.py:1104 - Sending transcription: urdu niwa abdul mai ke bulan naan jalan dua saniya (is_final: False)
2024-12-02 16:44:49,199 [INFO] app1.py:1205 - Speech recognized: Urdu niwa Abdul Mai ke bulan naan Jalan dua saniya.
2024-12-02 16:44:49,200 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1f467821aa6a4e7cbdf44c5223f68fca, text="Urdu niwa Abdul Mai ke bulan naan Jalan dua saniya.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:44:49,201 [DEBUG] app1.py:1104 - Sending transcription: Urdu niwa Abdul Mai ke bulan naan Jalan dua saniya. (is_final: True)
2024-12-02 16:44:51,491 [DEBUG] app1.py:1214 - Speech recognizing: cover
2024-12-02 16:44:51,493 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=36fdb8ce05b1433a8efbdc33ba506b95, text="cover", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:51,494 [DEBUG] app1.py:1104 - Sending transcription: cover (is_final: False)
2024-12-02 16:44:54,604 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:44:54,828 [DEBUG] app1.py:1214 - Speech recognizing: play kajol
2024-12-02 16:44:54,829 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cbdc33a888c44cf1a64844039634264b, text="play kajol", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:44:54,830 [DEBUG] app1.py:1104 - Sending transcription: play kajol (is_final: False)
2024-12-02 16:44:54,832 [INFO] app1.py:1205 - Speech recognized: Play Kajol.
2024-12-02 16:44:54,834 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fd946b6cf7c346838b9183b657f53b4a, text="Play Kajol.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:44:54,836 [DEBUG] app1.py:1104 - Sending transcription: Play Kajol. (is_final: True)
2024-12-02 16:44:54,837 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:45:02,644 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:45:32,645 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:46:02,647 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:46:32,649 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:47:02,651 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:47:32,652 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:47:36,480 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:47:36,495 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 16:47:36,549 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 16:47:36,665 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:47:36,748 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:47:39,122 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:47:39,123 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d36ab401e78b469489db778036006b66, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:47:39,124 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 16:47:40,011 [DEBUG] app1.py:1214 - Speech recognizing: hi what are
2024-12-02 16:47:40,011 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=27f609f46ca14eeaafe437290ea328da, text="hi what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:47:40,013 [DEBUG] app1.py:1104 - Sending transcription: hi what are (is_final: False)
2024-12-02 16:47:40,417 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 16:47:40,418 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=210e56c6c60744099999b629119d29bf, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:47:40,419 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 16:47:42,036 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 16:47:42,037 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=17cf25186c40461a9512a2a9b42b8855, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:47:42,038 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 16:47:50,155 [DEBUG] app1.py:1214 - Speech recognizing: download
2024-12-02 16:47:50,155 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b63cc97da9a443f9a7953e0bbe356fb1, text="download", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:47:50,156 [DEBUG] app1.py:1104 - Sending transcription: download (is_final: False)
2024-12-02 16:47:51,350 [DEBUG] app1.py:1214 - Speech recognizing: download hi
2024-12-02 16:47:51,351 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=af30003e983643f2876410c29528d50a, text="download hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:47:51,354 [DEBUG] app1.py:1104 - Sending transcription: download hi (is_final: False)
2024-12-02 16:47:51,366 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:47:51,367 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9333d3fce39245be9f924aacb1cb5ce3, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:47:51,368 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 16:47:52,232 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 16:47:52,361 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 16:48:02,654 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:48:32,656 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:49:02,657 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:49:32,659 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:50:02,671 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:50:32,676 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:51:02,677 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:51:32,678 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:52:02,680 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:52:32,682 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:53:02,684 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:53:32,690 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:54:02,691 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:54:32,692 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:55:02,695 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:55:32,698 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:56:02,699 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:56:32,700 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:57:00,972 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 16:57:01,121 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 16:57:01,211 [INFO] app1.py:1240 - Audio stream started
2024-12-02 16:57:02,701 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:57:03,187 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:57:03,189 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=807be1fc82064872a731789290807681, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:03,665 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 16:57:03,665 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=32af9b3bd512438a9f37cdbbb6d12e27, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:57:15,303 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:57:15,304 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=15078ea945c04485b7bd26809ae1f7fb, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:16,801 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:57:16,801 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ec3d8a22b38c41ea8418d9590b6d11a7, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:57:19,075 [DEBUG] app1.py:1214 - Speech recognizing: i
2024-12-02 16:57:19,076 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a629badab401452cb48c628eba8b0b32, text="i", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:19,481 [DEBUG] app1.py:1214 - Speech recognizing: i'm going to speak
2024-12-02 16:57:19,483 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=10f3b0e06d3b457d8cd2be642d2ad7b7, text="i'm going to speak", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:20,090 [DEBUG] app1.py:1214 - Speech recognizing: i'm going to speak to
2024-12-02 16:57:20,090 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2887144b3f1244ee8d95996bc65d5d29, text="i'm going to speak to", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:21,373 [DEBUG] app1.py:1214 - Speech recognizing: i'm going to speak to meri dekha
2024-12-02 16:57:21,373 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=df2ca64046054204a7fef853939dc374, text="i'm going to speak to meri dekha", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:22,710 [INFO] app1.py:1205 - Speech recognized: I'm going to speak to Meri Dekha.
2024-12-02 16:57:22,711 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9ad38276204445ed80c7efdd5ad8f7cf, text="I'm going to speak to Meri Dekha.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:57:32,702 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:57:43,108 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:57:43,109 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=12b110e2cc4d47749cac2c7555dcf61f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:57:48,787 [DEBUG] app1.py:1214 - Speech recognizing: i love
2024-12-02 16:57:48,788 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b4326035408d4f5f93d86adc8d30be1d, text="i love", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:49,189 [DEBUG] app1.py:1214 - Speech recognizing: i love this is my
2024-12-02 16:57:49,189 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=303be7d1f90549b68b994d3052423a2f, text="i love this is my", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:49,487 [DEBUG] app1.py:1214 - Speech recognizing: i love this is my best
2024-12-02 16:57:49,488 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=09613c77a6f341e69f5f3edfd3c8a9ee, text="i love this is my best", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:49,689 [DEBUG] app1.py:1214 - Speech recognizing: i love this is my interesting
2024-12-02 16:57:49,691 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=71ea3f0cba1c4bb1a1e0693357458b1d, text="i love this is my interesting", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:49,984 [DEBUG] app1.py:1214 - Speech recognizing: i love this is my interesting but
2024-12-02 16:57:49,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=832e5cb5491e4faa83de48f0348a1515, text="i love this is my interesting but", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:50,090 [DEBUG] app1.py:1214 - Speech recognizing: i love this is my best input are you doing
2024-12-02 16:57:50,091 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ab2283d66b04342a88b4ac3232a0547, text="i love this is my best input are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:50,484 [DEBUG] app1.py:1214 - Speech recognizing: i love this is my interesting but i really don't know
2024-12-02 16:57:50,485 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bd1f0840bf96490caf470f3d6693b54b, text="i love this is my interesting but i really don't know", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:50,814 [INFO] app1.py:1205 - Speech recognized: I love this is my interesting but I really don't know.
2024-12-02 16:57:50,825 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=84dac8cccb4f49a5b5e4baf2293080c4, text="I love this is my interesting but I really don't know.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:57:56,579 [DEBUG] app1.py:1214 - Speech recognizing: this is spanish language
2024-12-02 16:57:56,579 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=688a7414dab84976ae5b89cc111fb33c, text="this is spanish language", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:57,879 [DEBUG] app1.py:1214 - Speech recognizing: this is spanish language who is
2024-12-02 16:57:57,880 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=feada35bda3542cca5f85fe677a1bc79, text="this is spanish language who is", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:58,491 [DEBUG] app1.py:1214 - Speech recognizing: this is spanish language who is this
2024-12-02 16:57:58,495 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0f56249b727e41e3bb4189c35acf4ba2, text="this is spanish language who is this", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:57:58,611 [INFO] app1.py:1205 - Speech recognized: This is Spanish language. Who is this?
2024-12-02 16:57:58,612 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=67770c13cc704f1e9b23bdcb1a47c5ce, text="This is Spanish language. Who is this?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:58:02,704 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:58:04,685 [DEBUG] app1.py:1214 - Speech recognizing: can you
2024-12-02 16:58:04,685 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fa039ea192a441ec80125a1729e35adb, text="can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:04,996 [DEBUG] app1.py:1214 - Speech recognizing: can you hear
2024-12-02 16:58:04,996 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d28821f844cc4d98b553f99ba066a767, text="can you hear", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:05,587 [DEBUG] app1.py:1214 - Speech recognizing: can you hear my voice
2024-12-02 16:58:05,588 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8c378eea29484a70b9dd77fd4ba06579, text="can you hear my voice", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:05,911 [DEBUG] app1.py:1214 - Speech recognizing: can you hear my voice clearly
2024-12-02 16:58:05,912 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=218f09be3cd24d75915cf02cb9b81e52, text="can you hear my voice clearly", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:06,284 [DEBUG] app1.py:1214 - Speech recognizing: can you hear my voice clearly or
2024-12-02 16:58:06,284 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6c0b054be3a144f3b5ebc9f8fc184fb0, text="can you hear my voice clearly or", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:06,393 [DEBUG] app1.py:1214 - Speech recognizing: can you hear my voice clearly or not
2024-12-02 16:58:06,394 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cbdd43cc14dc4b1eabb30b09eec91bd8, text="can you hear my voice clearly or not", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:06,513 [INFO] app1.py:1205 - Speech recognized: Can you hear my voice clearly or not?
2024-12-02 16:58:06,515 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fdfd5dbfa0a04815bed84e2a2bf7cff8, text="Can you hear my voice clearly or not?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:58:16,684 [DEBUG] app1.py:1214 - Speech recognizing: OK can you
2024-12-02 16:58:16,686 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=13ea28d85bfc4fd2b3f1421dbfeae35c, text="OK can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:16,982 [DEBUG] app1.py:1214 - Speech recognizing: OK can you hear my voice
2024-12-02 16:58:16,983 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=09a800a8c5924ddaa4e4621159e7f0d2, text="OK can you hear my voice", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:18,058 [INFO] app1.py:1205 - Speech recognized: OK, can you hear my voice?
2024-12-02 16:58:18,059 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5319b14a3a66440c8a3c871b3288adc1, text="OK, can you hear my voice?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:58:20,292 [DEBUG] app1.py:1214 - Speech recognizing: niranjan lavi
2024-12-02 16:58:20,292 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=07c633a181a54eae8d1ba32003140d5d, text="niranjan lavi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:20,594 [DEBUG] app1.py:1214 - Speech recognizing: niranjan lavi jinnah
2024-12-02 16:58:20,606 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=54046efb4dfa4bb4a8d3a5edd8ae4a9b, text="niranjan lavi jinnah", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:20,887 [DEBUG] app1.py:1214 - Speech recognizing: niranjan lavi jinnah teresa
2024-12-02 16:58:20,887 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1ab9b6ecc741424ea3777750053473f2, text="niranjan lavi jinnah teresa", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:21,196 [DEBUG] app1.py:1214 - Speech recognizing: niranjan lavi jinnah teresa live
2024-12-02 16:58:21,197 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b777b670a5b14465850df0fe4b8c11da, text="niranjan lavi jinnah teresa live", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:21,901 [INFO] app1.py:1205 - Speech recognized: He runs Lavi Jinnah, Teresa Love.
2024-12-02 16:58:21,902 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=056746a2c9c344ccb6c704b9aa9e6add, text="He runs Lavi Jinnah, Teresa Love.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:58:29,776 [DEBUG] app1.py:1214 - Speech recognizing: hello can you
2024-12-02 16:58:29,777 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=76d11ff4c7b84aae887580f217c9f031, text="hello can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:30,181 [DEBUG] app1.py:1214 - Speech recognizing: hello can you hear my
2024-12-02 16:58:30,183 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=56c9c0166848427f920607a2565a9cc9, text="hello can you hear my", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:30,378 [DEBUG] app1.py:1214 - Speech recognizing: hello can you hear my voice
2024-12-02 16:58:30,379 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1e9bc087588049a4a131ff335d7dd767, text="hello can you hear my voice", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:30,705 [INFO] app1.py:1205 - Speech recognized: Hello, can you hear my voice?
2024-12-02 16:58:30,706 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eb0dc467aeeb4241bcc0e53b2d9c804e, text="Hello, can you hear my voice?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:58:32,705 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:58:36,785 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:58:36,785 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3128f2d572a8466ab619db11a47b7fe8, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:37,066 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:58:37,068 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e02e0765c5714648afe7f36f90fbb3b7, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:58:39,283 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 16:58:39,285 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e7432a46ff1a41ba9299d6dc9091dcd4, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:39,485 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 16:58:39,486 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=db544fd38c3348a4a93a0e13ac9d96a5, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:39,998 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 16:58:39,998 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ff1a6f8f5c624583b36fc693734da6e3, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:58:44,387 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:58:44,388 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a72f72d70abc4a1b93910c374383d542, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:44,883 [DEBUG] app1.py:1214 - Speech recognizing: hello can you
2024-12-02 16:58:44,901 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=15715956977e426bbdde9e21ff36939b, text="hello can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:46,279 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:58:46,281 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=43aaa69c16c648b399b08cd4b27ec0eb, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:46,481 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:58:46,482 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4e1c8515e3444535bd3b9041c3f7f9ad, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:58:47,124 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:58:47,124 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=30c8c5099d34434aaea8a9ce56e15039, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:02,707 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:59:05,506 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:59:05,507 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ed9649a07df8467aa53e3459d48afcc0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:11,498 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:59:11,498 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b70850197170471ca52f98630622fc52, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:12,013 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:59:12,013 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3bdb7516009e475ebb9095c56d11f678, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:30,588 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:59:30,589 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=059e2ab844e04a58a1b5ae7d5e9204e9, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:32,708 [INFO] app1.py:898 - Active clients: []
2024-12-02 16:59:47,042 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 16:59:47,044 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ef62aa2d5645488e845348b0a3281f65, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:50,373 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 16:59:50,373 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5fa624e3613c47f786206e5a70407e9d, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:50,374 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 16:59:50,374 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b077d299b610460eb98ca51411c94651, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:52,574 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 16:59:52,574 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7e0bb2ca762a47e5a37d0049b7139b90, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:53,181 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 16:59:53,182 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=63e140c4a74c483e9c1b0c81c1592bb3, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:54,584 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 16:59:54,585 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=130244a846554cc99be5003c9e9d14ff, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:54,881 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 16:59:54,882 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f6a38f081b114ff2ad658281a5dd41ab, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:55,487 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 16:59:55,488 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0fe7e4a8ced2476fb11f0f082efc39c8, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 16:59:56,875 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 16:59:56,875 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7c86106cd55040ef837d5b7f715300df, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:57,281 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 16:59:57,281 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cd6652e21e844d58a145f10c336690de, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:57,577 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 16:59:57,578 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5aa95a4f707e467c87c128bff41d1d56, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 16:59:58,402 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 16:59:58,403 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ff0eeb4149194325a334f1a3c4a823b4, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:00:02,710 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:00:14,582 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:00:14,583 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=526dee5d76a34f4e9e6735279b0910be, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:00:32,711 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:00:33,692 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:00:33,692 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9f1d0ac5fa854061a048ac78a7520b6c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:00:48,633 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:00:48,633 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=68f773b96e02423a993e52b0cafbdf0d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:00:58,013 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 17:00:58,014 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a9e7bcfae66c49309e673247080a3478, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:01:02,713 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:01:16,885 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:01:16,885 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fc578023165f4077897ac8a6852206c8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:01:32,715 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:01:33,033 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:01:33,033 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2d6d8eba4c5644649bfbc55147c9a945, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:01:48,292 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:01:48,293 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=71be9158e9e043e8a1ec60e73720c050, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:02:02,716 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:02:03,318 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:02:03,318 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=171dbb7f3f784ad2926781510e57cec3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:02:16,679 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:02:16,680 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6879e1268a974e0fb600f2bd1db89a38, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:02:17,021 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 17:02:17,022 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=01679d8b282b41e0825b7ed2614b1ce7, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:02:22,499 [DEBUG] app1.py:1214 - Speech recognizing: hello this is
2024-12-02 17:02:22,500 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=62a9fa673d9c4b4ca0c6d79d0753c6bf, text="hello this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:02:23,296 [INFO] app1.py:1205 - Speech recognized: Hello, this is Amit.
2024-12-02 17:02:23,297 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9d895a0581ad46bdb1643d51b35d2f22, text="Hello, this is Amit.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:02:29,094 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:02:29,095 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f6033dc5e8e540989576a0aa757cb92c, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:02:29,389 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 17:02:29,392 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e44d0ccc49764f4bb0f5ac22e1c90a42, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:02:29,685 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 17:02:29,686 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9801386d4d0a47589b1feeb650872206, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:02:29,792 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 17:02:29,793 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d5831954abd6414288feeabb57ec8abe, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:02:30,105 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 17:02:30,105 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e14b240f197f463f9c5c2d25ea3b8127, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:02:32,726 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:02:37,978 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 17:02:37,978 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=64052a3f254948debc08d0fb318e84ee, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:02:38,584 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 17:02:38,584 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=85db3367aaa5468a83305ea1e2cb85cf, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:02:59,001 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:02:59,001 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e449f40268494af6beff83bd97e67624, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:03:02,760 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:03:14,105 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:03:14,106 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=74951ac37ae54f2f9cde20a1e7790fbb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:03:29,171 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:03:29,172 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f3731022777040b1907e6225ca5d0322, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:03:32,762 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:03:44,271 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:03:44,272 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5230f553ad9b4349a894856f3b79a362, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:03:59,491 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:03:59,492 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=58b724bcc3ef4769a966eab77e40ef75, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:04:02,763 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:04:14,684 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:04:14,685 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c005e4d34eba47989c2c6df2011b6e59, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:04:29,997 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:04:29,998 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dec749cf498d438aa34aa9a416d0dbbf, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:04:32,764 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:04:44,945 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:04:44,945 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2fc5051ad7d7461ba9c36cd0b313320f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:04:59,966 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:04:59,967 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2c4f24f094f4466cb4cd001cc65b0909, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:05:02,766 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:05:15,180 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:05:15,181 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa099da6f6c0401bab2931375a1523f8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:05:30,608 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:05:30,609 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=73a8463a544f447eadfb8b05e6f15717, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:05:32,767 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:05:45,679 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:05:45,679 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5c00c76c298c448882ebf2ae27cf4d26, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:05:54,873 [DEBUG] app1.py:1214 - Speech recognizing: open
2024-12-02 17:05:54,874 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=90ac89de5bbb482a8b8b40bc17364146, text="open", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:00,793 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:06:00,794 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=953b63c4084a4f4b8cbb161b449c619b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:06:02,768 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:06:15,738 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:06:15,738 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ff8e67ffcae84dc3ae741682a18ce520, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:06:30,739 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:06:30,740 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=956ab40e6e2b4c11aad9e2245a0d5ec7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:06:32,769 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:06:43,505 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 17:06:43,506 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7059cad513c14615b527bb8451e7e861, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:06:47,883 [DEBUG] app1.py:1214 - Speech recognizing: hello hello
2024-12-02 17:06:47,884 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fb66d3279c4c44d8a5774a5dc913fa77, text="hello hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:48,085 [DEBUG] app1.py:1214 - Speech recognizing: hello hello can
2024-12-02 17:06:48,085 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1734a60e02354ed3b1f2162b68ab3d4e, text="hello hello can", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:48,179 [DEBUG] app1.py:1214 - Speech recognizing: hello hello can you hear
2024-12-02 17:06:48,179 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8ef1b23cde8a4575bc110b7333a6f8c8, text="hello hello can you hear", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:48,398 [DEBUG] app1.py:1214 - Speech recognizing: hello hello can you hear my voice
2024-12-02 17:06:48,400 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b1dc5bac9f1a46e2972d80387561cab9, text="hello hello can you hear my voice", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:49,303 [INFO] app1.py:1205 - Speech recognized: Hello. Hello. Can you hear my voice?
2024-12-02 17:06:49,303 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e8b84329b6584bc79b44dde7b0d2a4fb, text="Hello. Hello. Can you hear my voice?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:06:55,008 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 17:06:55,008 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ea5d32d3e15d4dd69f227e1c8f286e62, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:55,280 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you
2024-12-02 17:06:55,284 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=28e5d03b0263430981bd14174caaa20e, text="hello what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:55,389 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 17:06:55,391 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=01b4a865a16b44da80828941b1fb8942, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:06:56,181 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 17:06:56,184 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a05f6be022de440ba7f9d98bb37e6687, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:07:02,771 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:07:04,583 [DEBUG] app1.py:1214 - Speech recognizing: no this is
2024-12-02 17:07:04,584 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8a09549000ea486e861d9b31390d5410, text="no this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:06,890 [DEBUG] app1.py:1214 - Speech recognizing: hello this is amanda i can't hear
2024-12-02 17:07:06,891 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c8ad0663e55649cc8d8c4b2d5828438d, text="hello this is amanda i can't hear", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:07,180 [DEBUG] app1.py:1214 - Speech recognizing: hello this is amanda i can't hear my
2024-12-02 17:07:07,181 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ddc2e5e344444e118bf33b1ec2aa53c2, text="hello this is amanda i can't hear my", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:07,584 [DEBUG] app1.py:1214 - Speech recognizing: hello this is amanda i can't hear my voice
2024-12-02 17:07:07,585 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f2cbe9a108a24e0e8fe9e91ef16b8cba, text="hello this is amanda i can't hear my voice", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:10,881 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:07:10,881 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bb0e23b54be8411894e5c088e317980c, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:10,976 [DEBUG] app1.py:1214 - Speech recognizing: hello this is
2024-12-02 17:07:10,977 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=47048e5d2c814575ba46b923fa76d1fc, text="hello this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:11,588 [DEBUG] app1.py:1214 - Speech recognizing: hello this is an
2024-12-02 17:07:11,591 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b25ee2c4e70c459db8dac96270484e61, text="hello this is an", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:11,676 [DEBUG] app1.py:1214 - Speech recognizing: hello this is anand
2024-12-02 17:07:11,677 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8a24192322864678a902e8eef19f3ff5, text="hello this is anand", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:07:12,282 [INFO] app1.py:1205 - Speech recognized: Hello, this is Anand.
2024-12-02 17:07:12,285 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0a86f2e6334a48e896d31de481aa36f6, text="Hello, this is Anand.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:07:32,491 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:07:32,491 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c483dcef18124fb3981145b9e1e0e412, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:07:32,772 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:07:42,280 [INFO] app1.py:1205 - Speech recognized: The.
2024-12-02 17:07:42,280 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=58b94d1504914cccb2e55d834f77f6a4, text="The.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:08:02,490 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:08:02,490 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=be7a7ccb4599489087d280f52c7b7d48, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:08:02,772 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:08:17,437 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:08:17,438 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e7b5ddf8a93147f6a2974326ee7b9b78, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:08:32,572 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:08:32,573 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b34ffe8ded494db18a3adc97bf03a240, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:08:32,773 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:08:47,545 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:08:47,545 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fb607815b71e4c268da83883e58cd4b7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:08:51,962 [DEBUG] app1.py:1214 - Speech recognizing: hi what
2024-12-02 17:08:51,963 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6b761eef2881452bbc63bd0f79af7f84, text="hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:08:52,165 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 17:08:52,165 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=01fa75b8915549f8bff8901805060441, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:08:52,788 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 17:08:52,788 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f45fabcc762f46e4a23153df1f8d7c83, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:09:02,775 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:09:12,979 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:09:12,979 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=81d5681a35a947e49a6741b346860267, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:09:28,271 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:09:28,272 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bcb68298a9244c6e89e41e9a81cad19b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:09:32,776 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:09:43,502 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:09:43,502 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=83c7f1b25ac94360aefacd4edbefdb5f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:09:58,675 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:09:58,676 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=801c46df0382464b86aca335a10ace47, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:10:02,777 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:10:11,289 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:10:11,290 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fe4fe8850e3d4a0887a660ec2ad54a43, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:10:11,505 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 17:10:11,505 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6cc981f2ca184174a1b56049d4743ed1, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:10:12,908 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:10:12,909 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=083cc626441348cab799de9d942937ff, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:10:14,012 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:10:14,012 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6631f27050c9486e8aee85fb32f9b929, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:10:14,900 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:10:14,901 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5b8a3b6fa3fe4d85ab7cd511d13cc456, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:10:16,984 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:10:16,985 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=47857929c4cf45429b9131aca494baab, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:10:17,484 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:10:17,485 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=87987a582d934f1b815516f6c934cc39, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:10:19,283 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 17:10:19,283 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e10be8f795544f6e8be289702e9ec72d, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:10:32,779 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:10:39,385 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:10:39,390 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9e8088081f2947d880f742c51f402af3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:10:54,623 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:10:54,624 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0f257b561c1347f5b67cb0a733200358, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:11:02,780 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:11:09,692 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:11:09,693 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf391cca64984d03a3e8da2ed1a15d07, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:11:24,791 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:11:24,792 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9b6faf4ab52545f5a02eff8cdd34c4db, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:11:32,801 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:11:39,739 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:11:39,740 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1d062c9bc9b6434292b0c8ab5aa3c2c1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:11:54,785 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:11:54,786 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2af8a040cdf547cf88d183b34771fb32, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:11:58,188 [DEBUG] app1.py:1214 - Speech recognizing: yes sir
2024-12-02 17:11:58,188 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=978bc627886b4ed496e9b2087d1107ea, text="yes sir", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:12:02,802 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:12:09,739 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:12:09,740 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c7471adc9d614fdea85e4ebd6eaec01b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:12:24,758 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:12:24,759 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=802c9fd1b7a64aa38b615c25d65bf19e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:12:32,804 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:12:39,883 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:12:39,885 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=df4b305a634346d788ed89088da8da18, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:12:54,981 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:12:54,982 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e99497e43e474ab58dbf883a7583010d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:13:02,805 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:13:09,934 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:13:09,934 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a3a2ec3dff944689a4c2f3a228223b6b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:13:25,103 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:13:25,104 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f26eb185c528487187fe090ab67afe88, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:13:32,807 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:13:40,091 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:13:40,092 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4004b5a0949743bf91e2f9ba993b23ba, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:13:55,082 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:13:55,083 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9f8c97099808431888587343d4c954a6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:14:02,809 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:14:10,036 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:14:10,037 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4281a7bc87b1455cbe5557739cf79942, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:14:25,285 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:14:25,286 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=421dc83646c545d380ba1eacddb6bb46, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:14:32,811 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:14:40,238 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:14:40,239 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e09a7a85a66a47dbbb04f27e86860198, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:14:55,368 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:14:55,368 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=60017e15817c40b59283875d5009be05, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:15:02,812 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:15:10,620 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:15:10,621 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=17b2a3a500cd473a83ae2a50917135b3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:15:25,776 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:15:25,776 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cc175a32e14e41bb8ad580c24ec461ad, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:15:32,813 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:15:41,104 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:15:41,105 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7def514dba6b4993b5ff1d390c3a4f14, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:15:56,168 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:15:56,169 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d2d3436b536e4172ab553ef92bc494aa, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:16:02,814 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:16:11,309 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:16:11,310 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d7a1807ca8344825a4314dc982089720, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:16:22,259 [DEBUG] app1.py:1214 - Speech recognizing: kar
2024-12-02 17:16:22,261 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b937162be1f547f7bf6c8962969dfcb4, text="kar", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:22,553 [DEBUG] app1.py:1214 - Speech recognizing: karumudi
2024-12-02 17:16:22,554 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6a184b5f72e94100ad426c7d6879b21a, text="karumudi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:23,162 [DEBUG] app1.py:1214 - Speech recognizing: karumudiyama
2024-12-02 17:16:23,163 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ba8151413db94466945e7edcd5cc5ae5, text="karumudiyama", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:23,550 [DEBUG] app1.py:1214 - Speech recognizing: karumudiyamana
2024-12-02 17:16:23,551 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc022769088c4fea85f0c903f0429cc4, text="karumudiyamana", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:24,155 [DEBUG] app1.py:1214 - Speech recognizing: karumudiyamana chandigarh
2024-12-02 17:16:24,156 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7996c44a9f1846dbbe3367fe1cdfae65, text="karumudiyamana chandigarh", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:25,061 [DEBUG] app1.py:1214 - Speech recognizing: karumudiyamana chandigarh kannur
2024-12-02 17:16:25,064 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4243c91aefbc4bb18774fb44bda7c514, text="karumudiyamana chandigarh kannur", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:26,906 [INFO] app1.py:1205 - Speech recognized: Karumudiyama, Chandigarh.
2024-12-02 17:16:26,907 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3aa71a6d00674261ad15ca85a95a9492, text="Karumudiyama, Chandigarh.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:16:32,835 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:16:39,467 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:16:39,468 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=48ea8b0d622e4aa49e8c37503c06405d, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:39,690 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 17:16:39,691 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=743ff7b77e054ad2b7847789896dfbd3, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:16:41,468 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:16:41,469 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=24ee013f1a4547a18e803d6e5b2ba26e, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:41,984 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:16:41,984 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=77a361951b52421d82a86e5e66b5a62c, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:16:51,382 [DEBUG] app1.py:1214 - Speech recognizing: in december
2024-12-02 17:16:51,383 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b69502479b3e4df4ad08e51b2c46eec6, text="in december", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:57,508 [DEBUG] app1.py:1214 - Speech recognizing: criminal
2024-12-02 17:16:57,511 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c2dd4327197b4455aee1d1af1ca3cb5d, text="criminal", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:57,873 [DEBUG] app1.py:1214 - Speech recognizing: criminal module
2024-12-02 17:16:57,873 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=022de0b65998459c9c91544348deafac, text="criminal module", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:16:59,797 [INFO] app1.py:1205 - Speech recognized: Criminal Module.
2024-12-02 17:16:59,797 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dbb79424ec024f19bf63b878bbf13e8f, text="Criminal Module.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:17:02,837 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:17:03,364 [DEBUG] app1.py:1214 - Speech recognizing: PG
2024-12-02 17:17:03,365 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fbf87b0044d14c64816303921887f475, text="PG", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:17:05,067 [DEBUG] app1.py:1214 - Speech recognizing: PG PC
2024-12-02 17:17:05,068 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dcf79678e13f45d99fe30c39ec4528d6, text="PG PC", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:17:05,869 [DEBUG] app1.py:1214 - Speech recognizing: PG PC PC
2024-12-02 17:17:05,879 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e23dc93be0764a5aa7281e6cda50452e, text="PG PC PC", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:17:06,179 [INFO] app1.py:1205 - Speech recognized: PG PC. PC.
2024-12-02 17:17:06,180 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fe89c93d778e48a1bfb8c725de87c70c, text="PG PC. PC.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:17:26,292 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:17:26,292 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a69c7d80e1784139b590350f43296ce7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:17:32,838 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:17:41,487 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:17:41,488 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7ff802e2f4854fd1a6f0fb7b5355cc08, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:17:56,563 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:17:56,563 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bfe996843e4d429fa16ff1fda4bf6829, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:18:02,839 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:18:11,535 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:18:11,535 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=00aa8a981c3f47e9b3e9b81bba061e8b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:18:21,633 [INFO] app1.py:1205 - Speech recognized: OK.
2024-12-02 17:18:21,634 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=61b4adebbc874c24891bb04b0165d948, text="OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:18:32,841 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:18:39,664 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:18:39,665 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ac7b91f3eadb4640bc186cfc1d60d84c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:18:57,065 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:18:57,065 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6fcfc666178948829dfc997887c7455d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:19:02,842 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:19:12,415 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:19:12,415 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=74dfd7c6d03647d69eed4fec4428acde, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:19:27,336 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:19:27,337 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=035ab477f82647229eb410c147f3682a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:19:32,844 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:19:42,411 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:19:42,614 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ee3567da54a142d98a8726c58335bc58, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:19:57,487 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:19:57,488 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2f4473ab9e10494ab39db6cbf2c798ae, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:20:02,845 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:20:12,490 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:20:12,491 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=03c9fa0227c349eeafcb180e0a521bc5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:20:14,307 [DEBUG] app1.py:1214 - Speech recognizing: he a
2024-12-02 17:20:14,307 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2bde07e99fba4d6f9a0f93541ff4b1ca, text="he a", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:14,600 [DEBUG] app1.py:1214 - Speech recognizing: he a cassandra
2024-12-02 17:20:14,600 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b75d4c1553214f668d719ef7c6d65ea7, text="he a cassandra", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:15,316 [DEBUG] app1.py:1214 - Speech recognizing: he a cassandra P
2024-12-02 17:20:15,316 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=767a514e22fa4a8dbe8fde1f78db4762, text="he a cassandra P", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:15,611 [DEBUG] app1.py:1214 - Speech recognizing: he a cassandra P the internal
2024-12-02 17:20:15,613 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=08ccf2545c6142bab949754b0c11b567, text="he a cassandra P the internal", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:16,687 [INFO] app1.py:1205 - Speech recognized: He A Cassandra P. The internal P.
2024-12-02 17:20:16,688 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eb256d46423641e887320490eadaf06d, text="He A Cassandra P. The internal P.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:20:21,885 [DEBUG] app1.py:1214 - Speech recognizing: C
2024-12-02 17:20:21,887 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6f9db2bed00c4c2aaeb273d2b133cbfd, text="C", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:22,370 [DEBUG] app1.py:1214 - Speech recognizing: CGC
2024-12-02 17:20:22,370 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d495f5fabe940ea83f6726df763eb13, text="CGC", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:24,049 [INFO] app1.py:1205 - Speech recognized: CGC.
2024-12-02 17:20:24,050 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4b5d03089b20489d8de8a0a6287a50f4, text="CGC.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:20:32,059 [DEBUG] app1.py:1214 - Speech recognizing: 's
2024-12-02 17:20:32,059 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f9db783d6f6049a3a98fc7557c427175, text="'s", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:32,846 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:20:33,975 [INFO] app1.py:1205 - Speech recognized: 'S.
2024-12-02 17:20:33,977 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4fae02ece3ce4b49bb265c817ca7ce78, text="'S.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:20:44,679 [DEBUG] app1.py:1214 - Speech recognizing: is due to
2024-12-02 17:20:44,679 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=09962e69184a47f3a941832cd2ab8ce7, text="is due to", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:44,773 [DEBUG] app1.py:1214 - Speech recognizing: is due to google
2024-12-02 17:20:44,773 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b45d0a12761740fb91cd529638cf317b, text="is due to google", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:45,179 [DEBUG] app1.py:1214 - Speech recognizing: is due to google earth
2024-12-02 17:20:45,180 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3223baf1e83b42cebfe61dd084ceb427, text="is due to google earth", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:45,478 [DEBUG] app1.py:1214 - Speech recognizing: is due to google earth in
2024-12-02 17:20:45,478 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=19170307f8154518934a2d349d4f8492, text="is due to google earth in", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:46,586 [DEBUG] app1.py:1214 - Speech recognizing: is due to google earth
2024-12-02 17:20:46,587 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b3ed7957d74b41918738c4aa1d0f1641, text="is due to google earth", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:47,985 [DEBUG] app1.py:1214 - Speech recognizing: is due to google earth in three
2024-12-02 17:20:47,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4cccb265bbd346b6b926d58361eafddb, text="is due to google earth in three", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:48,485 [DEBUG] app1.py:1214 - Speech recognizing: is due to google earth in 3D
2024-12-02 17:20:48,486 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0759fd1c8dd9433cbac66cec9451deb3, text="is due to google earth in 3D", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:20:49,157 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:20:49,158 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2f3c03ec3b2342fa8683847922d5a86c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:21:02,847 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:21:09,088 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:21:09,088 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=40586d36a6f54c1fa45a6ec1073c6bd4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:21:24,173 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:21:24,174 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0c34575fde0841b7bc0bb6441aa2df5b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:21:32,849 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:21:39,387 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:21:39,387 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1aeef320d3da4237b327215c95b9b46e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:21:47,489 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 17:21:47,493 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ab0c52deb05e4ebd88113a12ff8dc15a, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:22:02,850 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:22:07,667 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:22:07,668 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c07fcaebc204428c8d1816c1437a1112, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:22:15,810 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 17:22:15,811 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3bf0f57587d8486cad3b5289dcbdce67, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:22:32,853 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:22:35,847 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:22:35,848 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cab1fd10b4f645ed80ee73c02e686e61, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:22:50,818 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:22:50,819 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a769036ce6dd4fc986c8dc2d93abaf5d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:23:02,856 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:23:05,830 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:23:05,830 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=856704bdc6a44ab9b8981af2b5c54dff, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:23:20,855 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:23:20,855 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7c6ff67305434edb9fe8a6936a35408b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:23:32,782 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 17:23:32,783 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1ed10af4190144d49d8c6d179e57498d, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:23:32,857 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:23:53,172 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:23:53,173 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aaa49ddad1ae40719551ceba1ad1f015, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:24:02,858 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:24:08,477 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:24:08,478 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=762afbb965e0405fa2dc29bf8157321b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:24:23,600 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:24:23,600 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f729b0e7667c44e6a21189cecb711c75, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:24:32,859 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:24:38,864 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:24:38,864 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d984b99687a345688f3c8466987a1d2b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:24:44,674 [DEBUG] app1.py:1214 - Speech recognizing: can you
2024-12-02 17:24:44,675 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3ff6853752db4cd9accea68a6d8f85d6, text="can you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:24:44,799 [DEBUG] app1.py:1214 - Speech recognizing: can you play
2024-12-02 17:24:44,800 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0262ff7de78f4fd8a2e59f21f0230c5b, text="can you play", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:24:45,766 [DEBUG] app1.py:1214 - Speech recognizing: can you play this is a
2024-12-02 17:24:45,767 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=14838479d4bc4411bee8ff81788a4531, text="can you play this is a", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:24:45,810 [INFO] app1.py:1205 - Speech recognized: Can you show me?
2024-12-02 17:24:45,813 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2c09c13786f54850ab8bf6ba03b5186d, text="Can you show me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:25:02,860 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:25:03,261 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:25:03,281 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ffff43f809b74803bcef109a38c5805e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:25:20,816 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:25:20,817 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d2d290b93d0a457a8a55e6e2ba23a450, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:25:32,862 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:25:36,093 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:25:36,094 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7416411e1a8b4f02bd7612b2b32242f6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:25:51,134 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:25:51,135 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8d224059daae423e86c7ac3da680caa1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:26:02,863 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:26:06,288 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:26:06,289 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b1a1083d59e04e43966e0b99711dbab6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:26:17,572 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 17:26:17,572 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b9ab9d6506e44f2fa5a72b0f8db7cb20, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:26:29,577 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 17:26:29,577 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b1dbb8d6f3ee4ca48951f54e65238c62, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:26:32,867 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:26:49,643 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:26:49,643 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b8b7615e77b047c4b7919b1d589054b6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:27:02,869 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:27:04,632 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:27:04,633 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d3eae78ce1f64310bb567b34869f59a9, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:27:19,963 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:27:19,964 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d89673981fec4bcebb44e252071d8262, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:27:32,870 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:27:34,930 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:27:34,931 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5c8635fe29f84f4d92b74a1934d034de, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:27:49,934 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:27:49,935 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3418d0b212a941baa7e797a9957e89b5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:27:52,469 [DEBUG] app1.py:1214 - Speech recognizing: shah rukh khan
2024-12-02 17:27:52,470 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3a13c65a2823435eb66d54616fefebc8, text="shah rukh khan", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:27:53,492 [INFO] app1.py:1205 - Speech recognized: Shah Rukh Khan.
2024-12-02 17:27:53,493 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6f852c99ef574ce7ab039a2b53067aae, text="Shah Rukh Khan.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:28:02,872 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:28:07,674 [DEBUG] app1.py:1214 - Speech recognizing: can hear
2024-12-02 17:28:07,674 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=53405dd379f741aeb58c43988a154bcf, text="can hear", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:28:08,079 [DEBUG] app1.py:1214 - Speech recognizing: can you hear me
2024-12-02 17:28:08,080 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4ba8531ca8934effb9e52d4fb6d22124, text="can you hear me", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:28:09,891 [INFO] app1.py:1205 - Speech recognized: Can you hear me?
2024-12-02 17:28:09,892 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=409e46031b1d43dbb2a39bffb7ba009b, text="Can you hear me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:28:14,087 [DEBUG] app1.py:1214 - Speech recognizing: sandwich
2024-12-02 17:28:14,088 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c95cb8babbf742e0af23c23a87fa7cf0, text="sandwich", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:28:14,495 [DEBUG] app1.py:1214 - Speech recognizing: it's supposed to be sandwich
2024-12-02 17:28:14,496 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9b363d3b4eac48dd9671e3561db1d6a0, text="it's supposed to be sandwich", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:28:14,679 [DEBUG] app1.py:1214 - Speech recognizing: it's supposed to be sandwiched
2024-12-02 17:28:14,683 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7c715189a0004fc2943e49cc0b9f7f13, text="it's supposed to be sandwiched", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:28:15,066 [INFO] app1.py:1205 - Speech recognized: It's supposed to be sandwiched in.
2024-12-02 17:28:15,068 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3f6a7d217869426e9aa92308f6b86b6e, text="It's supposed to be sandwiched in.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:28:32,318 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:28:32,319 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4944847dd04042678a758c38a8e92d08, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:28:32,873 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:28:50,188 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:28:50,189 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5522f2029ef04214968eb261c3cec3ef, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:29:02,876 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:29:05,407 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:29:05,408 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eaa72a12ee484581af7d40bf6d8b4010, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:29:19,174 [DEBUG] app1.py:1214 - Speech recognizing: ask
2024-12-02 17:29:19,174 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9b414bf004c4d0a86626603447d1c75, text="ask", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:29:19,469 [DEBUG] app1.py:1214 - Speech recognizing: i was coming
2024-12-02 17:29:19,470 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5a3a994bc7134eb4b0a1cd4be722dabc, text="i was coming", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:29:19,576 [DEBUG] app1.py:1214 - Speech recognizing: i was coming to
2024-12-02 17:29:19,577 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d7bcb5e847c541ec97cf3282f59699a8, text="i was coming to", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:29:19,670 [DEBUG] app1.py:1214 - Speech recognizing: i was coming to check
2024-12-02 17:29:19,670 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1b9c5ef3540e4ff8895895ababb64800, text="i was coming to check", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:29:20,077 [DEBUG] app1.py:1214 - Speech recognizing: was coming to jacuzzi
2024-12-02 17:29:20,077 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f0a037ccd87c4cfaafbbb7122ad68b94, text="was coming to jacuzzi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:29:22,082 [DEBUG] app1.py:1214 - Speech recognizing: was coming to jacuzzi aj
2024-12-02 17:29:22,083 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5dd271a8e7914cdaad7b17a202ac8b94, text="was coming to jacuzzi aj", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:29:22,281 [DEBUG] app1.py:1214 - Speech recognizing: was coming to jacuzzi ajagaoni
2024-12-02 17:29:22,281 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0177082a8ba943708bc669add3aa966f, text="was coming to jacuzzi ajagaoni", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:29:24,133 [INFO] app1.py:1205 - Speech recognized: Was coming to Jacuzzi Ajagaoni Ave.
2024-12-02 17:29:24,133 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=46e86130b85442bcbc70b32046fbcb81, text="Was coming to Jacuzzi Ajagaoni Ave.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:29:32,877 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:29:44,387 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:29:44,388 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=92a1047c3e974d1eb22ed84052c0cb12, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:29:59,332 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:29:59,332 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e12c4d06929343c29b4ce6e6dde0fc7f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:30:02,879 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:30:14,326 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:30:14,332 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=96790c4399f74ebc94344201d91ee821, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:30:29,333 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:30:29,335 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9857ba973bfa4778ae9b35aafca76cdb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:30:32,880 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:30:44,443 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:30:44,445 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cb19a8362a804838a7713fe3ab3ae8af, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:30:59,433 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:30:59,433 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5230192f531c4b1681c571b6d437ad75, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:31:01,249 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:31:01,249 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7d4c3b85ed4641769b94be1a4acfbe39, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:31:01,780 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:31:01,780 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c269ac8ef62f4ae48312d2edcbc56424, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:31:01,867 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:31:01,870 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:31:01,873 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:01,875 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:31:01,875 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:01,877 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:01,878 [DEBUG] app1.py:1104 - Sending transcription: i (is_final: False)
2024-12-02 17:31:01,878 [DEBUG] app1.py:1104 - Sending transcription: i'm going to speak (is_final: False)
2024-12-02 17:31:01,878 [DEBUG] app1.py:1104 - Sending transcription: i'm going to speak to (is_final: False)
2024-12-02 17:31:01,879 [DEBUG] app1.py:1104 - Sending transcription: i'm going to speak to meri dekha (is_final: False)
2024-12-02 17:31:01,881 [DEBUG] app1.py:1104 - Sending transcription: I'm going to speak to Meri Dekha. (is_final: True)
2024-12-02 17:31:01,882 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:01,892 [DEBUG] app1.py:1104 - Sending transcription: i love (is_final: False)
2024-12-02 17:31:01,894 [DEBUG] app1.py:1104 - Sending transcription: i love this is my (is_final: False)
2024-12-02 17:31:01,894 [DEBUG] app1.py:1104 - Sending transcription: i love this is my best (is_final: False)
2024-12-02 17:31:01,895 [DEBUG] app1.py:1104 - Sending transcription: i love this is my interesting (is_final: False)
2024-12-02 17:31:01,897 [DEBUG] app1.py:1104 - Sending transcription: i love this is my interesting but (is_final: False)
2024-12-02 17:31:01,897 [DEBUG] app1.py:1104 - Sending transcription: i love this is my best input are you doing (is_final: False)
2024-12-02 17:31:01,898 [DEBUG] app1.py:1104 - Sending transcription: i love this is my interesting but i really don't know (is_final: False)
2024-12-02 17:31:01,906 [DEBUG] app1.py:1104 - Sending transcription: I love this is my interesting but I really don't know. (is_final: True)
2024-12-02 17:31:01,910 [DEBUG] app1.py:1104 - Sending transcription: this is spanish language (is_final: False)
2024-12-02 17:31:01,912 [DEBUG] app1.py:1104 - Sending transcription: this is spanish language who is (is_final: False)
2024-12-02 17:31:01,912 [DEBUG] app1.py:1104 - Sending transcription: this is spanish language who is this (is_final: False)
2024-12-02 17:31:01,913 [DEBUG] app1.py:1104 - Sending transcription: This is Spanish language. Who is this? (is_final: True)
2024-12-02 17:31:01,913 [DEBUG] app1.py:1104 - Sending transcription: can you (is_final: False)
2024-12-02 17:31:01,914 [DEBUG] app1.py:1104 - Sending transcription: can you hear (is_final: False)
2024-12-02 17:31:01,943 [DEBUG] app1.py:1104 - Sending transcription: can you hear my voice (is_final: False)
2024-12-02 17:31:01,946 [DEBUG] app1.py:1104 - Sending transcription: can you hear my voice clearly (is_final: False)
2024-12-02 17:31:01,956 [DEBUG] app1.py:1104 - Sending transcription: can you hear my voice clearly or (is_final: False)
2024-12-02 17:31:01,958 [DEBUG] app1.py:1104 - Sending transcription: can you hear my voice clearly or not (is_final: False)
2024-12-02 17:31:01,959 [DEBUG] app1.py:1104 - Sending transcription: Can you hear my voice clearly or not? (is_final: True)
2024-12-02 17:31:01,960 [DEBUG] app1.py:1104 - Sending transcription: OK can you (is_final: False)
2024-12-02 17:31:01,962 [DEBUG] app1.py:1104 - Sending transcription: OK can you hear my voice (is_final: False)
2024-12-02 17:31:01,963 [DEBUG] app1.py:1104 - Sending transcription: OK, can you hear my voice? (is_final: True)
2024-12-02 17:31:01,968 [DEBUG] app1.py:1104 - Sending transcription: niranjan lavi (is_final: False)
2024-12-02 17:31:01,973 [DEBUG] app1.py:1104 - Sending transcription: niranjan lavi jinnah (is_final: False)
2024-12-02 17:31:01,974 [DEBUG] app1.py:1104 - Sending transcription: niranjan lavi jinnah teresa (is_final: False)
2024-12-02 17:31:01,976 [DEBUG] app1.py:1104 - Sending transcription: niranjan lavi jinnah teresa live (is_final: False)
2024-12-02 17:31:01,977 [DEBUG] app1.py:1104 - Sending transcription: He runs Lavi Jinnah, Teresa Love. (is_final: True)
2024-12-02 17:31:01,977 [DEBUG] app1.py:1104 - Sending transcription: hello can you (is_final: False)
2024-12-02 17:31:01,978 [DEBUG] app1.py:1104 - Sending transcription: hello can you hear my (is_final: False)
2024-12-02 17:31:01,978 [DEBUG] app1.py:1104 - Sending transcription: hello can you hear my voice (is_final: False)
2024-12-02 17:31:01,981 [DEBUG] app1.py:1104 - Sending transcription: Hello, can you hear my voice? (is_final: True)
2024-12-02 17:31:01,989 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:01,989 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:01,991 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 17:31:01,993 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 17:31:01,994 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 17:31:01,994 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:01,996 [DEBUG] app1.py:1104 - Sending transcription: hello can you (is_final: False)
2024-12-02 17:31:01,996 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 17:31:01,997 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 17:31:01,999 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 17:31:02,003 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,005 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:02,009 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:02,011 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,012 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,013 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:02,013 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:02,014 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:02,019 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:31:02,021 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 17:31:02,022 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 17:31:02,023 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 17:31:02,024 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 17:31:02,024 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 17:31:02,025 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 17:31:02,025 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 17:31:02,026 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,027 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,028 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,028 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 17:31:02,030 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,030 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,031 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,035 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,038 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:02,039 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:02,039 [DEBUG] app1.py:1104 - Sending transcription: hello this is (is_final: False)
2024-12-02 17:31:02,039 [DEBUG] app1.py:1104 - Sending transcription: Hello, this is Amit. (is_final: True)
2024-12-02 17:31:02,041 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:02,042 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 17:31:02,043 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 17:31:02,043 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 17:31:02,043 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 17:31:02,044 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 17:31:02,044 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 17:31:02,044 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,046 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,046 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,047 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,047 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,048 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,048 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,053 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,054 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,054 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,055 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,055 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,057 [DEBUG] app1.py:1104 - Sending transcription: open (is_final: False)
2024-12-02 17:31:02,058 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,058 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,059 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,059 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 17:31:02,060 [DEBUG] app1.py:1104 - Sending transcription: hello hello (is_final: False)
2024-12-02 17:31:02,060 [DEBUG] app1.py:1104 - Sending transcription: hello hello can (is_final: False)
2024-12-02 17:31:02,061 [DEBUG] app1.py:1104 - Sending transcription: hello hello can you hear (is_final: False)
2024-12-02 17:31:02,062 [DEBUG] app1.py:1104 - Sending transcription: hello hello can you hear my voice (is_final: False)
2024-12-02 17:31:02,062 [DEBUG] app1.py:1104 - Sending transcription: Hello. Hello. Can you hear my voice? (is_final: True)
2024-12-02 17:31:02,063 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 17:31:02,063 [DEBUG] app1.py:1104 - Sending transcription: hello what are you (is_final: False)
2024-12-02 17:31:02,065 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 17:31:02,068 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 17:31:02,070 [DEBUG] app1.py:1104 - Sending transcription: no this is (is_final: False)
2024-12-02 17:31:02,071 [DEBUG] app1.py:1104 - Sending transcription: hello this is amanda i can't hear (is_final: False)
2024-12-02 17:31:02,072 [DEBUG] app1.py:1104 - Sending transcription: hello this is amanda i can't hear my (is_final: False)
2024-12-02 17:31:02,075 [DEBUG] app1.py:1104 - Sending transcription: hello this is amanda i can't hear my voice (is_final: False)
2024-12-02 17:31:02,077 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:02,078 [DEBUG] app1.py:1104 - Sending transcription: hello this is (is_final: False)
2024-12-02 17:31:02,079 [DEBUG] app1.py:1104 - Sending transcription: hello this is an (is_final: False)
2024-12-02 17:31:02,079 [DEBUG] app1.py:1104 - Sending transcription: hello this is anand (is_final: False)
2024-12-02 17:31:02,080 [DEBUG] app1.py:1104 - Sending transcription: Hello, this is Anand. (is_final: True)
2024-12-02 17:31:02,081 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,081 [DEBUG] app1.py:1104 - Sending transcription: The. (is_final: True)
2024-12-02 17:31:02,084 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,087 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,087 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,088 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,089 [DEBUG] app1.py:1104 - Sending transcription: hi what (is_final: False)
2024-12-02 17:31:02,089 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 17:31:02,094 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 17:31:02,095 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,095 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,096 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,097 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,097 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:02,098 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:02,098 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:02,098 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:31:02,105 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:02,106 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:31:02,107 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:02,107 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:02,109 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,113 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,114 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,119 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,122 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,123 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,123 [DEBUG] app1.py:1104 - Sending transcription: yes sir (is_final: False)
2024-12-02 17:31:02,123 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,125 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,125 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,125 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,126 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,127 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,128 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,128 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,128 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,129 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,129 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,129 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,129 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,130 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,130 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,132 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,132 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,136 [DEBUG] app1.py:1104 - Sending transcription: kar (is_final: False)
2024-12-02 17:31:02,137 [DEBUG] app1.py:1104 - Sending transcription: karumudi (is_final: False)
2024-12-02 17:31:02,137 [DEBUG] app1.py:1104 - Sending transcription: karumudiyama (is_final: False)
2024-12-02 17:31:02,139 [DEBUG] app1.py:1104 - Sending transcription: karumudiyamana (is_final: False)
2024-12-02 17:31:02,139 [DEBUG] app1.py:1104 - Sending transcription: karumudiyamana chandigarh (is_final: False)
2024-12-02 17:31:02,139 [DEBUG] app1.py:1104 - Sending transcription: karumudiyamana chandigarh kannur (is_final: False)
2024-12-02 17:31:02,140 [DEBUG] app1.py:1104 - Sending transcription: Karumudiyama, Chandigarh. (is_final: True)
2024-12-02 17:31:02,140 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:31:02,142 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:31:02,142 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:02,143 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:31:02,145 [DEBUG] app1.py:1104 - Sending transcription: in december (is_final: False)
2024-12-02 17:31:02,146 [DEBUG] app1.py:1104 - Sending transcription: criminal (is_final: False)
2024-12-02 17:31:02,147 [DEBUG] app1.py:1104 - Sending transcription: criminal module (is_final: False)
2024-12-02 17:31:02,147 [DEBUG] app1.py:1104 - Sending transcription: Criminal Module. (is_final: True)
2024-12-02 17:31:02,148 [DEBUG] app1.py:1104 - Sending transcription: PG (is_final: False)
2024-12-02 17:31:02,155 [DEBUG] app1.py:1104 - Sending transcription: PG PC (is_final: False)
2024-12-02 17:31:02,156 [DEBUG] app1.py:1104 - Sending transcription: PG PC PC (is_final: False)
2024-12-02 17:31:02,157 [DEBUG] app1.py:1104 - Sending transcription: PG PC. PC. (is_final: True)
2024-12-02 17:31:02,157 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,158 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,158 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,159 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,159 [DEBUG] app1.py:1104 - Sending transcription: OK. (is_final: True)
2024-12-02 17:31:02,161 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,161 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,163 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,163 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,164 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,176 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,177 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,177 [DEBUG] app1.py:1104 - Sending transcription: he a (is_final: False)
2024-12-02 17:31:02,178 [DEBUG] app1.py:1104 - Sending transcription: he a cassandra (is_final: False)
2024-12-02 17:31:02,178 [DEBUG] app1.py:1104 - Sending transcription: he a cassandra P (is_final: False)
2024-12-02 17:31:02,179 [DEBUG] app1.py:1104 - Sending transcription: he a cassandra P the internal (is_final: False)
2024-12-02 17:31:02,179 [DEBUG] app1.py:1104 - Sending transcription: He A Cassandra P. The internal P. (is_final: True)
2024-12-02 17:31:02,188 [DEBUG] app1.py:1104 - Sending transcription: C (is_final: False)
2024-12-02 17:31:02,189 [DEBUG] app1.py:1104 - Sending transcription: CGC (is_final: False)
2024-12-02 17:31:02,190 [DEBUG] app1.py:1104 - Sending transcription: CGC. (is_final: True)
2024-12-02 17:31:02,190 [DEBUG] app1.py:1104 - Sending transcription: 's (is_final: False)
2024-12-02 17:31:02,191 [DEBUG] app1.py:1104 - Sending transcription: 'S. (is_final: True)
2024-12-02 17:31:02,191 [DEBUG] app1.py:1104 - Sending transcription: is due to (is_final: False)
2024-12-02 17:31:02,191 [DEBUG] app1.py:1104 - Sending transcription: is due to google (is_final: False)
2024-12-02 17:31:02,193 [DEBUG] app1.py:1104 - Sending transcription: is due to google earth (is_final: False)
2024-12-02 17:31:02,194 [DEBUG] app1.py:1104 - Sending transcription: is due to google earth in (is_final: False)
2024-12-02 17:31:02,194 [DEBUG] app1.py:1104 - Sending transcription: is due to google earth (is_final: False)
2024-12-02 17:31:02,194 [DEBUG] app1.py:1104 - Sending transcription: is due to google earth in three (is_final: False)
2024-12-02 17:31:02,196 [DEBUG] app1.py:1104 - Sending transcription: is due to google earth in 3D (is_final: False)
2024-12-02 17:31:02,196 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,197 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,198 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,203 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,203 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 17:31:02,205 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,205 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 17:31:02,206 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,206 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,207 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,207 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,209 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 17:31:02,209 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,209 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,209 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,211 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,211 [DEBUG] app1.py:1104 - Sending transcription: can you (is_final: False)
2024-12-02 17:31:02,211 [DEBUG] app1.py:1104 - Sending transcription: can you play (is_final: False)
2024-12-02 17:31:02,211 [DEBUG] app1.py:1104 - Sending transcription: can you play this is a (is_final: False)
2024-12-02 17:31:02,213 [DEBUG] app1.py:1104 - Sending transcription: Can you show me? (is_final: True)
2024-12-02 17:31:02,215 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,218 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,220 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,222 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,222 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,222 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 17:31:02,223 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 17:31:02,223 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,224 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,224 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,224 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,225 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,225 [DEBUG] app1.py:1104 - Sending transcription: shah rukh khan (is_final: False)
2024-12-02 17:31:02,227 [DEBUG] app1.py:1104 - Sending transcription: Shah Rukh Khan. (is_final: True)
2024-12-02 17:31:02,228 [DEBUG] app1.py:1104 - Sending transcription: can hear (is_final: False)
2024-12-02 17:31:02,228 [DEBUG] app1.py:1104 - Sending transcription: can you hear me (is_final: False)
2024-12-02 17:31:02,228 [DEBUG] app1.py:1104 - Sending transcription: Can you hear me? (is_final: True)
2024-12-02 17:31:02,229 [DEBUG] app1.py:1104 - Sending transcription: sandwich (is_final: False)
2024-12-02 17:31:02,229 [DEBUG] app1.py:1104 - Sending transcription: it's supposed to be sandwich (is_final: False)
2024-12-02 17:31:02,235 [DEBUG] app1.py:1104 - Sending transcription: it's supposed to be sandwiched (is_final: False)
2024-12-02 17:31:02,237 [DEBUG] app1.py:1104 - Sending transcription: It's supposed to be sandwiched in. (is_final: True)
2024-12-02 17:31:02,238 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,239 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,239 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,240 [DEBUG] app1.py:1104 - Sending transcription: ask (is_final: False)
2024-12-02 17:31:02,241 [DEBUG] app1.py:1104 - Sending transcription: i was coming (is_final: False)
2024-12-02 17:31:02,241 [DEBUG] app1.py:1104 - Sending transcription: i was coming to (is_final: False)
2024-12-02 17:31:02,243 [DEBUG] app1.py:1104 - Sending transcription: i was coming to check (is_final: False)
2024-12-02 17:31:02,243 [DEBUG] app1.py:1104 - Sending transcription: was coming to jacuzzi (is_final: False)
2024-12-02 17:31:02,244 [DEBUG] app1.py:1104 - Sending transcription: was coming to jacuzzi aj (is_final: False)
2024-12-02 17:31:02,245 [DEBUG] app1.py:1104 - Sending transcription: was coming to jacuzzi ajagaoni (is_final: False)
2024-12-02 17:31:02,246 [DEBUG] app1.py:1104 - Sending transcription: Was coming to Jacuzzi Ajagaoni Ave. (is_final: True)
2024-12-02 17:31:02,246 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,247 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,248 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,248 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,252 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,253 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:31:02,254 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:31:02,255 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:31:02,881 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:31:05,111 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 17:31:05,376 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 17:31:32,882 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:32:02,884 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:32:32,885 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:33:02,887 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:33:32,888 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:34:02,889 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:34:32,890 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:35:01,655 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 17:35:01,803 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 17:35:01,901 [INFO] app1.py:1240 - Audio stream started
2024-12-02 17:35:02,891 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:35:03,855 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:35:03,876 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=37e6d69f0022405bae573f0d7a202bbd, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:04,557 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:35:04,557 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=76df6d7854a14c3f81c96399f6d9e3d8, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:35:05,942 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:35:05,944 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5299b9998c1f495e92ed0463c31a6f67, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:06,457 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:35:06,458 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=70588acc0e264d86869b7787f56beabe, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:35:22,756 [DEBUG] app1.py:1214 - Speech recognizing: ethiopian
2024-12-02 17:35:22,756 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6a302b7c5caf43339dd0e12654c38e13, text="ethiopian", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:23,257 [DEBUG] app1.py:1214 - Speech recognizing: ethiopian trigger
2024-12-02 17:35:23,257 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7f900b5106324ecfbaade0988a84e043, text="ethiopian trigger", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:24,264 [DEBUG] app1.py:1214 - Speech recognizing: ethiopian trigger at home
2024-12-02 17:35:24,265 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cadca7f3cf294778acc0bd95a4b59a60, text="ethiopian trigger at home", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:25,070 [DEBUG] app1.py:1214 - Speech recognizing: ethiopian trigger at home is
2024-12-02 17:35:25,071 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2b989536e3bd4a2dab601b6247934d38, text="ethiopian trigger at home is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:25,568 [DEBUG] app1.py:1214 - Speech recognizing: ethiopian trigger at home abhishek
2024-12-02 17:35:25,568 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9a54fc2c74da4d21ae8db737a32c8637, text="ethiopian trigger at home abhishek", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:26,095 [INFO] app1.py:1205 - Speech recognized: Ethiopian trigger at home. Abhishek.
2024-12-02 17:35:26,096 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=60c8d9071a774a6a9d9f396fd6e2dfd6, text="Ethiopian trigger at home. Abhishek.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:35:28,047 [DEBUG] app1.py:1214 - Speech recognizing: play
2024-12-02 17:35:28,047 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f7973048294b425abdc03c4e92a2542f, text="play", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:28,342 [DEBUG] app1.py:1214 - Speech recognizing: play delhi pyar hai
2024-12-02 17:35:28,343 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1eadde3d65044b7a939951908356c1aa, text="play delhi pyar hai", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:28,775 [INFO] app1.py:1205 - Speech recognized: Play Delhi, Paris.
2024-12-02 17:35:28,775 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d666af074ca4402780766dc7ffde48d2, text="Play Delhi, Paris.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:35:32,892 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:35:48,351 [DEBUG] app1.py:1214 - Speech recognizing: translator
2024-12-02 17:35:48,352 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=44bade312bcd41a9817c94eb4bcfc6ef, text="translator", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:35:50,175 [INFO] app1.py:1205 - Speech recognized: Translator.
2024-12-02 17:35:50,176 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=daaaf81a49a744af92c85d4ebed549d3, text="Translator.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:36:02,893 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:36:10,358 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:36:10,365 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9f0a2d46a2ee4bef92de333229b6c79e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:36:25,358 [DEBUG] app1.py:1214 - Speech recognizing: provided
2024-12-02 17:36:25,360 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=87e0e7a5b7ab49da98396f170a0c2817, text="provided", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:26,658 [DEBUG] app1.py:1214 - Speech recognizing: provided trans
2024-12-02 17:36:26,660 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6c20094e76344376bf5c5f4fa0b8fdcc, text="provided trans", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:26,966 [DEBUG] app1.py:1214 - Speech recognizing: provided transcription
2024-12-02 17:36:26,967 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6563793e3cbe491fb17b9b5462ca6315, text="provided transcription", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:28,894 [INFO] app1.py:1205 - Speech recognized: Provided transcription.
2024-12-02 17:36:28,895 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c7900d73a17e4c45b59c2d5be2d2abc4, text="Provided transcription.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:36:32,895 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:36:37,072 [DEBUG] app1.py:1214 - Speech recognizing: we can go
2024-12-02 17:36:37,073 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f6531b1fb4f743cfa31fb91fba9b44c9, text="we can go", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:37,383 [DEBUG] app1.py:1214 - Speech recognizing: we can go live
2024-12-02 17:36:37,383 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8b246a6e39594fcd81a6774ff50947d8, text="we can go live", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:38,897 [INFO] app1.py:1205 - Speech recognized: We can go live.
2024-12-02 17:36:38,898 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0603b406926d4309965aca5870df9d7e, text="We can go live.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:36:39,547 [DEBUG] app1.py:1214 - Speech recognizing: ceremony
2024-12-02 17:36:39,548 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=08e6ab88aba24b12a3607c925baaea9b, text="ceremony", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:41,253 [DEBUG] app1.py:1214 - Speech recognizing: ceremony join
2024-12-02 17:36:41,254 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ca52ea62e59a4d6f94af890cedff06b0, text="ceremony join", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:41,455 [DEBUG] app1.py:1214 - Speech recognizing: ceremony
2024-12-02 17:36:41,456 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=646b894fe36b493fa6c7bc64a2a6f2b4, text="ceremony", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:42,559 [DEBUG] app1.py:1214 - Speech recognizing: ceremony join
2024-12-02 17:36:42,559 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=08d314192ec8442ba1157cfec9b56ae5, text="ceremony join", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:42,759 [DEBUG] app1.py:1214 - Speech recognizing: ceremony
2024-12-02 17:36:42,759 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1a68991fad7c49429a2f5e3456016219, text="ceremony", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:44,685 [INFO] app1.py:1205 - Speech recognized: Ceremony.
2024-12-02 17:36:44,685 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fce6cd571efd479bb2470fd78a53ee60, text="Ceremony.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:36:54,775 [INFO] app1.py:1205 - Speech recognized: And.
2024-12-02 17:36:54,776 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6c98283989334516975a62b37756dff9, text="And.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:36:56,860 [DEBUG] app1.py:1214 - Speech recognizing: replay
2024-12-02 17:36:56,860 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=caf0202487d94eb19932043fe1484bb5, text="replay", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:57,157 [DEBUG] app1.py:1214 - Speech recognizing: replay namma
2024-12-02 17:36:57,159 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8c372ed3ecbd45afa73227663b1d283d, text="replay namma", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:57,594 [DEBUG] app1.py:1214 - Speech recognizing: replay namma tum
2024-12-02 17:36:57,594 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dacbcb81129043c19a26303ca67d0e0d, text="replay namma tum", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:57,652 [DEBUG] app1.py:1214 - Speech recognizing: replay namma tumse
2024-12-02 17:36:57,652 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5282200066b04deeb587d000367b6ee1, text="replay namma tumse", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:58,353 [DEBUG] app1.py:1214 - Speech recognizing: replay namma tumse female
2024-12-02 17:36:58,353 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2a744251436947ee871e920f9c31976a, text="replay namma tumse female", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:59,053 [DEBUG] app1.py:1214 - Speech recognizing: replay namma tumse female vyap
2024-12-02 17:36:59,054 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d852ddfb06884c738e381a5235e22916, text="replay namma tumse female vyap", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:36:59,455 [DEBUG] app1.py:1214 - Speech recognizing: replay namma tumse female vyapam
2024-12-02 17:36:59,455 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fabee20a02cf44be98c94e0c26e3d549, text="replay namma tumse female vyapam", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:00,178 [INFO] app1.py:1205 - Speech recognized: Replay Namma Tumse female.
2024-12-02 17:37:00,179 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a269308dc2d14216bd820333aeb6b847, text="Replay Namma Tumse female.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:37:02,907 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:37:20,198 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:37:20,199 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b7863a00d2da4742afbd639272c998e2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:37:23,148 [DEBUG] app1.py:1214 - Speech recognizing: easy app
2024-12-02 17:37:23,150 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9a1a3b77221a42849d49329988a08f01, text="easy app", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:23,347 [DEBUG] app1.py:1214 - Speech recognizing: easy app component
2024-12-02 17:37:23,348 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6a6451dce0714425b74b6ea7391f92db, text="easy app component", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:24,044 [DEBUG] app1.py:1214 - Speech recognizing: easy app component app
2024-12-02 17:37:24,044 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e28ef163a4354e4abf6faec01d511775, text="easy app component app", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:24,093 [INFO] app1.py:1205 - Speech recognized: Easy app Component app.
2024-12-02 17:37:24,094 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=00ba9142c14c4b9cad5801a79d61aca0, text="Easy app Component app.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:37:26,060 [DEBUG] app1.py:1214 - Speech recognizing: it it already
2024-12-02 17:37:26,061 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cfaf235555c3437aaea7aa96c916fd93, text="it it already", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:26,555 [DEBUG] app1.py:1214 - Speech recognizing: it's already handy
2024-12-02 17:37:26,555 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a01c6c07a1cf49379432730f69afd376, text="it's already handy", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:27,274 [INFO] app1.py:1205 - Speech recognized: It it already got.
2024-12-02 17:37:27,274 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=771be2e3fd874089b3bf88ddec5fe712, text="It it already got.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:37:32,908 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:37:44,249 [DEBUG] app1.py:1214 - Speech recognizing: i
2024-12-02 17:37:44,250 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8b508219537f461b913e841d9345abcb, text="i", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:44,655 [DEBUG] app1.py:1214 - Speech recognizing: i want
2024-12-02 17:37:44,656 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8e3799ffc23d4509a97c60680766bc92, text="i want", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:45,850 [DEBUG] app1.py:1214 - Speech recognizing: i want here
2024-12-02 17:37:45,851 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=472b3406614d4fbebc2b4c724de79ef4, text="i want here", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:46,068 [INFO] app1.py:1205 - Speech recognized: I want here.
2024-12-02 17:37:46,069 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=196da7021354459f9271552aa2bf384d, text="I want here.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:37:54,473 [INFO] app1.py:1205 - Speech recognized: When I.
2024-12-02 17:37:54,474 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a31cbc0801f44f019d0852f1d77f7636, text="When I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:37:59,269 [DEBUG] app1.py:1214 - Speech recognizing: start start
2024-12-02 17:37:59,270 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e48925d16ec94060968c28c17788f353, text="start start", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:37:59,471 [DEBUG] app1.py:1214 - Speech recognizing: start start speaking
2024-12-02 17:37:59,471 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=167db1029644449aac48219e6d4e0bb2, text="start start speaking", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:00,395 [INFO] app1.py:1205 - Speech recognized: Start. Start speaking.
2024-12-02 17:38:00,396 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=33f14a8999fd4c22aeb6f3eeb3271947, text="Start. Start speaking.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:02,909 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:38:05,451 [DEBUG] app1.py:1214 - Speech recognizing: from
2024-12-02 17:38:05,451 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=88cc6ca80e7e47f7ba7c56e479b0d340, text="from", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:05,653 [DEBUG] app1.py:1214 - Speech recognizing: from my
2024-12-02 17:38:05,653 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8b833f5e957048a19aed1e0575b7a8dd, text="from my", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:06,153 [DEBUG] app1.py:1214 - Speech recognizing: from my first
2024-12-02 17:38:06,154 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b573afb81c8b46b7bfb4b516d274dab5, text="from my first", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:07,057 [DEBUG] app1.py:1214 - Speech recognizing: from my first page
2024-12-02 17:38:07,057 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aebf6ed7908041e5aa7354dfe05d47a5, text="from my first page", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:07,571 [INFO] app1.py:1205 - Speech recognized: From my first page.
2024-12-02 17:38:07,571 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=575ca45bc6604e2491d6b51a6095a975, text="From my first page.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:11,245 [DEBUG] app1.py:1214 - Speech recognizing: men only
2024-12-02 17:38:11,246 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d0000d6810bf4a34b4dbe0873fe16ad3, text="men only", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:11,853 [DEBUG] app1.py:1214 - Speech recognizing: men only STT
2024-12-02 17:38:11,854 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aa4decf9a972455c840043936fe4c977, text="men only STT", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:12,551 [INFO] app1.py:1205 - Speech recognized: Men only STT.
2024-12-02 17:38:12,552 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e97b0635699f456c83f6b09b321beaf1, text="Men only STT.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:14,444 [DEBUG] app1.py:1214 - Speech recognizing: play
2024-12-02 17:38:14,445 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=40c8e16090fe40e8aaa4620d09d2c269, text="play", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:14,837 [DEBUG] app1.py:1214 - Speech recognizing: play movie
2024-12-02 17:38:14,838 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dccd56c279d441bab85d67be04c7d2e6, text="play movie", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:16,050 [DEBUG] app1.py:1214 - Speech recognizing: play movie STD
2024-12-02 17:38:16,051 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d7b6710aa5e0403581d4714231f4a6a9, text="play movie STD", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:17,971 [INFO] app1.py:1205 - Speech recognized: Play Movie STD.
2024-12-02 17:38:17,971 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=88a0ff5b4cad4406acac9296dc6e2b7d, text="Play Movie STD.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:19,945 [DEBUG] app1.py:1214 - Speech recognizing: STT
2024-12-02 17:38:19,945 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=310146a42dd140e289d68126c374acdc, text="STT", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:21,791 [INFO] app1.py:1205 - Speech recognized: STT.
2024-12-02 17:38:21,791 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7afb0030ee1c476aa910924970db9727, text="STT.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:22,380 [DEBUG] app1.py:1214 - Speech recognizing: work
2024-12-02 17:38:22,381 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=642b147b5bc84dd79f4cbddf6bf5de30, text="work", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:22,395 [INFO] app1.py:1205 - Speech recognized: Work.
2024-12-02 17:38:22,395 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3b7ddc6ab6cd451cb88bb63afd30125c, text="Work.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:26,375 [DEBUG] app1.py:1214 - Speech recognizing: and
2024-12-02 17:38:26,375 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=449fc53fd4004a159cc954232d365a40, text="and", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:26,871 [DEBUG] app1.py:1214 - Speech recognizing: and when
2024-12-02 17:38:26,872 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9e166f7c8a9f47659b1abb667440df00, text="and when", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:27,171 [DEBUG] app1.py:1214 - Speech recognizing: and when and
2024-12-02 17:38:27,171 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ee4ff20f9c5e41f9bc86371a35ffec0a, text="and when and", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:27,874 [DEBUG] app1.py:1214 - Speech recognizing: and when and in
2024-12-02 17:38:27,874 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1222f3f2c3eb431d9874ff7b7499b116, text="and when and in", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:28,172 [DEBUG] app1.py:1214 - Speech recognizing: and when and in my
2024-12-02 17:38:28,173 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8209db25b6c3494db762a11410c809e1, text="and when and in my", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:28,464 [DEBUG] app1.py:1214 - Speech recognizing: and when and in my second
2024-12-02 17:38:28,465 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c2fe6996cdb74971810b340f23161764, text="and when and in my second", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:29,069 [DEBUG] app1.py:1214 - Speech recognizing: and when and in my second page
2024-12-02 17:38:29,069 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b11f1be24cb43e49f4ac3c34f923986, text="and when and in my second page", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:29,691 [INFO] app1.py:1205 - Speech recognized: And when and in my second page.
2024-12-02 17:38:29,691 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3a09515afee94ea8aa9796e8550083d9, text="And when and in my second page.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:32,911 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:38:34,471 [DEBUG] app1.py:1214 - Speech recognizing: 7
2024-12-02 17:38:34,471 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cbeb5a0ff784419b8301d6ea562b5103, text="7", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:34,485 [INFO] app1.py:1205 - Speech recognized: 7/3.
2024-12-02 17:38:34,485 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=43479ecd9f624033aad5827e4a22d0cc, text="7/3.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:35,869 [DEBUG] app1.py:1214 - Speech recognizing: i
2024-12-02 17:38:35,870 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bb45e9634a304f8d94405a262dd22223, text="i", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:36,074 [DEBUG] app1.py:1214 - Speech recognizing: i listen
2024-12-02 17:38:36,100 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=99da231a97a1415ab32f21d367271137, text="i listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:36,369 [DEBUG] app1.py:1214 - Speech recognizing: i listened to
2024-12-02 17:38:36,371 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=70479a0004ff4e91a411b022f68f2db3, text="i listened to", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:36,773 [DEBUG] app1.py:1214 - Speech recognizing: i listened that
2024-12-02 17:38:36,773 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3b46903c87a74a03a5c05a72b609033f, text="i listened that", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:36,976 [DEBUG] app1.py:1214 - Speech recognizing: i listened to that response
2024-12-02 17:38:36,977 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cc40fcdc7acf464caabb7ff72658c534, text="i listened to that response", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:37,380 [DEBUG] app1.py:1214 - Speech recognizing: i listened that response
2024-12-02 17:38:37,380 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3432deba16b74176b07341d30f93810b, text="i listened that response", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:37,675 [DEBUG] app1.py:1214 - Speech recognizing: i listened to that response
2024-12-02 17:38:37,676 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7a5419e6d066486fba2bd29c92012325, text="i listened to that response", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:38,066 [DEBUG] app1.py:1214 - Speech recognizing: i listened to that response with
2024-12-02 17:38:38,067 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2a8d30b2c8b24b2d932e85b750722a6d, text="i listened to that response with", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:38,287 [DEBUG] app1.py:1214 - Speech recognizing: i listened to that response with multiple
2024-12-02 17:38:38,288 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=af9383cb558e46dc9478484bb5348ee9, text="i listened to that response with multiple", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:38,671 [DEBUG] app1.py:1214 - Speech recognizing: i listened to that response with multiple language
2024-12-02 17:38:38,673 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d3e3605d3578415f9fd74dffd2856afd, text="i listened to that response with multiple language", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:39,865 [INFO] app1.py:1205 - Speech recognized: I listened to that response with multiple language.
2024-12-02 17:38:39,866 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=909554f5e33d4cc990a95324368c7ad8, text="I listened to that response with multiple language.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:45,267 [DEBUG] app1.py:1214 - Speech recognizing: multiple
2024-12-02 17:38:45,269 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fa6e0f7b69e2475f801a5e4c658c446a, text="multiple", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:46,891 [DEBUG] app1.py:1214 - Speech recognizing: multiple language
2024-12-02 17:38:46,892 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a5836522dfb64aa0a95407ad1a5b6ebc, text="multiple language", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:47,651 [INFO] app1.py:1205 - Speech recognized: Multiple language.
2024-12-02 17:38:47,652 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=abb2d90032ca49bc8ebc318ac7513c28, text="Multiple language.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:49,847 [DEBUG] app1.py:1214 - Speech recognizing: help
2024-12-02 17:38:49,848 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=01bc083a652e49dc9b90fdf96b871a0e, text="help", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:50,252 [DEBUG] app1.py:1214 - Speech recognizing: help go to TDS
2024-12-02 17:38:50,253 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3ed11a68c270477783b32e34cc6970fd, text="help go to TDS", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:50,548 [DEBUG] app1.py:1214 - Speech recognizing: help to TDS
2024-12-02 17:38:50,551 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c5e12bb73fad417ea752ed11407cc989, text="help to TDS", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:51,361 [INFO] app1.py:1205 - Speech recognized: Help to TDs.
2024-12-02 17:38:51,362 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dca31f91d5bd4cfcb87ed8c8e5df3a6f, text="Help to TDs.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:38:54,671 [DEBUG] app1.py:1214 - Speech recognizing: TS
2024-12-02 17:38:54,673 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=52570773ae8c4a2084b903b6fed19921, text="TS", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:54,969 [DEBUG] app1.py:1214 - Speech recognizing: TST
2024-12-02 17:38:54,969 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=85cc7704db5147c394d8eccca0c52a5e, text="TST", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:55,170 [DEBUG] app1.py:1214 - Speech recognizing: TSTT
2024-12-02 17:38:55,170 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3996ab9f9e634e8f9972a9ac8432c439, text="TSTT", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:55,558 [DEBUG] app1.py:1214 - Speech recognizing: TSTTS
2024-12-02 17:38:55,559 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=35981786dcac442897a805ff5f78bb89, text="TSTTS", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:38:56,995 [INFO] app1.py:1205 - Speech recognized: TSTTS 0.
2024-12-02 17:38:56,996 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=df98a1cb931c41049f2926940d4c7efc, text="TSTTS 0.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:00,253 [DEBUG] app1.py:1214 - Speech recognizing: here i see
2024-12-02 17:39:00,253 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=faa9c00c0027473ba0000fcc1d6a8ad7, text="here i see", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:00,751 [DEBUG] app1.py:1214 - Speech recognizing: here i see a space
2024-12-02 17:39:00,753 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d98dfe9fe6a14621a43cecfe5fd8ac0b, text="here i see a space", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:01,496 [DEBUG] app1.py:1214 - Speech recognizing: here i see a space the
2024-12-02 17:39:01,496 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cc2325d975e244a68e961369b7284f1f, text="here i see a space the", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:01,558 [DEBUG] app1.py:1214 - Speech recognizing: here i see a space name
2024-12-02 17:39:01,559 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bcd44d0be6d542a1a568c351eb882adb, text="here i see a space name", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:01,573 [INFO] app1.py:1205 - Speech recognized: Here I see a space name on that.
2024-12-02 17:39:01,574 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=40acf13593084133af862854bfe3c393, text="Here I see a space name on that.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:02,913 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:39:03,956 [DEBUG] app1.py:1214 - Speech recognizing: here here i
2024-12-02 17:39:03,957 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=664497f71d4248d5891eec9f741cb6cf, text="here here i", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:04,266 [DEBUG] app1.py:1214 - Speech recognizing: here here i found some
2024-12-02 17:39:04,267 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a3498eab75ca48a5a81b6cd0e9326203, text="here here i found some", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:04,656 [DEBUG] app1.py:1214 - Speech recognizing: here here i found some problem
2024-12-02 17:39:04,656 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ca3542ca70f4c04b0b746124a30455c, text="here here i found some problem", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:05,681 [INFO] app1.py:1205 - Speech recognized: Here here I found some problem.
2024-12-02 17:39:05,690 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ad8d0e3a2d194bd68323d05bdde30b73, text="Here here I found some problem.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:11,254 [DEBUG] app1.py:1214 - Speech recognizing: aiims
2024-12-02 17:39:11,255 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ffb718718d7847ef8ad9346cb0dcc415, text="aiims", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:12,256 [DEBUG] app1.py:1214 - Speech recognizing: aiims of government
2024-12-02 17:39:12,257 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2d5b4089f6b1414fbf455224b5993145, text="aiims of government", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:13,152 [DEBUG] app1.py:1214 - Speech recognizing: aiims of government when
2024-12-02 17:39:13,154 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=67c4ff2ceae441ea8aafd9870e8d61b6, text="aiims of government when", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:13,790 [INFO] app1.py:1205 - Speech recognized: AIIMS.
2024-12-02 17:39:13,791 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cd9a7c8417df4c5797d1b810f2fad6c6, text="AIIMS.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:19,847 [DEBUG] app1.py:1214 - Speech recognizing: i am speak
2024-12-02 17:39:19,848 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e33f65c1d64f4c7e8c2017a1373d9717, text="i am speak", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:20,250 [DEBUG] app1.py:1214 - Speech recognizing: speak in
2024-12-02 17:39:20,251 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eef9302e883b4f0abf3d9cb2bb78b975, text="speak in", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:20,752 [DEBUG] app1.py:1214 - Speech recognizing: speak in life
2024-12-02 17:39:20,754 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ae95640ba97645e6ba18e574e0f3cf10, text="speak in life", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:21,454 [DEBUG] app1.py:1214 - Speech recognizing: speak in life segment page
2024-12-02 17:39:21,455 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8ce63f0f01c84dc3a578b5fcb0eb42ee, text="speak in life segment page", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:22,090 [INFO] app1.py:1205 - Speech recognized: Speak in life.
2024-12-02 17:39:22,091 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ce0417832b384952b4f9b79bf39fa3d4, text="Speak in life.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:25,865 [DEBUG] app1.py:1214 - Speech recognizing: live 7
2024-12-02 17:39:25,866 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f1ca7bc57ecd4f449fab3a353c69ca52, text="live 7", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:27,159 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days
2024-12-02 17:39:27,161 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=79770ac0928e4f70ae1694d4a1d16516, text="live 7 days", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:27,358 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then
2024-12-02 17:39:27,359 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=04b22f8393154c6faca6cd7212223dca, text="live 7 days then", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:27,748 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then it
2024-12-02 17:39:27,749 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5b0c5b616847415990ed5e9bc1ffa73a, text="live 7 days then it", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:28,451 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then it also
2024-12-02 17:39:28,452 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8afc619652e34d24aeada8a9f1995ca3, text="live 7 days then it also", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:29,047 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then it also listens
2024-12-02 17:39:29,048 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=360817281f6b46febf922d772714ed79, text="live 7 days then it also listens", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:29,854 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then it also listens to
2024-12-02 17:39:29,854 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=295887977894456b98db462215cce815, text="live 7 days then it also listens to", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:30,353 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then it also listens to then
2024-12-02 17:39:30,354 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b04e3825ae074319bca6e510d1960a50, text="live 7 days then it also listens to then", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:30,557 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then it also listens then it
2024-12-02 17:39:30,558 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1999715a44fa4f3892b7ca94df2e811f, text="live 7 days then it also listens then it", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:30,962 [DEBUG] app1.py:1214 - Speech recognizing: live 7 days then it also listens then it also
2024-12-02 17:39:30,963 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f816146eb0764f37b1fce1409c5f4c19, text="live 7 days then it also listens then it also", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:31,709 [INFO] app1.py:1205 - Speech recognized: Live 7 days then it also listens then it also.
2024-12-02 17:39:31,711 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a05daadaf27144b88f1d542332898c35, text="Live 7 days then it also listens then it also.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:32,914 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:39:34,881 [DEBUG] app1.py:1214 - Speech recognizing: listen
2024-12-02 17:39:34,882 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d810f0bec36b40a792b4b629f776e24a, text="listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:34,898 [INFO] app1.py:1205 - Speech recognized: Listen, I will.
2024-12-02 17:39:34,898 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4b1742ed5b3f4468899f441f97c95eeb, text="Listen, I will.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:36,656 [DEBUG] app1.py:1214 - Speech recognizing: don't need
2024-12-02 17:39:36,657 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc94883c54e34370987aaefbb0dfbfd9, text="don't need", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:37,152 [DEBUG] app1.py:1214 - Speech recognizing: don't need that
2024-12-02 17:39:37,154 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=428d57a7acf44d15a5a5fb84773977e3, text="don't need that", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:39:39,067 [INFO] app1.py:1205 - Speech recognized: Don't need that.
2024-12-02 17:39:39,067 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a86cf1b32e644f4ab08ff77abbd34e03, text="Don't need that.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:39:54,473 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:39:54,474 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=29f109aa83fb46cdae852ebc249f0cad, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:02,915 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:40:07,693 [DEBUG] app1.py:1214 - Speech recognizing: can you tell the gate in
2024-12-02 17:40:07,694 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=97f9a0fb42c34dc78332fe7ca3eba22b, text="can you tell the gate in", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:07,984 [DEBUG] app1.py:1214 - Speech recognizing: the 18 volvo
2024-12-02 17:40:07,987 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b12e5ade11a74127bd9d465b11b1cda6, text="the 18 volvo", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:09,837 [INFO] app1.py:1205 - Speech recognized: The 18 Volvo.
2024-12-02 17:40:09,837 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3d267409e6b2445bb0b490133b6d42a5, text="The 18 Volvo.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:15,020 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:40:15,021 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ce1b3189156489bb64ee47a6fef28da, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:15,325 [DEBUG] app1.py:1214 - Speech recognizing: hello how are
2024-12-02 17:40:15,325 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=abfb74544bef49ba8fbb0d86c951e967, text="hello how are", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:15,424 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 17:40:15,424 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=18dc9f9c49bd49fda251efca4ba27f97, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:16,621 [INFO] app1.py:1205 - Speech recognized: Hello, how are you?
2024-12-02 17:40:16,624 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=070a068f4ff84567883ad635a607341e, text="Hello, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:20,606 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:40:20,606 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=47a0bd21b68b4b13a7ab052b35901dd6, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:21,871 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:40:21,872 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1944e4cd40084eba819281b6bd381693, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:24,081 [DEBUG] app1.py:1214 - Speech recognizing: it's a component
2024-12-02 17:40:24,081 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=40b28323dbad4404bb1eb925aea3aa19, text="it's a component", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:24,676 [DEBUG] app1.py:1214 - Speech recognizing: it's a component enakku
2024-12-02 17:40:24,677 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2d30269a213b4f588711f80dc47ddce4, text="it's a component enakku", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:25,079 [DEBUG] app1.py:1214 - Speech recognizing: it's a component in a kichbi
2024-12-02 17:40:25,080 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=67ce6f2081074594baa066890e0676b6, text="it's a component in a kichbi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:25,387 [DEBUG] app1.py:1214 - Speech recognizing: it's a component in a kichbi aisle
2024-12-02 17:40:25,388 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0bfc3bf0583447a9bae657472bcc6ded, text="it's a component in a kichbi aisle", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:25,683 [DEBUG] app1.py:1214 - Speech recognizing: it's a component in a kichbi aisle curry
2024-12-02 17:40:25,684 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=053e3560f5d44a59a522e76adc416dee, text="it's a component in a kichbi aisle curry", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:25,979 [DEBUG] app1.py:1214 - Speech recognizing: it's a component in a kichbi aisle curry on time
2024-12-02 17:40:25,979 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9331071d19dc4bc095666179639f4056, text="it's a component in a kichbi aisle curry on time", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:27,857 [INFO] app1.py:1205 - Speech recognized: It's a component in a kichbi aisle current.
2024-12-02 17:40:27,858 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf95befb05984786831f8eaf34d0c0ee, text="It's a component in a kichbi aisle current.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:32,916 [INFO] app1.py:898 - Active clients: []
2024-12-02 17:40:39,614 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:40:39,615 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=126ac24510c745c38b98f8c32f2f14d7, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:39,877 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:40:39,878 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ee7d25a9fbb64e4693d3c7c2f7207dc3, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:41,816 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:40:41,817 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:40:41,817 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:40:41,818 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:40:41,818 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:40:41,819 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:40:41,824 [DEBUG] app1.py:1104 - Sending transcription: ethiopian (is_final: False)
2024-12-02 17:40:41,828 [DEBUG] app1.py:1104 - Sending transcription: ethiopian trigger (is_final: False)
2024-12-02 17:40:41,830 [DEBUG] app1.py:1104 - Sending transcription: ethiopian trigger at home (is_final: False)
2024-12-02 17:40:41,836 [DEBUG] app1.py:1104 - Sending transcription: ethiopian trigger at home is (is_final: False)
2024-12-02 17:40:41,838 [DEBUG] app1.py:1104 - Sending transcription: ethiopian trigger at home abhishek (is_final: False)
2024-12-02 17:40:41,851 [DEBUG] app1.py:1104 - Sending transcription: Ethiopian trigger at home. Abhishek. (is_final: True)
2024-12-02 17:40:41,865 [DEBUG] app1.py:1104 - Sending transcription: play (is_final: False)
2024-12-02 17:40:41,866 [DEBUG] app1.py:1104 - Sending transcription: play delhi pyar hai (is_final: False)
2024-12-02 17:40:41,867 [DEBUG] app1.py:1104 - Sending transcription: Play Delhi, Paris. (is_final: True)
2024-12-02 17:40:41,870 [DEBUG] app1.py:1104 - Sending transcription: translator (is_final: False)
2024-12-02 17:40:41,871 [DEBUG] app1.py:1104 - Sending transcription: Translator. (is_final: True)
2024-12-02 17:40:41,874 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:40:41,875 [DEBUG] app1.py:1104 - Sending transcription: provided (is_final: False)
2024-12-02 17:40:41,876 [DEBUG] app1.py:1104 - Sending transcription: provided trans (is_final: False)
2024-12-02 17:40:41,877 [DEBUG] app1.py:1104 - Sending transcription: provided transcription (is_final: False)
2024-12-02 17:40:41,879 [DEBUG] app1.py:1104 - Sending transcription: Provided transcription. (is_final: True)
2024-12-02 17:40:41,879 [DEBUG] app1.py:1104 - Sending transcription: we can go (is_final: False)
2024-12-02 17:40:41,881 [DEBUG] app1.py:1104 - Sending transcription: we can go live (is_final: False)
2024-12-02 17:40:41,886 [DEBUG] app1.py:1104 - Sending transcription: We can go live. (is_final: True)
2024-12-02 17:40:41,886 [DEBUG] app1.py:1104 - Sending transcription: ceremony (is_final: False)
2024-12-02 17:40:41,897 [DEBUG] app1.py:1104 - Sending transcription: ceremony join (is_final: False)
2024-12-02 17:40:41,898 [DEBUG] app1.py:1104 - Sending transcription: ceremony (is_final: False)
2024-12-02 17:40:41,900 [DEBUG] app1.py:1104 - Sending transcription: ceremony join (is_final: False)
2024-12-02 17:40:41,901 [DEBUG] app1.py:1214 - Speech recognizing: shubham
2024-12-02 17:40:41,901 [DEBUG] app1.py:1104 - Sending transcription: ceremony (is_final: False)
2024-12-02 17:40:41,902 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=37291ee603134ee59e54c704d90aadca, text="shubham", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:41,904 [DEBUG] app1.py:1104 - Sending transcription: Ceremony. (is_final: True)
2024-12-02 17:40:41,904 [DEBUG] app1.py:1104 - Sending transcription: And. (is_final: True)
2024-12-02 17:40:41,905 [DEBUG] app1.py:1104 - Sending transcription: replay (is_final: False)
2024-12-02 17:40:41,905 [DEBUG] app1.py:1104 - Sending transcription: replay namma (is_final: False)
2024-12-02 17:40:41,907 [DEBUG] app1.py:1104 - Sending transcription: replay namma tum (is_final: False)
2024-12-02 17:40:41,909 [DEBUG] app1.py:1104 - Sending transcription: replay namma tumse (is_final: False)
2024-12-02 17:40:41,913 [DEBUG] app1.py:1104 - Sending transcription: replay namma tumse female (is_final: False)
2024-12-02 17:40:41,914 [DEBUG] app1.py:1104 - Sending transcription: replay namma tumse female vyap (is_final: False)
2024-12-02 17:40:41,915 [DEBUG] app1.py:1104 - Sending transcription: replay namma tumse female vyapam (is_final: False)
2024-12-02 17:40:41,917 [DEBUG] app1.py:1104 - Sending transcription: Replay Namma Tumse female. (is_final: True)
2024-12-02 17:40:41,917 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:40:41,917 [DEBUG] app1.py:1104 - Sending transcription: easy app (is_final: False)
2024-12-02 17:40:41,918 [DEBUG] app1.py:1104 - Sending transcription: easy app component (is_final: False)
2024-12-02 17:40:41,918 [DEBUG] app1.py:1104 - Sending transcription: easy app component app (is_final: False)
2024-12-02 17:40:41,919 [DEBUG] app1.py:1104 - Sending transcription: Easy app Component app. (is_final: True)
2024-12-02 17:40:41,920 [DEBUG] app1.py:1104 - Sending transcription: it it already (is_final: False)
2024-12-02 17:40:41,920 [DEBUG] app1.py:1104 - Sending transcription: it's already handy (is_final: False)
2024-12-02 17:40:41,922 [DEBUG] app1.py:1104 - Sending transcription: It it already got. (is_final: True)
2024-12-02 17:40:41,922 [DEBUG] app1.py:1104 - Sending transcription: i (is_final: False)
2024-12-02 17:40:41,926 [DEBUG] app1.py:1104 - Sending transcription: i want (is_final: False)
2024-12-02 17:40:41,927 [DEBUG] app1.py:1104 - Sending transcription: i want here (is_final: False)
2024-12-02 17:40:41,928 [DEBUG] app1.py:1104 - Sending transcription: I want here. (is_final: True)
2024-12-02 17:40:41,928 [DEBUG] app1.py:1104 - Sending transcription: When I. (is_final: True)
2024-12-02 17:40:41,932 [DEBUG] app1.py:1104 - Sending transcription: start start (is_final: False)
2024-12-02 17:40:41,933 [DEBUG] app1.py:1104 - Sending transcription: start start speaking (is_final: False)
2024-12-02 17:40:41,933 [DEBUG] app1.py:1104 - Sending transcription: Start. Start speaking. (is_final: True)
2024-12-02 17:40:41,935 [DEBUG] app1.py:1104 - Sending transcription: from (is_final: False)
2024-12-02 17:40:41,935 [DEBUG] app1.py:1104 - Sending transcription: from my (is_final: False)
2024-12-02 17:40:41,935 [DEBUG] app1.py:1104 - Sending transcription: from my first (is_final: False)
2024-12-02 17:40:41,936 [DEBUG] app1.py:1104 - Sending transcription: from my first page (is_final: False)
2024-12-02 17:40:41,936 [DEBUG] app1.py:1104 - Sending transcription: From my first page. (is_final: True)
2024-12-02 17:40:41,936 [DEBUG] app1.py:1104 - Sending transcription: men only (is_final: False)
2024-12-02 17:40:41,938 [DEBUG] app1.py:1104 - Sending transcription: men only STT (is_final: False)
2024-12-02 17:40:41,938 [DEBUG] app1.py:1104 - Sending transcription: Men only STT. (is_final: True)
2024-12-02 17:40:41,938 [DEBUG] app1.py:1104 - Sending transcription: play (is_final: False)
2024-12-02 17:40:41,943 [DEBUG] app1.py:1104 - Sending transcription: play movie (is_final: False)
2024-12-02 17:40:41,945 [DEBUG] app1.py:1104 - Sending transcription: play movie STD (is_final: False)
2024-12-02 17:40:41,946 [DEBUG] app1.py:1104 - Sending transcription: Play Movie STD. (is_final: True)
2024-12-02 17:40:41,947 [DEBUG] app1.py:1104 - Sending transcription: STT (is_final: False)
2024-12-02 17:40:41,948 [DEBUG] app1.py:1104 - Sending transcription: STT. (is_final: True)
2024-12-02 17:40:41,948 [DEBUG] app1.py:1104 - Sending transcription: work (is_final: False)
2024-12-02 17:40:41,949 [DEBUG] app1.py:1104 - Sending transcription: Work. (is_final: True)
2024-12-02 17:40:41,949 [DEBUG] app1.py:1104 - Sending transcription: and (is_final: False)
2024-12-02 17:40:41,949 [DEBUG] app1.py:1104 - Sending transcription: and when (is_final: False)
2024-12-02 17:40:41,951 [DEBUG] app1.py:1104 - Sending transcription: and when and (is_final: False)
2024-12-02 17:40:41,951 [DEBUG] app1.py:1104 - Sending transcription: and when and in (is_final: False)
2024-12-02 17:40:41,951 [DEBUG] app1.py:1104 - Sending transcription: and when and in my (is_final: False)
2024-12-02 17:40:41,952 [DEBUG] app1.py:1104 - Sending transcription: and when and in my second (is_final: False)
2024-12-02 17:40:41,952 [DEBUG] app1.py:1104 - Sending transcription: and when and in my second page (is_final: False)
2024-12-02 17:40:41,957 [DEBUG] app1.py:1104 - Sending transcription: And when and in my second page. (is_final: True)
2024-12-02 17:40:41,959 [DEBUG] app1.py:1104 - Sending transcription: 7 (is_final: False)
2024-12-02 17:40:41,960 [DEBUG] app1.py:1104 - Sending transcription: 7/3. (is_final: True)
2024-12-02 17:40:41,964 [DEBUG] app1.py:1104 - Sending transcription: i (is_final: False)
2024-12-02 17:40:41,964 [DEBUG] app1.py:1104 - Sending transcription: i listen (is_final: False)
2024-12-02 17:40:41,966 [DEBUG] app1.py:1104 - Sending transcription: i listened to (is_final: False)
2024-12-02 17:40:41,966 [DEBUG] app1.py:1104 - Sending transcription: i listened that (is_final: False)
2024-12-02 17:40:41,966 [DEBUG] app1.py:1104 - Sending transcription: i listened to that response (is_final: False)
2024-12-02 17:40:41,967 [DEBUG] app1.py:1104 - Sending transcription: i listened that response (is_final: False)
2024-12-02 17:40:41,967 [DEBUG] app1.py:1104 - Sending transcription: i listened to that response (is_final: False)
2024-12-02 17:40:41,967 [DEBUG] app1.py:1104 - Sending transcription: i listened to that response with (is_final: False)
2024-12-02 17:40:41,968 [DEBUG] app1.py:1104 - Sending transcription: i listened to that response with multiple (is_final: False)
2024-12-02 17:40:41,968 [DEBUG] app1.py:1104 - Sending transcription: i listened to that response with multiple language (is_final: False)
2024-12-02 17:40:41,968 [DEBUG] app1.py:1104 - Sending transcription: I listened to that response with multiple language. (is_final: True)
2024-12-02 17:40:41,970 [DEBUG] app1.py:1104 - Sending transcription: multiple (is_final: False)
2024-12-02 17:40:41,971 [DEBUG] app1.py:1104 - Sending transcription: multiple language (is_final: False)
2024-12-02 17:40:41,976 [DEBUG] app1.py:1104 - Sending transcription: Multiple language. (is_final: True)
2024-12-02 17:40:41,978 [DEBUG] app1.py:1104 - Sending transcription: help (is_final: False)
2024-12-02 17:40:41,978 [DEBUG] app1.py:1104 - Sending transcription: help go to TDS (is_final: False)
2024-12-02 17:40:41,982 [DEBUG] app1.py:1104 - Sending transcription: help to TDS (is_final: False)
2024-12-02 17:40:41,982 [DEBUG] app1.py:1104 - Sending transcription: Help to TDs. (is_final: True)
2024-12-02 17:40:41,983 [DEBUG] app1.py:1104 - Sending transcription: TS (is_final: False)
2024-12-02 17:40:41,983 [DEBUG] app1.py:1104 - Sending transcription: TST (is_final: False)
2024-12-02 17:40:41,985 [DEBUG] app1.py:1104 - Sending transcription: TSTT (is_final: False)
2024-12-02 17:40:41,985 [DEBUG] app1.py:1104 - Sending transcription: TSTTS (is_final: False)
2024-12-02 17:40:41,985 [DEBUG] app1.py:1104 - Sending transcription: TSTTS 0. (is_final: True)
2024-12-02 17:40:41,986 [DEBUG] app1.py:1104 - Sending transcription: here i see (is_final: False)
2024-12-02 17:40:41,986 [DEBUG] app1.py:1104 - Sending transcription: here i see a space (is_final: False)
2024-12-02 17:40:41,986 [DEBUG] app1.py:1104 - Sending transcription: here i see a space the (is_final: False)
2024-12-02 17:40:41,987 [DEBUG] app1.py:1104 - Sending transcription: here i see a space name (is_final: False)
2024-12-02 17:40:41,996 [DEBUG] app1.py:1104 - Sending transcription: Here I see a space name on that. (is_final: True)
2024-12-02 17:40:41,997 [DEBUG] app1.py:1104 - Sending transcription: here here i (is_final: False)
2024-12-02 17:40:41,997 [DEBUG] app1.py:1104 - Sending transcription: here here i found some (is_final: False)
2024-12-02 17:40:41,999 [DEBUG] app1.py:1104 - Sending transcription: here here i found some problem (is_final: False)
2024-12-02 17:40:42,001 [DEBUG] app1.py:1104 - Sending transcription: Here here I found some problem. (is_final: True)
2024-12-02 17:40:42,001 [DEBUG] app1.py:1104 - Sending transcription: aiims (is_final: False)
2024-12-02 17:40:42,002 [DEBUG] app1.py:1104 - Sending transcription: aiims of government (is_final: False)
2024-12-02 17:40:42,003 [DEBUG] app1.py:1104 - Sending transcription: aiims of government when (is_final: False)
2024-12-02 17:40:42,010 [DEBUG] app1.py:1104 - Sending transcription: AIIMS. (is_final: True)
2024-12-02 17:40:42,012 [DEBUG] app1.py:1104 - Sending transcription: i am speak (is_final: False)
2024-12-02 17:40:42,015 [DEBUG] app1.py:1104 - Sending transcription: speak in (is_final: False)
2024-12-02 17:40:42,015 [DEBUG] app1.py:1104 - Sending transcription: speak in life (is_final: False)
2024-12-02 17:40:42,016 [DEBUG] app1.py:1104 - Sending transcription: speak in life segment page (is_final: False)
2024-12-02 17:40:42,017 [DEBUG] app1.py:1104 - Sending transcription: Speak in life. (is_final: True)
2024-12-02 17:40:42,017 [DEBUG] app1.py:1104 - Sending transcription: live 7 (is_final: False)
2024-12-02 17:40:42,019 [DEBUG] app1.py:1104 - Sending transcription: live 7 days (is_final: False)
2024-12-02 17:40:42,020 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then (is_final: False)
2024-12-02 17:40:42,020 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then it (is_final: False)
2024-12-02 17:40:42,044 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then it also (is_final: False)
2024-12-02 17:40:42,048 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then it also listens (is_final: False)
2024-12-02 17:40:42,049 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then it also listens to (is_final: False)
2024-12-02 17:40:42,063 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then it also listens to then (is_final: False)
2024-12-02 17:40:42,064 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then it also listens then it (is_final: False)
2024-12-02 17:40:42,065 [DEBUG] app1.py:1104 - Sending transcription: live 7 days then it also listens then it also (is_final: False)
2024-12-02 17:40:42,067 [DEBUG] app1.py:1104 - Sending transcription: Live 7 days then it also listens then it also. (is_final: True)
2024-12-02 17:40:42,077 [DEBUG] app1.py:1104 - Sending transcription: listen (is_final: False)
2024-12-02 17:40:42,078 [DEBUG] app1.py:1104 - Sending transcription: Listen, I will. (is_final: True)
2024-12-02 17:40:42,081 [DEBUG] app1.py:1104 - Sending transcription: don't need (is_final: False)
2024-12-02 17:40:42,083 [DEBUG] app1.py:1104 - Sending transcription: don't need that (is_final: False)
2024-12-02 17:40:42,083 [DEBUG] app1.py:1104 - Sending transcription: Don't need that. (is_final: True)
2024-12-02 17:40:42,084 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:40:42,084 [DEBUG] app1.py:1104 - Sending transcription: can you tell the gate in (is_final: False)
2024-12-02 17:40:42,085 [DEBUG] app1.py:1104 - Sending transcription: the 18 volvo (is_final: False)
2024-12-02 17:40:42,085 [DEBUG] app1.py:1104 - Sending transcription: The 18 Volvo. (is_final: True)
2024-12-02 17:40:42,087 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:40:42,087 [DEBUG] app1.py:1104 - Sending transcription: hello how are (is_final: False)
2024-12-02 17:40:42,087 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 17:40:42,088 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? (is_final: True)
2024-12-02 17:40:42,089 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:40:42,093 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:40:42,095 [DEBUG] app1.py:1104 - Sending transcription: it's a component (is_final: False)
2024-12-02 17:40:42,096 [DEBUG] app1.py:1104 - Sending transcription: it's a component enakku (is_final: False)
2024-12-02 17:40:42,096 [DEBUG] app1.py:1104 - Sending transcription: it's a component in a kichbi (is_final: False)
2024-12-02 17:40:42,097 [DEBUG] app1.py:1104 - Sending transcription: it's a component in a kichbi aisle (is_final: False)
2024-12-02 17:40:42,097 [DEBUG] app1.py:1104 - Sending transcription: it's a component in a kichbi aisle curry (is_final: False)
2024-12-02 17:40:42,098 [DEBUG] app1.py:1104 - Sending transcription: it's a component in a kichbi aisle curry on time (is_final: False)
2024-12-02 17:40:42,098 [DEBUG] app1.py:1104 - Sending transcription: It's a component in a kichbi aisle current. (is_final: True)
2024-12-02 17:40:42,100 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:40:42,101 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:40:42,103 [DEBUG] app1.py:1104 - Sending transcription: shubham (is_final: False)
2024-12-02 17:40:42,198 [DEBUG] app1.py:1214 - Speech recognizing: shubhangi
2024-12-02 17:40:42,199 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8f21b30ab814435d9621ce9e2972fb68, text="shubhangi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:42,200 [DEBUG] app1.py:1104 - Sending transcription: shubhangi (is_final: False)
2024-12-02 17:40:42,400 [DEBUG] app1.py:1214 - Speech recognizing: shubham meenal
2024-12-02 17:40:42,401 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=efd59f4d7f414462a133817880866a4b, text="shubham meenal", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:42,404 [DEBUG] app1.py:1104 - Sending transcription: shubham meenal (is_final: False)
2024-12-02 17:40:42,861 [INFO] app1.py:1205 - Speech recognized: Shubhangi Nagar.
2024-12-02 17:40:42,862 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=15770124b4cf4646b836daf7f18c8558, text="Shubhangi Nagar.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:42,863 [DEBUG] app1.py:1104 - Sending transcription: Shubhangi Nagar. (is_final: True)
2024-12-02 17:40:48,090 [DEBUG] app1.py:1214 - Speech recognizing: nicki minaj
2024-12-02 17:40:48,091 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=20a947cbd48742ed85162466ee5aa10c, text="nicki minaj", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:48,092 [DEBUG] app1.py:1104 - Sending transcription: nicki minaj (is_final: False)
2024-12-02 17:40:48,902 [INFO] app1.py:1205 - Speech recognized: Liquid, hi.
2024-12-02 17:40:48,903 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=712e8ce7c2c04ae8832ff20ad01107db, text="Liquid, hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:40:48,904 [DEBUG] app1.py:1104 - Sending transcription: Liquid, hi. (is_final: True)
2024-12-02 17:40:52,363 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 17:40:52,570 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 17:40:55,134 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 17:40:55,146 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:40:55,161 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:40:55,166 [INFO] app1.py:1121 - New translation stream connection for client: d5f39e3f-1590-4632-8331-dd14565d65a0, language: es
2024-12-02 17:40:55,168 [INFO] app1.py:1131 - Creating new client connection: d5f39e3f-1590-4632-8331-dd14565d65a0
2024-12-02 17:40:55,237 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 17:40:55,409 [INFO] app1.py:1240 - Audio stream started
2024-12-02 17:40:59,299 [DEBUG] app1.py:1214 - Speech recognizing: hi hello
2024-12-02 17:40:59,300 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1a4af6f8b2f144dda19da7a01373e022, text="hi hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:40:59,301 [DEBUG] app1.py:1104 - Sending transcription: hi hello (is_final: False)
2024-12-02 17:40:59,382 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:40:59,384 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi hello', Target: es, Client: d5f39e3f-1590-4632-8331-dd14565d65a0, Final: False
2024-12-02 17:40:59,384 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:41:00,102 [INFO] app1.py:1205 - Speech recognized: Hi. Hello.
2024-12-02 17:41:00,102 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d90f944188254cb288fce5b838752f11, text="Hi. Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:41:00,104 [DEBUG] app1.py:1104 - Sending transcription: Hi. Hello. (is_final: True)
2024-12-02 17:41:00,109 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:41:00,109 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi. Hello.', Target: es, Client: d5f39e3f-1590-4632-8331-dd14565d65a0, Final: True
2024-12-02 17:41:00,110 [DEBUG] app1.py:1042 - Normalized text: 'hi. hello.'
2024-12-02 17:41:00,110 [DEBUG] app1.py:1056 - Checking cache with key: hi. hello.:es
2024-12-02 17:41:00,112 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 17:41:00,113 [INFO] app1.py:933 - Starting translation request - Text: 'hi. hello.', Target language: es
2024-12-02 17:41:00,120 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 17:41:00,121 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 17:41:00,121 [DEBUG] app1.py:964 - Request body: [{'text': 'hi. hello.'}]
2024-12-02 17:41:00,688 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 17:41:00,690 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'hola. Hola.', 'to': 'es'}]}]
2024-12-02 17:41:00,690 [DEBUG] app1.py:974 - Extracted translation: hola. Hola.
2024-12-02 17:41:00,691 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi. hello.' -> Translation: 'hola. Hola.' (es)
2024-12-02 17:41:00,692 [DEBUG] app1.py:918 - Sending translation to client d5f39e3f-1590-4632-8331-dd14565d65a0: hola. Hola.
2024-12-02 17:41:00,692 [DEBUG] app1.py:925 - Translation sent successfully to client d5f39e3f-1590-4632-8331-dd14565d65a0
2024-12-02 17:41:00,694 [DEBUG] app1.py:1144 - Sending message to client d5f39e3f-1590-4632-8331-dd14565d65a0: {'type': 'final', 'translation': 'hola. Hola.'}
2024-12-02 17:41:00,700 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'hola. Hola.', Language: es
2024-12-02 17:41:00,708 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0b8dad76-6435-4ae3-8ac8-e10504091b59.wav
2024-12-02 17:41:00,713 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 17:41:01,576 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 17:41:01,577 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_0b8dad76-6435-4ae3-8ac8-e10504091b59.wav
2024-12-02 17:41:02,917 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:41:08,508 [DEBUG] app1.py:1214 - Speech recognizing: open
2024-12-02 17:41:08,509 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1db0f51c8bae4654a469ac5cc2baa6b2, text="open", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:41:08,510 [DEBUG] app1.py:1104 - Sending transcription: open (is_final: False)
2024-12-02 17:41:08,515 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:41:08,515 [DEBUG] app1.py:1031 - Received translation request - Text: 'open', Target: es, Client: d5f39e3f-1590-4632-8331-dd14565d65a0, Final: False
2024-12-02 17:41:08,516 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:41:20,286 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:41:20,286 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=669ba3e4c0cc4288a9b25443ebe1714b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:41:20,287 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:41:29,095 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:41:29,096 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=54b22e9505f64fd38d5f036a9749b18b, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:41:29,902 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:41:29,902 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=579c26a6f18c492aa59d6bcdfb5b07de, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:41:33,009 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:41:42,043 [DEBUG] app1.py:1214 - Speech recognizing: thinking
2024-12-02 17:41:42,043 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6089f3a588144f0e8703c0f896cd177c, text="thinking", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:41:42,314 [DEBUG] app1.py:1214 - Speech recognizing: thinking and
2024-12-02 17:41:42,316 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0923eceb628b422f8c5357efc1e1a95d, text="thinking and", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:41:42,998 [DEBUG] app1.py:1214 - Speech recognizing: thinking and i'll
2024-12-02 17:41:42,999 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aadca716d4fc4000941c0be68ea64c3d, text="thinking and i'll", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:41:43,200 [DEBUG] app1.py:1214 - Speech recognizing: thinking and i'll kill why without
2024-12-02 17:41:43,200 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=08006909ccc74f3c8bdb58bada3fd547, text="thinking and i'll kill why without", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:41:45,116 [INFO] app1.py:1205 - Speech recognized: Thinking and I'll kill. Why without?
2024-12-02 17:41:45,117 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3c3173f373d54cdfb6faf688e66341f5, text="Thinking and I'll kill. Why without?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:41:49,712 [INFO] app1.py:1205 - Speech recognized: You.
2024-12-02 17:41:49,712 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7184c4abf02f4574970cfc45a1ae22ff, text="You.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:42:03,071 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:42:08,406 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:42:08,406 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a40eb297b9b54a5e858f1af7797e65c7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:42:12,576 [DEBUG] app1.py:1214 - Speech recognizing: he tried to
2024-12-02 17:42:12,577 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ad98ee6dfaab4596839d6dbbf5f2735f, text="he tried to", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:12,890 [DEBUG] app1.py:1214 - Speech recognizing: he tried to both
2024-12-02 17:42:12,891 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9fa5a81611f34d3db5df60d97d77c73d, text="he tried to both", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:13,279 [DEBUG] app1.py:1214 - Speech recognizing: he tried to both component
2024-12-02 17:42:13,280 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cad60d4c623148ce9f9624f36baf7935, text="he tried to both component", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:13,480 [DEBUG] app1.py:1214 - Speech recognizing: he tried to both component properly
2024-12-02 17:42:13,482 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fcc210b6715e47318896a76e7e3f840a, text="he tried to both component properly", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:14,791 [DEBUG] app1.py:1214 - Speech recognizing: he tried to both component properly with full code
2024-12-02 17:42:14,792 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=05369829457849d2a1fd4f2f6cd05287, text="he tried to both component properly with full code", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:15,628 [INFO] app1.py:1205 - Speech recognized: He tried to both component properly with full code.
2024-12-02 17:42:15,630 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a13a1138ffca4c6b8fc8ea14a567f955, text="He tried to both component properly with full code.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:42:18,386 [DEBUG] app1.py:1214 - Speech recognizing: write
2024-12-02 17:42:18,387 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=49c237fa5f8141c899427ea63d785748, text="write", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:18,390 [INFO] app1.py:1205 - Speech recognized: Write.
2024-12-02 17:42:18,392 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=286782eb2c464505b9a2e1cea438a895, text="Write.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:42:22,903 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:42:22,904 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7c5eaad1d7304a199f8aecac74ababa7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:42:33,072 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:42:37,096 [DEBUG] app1.py:1214 - Speech recognizing: also
2024-12-02 17:42:37,096 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=520c512a27e64b868aef88e4c22795fe, text="also", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:38,199 [DEBUG] app1.py:1214 - Speech recognizing: also i
2024-12-02 17:42:38,200 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eb65bf6e88d24a0fbd20f9ac1c6649ee, text="also i", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:38,307 [DEBUG] app1.py:1214 - Speech recognizing: also
2024-12-02 17:42:38,308 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c1486c50859a4aaa888d2fdc61b68839, text="also", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:38,695 [DEBUG] app1.py:1214 - Speech recognizing: also i also give
2024-12-02 17:42:38,696 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=90479fcb31e34654a4bc83756f60876e, text="also i also give", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:39,006 [DEBUG] app1.py:1214 - Speech recognizing: also i also give me
2024-12-02 17:42:39,007 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=74af246502b54a17b0021e7117c953b9, text="also i also give me", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:40,204 [DEBUG] app1.py:1214 - Speech recognizing: also i also give me full
2024-12-02 17:42:40,204 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e2491b7f1405473d8ae5cf301fa4384b, text="also i also give me full", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:40,297 [DEBUG] app1.py:1214 - Speech recognizing: also i also give me full code
2024-12-02 17:42:40,297 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5c61e7ebab654df09e190db69edd9570, text="also i also give me full code", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:41,509 [DEBUG] app1.py:1214 - Speech recognizing: also i also give me full code of
2024-12-02 17:42:41,510 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4dacccddb60741369a6c2db19db55236, text="also i also give me full code of", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:42,612 [DEBUG] app1.py:1214 - Speech recognizing: also i also give me full code of both
2024-12-02 17:42:42,613 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc4bcfb5e2844f60a6784b77ef171474, text="also i also give me full code of both", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:43,203 [DEBUG] app1.py:1214 - Speech recognizing: also i also give me full code of both complaint
2024-12-02 17:42:43,204 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=49797e1ff0654b898b6947df00b6dc71, text="also i also give me full code of both complaint", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:43,500 [DEBUG] app1.py:1214 - Speech recognizing: also i also give me full code of both complaint correctly
2024-12-02 17:42:43,501 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6e8a877e1a774806a009aba5958cc331, text="also i also give me full code of both complaint correctly", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:42:45,367 [INFO] app1.py:1205 - Speech recognized: Also give me full code of both complaint correctly.
2024-12-02 17:42:45,369 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b8bbb59110c84ed6a785c5581fa6004a, text="Also give me full code of both complaint correctly.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:43:03,073 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:43:03,228 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 17:43:03,230 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=46e69aa5aaaa4614bc727bc3083fc826, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:43:06,002 [DEBUG] app1.py:1214 - Speech recognizing: broadcast
2024-12-02 17:43:06,003 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c144223d737148b38e7d32a9fccb0b1f, text="broadcast", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:06,200 [DEBUG] app1.py:1214 - Speech recognizing: broadcaster
2024-12-02 17:43:06,201 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b8d3a10c12a24130a05354e075ea87f1, text="broadcaster", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:08,118 [INFO] app1.py:1205 - Speech recognized: Broadcaster.
2024-12-02 17:43:08,119 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0ef76b11b1eb4d91bd099b5d49c2ad87, text="Broadcaster.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:43:24,098 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:43:24,099 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa47b110ab104519aa709deb10248e4e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:43:32,595 [DEBUG] app1.py:1214 - Speech recognizing: apple
2024-12-02 17:43:32,595 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2770585b686e4f44b460ed0176e46504, text="apple", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:32,985 [DEBUG] app1.py:1214 - Speech recognizing: apple app index
2024-12-02 17:43:32,986 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=393cc139a8c44b678fdfa92c73793f8a, text="apple app index", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:33,073 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:43:43,385 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:43:43,385 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4733f7b32a614aa69db7c0354d2b0351, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:43:47,333 [DEBUG] app1.py:1214 - Speech recognizing: julie
2024-12-02 17:43:47,333 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9981c9ca9fd841b7a74ed1c4316eaafc, text="julie", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:47,798 [DEBUG] app1.py:1214 - Speech recognizing: julie dithya
2024-12-02 17:43:47,799 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f486afcc44ef44bfa123c7eab6fe0e9e, text="julie dithya", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:47,905 [DEBUG] app1.py:1214 - Speech recognizing: julie dithya nearer
2024-12-02 17:43:47,906 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6056a4e6129e4bd79e950f8226ec1034, text="julie dithya nearer", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:48,540 [INFO] app1.py:1205 - Speech recognized: Julie Dithya Nearer.
2024-12-02 17:43:48,541 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=35b9feea0a6e45988cbcca1b216ab95a, text="Julie Dithya Nearer.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:43:57,802 [DEBUG] app1.py:1214 - Speech recognizing: i want to go
2024-12-02 17:43:57,803 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1bc28d3dfa294c49adf44a9dbed70751, text="i want to go", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:58,192 [DEBUG] app1.py:1214 - Speech recognizing: i want to go live
2024-12-02 17:43:58,193 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f550827559d04599b055894fa269de5c, text="i want to go live", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:58,394 [DEBUG] app1.py:1214 - Speech recognizing: i want to go live with
2024-12-02 17:43:58,395 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c69dd088d0dc47e9a4f3814975528475, text="i want to go live with", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:58,795 [DEBUG] app1.py:1214 - Speech recognizing: i want to go live with it
2024-12-02 17:43:58,796 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=67c8b12fe28c469ba3c10ba29914a31b, text="i want to go live with it", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:59,094 [DEBUG] app1.py:1214 - Speech recognizing: i want to go live with a
2024-12-02 17:43:59,094 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=26dc7f29ba39424091892873a03798a9, text="i want to go live with a", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:43:59,141 [INFO] app1.py:1205 - Speech recognized: I want to go live with a.
2024-12-02 17:43:59,143 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b72e18fbd7044113a802b59001c0f929, text="I want to go live with a.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:44:03,075 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:44:19,336 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:44:19,337 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=405998a0622348d3a81604597a084950, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:44:33,077 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:44:34,543 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:44:34,544 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b875016396fa4da48c747e6dfde2e1a2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:44:36,084 [DEBUG] app1.py:1214 - Speech recognizing: to write
2024-12-02 17:44:36,085 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0b1676e1e41c4d2e866c7a5dcb7f8e7c, text="to write", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:44:36,787 [DEBUG] app1.py:1214 - Speech recognizing: to write a second page
2024-12-02 17:44:36,789 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b2b6b9d95ea44b4fa3c976f7b38f4d17, text="to write a second page", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:44:38,620 [INFO] app1.py:1205 - Speech recognized: To write the second page.
2024-12-02 17:44:38,621 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ef97afbd33654442beaa1658f57cb7a3, text="To write the second page.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:44:40,019 [DEBUG] app1.py:1214 - Speech recognizing: 9
2024-12-02 17:44:40,019 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fd5e3db051e848a9905a298e3f405221, text="9", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:44:40,114 [DEBUG] app1.py:1214 - Speech recognizing: 944
2024-12-02 17:44:40,114 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e2876c149dc14e7cbbf6d9d0f2f7aa92, text="944", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:44:42,012 [INFO] app1.py:1205 - Speech recognized: 944.
2024-12-02 17:44:42,013 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=188972cffa364d6daefd5732949ab9c1, text="944.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:44:46,913 [INFO] app1.py:1205 - Speech recognized: 6.
2024-12-02 17:44:46,914 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=295e4192b2a3400fa542d5c41b033ef0, text="6.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:45:03,078 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:45:07,018 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:45:07,018 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=380fcd950fe4473fa04a1354cc094de0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:45:22,127 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:45:22,128 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e25efb2adb4a459db6fd97a196b9eecd, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:45:30,883 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:45:30,884 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0dedac4359f0486a9f4a3ae63d3db026, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:45:31,086 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 17:45:31,088 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=acd846c644864485b93934289fec7b6d, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:45:33,080 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:45:40,106 [DEBUG] app1.py:1214 - Speech recognizing: hello hi hello
2024-12-02 17:45:40,107 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1bf581a4f3e04cda9ee13eaa220564d8, text="hello hi hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:45:41,686 [INFO] app1.py:1205 - Speech recognized: Hi. Hello.
2024-12-02 17:45:41,686 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=59f340fb724a462b846826ee416521e2, text="Hi. Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:45:42,480 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:45:42,481 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c3b2b912cda4ede92e4d80adbd01387, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:45:43,398 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:45:43,398 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f70aea02b6cf44cda606f684a2985b4d, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:45:53,094 [DEBUG] app1.py:1214 - Speech recognizing: type of
2024-12-02 17:45:53,095 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=79181dee1aea40d1afc9992d0deed601, text="type of", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:45:53,977 [DEBUG] app1.py:1214 - Speech recognizing: type of india
2024-12-02 17:45:53,978 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1138120c773845249a3ba86d55adddc2, text="type of india", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:45:55,808 [INFO] app1.py:1205 - Speech recognized: Type of India.
2024-12-02 17:45:55,808 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cee4e68b17714976a74f963ab68a0cdb, text="Type of India.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:46:03,081 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:46:03,574 [DEBUG] app1.py:1214 - Speech recognizing: hafiz
2024-12-02 17:46:03,574 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=edfdc3c83e2c43eea87cd81352afcd48, text="hafiz", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:03,777 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharrah gives
2024-12-02 17:46:03,777 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ae0e4a9462344e7697b536b7fc0e8702, text="hafiz muharrah gives", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:04,184 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharrah gives twitter
2024-12-02 17:46:04,185 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c668a5d591604b459bfff2a4b682fca4, text="hafiz muharrah gives twitter", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:04,479 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharraq's twitter has been
2024-12-02 17:46:04,479 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=87b3c0674ed6480eb51ef1fbeed29786, text="hafiz muharraq's twitter has been", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:05,681 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharraq's twitter has been PH
2024-12-02 17:46:05,682 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5a9fc4b99bc24ea08cbffd73581a90ca, text="hafiz muharraq's twitter has been PH", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:06,086 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharraq's twitter has been PHD
2024-12-02 17:46:06,087 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=15a20aa4d04a40e9b69b21d2fc8c0d1b, text="hafiz muharraq's twitter has been PHD", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:07,372 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharraq's twitter has been PHDS
2024-12-02 17:46:07,373 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6e5e0c311b7f4578848cc531896e4d9b, text="hafiz muharraq's twitter has been PHDS", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:07,685 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharraq's twitter has been PHDS infrastructure
2024-12-02 17:46:07,687 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cad3fcd17fec486fabb89e8d238277c9, text="hafiz muharraq's twitter has been PHDS infrastructure", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:08,679 [DEBUG] app1.py:1214 - Speech recognizing: hafiz muharraq's twitter has been PHDS infrastructure ID
2024-12-02 17:46:08,700 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=64498b0688834e78b89b22c562c28acb, text="hafiz muharraq's twitter has been PHDS infrastructure ID", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:10,542 [INFO] app1.py:1205 - Speech recognized: Hafiz Muharraq's Twitter has been PhDs infrastructure.
2024-12-02 17:46:10,544 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5c057692006340829390df0981b5d887, text="Hafiz Muharraq's Twitter has been PhDs infrastructure.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:46:15,881 [DEBUG] app1.py:1214 - Speech recognizing: basically
2024-12-02 17:46:15,882 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4983dd798e8443e292d0c6e8521939b4, text="basically", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:16,194 [DEBUG] app1.py:1214 - Speech recognizing: basically england
2024-12-02 17:46:16,195 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d8848a1b9bbb45aaa38dd5d5441f85ca, text="basically england", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:16,398 [DEBUG] app1.py:1214 - Speech recognizing: basically england ah
2024-12-02 17:46:16,399 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6300ff4856f2433c95bbef8dce1a5442, text="basically england ah", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:16,490 [DEBUG] app1.py:1214 - Speech recognizing: basically england the whole
2024-12-02 17:46:16,490 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f78f2aafcfa044c7a12702e26f68bf05, text="basically england the whole", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:16,786 [DEBUG] app1.py:1214 - Speech recognizing: basically england the whole katr
2024-12-02 17:46:16,787 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=839146852cea414883e43d45965520ea, text="basically england the whole katr", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:16,892 [DEBUG] app1.py:1214 - Speech recognizing: basically england the whole karratha
2024-12-02 17:46:16,893 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d4a95eab96c341569fdad185c97be09d, text="basically england the whole karratha", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:16,985 [DEBUG] app1.py:1214 - Speech recognizing: basically england the whole karratha video
2024-12-02 17:46:16,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d5064ab9ee1345fabb2f2f98ffcf0457, text="basically england the whole karratha video", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:17,093 [DEBUG] app1.py:1214 - Speech recognizing: basically england the whole karratha vito
2024-12-02 17:46:17,094 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b264fe62b387499eb5adc1983f088905, text="basically england the whole karratha vito", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:17,622 [INFO] app1.py:1205 - Speech recognized: Basically England. The whole Karratha video.
2024-12-02 17:46:17,622 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dfcf556d7120442a8f156ab2e7fcffce, text="Basically England. The whole Karratha video.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:46:33,082 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:46:37,611 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:46:37,611 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c43a4ceeda92423c818d31c4b7c1e91c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:46:39,881 [DEBUG] app1.py:1214 - Speech recognizing: code is
2024-12-02 17:46:39,883 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3f166323d2e64d489c2edc9382044b0a, text="code is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:40,084 [DEBUG] app1.py:1214 - Speech recognizing: code is applied
2024-12-02 17:46:40,085 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5585d3da8a4b48e08f4d53fd30190554, text="code is applied", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:40,483 [DEBUG] app1.py:1214 - Speech recognizing: code is the blind address
2024-12-02 17:46:40,484 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d241323033844d59905dc6268958663e, text="code is the blind address", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:40,685 [DEBUG] app1.py:1214 - Speech recognizing: code is applied address
2024-12-02 17:46:40,687 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=08fe5073d4244d9e8190b6d20653879b, text="code is applied address", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:40,981 [DEBUG] app1.py:1214 - Speech recognizing: code is applied address book
2024-12-02 17:46:40,983 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f1c934a0dc5148bbbaaebc03dca4072a, text="code is applied address book", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:41,335 [INFO] app1.py:1205 - Speech recognized: Code is applied address book.
2024-12-02 17:46:41,337 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c12e34a72c024dc9b6e507b90a2b768e, text="Code is applied address book.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:46:45,899 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 17:46:45,900 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=817f78bfa684429d81181c288e81eb8b, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:46:47,699 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:46:47,701 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7c9a220fbd4b4853b7b8354801605d75, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:47,813 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:46:47,814 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a9bba4980c984384ab2b4fe0a791c757, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:46:48,891 [DEBUG] app1.py:1214 - Speech recognizing: how are you
2024-12-02 17:46:48,892 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b21857ae9f643909be393e0ece31acb, text="how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:46:49,529 [INFO] app1.py:1205 - Speech recognized: How are you?
2024-12-02 17:46:49,530 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c1e1434ebf0541d9a22f6ec3373ba591, text="How are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:47:03,117 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:47:05,775 [DEBUG] app1.py:1214 - Speech recognizing: india
2024-12-02 17:47:05,775 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=df447bee1fd54b3186f29bda240761ca, text="india", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:06,384 [DEBUG] app1.py:1214 - Speech recognizing: india appointed
2024-12-02 17:47:06,385 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=918fbea00b174d519ae2e470eb79efdd, text="india appointed", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:06,479 [DEBUG] app1.py:1214 - Speech recognizing: india calendar for
2024-12-02 17:47:06,479 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eccf725a8c8b4f98990272d89fba5db8, text="india calendar for", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:06,619 [INFO] app1.py:1205 - Speech recognized: India appointed.
2024-12-02 17:47:06,619 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8dd77f6cedd84fdcaff97a9a64c3cf87, text="India appointed.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:47:13,873 [DEBUG] app1.py:1214 - Speech recognizing: nithya
2024-12-02 17:47:13,873 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2a60f0c6a45341cbb6e0c5fb50eafde7, text="nithya", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:14,775 [DEBUG] app1.py:1214 - Speech recognizing: nitin gadkari
2024-12-02 17:47:14,776 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=91cbda6d5c834b139dbbbc327273df43, text="nitin gadkari", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:25,494 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:47:25,495 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=68bfb1f0bb5440c0901a8134001bfac3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:47:33,149 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:47:41,810 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:47:41,810 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=54dfd76c58d8449db0811937327c64e6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:47:46,900 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:47:46,901 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=510489c2545a4e849a088ec588b73c2c, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:48,004 [DEBUG] app1.py:1214 - Speech recognizing: hello how are
2024-12-02 17:47:48,005 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=985e20d0584e4117be078e5f075fd7c8, text="hello how are", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:48,096 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 17:47:48,097 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dad34143678f4ef5a77fc5f17cdfb0d7, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:47:49,704 [INFO] app1.py:1205 - Speech recognized: Hello, how are you?
2024-12-02 17:47:49,705 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=31f9e6546e3a49cc8fb95bc92aed7cbc, text="Hello, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:47:58,973 [DEBUG] app1.py:1214 - Speech recognizing: working
2024-12-02 17:47:58,974 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=71e4a0e071dd4fa290ecffc4f3eeadf2, text="working", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:00,599 [INFO] app1.py:1205 - Speech recognized: Working.
2024-12-02 17:48:00,600 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=943c906db75e4b9f92fade15ac5794f5, text="Working.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:48:02,179 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:48:02,179 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3165e9cc8b684920b422731314179d8c, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:02,508 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:48:02,508 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=254437f0f4484df58e7792a677c9e131, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:48:03,151 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:48:06,998 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:48:06,999 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ae7fd70a55d2499592a25a93ec72ee9a, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:07,511 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:48:07,513 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5cdd97acb46a4a4da43ed1cea0987d9b, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:48:10,486 [DEBUG] app1.py:1214 - Speech recognizing: equally
2024-12-02 17:48:10,487 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=67a13cfd57024355953ef9558f5996e2, text="equally", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:11,013 [INFO] app1.py:1205 - Speech recognized: Equally enjoyable.
2024-12-02 17:48:11,014 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=13f32e09dde3498f9539a3566f391616, text="Equally enjoyable.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:48:12,781 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:48:12,782 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c294742f66514f3eb75d5cb5505d6f6f, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:13,495 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 17:48:13,496 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b02084cf89c34d4da993b9cdcd8d3f9c, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:14,781 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you what
2024-12-02 17:48:14,781 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b5f35fde9697496293cf931f783ab431, text="hello how are you what", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:14,998 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you what are you
2024-12-02 17:48:14,998 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1109853736df45b399506ecd343a10eb, text="hello how are you what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:15,093 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you what are you doing
2024-12-02 17:48:15,094 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=90a7156ba55041868be3ddce0d1a82f4, text="hello how are you what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:15,699 [INFO] app1.py:1205 - Speech recognized: Hello, how are you? What are you doing?
2024-12-02 17:48:15,700 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ae74baa49c414626ac220919e422bbc4, text="Hello, how are you? What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:48:33,153 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:48:35,507 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:48:35,508 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5c1bad7f4f054eabbc323e1f3d41bb31, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:48:50,922 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:48:50,922 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e02e9cd8c9c2485da7a8c3f15473df70, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:48:52,822 [DEBUG] app1.py:1214 - Speech recognizing: KDL
2024-12-02 17:48:52,823 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=94f049cddec546c69fd20faad631cde1, text="KDL", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:53,394 [DEBUG] app1.py:1214 - Speech recognizing: KDLAPI
2024-12-02 17:48:53,395 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=40dda5d616f240bb9705f517ec221b90, text="KDLAPI", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:53,800 [DEBUG] app1.py:1214 - Speech recognizing: KDLAPID data
2024-12-02 17:48:53,802 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7a9c43367e8c48f7a96ebe649066a0ff, text="KDLAPID data", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:54,002 [DEBUG] app1.py:1214 - Speech recognizing: KDLAPIT data
2024-12-02 17:48:54,003 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=364c9a41ac344afaabe28f7a5da7a6b4, text="KDLAPIT data", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:55,308 [DEBUG] app1.py:1214 - Speech recognizing: KDLAPIT data broadcast
2024-12-02 17:48:55,308 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fe3af374060f4f95a50fd779df23d509, text="KDLAPIT data broadcast", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:56,495 [DEBUG] app1.py:1214 - Speech recognizing: KDLAPID data broadcast
2024-12-02 17:48:56,496 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aaa71cf9da8f42c48a336ed250bd22e6, text="KDLAPID data broadcast", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:48:58,256 [INFO] app1.py:1205 - Speech recognized: KDLAPID data broadcast.
2024-12-02 17:48:58,257 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0f7ad1b5dcb241d38925f62953f9096f, text="KDLAPID data broadcast.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:01,494 [DEBUG] app1.py:1214 - Speech recognizing: broadcast
2024-12-02 17:49:01,495 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1311dd5020c24b2a93d748e08f449760, text="broadcast", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:03,155 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:49:03,314 [INFO] app1.py:1205 - Speech recognized: Broadcast.
2024-12-02 17:49:03,316 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=92875876779d486fba6d65e1dc833493, text="Broadcast.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:04,699 [DEBUG] app1.py:1214 - Speech recognizing: response
2024-12-02 17:49:04,699 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b428ff0785c64f22bdbc73c74b3a6c67, text="response", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:06,006 [DEBUG] app1.py:1214 - Speech recognizing: response control
2024-12-02 17:49:06,008 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=abe3d21560cb4d2fa2def3a01748b4e6, text="response control", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:07,417 [INFO] app1.py:1205 - Speech recognized: Response control.
2024-12-02 17:49:07,418 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3718b1a6e9e44a1ca27bae15dda64868, text="Response control.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:09,429 [DEBUG] app1.py:1214 - Speech recognizing: consolidated
2024-12-02 17:49:09,430 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0fc5434836fc4638ac5ac33b059611ed, text="consolidated", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:09,739 [DEBUG] app1.py:1214 - Speech recognizing: solidarity
2024-12-02 17:49:09,739 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4809d1b369584d6bb286cd610b7c369b, text="solidarity", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:10,126 [INFO] app1.py:1205 - Speech recognized: Solidarity.
2024-12-02 17:49:10,127 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=69f32cbd536c47db84f69affc98a924d, text="Solidarity.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:11,923 [DEBUG] app1.py:1214 - Speech recognizing: response
2024-12-02 17:49:11,924 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1795726b2ed4486696b17d3e740408b4, text="response", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:12,416 [DEBUG] app1.py:1214 - Speech recognizing: response garcons
2024-12-02 17:49:12,416 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=318e1d58b6c54bda863b4076b1fb7339, text="response garcons", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:12,822 [DEBUG] app1.py:1214 - Speech recognizing: response
2024-12-02 17:49:12,827 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2485f0da22f443f38ca5c2dbb156888f, text="response", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:12,869 [INFO] app1.py:1205 - Speech recognized: Response Car Consort.
2024-12-02 17:49:12,870 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7c7b0c7a561e4be4866e315baa361ae2, text="Response Car Consort.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:31,104 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:49:31,105 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c6e846f5d6ff4d1586de0352670b4114, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:33,156 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:49:34,978 [DEBUG] app1.py:1214 - Speech recognizing: american
2024-12-02 17:49:34,981 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=78eb15b838c640b3b2c791645878ac13, text="american", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:35,884 [DEBUG] app1.py:1214 - Speech recognizing: american tool
2024-12-02 17:49:35,885 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1ec1f3f81c9c45889e68f831a486165b, text="american tool", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:36,086 [INFO] app1.py:1205 - Speech recognized: American Trollis.
2024-12-02 17:49:36,086 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=57f41b6ac81943149e52aee82542336b, text="American Trollis.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:45,394 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:49:45,396 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=87cca8c140ba4e958358f019cf8f004b, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:46,592 [DEBUG] app1.py:1214 - Speech recognizing: hello how
2024-12-02 17:49:46,594 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8bd30cd6923a4af1a6d41a5acdda97a7, text="hello how", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:46,701 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 17:49:46,702 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f50d26bd89ca4910a1e304c0273290fe, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:49:47,617 [INFO] app1.py:1205 - Speech recognized: Hello, how are you?
2024-12-02 17:49:47,617 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=446dea2129984911a51472a6f2c1f0a7, text="Hello, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:49:58,672 [DEBUG] app1.py:1214 - Speech recognizing: jump rd
2024-12-02 17:49:58,673 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f9011462e9da46d68073cbc9e6fb0b03, text="jump rd", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:00,524 [INFO] app1.py:1205 - Speech recognized: Jump Rd.
2024-12-02 17:50:00,525 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=646ac5de15324f80b8b52f24938446ed, text="Jump Rd.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:50:03,157 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:50:20,804 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:50:20,809 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1dfcfef61451439fbd6952a435b85692, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:50:33,158 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:50:35,905 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:50:35,905 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7b7f9b0acd1546cda83c41789cc7b5f5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:50:38,297 [DEBUG] app1.py:1214 - Speech recognizing: listener listener
2024-12-02 17:50:38,298 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=07de5efd9a6f47ebab5d5eaeeac30605, text="listener listener", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:39,276 [INFO] app1.py:1205 - Speech recognized: Listener, listener.
2024-12-02 17:50:39,277 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d0731bc880174586a37ac3fa586b5d29, text="Listener, listener.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:50:41,300 [DEBUG] app1.py:1214 - Speech recognizing: post
2024-12-02 17:50:41,301 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ca5d11788f545f6955b5afb409e9798, text="post", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:41,596 [DEBUG] app1.py:1214 - Speech recognizing: postal gastonia
2024-12-02 17:50:41,597 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1eb56f7df2fa4fcb903aa44d5780ed7f, text="postal gastonia", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:41,904 [INFO] app1.py:1205 - Speech recognized: Postal Gastonia.
2024-12-02 17:50:41,904 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d743e46b5de14027b2c779d069550b53, text="Postal Gastonia.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:50:45,702 [DEBUG] app1.py:1214 - Speech recognizing: manulife
2024-12-02 17:50:45,703 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0fdf0f3136824d839235d49a2049401b, text="manulife", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:45,995 [DEBUG] app1.py:1214 - Speech recognizing: manulife and sold out
2024-12-02 17:50:45,996 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=61218772c4fb4a529098f10a4c2eb159, text="manulife and sold out", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:46,606 [DEBUG] app1.py:1214 - Speech recognizing: manulife and sold out low
2024-12-02 17:50:46,606 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=00264ae275424760a2535cd369251d16, text="manulife and sold out low", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:46,950 [INFO] app1.py:1205 - Speech recognized: Manulife and sold out low.
2024-12-02 17:50:46,953 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d4bd63c01b314ab090aff392ccd31b3a, text="Manulife and sold out low.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:50:53,490 [DEBUG] app1.py:1214 - Speech recognizing: spouse
2024-12-02 17:50:53,490 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bc48afd722ee473ea37cc061361b0fdd, text="spouse", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:57,890 [DEBUG] app1.py:1214 - Speech recognizing: engineering
2024-12-02 17:50:57,890 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3d151d94e35e4f578391588394f51fb7, text="engineering", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:58,292 [DEBUG] app1.py:1214 - Speech recognizing: engineering HIV
2024-12-02 17:50:58,293 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9b0b6d7185424c6781a683155a1b2e49, text="engineering HIV", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:58,494 [DEBUG] app1.py:1214 - Speech recognizing: engineering HIV data
2024-12-02 17:50:58,495 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e81b5e91e920444d810dcb367d8092dc, text="engineering HIV data", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:50:59,786 [DEBUG] app1.py:1214 - Speech recognizing: engineering HIV data positioning in duchess iw
2024-12-02 17:50:59,787 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=82a3906a8c9e4244847e4e899687726a, text="engineering HIV data positioning in duchess iw", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:00,201 [DEBUG] app1.py:1214 - Speech recognizing: engineering HIV data positioning in duchess iw duchess
2024-12-02 17:51:00,202 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=02dcbf164016458f9d413a28ced3c4db, text="engineering HIV data positioning in duchess iw duchess", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:00,487 [DEBUG] app1.py:1214 - Speech recognizing: engineering HIV data positioning in duchess iw duchess ID
2024-12-02 17:51:00,488 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=eb768ee78dcf428cace1ea982f71f28c, text="engineering HIV data positioning in duchess iw duchess ID", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:00,801 [DEBUG] app1.py:1214 - Speech recognizing: engineering HIV data positioning in duchess iw duchess ID API
2024-12-02 17:51:00,806 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=668162df0abd416283dd9e4e651cb3c5, text="engineering HIV data positioning in duchess iw duchess ID API", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:02,769 [INFO] app1.py:1205 - Speech recognized: Engineering HIV data positioning in Duchess IW Duchess API.
2024-12-02 17:51:02,769 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=15c259ffd31144b1b83ae4f37b3e0e87, text="Engineering HIV data positioning in Duchess IW Duchess API.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:51:03,159 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:51:11,102 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 17:51:11,103 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eba1fbbce96244a086f231d08ea635bf, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:51:26,593 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:51:26,594 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cc0d356d434147b7a6cd2029221dcc03, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:26,798 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 17:51:26,799 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f72c91bd78424451a55c2e58781b5ec5, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:27,719 [INFO] app1.py:1205 - Speech recognized: Hello, how are you?
2024-12-02 17:51:27,719 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=22d92b9964ea4f1fad9f9c0eb7572bb4, text="Hello, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:51:29,103 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 17:51:29,103 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dd099376467043bbb1a3fecdf7eca402, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:30,992 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing hi
2024-12-02 17:51:30,992 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=caff3957f6ae48ff85ef3255004d0f77, text="what are you doing hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:31,504 [INFO] app1.py:1205 - Speech recognized: What are you doing? Hi.
2024-12-02 17:51:31,505 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=76dbd60365914df3ae3e4630a2bce527, text="What are you doing? Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:51:33,160 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:51:38,287 [DEBUG] app1.py:1214 - Speech recognizing: play
2024-12-02 17:51:38,288 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=959b467fc7994ddbb33eabb52a553b4f, text="play", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:38,596 [DEBUG] app1.py:1214 - Speech recognizing: play kenny
2024-12-02 17:51:38,598 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=35ebfdc2f81848fbb81279af5d795673, text="play kenny", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:38,985 [DEBUG] app1.py:1214 - Speech recognizing: play kaniya dey
2024-12-02 17:51:38,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3181a3c7be5845209f7a23601539fc24, text="play kaniya dey", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:39,112 [INFO] app1.py:1205 - Speech recognized: Play Kenny Adele.
2024-12-02 17:51:39,113 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2d87df7ed8b949fd824027c94c39f6b3, text="Play Kenny Adele.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:51:41,293 [DEBUG] app1.py:1214 - Speech recognizing: it is
2024-12-02 17:51:41,294 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ef54668c2fd140a4828a21cd03985a4d, text="it is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:41,493 [DEBUG] app1.py:1214 - Speech recognizing: it is an
2024-12-02 17:51:41,494 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4aeeff67ceba4f81ad74e9c0de00b496, text="it is an", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:41,897 [DEBUG] app1.py:1214 - Speech recognizing: it is an original
2024-12-02 17:51:41,900 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=50e1db5e3042412b8bcda7637ce67944, text="it is an original", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:42,195 [DEBUG] app1.py:1214 - Speech recognizing: it is an original web thakart
2024-12-02 17:51:42,197 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3df063cd2fdf4a59bb7454de0c4ef771, text="it is an original web thakart", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:42,568 [INFO] app1.py:1205 - Speech recognized: It is an original web thakkartheon.
2024-12-02 17:51:42,569 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e9b81bfa7fbd40928815ab276e0e1339, text="It is an original web thakkartheon.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:51:50,609 [DEBUG] app1.py:1214 - Speech recognizing: automatic
2024-12-02 17:51:50,610 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8b249db65d5a4a38b3d24a09b8f7d896, text="automatic", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:51:51,712 [INFO] app1.py:1205 - Speech recognized: Automatic.
2024-12-02 17:51:51,714 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8bb76b20798a494aa24e377bafcb2f39, text="Automatic.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:03,162 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:52:04,910 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:52:04,911 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9ca80275b40245c09b68623a84c3261a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:07,507 [DEBUG] app1.py:1214 - Speech recognizing: speaker
2024-12-02 17:52:07,507 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0405a601f4d5437daca203e95607e638, text="speaker", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:09,310 [INFO] app1.py:1205 - Speech recognized: Speaker.
2024-12-02 17:52:09,311 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=07471f3d041043c598fba4d275943585, text="Speaker.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:10,910 [DEBUG] app1.py:1214 - Speech recognizing: response
2024-12-02 17:52:10,911 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=94d30a85a58241f9abb6953cc190c2ee, text="response", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:10,914 [INFO] app1.py:1205 - Speech recognized: Response.
2024-12-02 17:52:10,914 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=372dd4337b724ee596b890a2a1dc1fe2, text="Response.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:12,390 [DEBUG] app1.py:1214 - Speech recognizing: beating
2024-12-02 17:52:12,391 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4ef3446c269c42c3895b4331c28f418b, text="beating", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:12,592 [DEBUG] app1.py:1214 - Speech recognizing: beating horse
2024-12-02 17:52:12,593 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3af8f19bfb94436cbaf9900d50aaeb80, text="beating horse", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:14,150 [INFO] app1.py:1205 - Speech recognized: Beating Horse.
2024-12-02 17:52:14,167 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=93fa5789baf1420fb587d84d0780fc22, text="Beating Horse.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:23,014 [DEBUG] app1.py:1214 - Speech recognizing: illinois enna
2024-12-02 17:52:23,014 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ccc72474f4a4fa0a00bb74c7f119039, text="illinois enna", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:23,905 [DEBUG] app1.py:1214 - Speech recognizing: is
2024-12-02 17:52:23,906 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f82272e26ec34e5b9d1081363bc8f7a1, text="is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:24,216 [DEBUG] app1.py:1214 - Speech recognizing: illinois enna is speak
2024-12-02 17:52:24,216 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6255c1be30f848a0a7720f9904d402e9, text="illinois enna is speak", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:24,310 [DEBUG] app1.py:1214 - Speech recognizing: is speak collective
2024-12-02 17:52:24,311 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3edd24c8f8344b4e9d4575f17cdc7340, text="is speak collective", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:24,719 [DEBUG] app1.py:1214 - Speech recognizing: illinois enna is speak collective kenya
2024-12-02 17:52:24,719 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cd45409bd600490fbebc77d44d1064c7, text="illinois enna is speak collective kenya", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:24,933 [DEBUG] app1.py:1214 - Speech recognizing: illinois enna is speak collective can you all
2024-12-02 17:52:24,935 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c5970f7841eb4b50b2d703f891151678, text="illinois enna is speak collective can you all", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:25,215 [DEBUG] app1.py:1214 - Speech recognizing: illinois enna is speak collective can you all activate
2024-12-02 17:52:25,217 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cb19a731a1f8469e8d8705bd7c1aa0c9, text="illinois enna is speak collective can you all activate", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:25,981 [INFO] app1.py:1205 - Speech recognized: Is speak collective? Can you all activate?
2024-12-02 17:52:25,982 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=91306a5d7fb8401cb10291f845ef12c8, text="Is speak collective? Can you all activate?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:29,198 [DEBUG] app1.py:1214 - Speech recognizing: is
2024-12-02 17:52:29,198 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4b354e3a136c4c149e1e0e60f841300d, text="is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:29,399 [DEBUG] app1.py:1214 - Speech recognizing: is salman
2024-12-02 17:52:29,400 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e86175b3771e49c58b0ed2c87f14d763, text="is salman", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:29,695 [DEBUG] app1.py:1214 - Speech recognizing: is salman active in
2024-12-02 17:52:29,696 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a59f888df3924a41bab2f0decfa4ac61, text="is salman active in", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:30,101 [DEBUG] app1.py:1214 - Speech recognizing: is your salmon active in yoga
2024-12-02 17:52:30,102 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b3fd4688f387470185caeaf53f1c9409, text="is your salmon active in yoga", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:30,710 [DEBUG] app1.py:1214 - Speech recognizing: is your salmon active in yoga is
2024-12-02 17:52:30,710 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c6b63e6d010e4c6f8cbff99c75325e27, text="is your salmon active in yoga is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:31,102 [DEBUG] app1.py:1214 - Speech recognizing: is your salmon active in yoga is salmon
2024-12-02 17:52:31,103 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6c06adbf27454653bb29f4fa7972124a, text="is your salmon active in yoga is salmon", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:31,306 [DEBUG] app1.py:1214 - Speech recognizing: is your salmon active in yoga is salmon active
2024-12-02 17:52:31,307 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=45dbaba6d6bb4f8b94f6fa18039ed2b2, text="is your salmon active in yoga is salmon active", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:32,038 [INFO] app1.py:1205 - Speech recognized: Is your salmon active in yoga? Is salmon active?
2024-12-02 17:52:32,038 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=17945fc585574ad9acaf6ba3b5c1acc7, text="Is your salmon active in yoga? Is salmon active?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:33,164 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:52:52,213 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:52:52,214 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=42ffb7a0ee9c4a4097561791569b054c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:55,085 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 17:52:55,086 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b384ff28d43c4271b0cf68535c261be0, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:56,501 [INFO] app1.py:1205 - Speech recognized: Hey, Cortana.
2024-12-02 17:52:56,503 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=94213d53efc848e98ca274cd9105f917, text="Hey, Cortana.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:52:56,997 [DEBUG] app1.py:1214 - Speech recognizing: starts with
2024-12-02 17:52:56,999 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=34dbeb6399d1479abea718205d571cf3, text="starts with", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:58,417 [DEBUG] app1.py:1214 - Speech recognizing: starts with active
2024-12-02 17:52:58,418 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4aab54f633a844aebb5f3fced3077a7f, text="starts with active", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:59,084 [DEBUG] app1.py:1214 - Speech recognizing: starts with active start
2024-12-02 17:52:59,085 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c4878c75736c434482947b69ba27a5ca, text="starts with active start", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:59,394 [DEBUG] app1.py:1214 - Speech recognizing: starts with active start status
2024-12-02 17:52:59,394 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1f9598a8adb147ac8ae2f790b28a561a, text="starts with active start status", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:52:59,783 [DEBUG] app1.py:1214 - Speech recognizing: starts with active start status speaker
2024-12-02 17:52:59,784 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3d3cd3261db145caa9da9f5819dc35f7, text="starts with active start status speaker", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:00,202 [DEBUG] app1.py:1214 - Speech recognizing: starts with active start status speaker status
2024-12-02 17:53:00,202 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bcaf24e43d7b46ff95ac7329b5c66ff7, text="starts with active start status speaker status", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:00,712 [DEBUG] app1.py:1214 - Speech recognizing: starts with active start status speaker status active
2024-12-02 17:53:00,713 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d16d635b9dee44108bc0bb07e3fe0bed, text="starts with active start status speaker status active", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:02,387 [INFO] app1.py:1205 - Speech recognized: Starts with active start status, speaker status active.
2024-12-02 17:53:02,388 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=159c86ec13ec476c9efb7f7f5c54d990, text="Starts with active start status, speaker status active.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:53:03,166 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:53:06,583 [DEBUG] app1.py:1214 - Speech recognizing: control
2024-12-02 17:53:06,584 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8d94bbcf738f4dbbae7045478a7a44c9, text="control", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:08,396 [INFO] app1.py:1205 - Speech recognized: Control.
2024-12-02 17:53:08,397 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fc9b51ef3143408e905f08d1e353853b, text="Control.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:53:14,071 [DEBUG] app1.py:1214 - Speech recognizing: control Z
2024-12-02 17:53:14,071 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=87a98f2d4f1944d88f55d6f71c211e49, text="control Z", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:14,369 [DEBUG] app1.py:1214 - Speech recognizing: control Z madhav
2024-12-02 17:53:14,370 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a30bb96c25624f758493318880d19c4d, text="control Z madhav", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:14,776 [DEBUG] app1.py:1214 - Speech recognizing: control Z mandi bilikpuri
2024-12-02 17:53:14,777 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=358b58e9c0fc4824bc3c73a056df528e, text="control Z mandi bilikpuri", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:14,978 [DEBUG] app1.py:1214 - Speech recognizing: control Z mandi bilikpuri sri radha
2024-12-02 17:53:14,978 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e4d935def2f34379912e57d16189f8b8, text="control Z mandi bilikpuri sri radha", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:15,387 [DEBUG] app1.py:1214 - Speech recognizing: control Z mandi bilikpuri sri radha kodai
2024-12-02 17:53:15,393 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e9aa9ebc896b408a86a51cd59268720f, text="control Z mandi bilikpuri sri radha kodai", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:15,677 [DEBUG] app1.py:1214 - Speech recognizing: control Z mandi bilikpuri sri radha kodi
2024-12-02 17:53:15,678 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7974a85d82314f05ab63d93ed35c7b47, text="control Z mandi bilikpuri sri radha kodi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:16,072 [DEBUG] app1.py:1214 - Speech recognizing: control Z mandi bilikpuri sri radha kodi anna
2024-12-02 17:53:16,073 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ef196931b77b4968876270fddcde34ef, text="control Z mandi bilikpuri sri radha kodi anna", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:16,504 [INFO] app1.py:1205 - Speech recognized: Control Z Mandi Bilikpuri Sri Radha Kodi Anna.
2024-12-02 17:53:16,505 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=85f445a1b6dc4906bb4a8743073fe864, text="Control Z Mandi Bilikpuri Sri Radha Kodi Anna.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:53:18,875 [DEBUG] app1.py:1214 - Speech recognizing: cosmetic
2024-12-02 17:53:18,876 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c13a81cf3f35446eadaabaef47713fce, text="cosmetic", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:33,167 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:53:33,187 [DEBUG] app1.py:1214 - Speech recognizing: a
2024-12-02 17:53:33,188 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=264cc7c097f842ec87321f840393a224, text="a", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:33,279 [DEBUG] app1.py:1214 - Speech recognizing: a timeline
2024-12-02 17:53:33,280 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=29ad9bd501f14f90a1a6cb1e74d03389, text="a timeline", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:35,206 [INFO] app1.py:1205 - Speech recognized: A timeline.
2024-12-02 17:53:35,208 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2b934b94330549a28e7c94dbeb9620e1, text="A timeline.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:53:51,178 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:53:51,179 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=925e42bbc60e4fa4a3b81a27e69c6be5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:53:54,681 [DEBUG] app1.py:1214 - Speech recognizing: i don't mind getting
2024-12-02 17:53:54,682 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f2341cb3b7b84109acc6409ec2309b90, text="i don't mind getting", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:54,976 [DEBUG] app1.py:1214 - Speech recognizing: deployment
2024-12-02 17:53:54,978 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1cc6b8c634c84415b5d3604577a1a7c6, text="deployment", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:55,579 [DEBUG] app1.py:1214 - Speech recognizing: i don't mind getting deployment branches
2024-12-02 17:53:55,580 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d612d431cd1a451f8cd7ca0e82a8a7c6, text="i don't mind getting deployment branches", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:55,978 [DEBUG] app1.py:1214 - Speech recognizing: i don't mind getting deployment branches explore for
2024-12-02 17:53:55,978 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8edb2951669b4e01a20345cd86e82524, text="i don't mind getting deployment branches explore for", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:56,582 [DEBUG] app1.py:1214 - Speech recognizing: i don't mind getting deployment branches explore for CVS
2024-12-02 17:53:56,691 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0d632a4362d1411c9efcd647307468bd, text="i don't mind getting deployment branches explore for CVS", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:53:56,827 [INFO] app1.py:1205 - Speech recognized: I don't mind getting deployment branches explore for CVS.
2024-12-02 17:53:56,827 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2eba65856d4f4b5a8eb4b1a9b2be9975, text="I don't mind getting deployment branches explore for CVS.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:00,676 [DEBUG] app1.py:1214 - Speech recognizing: nike
2024-12-02 17:54:00,677 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b588d1b3a3bb473eb7d4f40b263d1db7, text="nike", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:01,065 [DEBUG] app1.py:1214 - Speech recognizing: nike pujan
2024-12-02 17:54:01,066 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b458758d899f4c22af5b119f7d29cb83, text="nike pujan", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:01,374 [DEBUG] app1.py:1214 - Speech recognizing: nike puja naara
2024-12-02 17:54:01,375 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2747a817352e4535be933d8a46901491, text="nike puja naara", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:01,778 [DEBUG] app1.py:1214 - Speech recognizing: nike pujana harami kul
2024-12-02 17:54:01,779 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8e608aec25e944c6b43cdbe81a5ddfdf, text="nike pujana harami kul", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:01,980 [DEBUG] app1.py:1214 - Speech recognizing: nike puja naara me to india nuk
2024-12-02 17:54:01,980 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=680db729de114e0694e678d583f19181, text="nike puja naara me to india nuk", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:02,370 [DEBUG] app1.py:1214 - Speech recognizing: nike pujana harami kulam
2024-12-02 17:54:02,373 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=94df74973d724d1ba8939e8683f233f4, text="nike pujana harami kulam", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:02,571 [DEBUG] app1.py:1214 - Speech recognizing: nike puja naara me to india nukku naal
2024-12-02 17:54:02,572 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3c60eed815b0401295d66e7f141ece46, text="nike puja naara me to india nukku naal", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:03,168 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:54:03,634 [INFO] app1.py:1205 - Speech recognized: Nike Pujana Harami Kulamati.
2024-12-02 17:54:03,635 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=702cca8322804337b9e68507c7cff114, text="Nike Pujana Harami Kulamati.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:07,402 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:54:07,404 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c2cd7b0cd8754d5f950f1b783817257c, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:08,192 [DEBUG] app1.py:1214 - Speech recognizing: hi hi
2024-12-02 17:54:08,212 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=39ce650ac43547c1b9cc9761bd315e86, text="hi hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:08,595 [DEBUG] app1.py:1214 - Speech recognizing: hi hi this
2024-12-02 17:54:08,597 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a5a896489aff4823afb69d62a4293a76, text="hi hi this", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:08,703 [DEBUG] app1.py:1214 - Speech recognizing: hi hi this is
2024-12-02 17:54:08,705 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d8b2dec6c473447986c5c89b647e9c3a, text="hi hi this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:09,988 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 17:54:09,988 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=41b5d94fc4dc41418f6277543e7cedec, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:11,386 [DEBUG] app1.py:1214 - Speech recognizing: how can i
2024-12-02 17:54:11,386 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3ebbeeebbe3f43f6a8aaa7c850ed0b9e, text="how can i", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:11,494 [DEBUG] app1.py:1214 - Speech recognizing: how can i help you today
2024-12-02 17:54:11,495 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5b0173c1531f4a55a4a6ea2784b0c790, text="how can i help you today", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:12,130 [INFO] app1.py:1205 - Speech recognized: How can I help you today?
2024-12-02 17:54:12,131 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=67baa1ff971b42f09e7929f109080916, text="How can I help you today?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:14,275 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:54:14,275 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=80dad2d61c9e4f18bf32cf204eddb83a, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:14,818 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:54:14,819 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3c0f72d0cdff4aeaaeca55513332d241, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:23,479 [DEBUG] app1.py:1214 - Speech recognizing: kivena
2024-12-02 17:54:23,481 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b367694b65ba4681ba304fcafca255ba, text="kivena", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:23,773 [DEBUG] app1.py:1214 - Speech recognizing: kivena main
2024-12-02 17:54:23,774 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8c43f08fe7194e09a6507933d41b2e95, text="kivena main", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:24,177 [DEBUG] app1.py:1214 - Speech recognizing: kivena maine shuky
2024-12-02 17:54:24,195 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1603cb7eb89b482782f8864dd53529b1, text="kivena maine shuky", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:24,378 [DEBUG] app1.py:1214 - Speech recognizing: kivena maine shukya
2024-12-02 17:54:24,379 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2156b3e3eef04d948134ec107ba51f8b, text="kivena maine shukya", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:24,783 [DEBUG] app1.py:1214 - Speech recognizing: kivena maine shukya aadhaar
2024-12-02 17:54:24,784 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=08076f385d7947c893bf59353fbfdc89, text="kivena maine shukya aadhaar", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:24,986 [DEBUG] app1.py:1214 - Speech recognizing: kivena maine shukya aadhaar is division
2024-12-02 17:54:24,987 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1d32bc6669a74d6283ec783908e0e112, text="kivena maine shukya aadhaar is division", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:25,391 [DEBUG] app1.py:1214 - Speech recognizing: kivena maine shukya aadhaar is division 2000
2024-12-02 17:54:25,392 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4158838ec75d49beb2539b09d97ec297, text="kivena maine shukya aadhaar is division 2000", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:26,286 [DEBUG] app1.py:1214 - Speech recognizing: kivena maine shukya aadhaar is division 2018
2024-12-02 17:54:26,287 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ec6717b4713a443d9a40b7542a5eba0e, text="kivena maine shukya aadhaar is division 2018", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:28,271 [INFO] app1.py:1205 - Speech recognized: Kivena, Maine. Shukya. Aadhaar is division 2018.
2024-12-02 17:54:28,271 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fb41b661967a4d4cba83ce66561748c8, text="Kivena, Maine. Shukya. Aadhaar is division 2018.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:33,170 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:54:48,380 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:54:48,380 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2b46543c50f14fdea20a1e638a444737, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:50,883 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:54:50,885 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1cf82f3327c04639aef0aeb478a6cb33, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:51,779 [DEBUG] app1.py:1214 - Speech recognizing: hi how
2024-12-02 17:54:51,779 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=92abc9e1427c463f92aaf0ba6e5a143a, text="hi how", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:51,984 [DEBUG] app1.py:1214 - Speech recognizing: hi how are
2024-12-02 17:54:51,985 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8d317e38207542bda53610cf5746b766, text="hi how are", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:52,092 [DEBUG] app1.py:1214 - Speech recognizing: hi how are you
2024-12-02 17:54:52,094 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=458c73677faf4b569b975783176b6fe9, text="hi how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:52,870 [INFO] app1.py:1205 - Speech recognized: Hi, how are you?
2024-12-02 17:54:52,871 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=80a2e60f628948f3b3cf03fea6452c1a, text="Hi, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:53,476 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:54:53,477 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e5c53c0fc7da452898d8273d40256856, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:55,380 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:54:55,382 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f8d8c212c9fa4cd5b7c877844ddaeed3, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:57,985 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:54:57,986 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8ad93f046abd4bddb12319d3e2bc28e6, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:54:59,489 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:54:59,490 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cb60a2581a6a40018e14ae938f50ab96, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:54:59,582 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:54:59,582 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:54:59,583 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,584 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:54:59,584 [DEBUG] app1.py:1104 - Sending transcription: thinking (is_final: False)
2024-12-02 17:54:59,586 [DEBUG] app1.py:1104 - Sending transcription: thinking and (is_final: False)
2024-12-02 17:54:59,587 [DEBUG] app1.py:1104 - Sending transcription: thinking and i'll (is_final: False)
2024-12-02 17:54:59,587 [DEBUG] app1.py:1104 - Sending transcription: thinking and i'll kill why without (is_final: False)
2024-12-02 17:54:59,587 [DEBUG] app1.py:1104 - Sending transcription: Thinking and I'll kill. Why without? (is_final: True)
2024-12-02 17:54:59,595 [DEBUG] app1.py:1104 - Sending transcription: You. (is_final: True)
2024-12-02 17:54:59,596 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,597 [DEBUG] app1.py:1104 - Sending transcription: he tried to (is_final: False)
2024-12-02 17:54:59,597 [DEBUG] app1.py:1104 - Sending transcription: he tried to both (is_final: False)
2024-12-02 17:54:59,598 [DEBUG] app1.py:1104 - Sending transcription: he tried to both component (is_final: False)
2024-12-02 17:54:59,603 [DEBUG] app1.py:1104 - Sending transcription: he tried to both component properly (is_final: False)
2024-12-02 17:54:59,604 [DEBUG] app1.py:1104 - Sending transcription: he tried to both component properly with full code (is_final: False)
2024-12-02 17:54:59,605 [DEBUG] app1.py:1104 - Sending transcription: He tried to both component properly with full code. (is_final: True)
2024-12-02 17:54:59,605 [DEBUG] app1.py:1104 - Sending transcription: write (is_final: False)
2024-12-02 17:54:59,623 [DEBUG] app1.py:1104 - Sending transcription: Write. (is_final: True)
2024-12-02 17:54:59,625 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,626 [DEBUG] app1.py:1104 - Sending transcription: also (is_final: False)
2024-12-02 17:54:59,627 [DEBUG] app1.py:1104 - Sending transcription: also i (is_final: False)
2024-12-02 17:54:59,629 [DEBUG] app1.py:1104 - Sending transcription: also (is_final: False)
2024-12-02 17:54:59,639 [DEBUG] app1.py:1104 - Sending transcription: also i also give (is_final: False)
2024-12-02 17:54:59,641 [DEBUG] app1.py:1104 - Sending transcription: also i also give me (is_final: False)
2024-12-02 17:54:59,642 [DEBUG] app1.py:1104 - Sending transcription: also i also give me full (is_final: False)
2024-12-02 17:54:59,642 [DEBUG] app1.py:1104 - Sending transcription: also i also give me full code (is_final: False)
2024-12-02 17:54:59,644 [DEBUG] app1.py:1104 - Sending transcription: also i also give me full code of (is_final: False)
2024-12-02 17:54:59,645 [DEBUG] app1.py:1104 - Sending transcription: also i also give me full code of both (is_final: False)
2024-12-02 17:54:59,645 [DEBUG] app1.py:1104 - Sending transcription: also i also give me full code of both complaint (is_final: False)
2024-12-02 17:54:59,647 [DEBUG] app1.py:1104 - Sending transcription: also i also give me full code of both complaint correctly (is_final: False)
2024-12-02 17:54:59,654 [DEBUG] app1.py:1104 - Sending transcription: Also give me full code of both complaint correctly. (is_final: True)
2024-12-02 17:54:59,656 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 17:54:59,657 [DEBUG] app1.py:1104 - Sending transcription: broadcast (is_final: False)
2024-12-02 17:54:59,659 [DEBUG] app1.py:1104 - Sending transcription: broadcaster (is_final: False)
2024-12-02 17:54:59,659 [DEBUG] app1.py:1104 - Sending transcription: Broadcaster. (is_final: True)
2024-12-02 17:54:59,665 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,676 [DEBUG] app1.py:1104 - Sending transcription: apple (is_final: False)
2024-12-02 17:54:59,679 [DEBUG] app1.py:1104 - Sending transcription: apple app index (is_final: False)
2024-12-02 17:54:59,692 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,694 [DEBUG] app1.py:1104 - Sending transcription: julie (is_final: False)
2024-12-02 17:54:59,694 [DEBUG] app1.py:1104 - Sending transcription: julie dithya (is_final: False)
2024-12-02 17:54:59,696 [DEBUG] app1.py:1104 - Sending transcription: julie dithya nearer (is_final: False)
2024-12-02 17:54:59,697 [DEBUG] app1.py:1104 - Sending transcription: Julie Dithya Nearer. (is_final: True)
2024-12-02 17:54:59,704 [DEBUG] app1.py:1104 - Sending transcription: i want to go (is_final: False)
2024-12-02 17:54:59,705 [DEBUG] app1.py:1104 - Sending transcription: i want to go live (is_final: False)
2024-12-02 17:54:59,706 [DEBUG] app1.py:1104 - Sending transcription: i want to go live with (is_final: False)
2024-12-02 17:54:59,706 [DEBUG] app1.py:1104 - Sending transcription: i want to go live with it (is_final: False)
2024-12-02 17:54:59,707 [DEBUG] app1.py:1104 - Sending transcription: i want to go live with a (is_final: False)
2024-12-02 17:54:59,709 [DEBUG] app1.py:1104 - Sending transcription: I want to go live with a. (is_final: True)
2024-12-02 17:54:59,709 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,710 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,711 [DEBUG] app1.py:1104 - Sending transcription: to write (is_final: False)
2024-12-02 17:54:59,712 [DEBUG] app1.py:1104 - Sending transcription: to write a second page (is_final: False)
2024-12-02 17:54:59,713 [DEBUG] app1.py:1104 - Sending transcription: To write the second page. (is_final: True)
2024-12-02 17:54:59,713 [DEBUG] app1.py:1104 - Sending transcription: 9 (is_final: False)
2024-12-02 17:54:59,714 [DEBUG] app1.py:1104 - Sending transcription: 944 (is_final: False)
2024-12-02 17:54:59,719 [DEBUG] app1.py:1104 - Sending transcription: 944. (is_final: True)
2024-12-02 17:54:59,721 [DEBUG] app1.py:1104 - Sending transcription: 6. (is_final: True)
2024-12-02 17:54:59,722 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,722 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,723 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:54:59,723 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:54:59,725 [DEBUG] app1.py:1104 - Sending transcription: hello hi hello (is_final: False)
2024-12-02 17:54:59,725 [DEBUG] app1.py:1104 - Sending transcription: Hi. Hello. (is_final: True)
2024-12-02 17:54:59,726 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,726 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:54:59,727 [DEBUG] app1.py:1104 - Sending transcription: type of (is_final: False)
2024-12-02 17:54:59,728 [DEBUG] app1.py:1104 - Sending transcription: type of india (is_final: False)
2024-12-02 17:54:59,728 [DEBUG] app1.py:1104 - Sending transcription: Type of India. (is_final: True)
2024-12-02 17:54:59,730 [DEBUG] app1.py:1104 - Sending transcription: hafiz (is_final: False)
2024-12-02 17:54:59,730 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharrah gives (is_final: False)
2024-12-02 17:54:59,735 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharrah gives twitter (is_final: False)
2024-12-02 17:54:59,738 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharraq's twitter has been (is_final: False)
2024-12-02 17:54:59,738 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharraq's twitter has been PH (is_final: False)
2024-12-02 17:54:59,739 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharraq's twitter has been PHD (is_final: False)
2024-12-02 17:54:59,740 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharraq's twitter has been PHDS (is_final: False)
2024-12-02 17:54:59,740 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharraq's twitter has been PHDS infrastructure (is_final: False)
2024-12-02 17:54:59,742 [DEBUG] app1.py:1104 - Sending transcription: hafiz muharraq's twitter has been PHDS infrastructure ID (is_final: False)
2024-12-02 17:54:59,742 [DEBUG] app1.py:1104 - Sending transcription: Hafiz Muharraq's Twitter has been PhDs infrastructure. (is_final: True)
2024-12-02 17:54:59,743 [DEBUG] app1.py:1104 - Sending transcription: basically (is_final: False)
2024-12-02 17:54:59,744 [DEBUG] app1.py:1104 - Sending transcription: basically england (is_final: False)
2024-12-02 17:54:59,746 [DEBUG] app1.py:1104 - Sending transcription: basically england ah (is_final: False)
2024-12-02 17:54:59,746 [DEBUG] app1.py:1104 - Sending transcription: basically england the whole (is_final: False)
2024-12-02 17:54:59,747 [DEBUG] app1.py:1104 - Sending transcription: basically england the whole katr (is_final: False)
2024-12-02 17:54:59,747 [DEBUG] app1.py:1104 - Sending transcription: basically england the whole karratha (is_final: False)
2024-12-02 17:54:59,748 [DEBUG] app1.py:1104 - Sending transcription: basically england the whole karratha video (is_final: False)
2024-12-02 17:54:59,754 [DEBUG] app1.py:1104 - Sending transcription: basically england the whole karratha vito (is_final: False)
2024-12-02 17:54:59,756 [DEBUG] app1.py:1104 - Sending transcription: Basically England. The whole Karratha video. (is_final: True)
2024-12-02 17:54:59,757 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,757 [DEBUG] app1.py:1104 - Sending transcription: code is (is_final: False)
2024-12-02 17:54:59,757 [DEBUG] app1.py:1104 - Sending transcription: code is applied (is_final: False)
2024-12-02 17:54:59,759 [DEBUG] app1.py:1104 - Sending transcription: code is the blind address (is_final: False)
2024-12-02 17:54:59,761 [DEBUG] app1.py:1104 - Sending transcription: code is applied address (is_final: False)
2024-12-02 17:54:59,762 [DEBUG] app1.py:1104 - Sending transcription: code is applied address book (is_final: False)
2024-12-02 17:54:59,762 [DEBUG] app1.py:1104 - Sending transcription: Code is applied address book. (is_final: True)
2024-12-02 17:54:59,763 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 17:54:59,764 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,764 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:54:59,769 [DEBUG] app1.py:1104 - Sending transcription: how are you (is_final: False)
2024-12-02 17:54:59,772 [DEBUG] app1.py:1104 - Sending transcription: How are you? (is_final: True)
2024-12-02 17:54:59,773 [DEBUG] app1.py:1104 - Sending transcription: india (is_final: False)
2024-12-02 17:54:59,773 [DEBUG] app1.py:1104 - Sending transcription: india appointed (is_final: False)
2024-12-02 17:54:59,774 [DEBUG] app1.py:1104 - Sending transcription: india calendar for (is_final: False)
2024-12-02 17:54:59,775 [DEBUG] app1.py:1104 - Sending transcription: India appointed. (is_final: True)
2024-12-02 17:54:59,775 [DEBUG] app1.py:1104 - Sending transcription: nithya (is_final: False)
2024-12-02 17:54:59,776 [DEBUG] app1.py:1104 - Sending transcription: nitin gadkari (is_final: False)
2024-12-02 17:54:59,777 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,780 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,781 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,788 [DEBUG] app1.py:1104 - Sending transcription: hello how are (is_final: False)
2024-12-02 17:54:59,789 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 17:54:59,790 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? (is_final: True)
2024-12-02 17:54:59,791 [DEBUG] app1.py:1104 - Sending transcription: working (is_final: False)
2024-12-02 17:54:59,792 [DEBUG] app1.py:1104 - Sending transcription: Working. (is_final: True)
2024-12-02 17:54:59,792 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,793 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:54:59,793 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,795 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:54:59,795 [DEBUG] app1.py:1104 - Sending transcription: equally (is_final: False)
2024-12-02 17:54:59,795 [DEBUG] app1.py:1104 - Sending transcription: Equally enjoyable. (is_final: True)
2024-12-02 17:54:59,796 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,797 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 17:54:59,797 [DEBUG] app1.py:1104 - Sending transcription: hello how are you what (is_final: False)
2024-12-02 17:54:59,797 [DEBUG] app1.py:1104 - Sending transcription: hello how are you what are you (is_final: False)
2024-12-02 17:54:59,804 [DEBUG] app1.py:1104 - Sending transcription: hello how are you what are you doing (is_final: False)
2024-12-02 17:54:59,805 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? What are you doing? (is_final: True)
2024-12-02 17:54:59,805 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,806 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,806 [DEBUG] app1.py:1104 - Sending transcription: KDL (is_final: False)
2024-12-02 17:54:59,807 [DEBUG] app1.py:1104 - Sending transcription: KDLAPI (is_final: False)
2024-12-02 17:54:59,807 [DEBUG] app1.py:1104 - Sending transcription: KDLAPID data (is_final: False)
2024-12-02 17:54:59,807 [DEBUG] app1.py:1104 - Sending transcription: KDLAPIT data (is_final: False)
2024-12-02 17:54:59,808 [DEBUG] app1.py:1104 - Sending transcription: KDLAPIT data broadcast (is_final: False)
2024-12-02 17:54:59,811 [DEBUG] app1.py:1104 - Sending transcription: KDLAPID data broadcast (is_final: False)
2024-12-02 17:54:59,811 [DEBUG] app1.py:1104 - Sending transcription: KDLAPID data broadcast. (is_final: True)
2024-12-02 17:54:59,812 [DEBUG] app1.py:1104 - Sending transcription: broadcast (is_final: False)
2024-12-02 17:54:59,812 [DEBUG] app1.py:1104 - Sending transcription: Broadcast. (is_final: True)
2024-12-02 17:54:59,813 [DEBUG] app1.py:1104 - Sending transcription: response (is_final: False)
2024-12-02 17:54:59,815 [DEBUG] app1.py:1104 - Sending transcription: response control (is_final: False)
2024-12-02 17:54:59,821 [DEBUG] app1.py:1104 - Sending transcription: Response control. (is_final: True)
2024-12-02 17:54:59,822 [DEBUG] app1.py:1104 - Sending transcription: consolidated (is_final: False)
2024-12-02 17:54:59,824 [DEBUG] app1.py:1104 - Sending transcription: solidarity (is_final: False)
2024-12-02 17:54:59,825 [DEBUG] app1.py:1104 - Sending transcription: Solidarity. (is_final: True)
2024-12-02 17:54:59,827 [DEBUG] app1.py:1104 - Sending transcription: response (is_final: False)
2024-12-02 17:54:59,827 [DEBUG] app1.py:1104 - Sending transcription: response garcons (is_final: False)
2024-12-02 17:54:59,829 [DEBUG] app1.py:1104 - Sending transcription: response (is_final: False)
2024-12-02 17:54:59,829 [DEBUG] app1.py:1104 - Sending transcription: Response Car Consort. (is_final: True)
2024-12-02 17:54:59,835 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,837 [DEBUG] app1.py:1104 - Sending transcription: american (is_final: False)
2024-12-02 17:54:59,837 [DEBUG] app1.py:1104 - Sending transcription: american tool (is_final: False)
2024-12-02 17:54:59,838 [DEBUG] app1.py:1104 - Sending transcription: American Trollis. (is_final: True)
2024-12-02 17:54:59,838 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,839 [DEBUG] app1.py:1104 - Sending transcription: hello how (is_final: False)
2024-12-02 17:54:59,839 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 17:54:59,842 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? (is_final: True)
2024-12-02 17:54:59,843 [DEBUG] app1.py:1104 - Sending transcription: jump rd (is_final: False)
2024-12-02 17:54:59,843 [DEBUG] app1.py:1104 - Sending transcription: Jump Rd. (is_final: True)
2024-12-02 17:54:59,845 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,845 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,846 [DEBUG] app1.py:1104 - Sending transcription: listener listener (is_final: False)
2024-12-02 17:54:59,847 [DEBUG] app1.py:1104 - Sending transcription: Listener, listener. (is_final: True)
2024-12-02 17:54:59,847 [DEBUG] app1.py:1104 - Sending transcription: post (is_final: False)
2024-12-02 17:54:59,847 [DEBUG] app1.py:1104 - Sending transcription: postal gastonia (is_final: False)
2024-12-02 17:54:59,851 [DEBUG] app1.py:1104 - Sending transcription: Postal Gastonia. (is_final: True)
2024-12-02 17:54:59,853 [DEBUG] app1.py:1104 - Sending transcription: manulife (is_final: False)
2024-12-02 17:54:59,854 [DEBUG] app1.py:1104 - Sending transcription: manulife and sold out (is_final: False)
2024-12-02 17:54:59,854 [DEBUG] app1.py:1104 - Sending transcription: manulife and sold out low (is_final: False)
2024-12-02 17:54:59,855 [DEBUG] app1.py:1104 - Sending transcription: Manulife and sold out low. (is_final: True)
2024-12-02 17:54:59,856 [DEBUG] app1.py:1104 - Sending transcription: spouse (is_final: False)
2024-12-02 17:54:59,857 [DEBUG] app1.py:1104 - Sending transcription: engineering (is_final: False)
2024-12-02 17:54:59,857 [DEBUG] app1.py:1104 - Sending transcription: engineering HIV (is_final: False)
2024-12-02 17:54:59,860 [DEBUG] app1.py:1104 - Sending transcription: engineering HIV data (is_final: False)
2024-12-02 17:54:59,861 [DEBUG] app1.py:1104 - Sending transcription: engineering HIV data positioning in duchess iw (is_final: False)
2024-12-02 17:54:59,862 [DEBUG] app1.py:1104 - Sending transcription: engineering HIV data positioning in duchess iw duchess (is_final: False)
2024-12-02 17:54:59,863 [DEBUG] app1.py:1104 - Sending transcription: engineering HIV data positioning in duchess iw duchess ID (is_final: False)
2024-12-02 17:54:59,863 [DEBUG] app1.py:1104 - Sending transcription: engineering HIV data positioning in duchess iw duchess ID API (is_final: False)
2024-12-02 17:54:59,867 [DEBUG] app1.py:1104 - Sending transcription: Engineering HIV data positioning in Duchess IW Duchess API. (is_final: True)
2024-12-02 17:54:59,869 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 17:54:59,869 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:54:59,872 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 17:54:59,873 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? (is_final: True)
2024-12-02 17:54:59,873 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 17:54:59,874 [DEBUG] app1.py:1104 - Sending transcription: what are you doing hi (is_final: False)
2024-12-02 17:54:59,874 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? Hi. (is_final: True)
2024-12-02 17:54:59,874 [DEBUG] app1.py:1104 - Sending transcription: play (is_final: False)
2024-12-02 17:54:59,876 [DEBUG] app1.py:1104 - Sending transcription: play kenny (is_final: False)
2024-12-02 17:54:59,876 [DEBUG] app1.py:1104 - Sending transcription: play kaniya dey (is_final: False)
2024-12-02 17:54:59,878 [DEBUG] app1.py:1104 - Sending transcription: Play Kenny Adele. (is_final: True)
2024-12-02 17:54:59,886 [DEBUG] app1.py:1104 - Sending transcription: it is (is_final: False)
2024-12-02 17:54:59,888 [DEBUG] app1.py:1104 - Sending transcription: it is an (is_final: False)
2024-12-02 17:54:59,890 [DEBUG] app1.py:1104 - Sending transcription: it is an original (is_final: False)
2024-12-02 17:54:59,891 [DEBUG] app1.py:1104 - Sending transcription: it is an original web thakart (is_final: False)
2024-12-02 17:54:59,892 [DEBUG] app1.py:1104 - Sending transcription: It is an original web thakkartheon. (is_final: True)
2024-12-02 17:54:59,893 [DEBUG] app1.py:1104 - Sending transcription: automatic (is_final: False)
2024-12-02 17:54:59,894 [DEBUG] app1.py:1104 - Sending transcription: Automatic. (is_final: True)
2024-12-02 17:54:59,896 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:54:59,896 [DEBUG] app1.py:1104 - Sending transcription: speaker (is_final: False)
2024-12-02 17:54:59,898 [DEBUG] app1.py:1104 - Sending transcription: Speaker. (is_final: True)
2024-12-02 17:54:59,898 [DEBUG] app1.py:1104 - Sending transcription: response (is_final: False)
2024-12-02 17:54:59,947 [DEBUG] app1.py:1104 - Sending transcription: Response. (is_final: True)
2024-12-02 17:54:59,961 [DEBUG] app1.py:1104 - Sending transcription: beating (is_final: False)
2024-12-02 17:54:59,963 [DEBUG] app1.py:1104 - Sending transcription: beating horse (is_final: False)
2024-12-02 17:54:59,964 [DEBUG] app1.py:1104 - Sending transcription: Beating Horse. (is_final: True)
2024-12-02 17:54:59,964 [DEBUG] app1.py:1104 - Sending transcription: illinois enna (is_final: False)
2024-12-02 17:54:59,979 [DEBUG] app1.py:1104 - Sending transcription: is (is_final: False)
2024-12-02 17:54:59,979 [DEBUG] app1.py:1104 - Sending transcription: illinois enna is speak (is_final: False)
2024-12-02 17:54:59,981 [DEBUG] app1.py:1104 - Sending transcription: is speak collective (is_final: False)
2024-12-02 17:54:59,986 [DEBUG] app1.py:1104 - Sending transcription: illinois enna is speak collective kenya (is_final: False)
2024-12-02 17:54:59,987 [DEBUG] app1.py:1104 - Sending transcription: illinois enna is speak collective can you all (is_final: False)
2024-12-02 17:54:59,990 [DEBUG] app1.py:1104 - Sending transcription: illinois enna is speak collective can you all activate (is_final: False)
2024-12-02 17:54:59,992 [DEBUG] app1.py:1104 - Sending transcription: Is speak collective? Can you all activate? (is_final: True)
2024-12-02 17:54:59,993 [DEBUG] app1.py:1104 - Sending transcription: is (is_final: False)
2024-12-02 17:54:59,995 [DEBUG] app1.py:1104 - Sending transcription: is salman (is_final: False)
2024-12-02 17:54:59,996 [DEBUG] app1.py:1104 - Sending transcription: is salman active in (is_final: False)
2024-12-02 17:54:59,997 [DEBUG] app1.py:1104 - Sending transcription: is your salmon active in yoga (is_final: False)
2024-12-02 17:54:59,998 [DEBUG] app1.py:1104 - Sending transcription: is your salmon active in yoga is (is_final: False)
2024-12-02 17:55:00,002 [DEBUG] app1.py:1104 - Sending transcription: is your salmon active in yoga is salmon (is_final: False)
2024-12-02 17:55:00,006 [DEBUG] app1.py:1104 - Sending transcription: is your salmon active in yoga is salmon active (is_final: False)
2024-12-02 17:55:00,015 [DEBUG] app1.py:1104 - Sending transcription: Is your salmon active in yoga? Is salmon active? (is_final: True)
2024-12-02 17:55:00,025 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:55:00,029 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 17:55:00,035 [DEBUG] app1.py:1104 - Sending transcription: Hey, Cortana. (is_final: True)
2024-12-02 17:55:00,037 [DEBUG] app1.py:1104 - Sending transcription: starts with (is_final: False)
2024-12-02 17:55:00,037 [DEBUG] app1.py:1104 - Sending transcription: starts with active (is_final: False)
2024-12-02 17:55:00,037 [DEBUG] app1.py:1104 - Sending transcription: starts with active start (is_final: False)
2024-12-02 17:55:00,040 [DEBUG] app1.py:1104 - Sending transcription: starts with active start status (is_final: False)
2024-12-02 17:55:00,041 [DEBUG] app1.py:1104 - Sending transcription: starts with active start status speaker (is_final: False)
2024-12-02 17:55:00,042 [DEBUG] app1.py:1104 - Sending transcription: starts with active start status speaker status (is_final: False)
2024-12-02 17:55:00,042 [DEBUG] app1.py:1104 - Sending transcription: starts with active start status speaker status active (is_final: False)
2024-12-02 17:55:00,043 [DEBUG] app1.py:1104 - Sending transcription: Starts with active start status, speaker status active. (is_final: True)
2024-12-02 17:55:00,043 [DEBUG] app1.py:1104 - Sending transcription: control (is_final: False)
2024-12-02 17:55:00,043 [DEBUG] app1.py:1104 - Sending transcription: Control. (is_final: True)
2024-12-02 17:55:00,044 [DEBUG] app1.py:1104 - Sending transcription: control Z (is_final: False)
2024-12-02 17:55:00,045 [DEBUG] app1.py:1104 - Sending transcription: control Z madhav (is_final: False)
2024-12-02 17:55:00,046 [DEBUG] app1.py:1104 - Sending transcription: control Z mandi bilikpuri (is_final: False)
2024-12-02 17:55:00,047 [DEBUG] app1.py:1104 - Sending transcription: control Z mandi bilikpuri sri radha (is_final: False)
2024-12-02 17:55:00,052 [DEBUG] app1.py:1104 - Sending transcription: control Z mandi bilikpuri sri radha kodai (is_final: False)
2024-12-02 17:55:00,053 [DEBUG] app1.py:1104 - Sending transcription: control Z mandi bilikpuri sri radha kodi (is_final: False)
2024-12-02 17:55:00,053 [DEBUG] app1.py:1104 - Sending transcription: control Z mandi bilikpuri sri radha kodi anna (is_final: False)
2024-12-02 17:55:00,054 [DEBUG] app1.py:1104 - Sending transcription: Control Z Mandi Bilikpuri Sri Radha Kodi Anna. (is_final: True)
2024-12-02 17:55:00,055 [DEBUG] app1.py:1104 - Sending transcription: cosmetic (is_final: False)
2024-12-02 17:55:00,056 [DEBUG] app1.py:1104 - Sending transcription: a (is_final: False)
2024-12-02 17:55:00,057 [DEBUG] app1.py:1104 - Sending transcription: a timeline (is_final: False)
2024-12-02 17:55:00,058 [DEBUG] app1.py:1104 - Sending transcription: A timeline. (is_final: True)
2024-12-02 17:55:00,059 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:55:00,059 [DEBUG] app1.py:1104 - Sending transcription: i don't mind getting (is_final: False)
2024-12-02 17:55:00,061 [DEBUG] app1.py:1104 - Sending transcription: deployment (is_final: False)
2024-12-02 17:55:00,061 [DEBUG] app1.py:1104 - Sending transcription: i don't mind getting deployment branches (is_final: False)
2024-12-02 17:55:00,063 [DEBUG] app1.py:1104 - Sending transcription: i don't mind getting deployment branches explore for (is_final: False)
2024-12-02 17:55:00,063 [DEBUG] app1.py:1104 - Sending transcription: i don't mind getting deployment branches explore for CVS (is_final: False)
2024-12-02 17:55:00,063 [DEBUG] app1.py:1104 - Sending transcription: I don't mind getting deployment branches explore for CVS. (is_final: True)
2024-12-02 17:55:00,064 [DEBUG] app1.py:1104 - Sending transcription: nike (is_final: False)
2024-12-02 17:55:00,070 [DEBUG] app1.py:1104 - Sending transcription: nike pujan (is_final: False)
2024-12-02 17:55:00,071 [DEBUG] app1.py:1104 - Sending transcription: nike puja naara (is_final: False)
2024-12-02 17:55:00,073 [DEBUG] app1.py:1104 - Sending transcription: nike pujana harami kul (is_final: False)
2024-12-02 17:55:00,073 [DEBUG] app1.py:1104 - Sending transcription: nike puja naara me to india nuk (is_final: False)
2024-12-02 17:55:00,075 [DEBUG] app1.py:1104 - Sending transcription: nike pujana harami kulam (is_final: False)
2024-12-02 17:55:00,077 [DEBUG] app1.py:1104 - Sending transcription: nike puja naara me to india nukku naal (is_final: False)
2024-12-02 17:55:00,079 [DEBUG] app1.py:1104 - Sending transcription: Nike Pujana Harami Kulamati. (is_final: True)
2024-12-02 17:55:00,080 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:55:00,080 [DEBUG] app1.py:1104 - Sending transcription: hi hi (is_final: False)
2024-12-02 17:55:00,081 [DEBUG] app1.py:1104 - Sending transcription: hi hi this (is_final: False)
2024-12-02 17:55:00,087 [DEBUG] app1.py:1104 - Sending transcription: hi hi this is (is_final: False)
2024-12-02 17:55:00,088 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 17:55:00,088 [DEBUG] app1.py:1104 - Sending transcription: how can i (is_final: False)
2024-12-02 17:55:00,089 [DEBUG] app1.py:1104 - Sending transcription: how can i help you today (is_final: False)
2024-12-02 17:55:00,090 [DEBUG] app1.py:1104 - Sending transcription: How can I help you today? (is_final: True)
2024-12-02 17:55:00,092 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:55:00,093 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:55:00,094 [DEBUG] app1.py:1104 - Sending transcription: kivena (is_final: False)
2024-12-02 17:55:00,095 [DEBUG] app1.py:1104 - Sending transcription: kivena main (is_final: False)
2024-12-02 17:55:00,095 [DEBUG] app1.py:1104 - Sending transcription: kivena maine shuky (is_final: False)
2024-12-02 17:55:00,097 [DEBUG] app1.py:1104 - Sending transcription: kivena maine shukya (is_final: False)
2024-12-02 17:55:00,099 [DEBUG] app1.py:1104 - Sending transcription: kivena maine shukya aadhaar (is_final: False)
2024-12-02 17:55:00,103 [DEBUG] app1.py:1104 - Sending transcription: kivena maine shukya aadhaar is division (is_final: False)
2024-12-02 17:55:00,104 [DEBUG] app1.py:1104 - Sending transcription: kivena maine shukya aadhaar is division 2000 (is_final: False)
2024-12-02 17:55:00,107 [DEBUG] app1.py:1104 - Sending transcription: kivena maine shukya aadhaar is division 2018 (is_final: False)
2024-12-02 17:55:00,108 [DEBUG] app1.py:1104 - Sending transcription: Kivena, Maine. Shukya. Aadhaar is division 2018. (is_final: True)
2024-12-02 17:55:00,109 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 17:55:00,109 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:55:00,111 [DEBUG] app1.py:1104 - Sending transcription: hi how (is_final: False)
2024-12-02 17:55:00,112 [DEBUG] app1.py:1104 - Sending transcription: hi how are (is_final: False)
2024-12-02 17:55:00,112 [DEBUG] app1.py:1104 - Sending transcription: hi how are you (is_final: False)
2024-12-02 17:55:00,112 [DEBUG] app1.py:1104 - Sending transcription: Hi, how are you? (is_final: True)
2024-12-02 17:55:00,115 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:55:00,118 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:55:00,119 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:55:00,120 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:55:01,185 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:55:01,186 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6ff7d7e7fc664cd99718c5336750f4de, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:01,187 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:55:01,590 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 17:55:01,591 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f5478e046695435eb80b6288993b1402, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:55:01,592 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 17:55:03,075 [DEBUG] app1.py:1214 - Speech recognizing: jalapeno
2024-12-02 17:55:03,076 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4ecae330c6f1491093be32986171ca82, text="jalapeno", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:03,077 [DEBUG] app1.py:1104 - Sending transcription: jalapeno (is_final: False)
2024-12-02 17:55:03,171 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:55:03,370 [DEBUG] app1.py:1214 - Speech recognizing: jalebi ah jollibean
2024-12-02 17:55:03,372 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b3dd4cbbd805464bb505d3500b4adef8, text="jalebi ah jollibean", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:03,373 [DEBUG] app1.py:1104 - Sending transcription: jalebi ah jollibean (is_final: False)
2024-12-02 17:55:03,947 [INFO] app1.py:1205 - Speech recognized: Jalapeno jalebi.
2024-12-02 17:55:03,949 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=49d1f29ba1e6433ebd2c1140491c44f7, text="Jalapeno jalebi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:55:03,950 [DEBUG] app1.py:1104 - Sending transcription: Jalapeno jalebi. (is_final: True)
2024-12-02 17:55:05,684 [DEBUG] app1.py:1214 - Speech recognizing: jalapeno
2024-12-02 17:55:05,685 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=addd10e01f1f4affb99163d4e6e21c09, text="jalapeno", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:05,686 [DEBUG] app1.py:1104 - Sending transcription: jalapeno (is_final: False)
2024-12-02 17:55:06,186 [DEBUG] app1.py:1214 - Speech recognizing: jalapeno jaleb
2024-12-02 17:55:06,196 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3cbcb1d3441f418dae416e9eb2379fbb, text="jalapeno jaleb", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:06,209 [DEBUG] app1.py:1104 - Sending transcription: jalapeno jaleb (is_final: False)
2024-12-02 17:55:06,277 [DEBUG] app1.py:1214 - Speech recognizing: jalapeno jalebi
2024-12-02 17:55:06,277 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5a806a349f85480aafbebb70807eff8a, text="jalapeno jalebi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:06,279 [DEBUG] app1.py:1104 - Sending transcription: jalapeno jalebi (is_final: False)
2024-12-02 17:55:06,991 [DEBUG] app1.py:1214 - Speech recognizing: jalapeno
2024-12-02 17:55:06,992 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6b984df8d1bf4f44a28ed838830b454f, text="jalapeno", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:06,994 [DEBUG] app1.py:1104 - Sending transcription: jalapeno (is_final: False)
2024-12-02 17:55:08,821 [INFO] app1.py:1205 - Speech recognized: Jalapeno.
2024-12-02 17:55:08,822 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d73d63f2781145cc85b80d0faa45d132, text="Jalapeno.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:55:11,832 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:55:11,832 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:55:11,834 [DEBUG] app1.py:1104 - Sending transcription: Jalapeno. (is_final: True)
2024-12-02 17:55:15,280 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 17:55:15,281 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5504051e79244751b8365701c7b8b2d1, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:15,282 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 17:55:15,482 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing what are you
2024-12-02 17:55:15,483 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=84cd376f60e046598b3f06493161a118, text="what are you doing what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:15,484 [DEBUG] app1.py:1104 - Sending transcription: what are you doing what are you (is_final: False)
2024-12-02 17:55:15,592 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing what are you doing
2024-12-02 17:55:15,594 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6c0d11902c66430999c0d03aa7f999fe, text="what are you doing what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:55:15,596 [DEBUG] app1.py:1104 - Sending transcription: what are you doing what are you doing (is_final: False)
2024-12-02 17:55:17,412 [INFO] app1.py:1205 - Speech recognized: What are you doing? What are you doing?
2024-12-02 17:55:17,413 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=814ee80872be43c385db19adca29fc40, text="What are you doing? What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:55:17,415 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? What are you doing? (is_final: True)
2024-12-02 17:55:29,935 [INFO] app1.py:1205 - Speech recognized: Oh.
2024-12-02 17:55:29,936 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8554c1b54ea84a0ba8ab1f5e1a7172c4, text="Oh.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:55:29,937 [DEBUG] app1.py:1104 - Sending transcription: Oh. (is_final: True)
2024-12-02 17:55:33,172 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:55:33,933 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 17:55:34,130 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 17:56:03,174 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:56:33,176 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0']
2024-12-02 17:56:36,157 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 17:56:36,165 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:56:36,166 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:56:36,208 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 17:56:36,302 [INFO] app1.py:1240 - Audio stream started
2024-12-02 17:56:41,839 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 17:56:41,841 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=acd44954d74d459a87839e0d5d19cd75, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:41,842 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 17:56:42,645 [DEBUG] app1.py:1214 - Speech recognizing: hello what
2024-12-02 17:56:42,646 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3748e845a8fa4d3c9ffa72e04e522ac4, text="hello what", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:42,647 [DEBUG] app1.py:1104 - Sending transcription: hello what (is_final: False)
2024-12-02 17:56:43,140 [DEBUG] app1.py:1214 - Speech recognizing: hello what are you doing
2024-12-02 17:56:43,141 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ef9ddce2f1cf4babaddf888428fbbab8, text="hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:43,143 [DEBUG] app1.py:1104 - Sending transcription: hello what are you doing (is_final: False)
2024-12-02 17:56:44,974 [INFO] app1.py:1205 - Speech recognized: Hello, what are you doing?
2024-12-02 17:56:44,976 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ca05c583eceb47a8a365a905c784d9d3, text="Hello, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:56:44,976 [DEBUG] app1.py:1104 - Sending transcription: Hello, what are you doing? (is_final: True)
2024-12-02 17:56:46,066 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 17:56:46,067 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ed16a967ecdc447cbb766e354be46fe4, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:46,069 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 17:56:46,270 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 17:56:46,271 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d3b81590977644f38c41a5dadccd0fd7, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:46,271 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 17:56:46,381 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 17:56:46,382 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=748d3fe4f61e4faba6df290575faee1f, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:46,382 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 17:56:47,441 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 17:56:47,642 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 17:56:47,643 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=28ab12573ef24e9283cdfdb306237db5, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:56:47,645 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 17:56:47,645 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 17:56:49,469 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 17:56:49,474 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:56:49,474 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:56:49,477 [INFO] app1.py:1121 - New translation stream connection for client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, language: es
2024-12-02 17:56:49,477 [INFO] app1.py:1131 - Creating new client connection: 65e638b0-1041-4202-aed0-ae5b89ca2da2
2024-12-02 17:56:49,558 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 17:56:49,643 [INFO] app1.py:1240 - Audio stream started
2024-12-02 17:56:51,008 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 17:56:51,009 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e5d2a828b9fb4593962d21d204cee94d, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:51,009 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 17:56:51,018 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:51,019 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:51,020 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:51,320 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you
2024-12-02 17:56:51,321 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4188a88fe5cb4d069c5c5bb48acc5d7f, text="hi what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:51,322 [DEBUG] app1.py:1104 - Sending transcription: hi what are you (is_final: False)
2024-12-02 17:56:51,345 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:51,346 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:51,346 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:51,415 [DEBUG] app1.py:1214 - Speech recognizing: hi what are you doing
2024-12-02 17:56:51,416 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3f01ae77444e4634ba557d8c7a1bf72b, text="hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:51,416 [DEBUG] app1.py:1104 - Sending transcription: hi what are you doing (is_final: False)
2024-12-02 17:56:51,420 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:51,421 [DEBUG] app1.py:1031 - Received translation request - Text: 'hi what are you doing', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:51,421 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:52,845 [INFO] app1.py:1205 - Speech recognized: Hi, what are you doing?
2024-12-02 17:56:52,845 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=35ba4236de2a4749b679e1e2db203a17, text="Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:56:52,846 [DEBUG] app1.py:1104 - Sending transcription: Hi, what are you doing? (is_final: True)
2024-12-02 17:56:52,852 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:52,853 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hi, what are you doing?', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: True
2024-12-02 17:56:52,853 [DEBUG] app1.py:1042 - Normalized text: 'hi, what are you doing?'
2024-12-02 17:56:52,854 [DEBUG] app1.py:1056 - Checking cache with key: hi, what are you doing?:es
2024-12-02 17:56:52,854 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 17:56:52,854 [INFO] app1.py:933 - Starting translation request - Text: 'hi, what are you doing?', Target language: es
2024-12-02 17:56:52,856 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 17:56:52,857 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 17:56:52,859 [DEBUG] app1.py:964 - Request body: [{'text': 'hi, what are you doing?'}]
2024-12-02 17:56:53,295 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 17:56:53,371 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 17:56:53,373 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'hola, qu est haciendo?', 'to': 'es'}]}]
2024-12-02 17:56:53,374 [DEBUG] app1.py:974 - Extracted translation: hola, qu est haciendo?
2024-12-02 17:56:53,375 [INFO] app1.py:975 - Translation completed successfully - Original: 'hi, what are you doing?' -> Translation: 'hola, qu est haciendo?' (es)
2024-12-02 17:56:53,376 [DEBUG] app1.py:918 - Sending translation to client 65e638b0-1041-4202-aed0-ae5b89ca2da2: hola, qu est haciendo?
2024-12-02 17:56:53,376 [DEBUG] app1.py:925 - Translation sent successfully to client 65e638b0-1041-4202-aed0-ae5b89ca2da2
2024-12-02 17:56:53,376 [DEBUG] app1.py:1144 - Sending message to client 65e638b0-1041-4202-aed0-ae5b89ca2da2: {'type': 'final', 'translation': 'hola, qu est haciendo?'}
2024-12-02 17:56:53,481 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 17:56:56,122 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 17:56:56,213 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 17:56:56,305 [INFO] app1.py:1240 - Audio stream started
2024-12-02 17:56:58,059 [DEBUG] app1.py:1214 - Speech recognizing: hey what are you
2024-12-02 17:56:58,060 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e039b50b81a3448a8a87a26672701b96, text="hey what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:58,262 [DEBUG] app1.py:1214 - Speech recognizing: hey what are you doing
2024-12-02 17:56:58,262 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=beb01183f5e8414cbcb75752258e049a, text="hey what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:59,257 [DEBUG] app1.py:1214 - Speech recognizing: hey what are you doing are you
2024-12-02 17:56:59,257 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1b2af1d6265040308f68937b8479002b, text="hey what are you doing are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:59,459 [DEBUG] app1.py:1214 - Speech recognizing: hey what are you doing are you listen
2024-12-02 17:56:59,460 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=861a36e066a04d438ad4777db1cf38ee, text="hey what are you doing are you listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:59,497 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 17:56:59,498 [INFO] app1.py:1121 - New translation stream connection for client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, language: es
2024-12-02 17:56:59,498 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 17:56:59,499 [DEBUG] app1.py:1104 - Sending transcription: hey what are you (is_final: False)
2024-12-02 17:56:59,499 [DEBUG] app1.py:1104 - Sending transcription: hey what are you doing (is_final: False)
2024-12-02 17:56:59,501 [DEBUG] app1.py:1104 - Sending transcription: hey what are you doing are you (is_final: False)
2024-12-02 17:56:59,502 [DEBUG] app1.py:1104 - Sending transcription: hey what are you doing are you listen (is_final: False)
2024-12-02 17:56:59,516 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:59,523 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey what are you', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:59,524 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:59,524 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:59,524 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:59,524 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey what are you doing', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:59,524 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:59,525 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey what are you doing are you', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:59,527 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:59,527 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey what are you doing are you listen', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:59,528 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:59,528 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:59,566 [DEBUG] app1.py:1214 - Speech recognizing: hey what are you doing are you listening
2024-12-02 17:56:59,568 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9a3cc2285364abb84818a767f21f928, text="hey what are you doing are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:59,571 [DEBUG] app1.py:1104 - Sending transcription: hey what are you doing are you listening (is_final: False)
2024-12-02 17:56:59,574 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:59,575 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey what are you doing are you listening', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:59,575 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:56:59,955 [DEBUG] app1.py:1214 - Speech recognizing: hey what are you doing are you listening me
2024-12-02 17:56:59,956 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=93e4f91610184957ab8fa58850ed8b6e, text="hey what are you doing are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:56:59,956 [DEBUG] app1.py:1104 - Sending transcription: hey what are you doing are you listening me (is_final: False)
2024-12-02 17:56:59,961 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:56:59,961 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey what are you doing are you listening me', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:56:59,962 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:57:01,572 [INFO] app1.py:1205 - Speech recognized: Hey, what are you doing? Are you listening me?
2024-12-02 17:57:01,574 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ce7ab82701e3490486d397902dc01984, text="Hey, what are you doing? Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:57:01,575 [DEBUG] app1.py:1104 - Sending transcription: Hey, what are you doing? Are you listening me? (is_final: True)
2024-12-02 17:57:01,600 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:57:01,600 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hey, what are you doing? Are you listening me?', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: True
2024-12-02 17:57:01,601 [DEBUG] app1.py:1042 - Normalized text: 'hey, what are you doing? are you listening me?'
2024-12-02 17:57:01,604 [DEBUG] app1.py:1048 - Time since last translation for 65e638b0-1041-4202-aed0-ae5b89ca2da2:es: 8.749036312103271s
2024-12-02 17:57:01,604 [DEBUG] app1.py:1056 - Checking cache with key: hey, what are you doing? are you listening me?:es
2024-12-02 17:57:01,604 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 17:57:01,604 [INFO] app1.py:933 - Starting translation request - Text: 'hey, what are you doing? are you listening me?', Target language: es
2024-12-02 17:57:01,605 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 17:57:01,606 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 17:57:01,606 [DEBUG] app1.py:964 - Request body: [{'text': 'hey, what are you doing? are you listening me?'}]
2024-12-02 17:57:02,656 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 17:57:02,657 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7bcacc8dc2cc4837bb68d87375c8d132, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:57:02,658 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 17:57:02,661 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:57:02,662 [DEBUG] app1.py:1031 - Received translation request - Text: 'are you listening', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:57:02,662 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:57:02,845 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 17:57:02,846 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Oye, qu ests haciendo? Me ests escuchando?', 'to': 'es'}]}]
2024-12-02 17:57:02,847 [DEBUG] app1.py:974 - Extracted translation: Oye, qu ests haciendo? Me ests escuchando?
2024-12-02 17:57:02,848 [INFO] app1.py:975 - Translation completed successfully - Original: 'hey, what are you doing? are you listening me?' -> Translation: 'Oye, qu ests haciendo? Me ests escuchando?' (es)
2024-12-02 17:57:02,849 [DEBUG] app1.py:918 - Sending translation to client 65e638b0-1041-4202-aed0-ae5b89ca2da2: Oye, qu ests haciendo? Me ests escuchando?
2024-12-02 17:57:02,850 [DEBUG] app1.py:925 - Translation sent successfully to client 65e638b0-1041-4202-aed0-ae5b89ca2da2
2024-12-02 17:57:02,851 [DEBUG] app1.py:1144 - Sending message to client 65e638b0-1041-4202-aed0-ae5b89ca2da2: {'type': 'final', 'translation': 'Oye, qu ests haciendo? Me ests escuchando?'}
2024-12-02 17:57:02,857 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Oye, qu ests haciendo? Me ests escuchando?', Language: es
2024-12-02 17:57:02,858 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_158c950c-488b-4be2-8cba-a0c5daa51f30.wav
2024-12-02 17:57:02,859 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 17:57:03,178 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 17:57:03,902 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 17:57:03,903 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_158c950c-488b-4be2-8cba-a0c5daa51f30.wav
2024-12-02 17:57:04,459 [INFO] app1.py:1205 - Speech recognized: Are you listening?
2024-12-02 17:57:04,460 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fd1ed545cba04f9a81010b2f83e2c536, text="Are you listening?", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:57:04,460 [DEBUG] app1.py:1104 - Sending transcription: Are you listening? (is_final: True)
2024-12-02 17:57:04,464 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:57:04,465 [DEBUG] app1.py:1031 - Received translation request - Text: 'Are you listening?', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: True
2024-12-02 17:57:04,465 [DEBUG] app1.py:1042 - Normalized text: 'are you listening?'
2024-12-02 17:57:04,465 [DEBUG] app1.py:1048 - Time since last translation for 65e638b0-1041-4202-aed0-ae5b89ca2da2:es: 2.8617372512817383s
2024-12-02 17:57:04,465 [DEBUG] app1.py:1056 - Checking cache with key: are you listening?:es
2024-12-02 17:57:04,465 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 17:57:04,465 [INFO] app1.py:933 - Starting translation request - Text: 'are you listening?', Target language: es
2024-12-02 17:57:04,465 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 17:57:04,465 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 17:57:04,465 [DEBUG] app1.py:964 - Request body: [{'text': 'are you listening?'}]
2024-12-02 17:57:04,773 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 17:57:04,774 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Ests escuchando?', 'to': 'es'}]}]
2024-12-02 17:57:04,775 [DEBUG] app1.py:974 - Extracted translation: Ests escuchando?
2024-12-02 17:57:04,775 [INFO] app1.py:975 - Translation completed successfully - Original: 'are you listening?' -> Translation: 'Ests escuchando?' (es)
2024-12-02 17:57:04,777 [DEBUG] app1.py:918 - Sending translation to client 65e638b0-1041-4202-aed0-ae5b89ca2da2: Ests escuchando?
2024-12-02 17:57:04,778 [DEBUG] app1.py:925 - Translation sent successfully to client 65e638b0-1041-4202-aed0-ae5b89ca2da2
2024-12-02 17:57:04,779 [DEBUG] app1.py:1144 - Sending message to client 65e638b0-1041-4202-aed0-ae5b89ca2da2: {'type': 'final', 'translation': 'Ests escuchando?'}
2024-12-02 17:57:19,660 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 17:57:19,660 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=25e083bafe694bb7a5a5ca51dcb20c89, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:57:19,661 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 17:57:19,667 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:57:19,668 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:57:19,669 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:57:20,066 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana the fancy
2024-12-02 17:57:20,067 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=06101c14dd0c44c0a624be90f0e66dfc, text="hey cortana the fancy", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:57:20,069 [DEBUG] app1.py:1104 - Sending transcription: hey cortana the fancy (is_final: False)
2024-12-02 17:57:20,074 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:57:20,074 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana the fancy', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:57:20,075 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:57:20,362 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana the fancy element
2024-12-02 17:57:20,363 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c8312fcb80e745d09a600deb0f676ef8, text="hey cortana the fancy element", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:57:20,364 [DEBUG] app1.py:1104 - Sending transcription: hey cortana the fancy element (is_final: False)
2024-12-02 17:57:20,369 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:57:20,369 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana the fancy element', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:57:20,370 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:57:20,660 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 17:57:20,661 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=edb66cf03bad4f1780960297ef51d4b8, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:57:20,662 [DEBUG] app1.py:1104 - Sending transcription: hey cortana (is_final: False)
2024-12-02 17:57:20,666 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 17:57:20,666 [DEBUG] app1.py:1031 - Received translation request - Text: 'hey cortana', Target: es, Client: 65e638b0-1041-4202-aed0-ae5b89ca2da2, Final: False
2024-12-02 17:57:20,667 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 17:57:22,587 [INFO] app1.py:1205 - Speech recognized: Hey, Cortana.
2024-12-02 17:57:22,588 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bfb6872dc5ec4c268d1199832161e4ed, text="Hey, Cortana.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:57:22,590 [DEBUG] app1.py:1104 - Sending transcription: Hey, Cortana. (is_final: True)
2024-12-02 17:57:33,180 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 17:57:42,810 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:57:42,811 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2fb49dc79b0d43f98c4d087b86967e67, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:57:49,066 [DEBUG] app1.py:1214 - Speech recognizing: thank you so much
2024-12-02 17:57:49,067 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f99e1e34025b447884b037119221e302, text="thank you so much", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:57:50,872 [INFO] app1.py:1205 - Speech recognized: Thank you so much.
2024-12-02 17:57:50,872 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d51336bcada54851861efd34cf273a12, text="Thank you so much.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:58:03,182 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 17:58:10,798 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:58:10,799 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=77505ad235414ed4af37b0375baba03a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:58:23,053 [DEBUG] app1.py:1214 - Speech recognizing: the
2024-12-02 17:58:23,054 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2899559ab56f4205912826ef56221620, text="the", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:58:24,686 [INFO] app1.py:1205 - Speech recognized: The.
2024-12-02 17:58:24,687 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=602d5e6f7ce14f27a2e4d06c36edb5a1, text="The.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:58:29,165 [DEBUG] app1.py:1214 - Speech recognizing: enemy
2024-12-02 17:58:29,166 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a9a3ae53a05d4f0886a10d2ea50612b6, text="enemy", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:58:31,073 [INFO] app1.py:1205 - Speech recognized: Enemy.
2024-12-02 17:58:31,073 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=19a616ab45ee42d9987adb02838ea8e0, text="Enemy.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:58:33,184 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 17:58:48,863 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:58:48,865 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=137a737a93e94211a6854542e5816ed4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:59:03,187 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 17:59:06,029 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:59:06,029 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e10d6584e78843cf89a398305e010858, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:59:21,030 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:59:21,031 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4d677f71dc554c849949559d4eb3c864, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:59:24,567 [DEBUG] app1.py:1214 - Speech recognizing: the
2024-12-02 17:59:24,569 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9c2b36f42bab403c8f39c603b3e1550f, text="the", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:59:25,080 [DEBUG] app1.py:1214 - Speech recognizing: the bag
2024-12-02 17:59:25,081 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2c387e7ba2824ae6bef222ad34bdbc32, text="the bag", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:59:25,172 [DEBUG] app1.py:1214 - Speech recognizing: the bag down there
2024-12-02 17:59:25,173 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=84ad368a3aaf4be1bc0941cb02249242, text="the bag down there", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:59:26,073 [DEBUG] app1.py:1214 - Speech recognizing: the bag out there bagged out
2024-12-02 17:59:26,074 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f0f8aed804d848b7aa42372ddec32143, text="the bag out there bagged out", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:59:26,477 [DEBUG] app1.py:1214 - Speech recognizing: the bag down there back down there
2024-12-02 17:59:26,478 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=94233984a151497e82e8138a4cd3d541, text="the bag down there back down there", reason=ResultReason.RecognizingSpeech)
2024-12-02 17:59:26,772 [INFO] app1.py:1205 - Speech recognized: The bag down there, back down there.
2024-12-02 17:59:26,773 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf3b01397d4c45df8a09cd317366afd8, text="The bag down there, back down there.", reason=ResultReason.RecognizedSpeech)
2024-12-02 17:59:33,188 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 17:59:46,993 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 17:59:46,994 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a1f40b7011574d28aff19b58d26f5a99, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:00:02,081 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:00:02,081 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=750dc810bff441449d175bf9fe761035, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:00:03,191 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:00:17,029 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:00:17,030 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7b00fdf7eacd48dabe4925650bbe0a68, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:00:32,267 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:00:32,268 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5019ec2a5d5f42fb8451aa81a6f9c118, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:00:33,193 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:00:47,271 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:00:47,272 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=117cc13cfa2143c0b3b79fc0c2c73093, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:01:01,416 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 18:01:01,417 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ab5eff4c6c4245b19cbc5635fea80642, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:01:03,195 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:01:05,027 [DEBUG] app1.py:1214 - Speech recognizing: premar
2024-12-02 18:01:05,027 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f15ab28053044f5da7f4bd81262b3f14, text="premar", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:01:05,524 [DEBUG] app1.py:1214 - Speech recognizing: priyanka marathon
2024-12-02 18:01:05,525 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a8cfc5d991bb4e3caf791c79aaff8916, text="priyanka marathon", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:01:07,430 [INFO] app1.py:1205 - Speech recognized: Premarin.
2024-12-02 18:01:07,432 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7826920fdadf43b2a27d6fdeeae72be1, text="Premarin.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:01:24,365 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:01:24,365 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1e544fe1fb7d4935aadcf65e88ded05b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:01:33,198 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:01:36,444 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 18:01:36,445 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f769c36e8a854d2f85b6d78e34444966, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:01:54,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:01:54,569 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d3ec83cd25234306836ccf3bc312a9b7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:02:03,200 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:02:11,441 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:02:11,443 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=da063dbe3619401b8107600a71abb90b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:02:26,431 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:02:26,432 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=69c309f04d6048d28a15a93965d4c8aa, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:02:33,201 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:02:41,681 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:02:41,681 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ceb8601c311c439d87d89643fff7d143, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:02:56,638 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:02:56,639 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cdb76247ae944cf885d97e669f2f83ed, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:03:03,204 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:03:11,628 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:03:11,629 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=60e1fb02b1d5431d9806089c938825fb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:03:18,557 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 18:03:18,558 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=77c21ed9b2204763ba2e67522c2f5dbe, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:03:33,205 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:03:38,422 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:03:38,423 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c15fcb7f2cf444ae895a1bde9c45e478, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:03:44,145 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:03:44,146 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:03:44,146 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,148 [DEBUG] app1.py:1104 - Sending transcription: thank you so much (is_final: False)
2024-12-02 18:03:44,148 [DEBUG] app1.py:1104 - Sending transcription: Thank you so much. (is_final: True)
2024-12-02 18:03:44,149 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,149 [DEBUG] app1.py:1104 - Sending transcription: the (is_final: False)
2024-12-02 18:03:44,150 [DEBUG] app1.py:1104 - Sending transcription: The. (is_final: True)
2024-12-02 18:03:44,150 [DEBUG] app1.py:1104 - Sending transcription: enemy (is_final: False)
2024-12-02 18:03:44,151 [DEBUG] app1.py:1104 - Sending transcription: Enemy. (is_final: True)
2024-12-02 18:03:44,152 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,161 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,164 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,167 [DEBUG] app1.py:1104 - Sending transcription: the (is_final: False)
2024-12-02 18:03:44,168 [DEBUG] app1.py:1104 - Sending transcription: the bag (is_final: False)
2024-12-02 18:03:44,170 [DEBUG] app1.py:1104 - Sending transcription: the bag down there (is_final: False)
2024-12-02 18:03:44,171 [DEBUG] app1.py:1104 - Sending transcription: the bag out there bagged out (is_final: False)
2024-12-02 18:03:44,174 [DEBUG] app1.py:1104 - Sending transcription: the bag down there back down there (is_final: False)
2024-12-02 18:03:44,174 [DEBUG] app1.py:1104 - Sending transcription: The bag down there, back down there. (is_final: True)
2024-12-02 18:03:44,181 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,182 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,183 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,184 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,185 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,186 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 18:03:44,186 [DEBUG] app1.py:1104 - Sending transcription: premar (is_final: False)
2024-12-02 18:03:44,187 [DEBUG] app1.py:1104 - Sending transcription: priyanka marathon (is_final: False)
2024-12-02 18:03:44,191 [DEBUG] app1.py:1104 - Sending transcription: Premarin. (is_final: True)
2024-12-02 18:03:44,192 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,193 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 18:03:44,197 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,199 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,199 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,201 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,202 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,202 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:44,204 [DEBUG] app1.py:1104 - Sending transcription: I. (is_final: True)
2024-12-02 18:03:44,209 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:03:45,557 [DEBUG] app1.py:1214 - Speech recognizing: thank you
2024-12-02 18:03:45,561 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=63e83ff66d4549e8ae914d21c4300477, text="thank you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:03:45,562 [DEBUG] app1.py:1104 - Sending transcription: thank you (is_final: False)
2024-12-02 18:03:45,760 [DEBUG] app1.py:1214 - Speech recognizing: thank you so much
2024-12-02 18:03:45,762 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=49e6ba1e83034fad860cb2a6e5b64e11, text="thank you so much", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:03:45,763 [DEBUG] app1.py:1104 - Sending transcription: thank you so much (is_final: False)
2024-12-02 18:03:46,886 [INFO] app1.py:1205 - Speech recognized: Thank you so much.
2024-12-02 18:03:46,887 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a17f071427eb4372b57b6a967ed4da6f, text="Thank you so much.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:03:46,888 [DEBUG] app1.py:1104 - Sending transcription: Thank you so much. (is_final: True)
2024-12-02 18:03:52,256 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 18:03:52,257 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4a0b9c02125846bfa737e1c378d63075, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:03:52,259 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 18:03:52,660 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 18:03:52,662 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aa2caac6b9a140ab83502abffe2223ba, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:03:52,663 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 18:03:54,571 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:03:54,572 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7435bf4455e1437181a97493550472af, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:03:54,572 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:03:54,574 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:03:54,574 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6cf79821fcad4a6d81cd7c9610cb37dd, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:03:54,574 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 18:03:57,650 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:03:57,651 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0ae4fd98ee0a4032a3838618bc913d22, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:03:57,651 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:03:59,788 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 18:03:59,979 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 18:04:03,207 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2']
2024-12-02 18:04:05,795 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 18:04:05,802 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:04:05,803 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:04:05,804 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:04:05,804 [INFO] app1.py:1131 - Creating new client connection: ab2ee750-7736-495c-bd4f-3077d2402fea
2024-12-02 18:04:05,849 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 18:04:05,941 [INFO] app1.py:1240 - Audio stream started
2024-12-02 18:04:08,335 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:04:08,336 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=26bea70a336c4515b51c5ee85e3c3e7b, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:08,336 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:04:08,344 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:08,344 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:08,344 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:08,537 [DEBUG] app1.py:1214 - Speech recognizing: hello how are you
2024-12-02 18:04:08,538 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=115a24dda5a14bc2a3e08bb6c3d246fe, text="hello how are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:08,540 [DEBUG] app1.py:1104 - Sending transcription: hello how are you (is_final: False)
2024-12-02 18:04:08,544 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:08,545 [DEBUG] app1.py:1031 - Received translation request - Text: 'hello how are you', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:08,547 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:09,455 [INFO] app1.py:1205 - Speech recognized: Hello, how are you?
2024-12-02 18:04:09,455 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8ce6f5e223ed4d8ba27930ee909e50a7, text="Hello, how are you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:04:09,456 [DEBUG] app1.py:1104 - Sending transcription: Hello, how are you? (is_final: True)
2024-12-02 18:04:09,460 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:09,461 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hello, how are you?', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: True
2024-12-02 18:04:09,461 [DEBUG] app1.py:1042 - Normalized text: 'hello, how are you?'
2024-12-02 18:04:09,462 [DEBUG] app1.py:1056 - Checking cache with key: hello, how are you?:es
2024-12-02 18:04:09,462 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 18:04:09,463 [INFO] app1.py:933 - Starting translation request - Text: 'hello, how are you?', Target language: es
2024-12-02 18:04:09,463 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 18:04:09,464 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 18:04:09,464 [DEBUG] app1.py:964 - Request body: [{'text': 'hello, how are you?'}]
2024-12-02 18:04:10,678 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 18:04:10,679 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 1.0}, 'translations': [{'text': 'Hola cmo ests?', 'to': 'es'}]}]
2024-12-02 18:04:10,679 [DEBUG] app1.py:974 - Extracted translation: Hola cmo ests?
2024-12-02 18:04:10,680 [INFO] app1.py:975 - Translation completed successfully - Original: 'hello, how are you?' -> Translation: 'Hola cmo ests?' (es)
2024-12-02 18:04:10,681 [DEBUG] app1.py:918 - Sending translation to client ab2ee750-7736-495c-bd4f-3077d2402fea: Hola cmo ests?
2024-12-02 18:04:10,682 [DEBUG] app1.py:925 - Translation sent successfully to client ab2ee750-7736-495c-bd4f-3077d2402fea
2024-12-02 18:04:10,682 [DEBUG] app1.py:1144 - Sending message to client ab2ee750-7736-495c-bd4f-3077d2402fea: {'type': 'final', 'translation': 'Hola cmo ests?'}
2024-12-02 18:04:10,688 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Hola cmo ests?', Language: es
2024-12-02 18:04:10,689 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_5bca778d-b1f6-4a34-aa3c-7f5c7f73efd8.wav
2024-12-02 18:04:10,691 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 18:04:11,642 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 18:04:11,643 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_5bca778d-b1f6-4a34-aa3c-7f5c7f73efd8.wav
2024-12-02 18:04:13,333 [DEBUG] app1.py:1214 - Speech recognizing: hola
2024-12-02 18:04:13,335 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d118b59884984d428e81724e0a9ca751, text="hola", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:13,335 [DEBUG] app1.py:1104 - Sending transcription: hola (is_final: False)
2024-12-02 18:04:13,355 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:13,356 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:13,357 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:14,106 [DEBUG] app1.py:1214 - Speech recognizing: hola comoza
2024-12-02 18:04:14,107 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3175a390730844a2ac9a62e831f24cc9, text="hola comoza", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:14,107 [DEBUG] app1.py:1104 - Sending transcription: hola comoza (is_final: False)
2024-12-02 18:04:14,113 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:14,114 [DEBUG] app1.py:1031 - Received translation request - Text: 'hola comoza', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:14,114 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:14,414 [INFO] app1.py:1205 - Speech recognized: Hola.
2024-12-02 18:04:14,414 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d46943976d274aa9a8dda7555d6d62ed, text="Hola.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:04:14,415 [DEBUG] app1.py:1104 - Sending transcription: Hola. (is_final: True)
2024-12-02 18:04:14,420 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:14,420 [DEBUG] app1.py:1031 - Received translation request - Text: 'Hola.', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: True
2024-12-02 18:04:14,421 [DEBUG] app1.py:1042 - Normalized text: 'hola.'
2024-12-02 18:04:14,421 [DEBUG] app1.py:1048 - Time since last translation for ab2ee750-7736-495c-bd4f-3077d2402fea:es: 4.9594197273254395s
2024-12-02 18:04:14,422 [DEBUG] app1.py:1056 - Checking cache with key: hola.:es
2024-12-02 18:04:14,422 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 18:04:14,422 [INFO] app1.py:933 - Starting translation request - Text: 'hola.', Target language: es
2024-12-02 18:04:14,423 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 18:04:14,423 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 18:04:14,423 [DEBUG] app1.py:964 - Request body: [{'text': 'hola.'}]
2024-12-02 18:04:14,922 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 18:04:14,923 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'es', 'score': 1.0}, 'translations': [{'text': 'hola.', 'to': 'es'}]}]
2024-12-02 18:04:14,924 [DEBUG] app1.py:974 - Extracted translation: hola.
2024-12-02 18:04:14,926 [INFO] app1.py:975 - Translation completed successfully - Original: 'hola.' -> Translation: 'hola.' (es)
2024-12-02 18:04:14,927 [DEBUG] app1.py:918 - Sending translation to client ab2ee750-7736-495c-bd4f-3077d2402fea: hola.
2024-12-02 18:04:14,927 [DEBUG] app1.py:925 - Translation sent successfully to client ab2ee750-7736-495c-bd4f-3077d2402fea
2024-12-02 18:04:14,927 [DEBUG] app1.py:1144 - Sending message to client ab2ee750-7736-495c-bd4f-3077d2402fea: {'type': 'final', 'translation': 'hola.'}
2024-12-02 18:04:14,931 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'hola.', Language: es
2024-12-02 18:04:14,951 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3b55f0de-22e4-4e14-9ad0-6f0ce3a9d0aa.wav
2024-12-02 18:04:14,952 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 18:04:15,764 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 18:04:15,765 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_3b55f0de-22e4-4e14-9ad0-6f0ce3a9d0aa.wav
2024-12-02 18:04:16,821 [DEBUG] app1.py:1214 - Speech recognizing: cuban
2024-12-02 18:04:16,824 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3f64a0b35d0f4f03b959f25ef5fae04e, text="cuban", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:16,825 [DEBUG] app1.py:1104 - Sending transcription: cuban (is_final: False)
2024-12-02 18:04:16,831 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:16,831 [DEBUG] app1.py:1031 - Received translation request - Text: 'cuban', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:16,831 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:17,114 [DEBUG] app1.py:1214 - Speech recognizing: cuban olymp
2024-12-02 18:04:17,115 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bea37428fa0a4cc3a03079b6a8db7662, text="cuban olymp", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:17,117 [DEBUG] app1.py:1104 - Sending transcription: cuban olymp (is_final: False)
2024-12-02 18:04:17,123 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:17,124 [DEBUG] app1.py:1031 - Received translation request - Text: 'cuban olymp', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:17,125 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:17,210 [DEBUG] app1.py:1214 - Speech recognizing: cuban olympia
2024-12-02 18:04:17,211 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3fc4e44d531d4c469241ba501ae29115, text="cuban olympia", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:17,212 [DEBUG] app1.py:1104 - Sending transcription: cuban olympia (is_final: False)
2024-12-02 18:04:17,221 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:17,223 [DEBUG] app1.py:1031 - Received translation request - Text: 'cuban olympia', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:17,224 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:17,653 [INFO] app1.py:1205 - Speech recognized: Cuban Olympia College.
2024-12-02 18:04:17,654 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a8e89867ac8c4cdbae3d2687d1fd2978, text="Cuban Olympia College.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:04:17,657 [DEBUG] app1.py:1104 - Sending transcription: Cuban Olympia College. (is_final: True)
2024-12-02 18:04:17,681 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:17,681 [DEBUG] app1.py:1031 - Received translation request - Text: 'Cuban Olympia College.', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: True
2024-12-02 18:04:17,682 [DEBUG] app1.py:1042 - Normalized text: 'cuban olympia college.'
2024-12-02 18:04:17,683 [DEBUG] app1.py:1048 - Time since last translation for ab2ee750-7736-495c-bd4f-3077d2402fea:es: 3.2622790336608887s
2024-12-02 18:04:17,683 [DEBUG] app1.py:1056 - Checking cache with key: cuban olympia college.:es
2024-12-02 18:04:17,683 [DEBUG] app1.py:1071 - No cache hit, proceeding with translation
2024-12-02 18:04:17,684 [INFO] app1.py:933 - Starting translation request - Text: 'cuban olympia college.', Target language: es
2024-12-02 18:04:17,686 [DEBUG] app1.py:962 - Making API request to https://api.cognitive.microsofttranslator.com/translate
2024-12-02 18:04:17,686 [DEBUG] app1.py:963 - Request params: {'api-version': '3.0', 'to': 'es'}
2024-12-02 18:04:17,687 [DEBUG] app1.py:964 - Request body: [{'text': 'cuban olympia college.'}]
2024-12-02 18:04:17,983 [DEBUG] app1.py:967 - Response status: 200
2024-12-02 18:04:17,984 [DEBUG] app1.py:971 - Raw API response: [{'detectedLanguage': {'language': 'en', 'score': 0.99}, 'translations': [{'text': 'Colegio Olimpiado Cubano.', 'to': 'es'}]}]
2024-12-02 18:04:17,987 [DEBUG] app1.py:974 - Extracted translation: Colegio Olimpiado Cubano.
2024-12-02 18:04:17,988 [INFO] app1.py:975 - Translation completed successfully - Original: 'cuban olympia college.' -> Translation: 'Colegio Olimpiado Cubano.' (es)
2024-12-02 18:04:17,990 [DEBUG] app1.py:918 - Sending translation to client ab2ee750-7736-495c-bd4f-3077d2402fea: Colegio Olimpiado Cubano.
2024-12-02 18:04:17,993 [DEBUG] app1.py:925 - Translation sent successfully to client ab2ee750-7736-495c-bd4f-3077d2402fea
2024-12-02 18:04:17,994 [DEBUG] app1.py:1144 - Sending message to client ab2ee750-7736-495c-bd4f-3077d2402fea: {'type': 'final', 'translation': 'Colegio Olimpiado Cubano.'}
2024-12-02 18:04:18,027 [INFO] app1.py:1274 - Speech synthesis requested - Text: 'Colegio Olimpiado Cubano.', Language: es
2024-12-02 18:04:18,027 [DEBUG] app1.py:1295 - Created temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_92a6bb76-91ff-46d9-a82a-9b4f9659f437.wav
2024-12-02 18:04:18,029 [DEBUG] app1.py:1304 - Starting speech synthesis
2024-12-02 18:04:18,969 [INFO] app1.py:1317 - Speech synthesis completed successfully
2024-12-02 18:04:18,970 [DEBUG] app1.py:1341 - Cleaning up temporary file: C:\Users\RAHULR~1\AppData\Local\Temp\speech_92a6bb76-91ff-46d9-a82a-9b4f9659f437.wav
2024-12-02 18:04:20,898 [DEBUG] app1.py:1214 - Speech recognizing: collection
2024-12-02 18:04:20,899 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7e5390f14b6543c89ba2a1e8e49720fb, text="collection", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:20,900 [DEBUG] app1.py:1104 - Sending transcription: collection (is_final: False)
2024-12-02 18:04:20,907 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:20,907 [DEBUG] app1.py:1031 - Received translation request - Text: 'collection', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:20,909 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:29,296 [DEBUG] app1.py:1214 - Speech recognizing: panama
2024-12-02 18:04:29,297 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=650301fd63f54c19b625c1ec016fca8c, text="panama", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:29,299 [DEBUG] app1.py:1104 - Sending transcription: panama (is_final: False)
2024-12-02 18:04:29,305 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:29,306 [DEBUG] app1.py:1031 - Received translation request - Text: 'panama', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:29,306 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:33,209 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:04:37,528 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:04:37,529 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4686ec1b324e40f99fec9445b5084a2f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:04:37,529 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:04:46,779 [DEBUG] app1.py:1214 - Speech recognizing: finish
2024-12-02 18:04:46,780 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=904c212a102a4c7d86a52e5d9a4f31b3, text="finish", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:04:46,781 [DEBUG] app1.py:1104 - Sending transcription: finish (is_final: False)
2024-12-02 18:04:46,789 [INFO] app1.py:1023 - Real-time translation endpoint called
2024-12-02 18:04:46,790 [DEBUG] app1.py:1031 - Received translation request - Text: 'finish', Target: es, Client: ab2ee750-7736-495c-bd4f-3077d2402fea, Final: False
2024-12-02 18:04:46,790 [DEBUG] app1.py:1038 - Skipping non-final transcription
2024-12-02 18:04:48,267 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:04:50,290 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:04:51,295 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:04:52,889 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:04:52,891 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1d9784169ad54fbeb8fb01a6a995879a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:04:52,892 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:04:53,656 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:04:54,671 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:04:57,656 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:04:58,660 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:00,669 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:01,524 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:05:01,525 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:05:01,686 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:03,211 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:05:03,697 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:03,817 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:05:03,819 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=46a5b7a870cb461fbecbf0c22844adbc, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:05:03,820 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:05:04,536 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:05:04,538 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d008cb7c1fe8464d8634eb1f4aa97d78, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:05:04,539 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 18:05:04,707 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:06,721 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:07,450 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:05:07,451 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e71c29ccad4a430282617859e2c2098c, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:05:07,453 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:05:07,454 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:05:07,455 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4761f5798faa43c0bfeb72f276a7cc96, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:05:07,456 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 18:05:07,738 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:10,661 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:11,664 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:14,623 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 18:05:14,624 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aa4082f15b3c4d6187d6e46a63880d4f, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:05:14,626 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 18:05:14,654 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:14,713 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 18:05:14,714 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=20c4eb5be4d54f178c239bbb976b4d6a, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:05:14,714 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 18:05:15,671 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:17,236 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 18:05:17,394 [DEBUG] app1.py:1214 - Speech recognizing: home
2024-12-02 18:05:17,395 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1bacb36d4e474466a8edf422a820da57, text="home", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:05:17,395 [DEBUG] app1.py:1104 - Sending transcription: home (is_final: False)
2024-12-02 18:05:17,396 [INFO] app1.py:1205 - Speech recognized: Home.
2024-12-02 18:05:17,397 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=deb3e1e59c224bd8b6365e3189fa5585, text="Home.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:05:17,397 [DEBUG] app1.py:1104 - Sending transcription: Home. (is_final: True)
2024-12-02 18:05:17,397 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 18:05:17,691 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:18,700 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:21,659 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:22,667 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:25,265 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:26,284 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:28,660 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:29,669 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:32,659 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:33,213 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:05:33,665 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:36,650 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:37,662 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:39,668 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:40,678 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:43,655 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:44,666 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:46,261 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 18:05:46,428 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 18:05:46,527 [INFO] app1.py:1240 - Audio stream started
2024-12-02 18:05:47,650 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:48,656 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:50,239 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:05:50,240 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8bdc9e1a9a28478080b7a41f1301c8d4, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:05:50,426 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:05:50,427 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c93511fb3f9648a9bb73aa58e30c34f1, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:05:51,667 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:52,699 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:54,722 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:55,017 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:05:55,017 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:05:55,018 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:05:55,019 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 18:05:55,732 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:05:56,602 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:05:56,603 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=763bdcc5f0744a098d173f8a41bf2b10, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:05:56,604 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:05:56,926 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:05:56,927 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4a41c03b71464cef837808a5fd1162d7, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:05:56,928 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 18:05:57,751 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:05:58,758 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:06:00,766 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:06:00,817 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 18:06:00,817 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a3589cb81c0642e0ab000333102fefbe, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:00,818 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 18:06:01,486 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 18:06:01,487 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f84f740637c14cd4bf4f04b72934090e, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:06:01,489 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 18:06:01,796 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:06:03,216 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:06:04,655 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:06:05,414 [DEBUG] app1.py:1214 - Speech recognizing: what are
2024-12-02 18:06:05,415 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3d7b0549f8c441a28cbd72f10a83724b, text="what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:05,416 [DEBUG] app1.py:1104 - Sending transcription: what are (is_final: False)
2024-12-02 18:06:05,662 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:06:05,817 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 18:06:05,819 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=807af0f4693c40d0908a1a3ad9416024, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:05,820 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 18:06:06,426 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 18:06:06,427 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4d49d7c1ea0a4652929bded574da0648, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:06:06,428 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 18:06:07,686 [DEBUG] app1.py:1214 - Speech recognizing: what are you
2024-12-02 18:06:07,686 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c1b1e628dd0c42cbafbe6923aba85813, text="what are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:07,686 [DEBUG] app1.py:1104 - Sending transcription: what are you (is_final: False)
2024-12-02 18:06:07,692 [INFO] app1.py:1121 - New translation stream connection for client: ab2ee750-7736-495c-bd4f-3077d2402fea, language: es
2024-12-02 18:06:07,994 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 18:06:07,994 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6b7f38cf58be44f883bb2c550f0d6481, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:07,996 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 18:06:08,290 [INFO] app1.py:1205 - Speech recognized: What are you doing?
2024-12-02 18:06:08,291 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=77c537c906554340a89ad20aeb07c31d, text="What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:06:08,291 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? (is_final: True)
2024-12-02 18:06:08,544 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 18:06:08,694 [WARNING] app1.py:1148 - Client ab2ee750-7736-495c-bd4f-3077d2402fea connection timed out
2024-12-02 18:06:08,771 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 18:06:15,548 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 18:06:15,713 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 18:06:15,826 [INFO] app1.py:1240 - Audio stream started
2024-12-02 18:06:17,778 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:06:17,779 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6af2ef524dca4d4583f863794ae369e5, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:18,373 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:06:18,375 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c8fe17024aa34ee4b674a57babece7ae, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:19,087 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 18:06:19,088 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f39c00a7c6a84bf2a51eee40da6fe89b, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:06:24,298 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:06:24,299 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:06:24,300 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:06:24,300 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:06:24,301 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 18:06:26,166 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 18:06:26,166 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=66cf5293e8e848538dc979452dbcd1ad, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:26,167 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 18:06:33,218 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:06:39,096 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:06:39,097 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c98d7dc0fed947d0af9116f07fffcbe6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:06:39,101 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:06:47,360 [DEBUG] app1.py:1214 - Speech recognizing: oh but i can see
2024-12-02 18:06:47,361 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9ba340da598140929d8e0f0d1ce35c7f, text="oh but i can see", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:47,362 [DEBUG] app1.py:1104 - Sending transcription: oh but i can see (is_final: False)
2024-12-02 18:06:48,060 [DEBUG] app1.py:1214 - Speech recognizing: oh but i can see your mom
2024-12-02 18:06:48,061 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=960b01e423e9437f874952611bceb109, text="oh but i can see your mom", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:48,062 [DEBUG] app1.py:1104 - Sending transcription: oh but i can see your mom (is_final: False)
2024-12-02 18:06:50,366 [DEBUG] app1.py:1214 - Speech recognizing: you can't
2024-12-02 18:06:50,367 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e19e2da6516e477b8835ff315ee74b2b, text="you can't", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:50,367 [DEBUG] app1.py:1104 - Sending transcription: you can't (is_final: False)
2024-12-02 18:06:50,460 [DEBUG] app1.py:1214 - Speech recognizing: you can't see
2024-12-02 18:06:50,461 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fc444768893e4e638edc44aed21e5c2e, text="you can't see", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:50,461 [DEBUG] app1.py:1104 - Sending transcription: you can't see (is_final: False)
2024-12-02 18:06:50,961 [DEBUG] app1.py:1214 - Speech recognizing: you can't see a man
2024-12-02 18:06:50,963 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=456666064a774dabaee710d5f3869b64, text="you can't see a man", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:50,964 [DEBUG] app1.py:1104 - Sending transcription: you can't see a man (is_final: False)
2024-12-02 18:06:51,160 [INFO] app1.py:1205 - Speech recognized: You can't see a human match.
2024-12-02 18:06:51,161 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=70b0ad2921f8493e88832718745bd375, text="You can't see a human match.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:06:51,161 [DEBUG] app1.py:1104 - Sending transcription: You can't see a human match. (is_final: True)
2024-12-02 18:06:53,554 [DEBUG] app1.py:1214 - Speech recognizing: i can't see you
2024-12-02 18:06:53,555 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc31d95e56c046a8a105a2f982e59c79, text="i can't see you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:06:53,556 [DEBUG] app1.py:1104 - Sending transcription: i can't see you (is_final: False)
2024-12-02 18:07:03,219 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:07:08,863 [INFO] app1.py:1205 - Speech recognized: OK.
2024-12-02 18:07:08,865 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=58fdbf4a91f0402fa7ac9dcd5445c09c, text="OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:08,867 [DEBUG] app1.py:1104 - Sending transcription: OK. (is_final: True)
2024-12-02 18:07:10,251 [DEBUG] app1.py:1214 - Speech recognizing: OK
2024-12-02 18:07:10,252 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e6869e98b1b74613ac1a3d384c1f7598, text="OK", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:10,252 [DEBUG] app1.py:1104 - Sending transcription: OK (is_final: False)
2024-12-02 18:07:12,070 [INFO] app1.py:1205 - Speech recognized: OK.
2024-12-02 18:07:12,072 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=df87191d851e43c1b0f4c65b6debef6f, text="OK.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:12,073 [DEBUG] app1.py:1104 - Sending transcription: OK. (is_final: True)
2024-12-02 18:07:12,461 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 18:07:12,461 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce4d4eccab534e13991b7317e2aff58c, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:12,464 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 18:07:12,961 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 18:07:12,962 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3cfa7666003647fea7ccc9ba9e109019, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:12,999 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 18:07:16,056 [DEBUG] app1.py:1214 - Speech recognizing: what
2024-12-02 18:07:16,062 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f7e3eda88ed343afb2361b17fc56986a, text="what", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:16,063 [DEBUG] app1.py:1104 - Sending transcription: what (is_final: False)
2024-12-02 18:07:16,458 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing
2024-12-02 18:07:16,458 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e4097a2339fc4b1d849db940b3616b3d, text="what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:16,459 [DEBUG] app1.py:1104 - Sending transcription: what are you doing (is_final: False)
2024-12-02 18:07:17,555 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing hi what
2024-12-02 18:07:17,556 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1e79a441c2e845a28eb557f4d5415006, text="what are you doing hi what", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:17,556 [DEBUG] app1.py:1104 - Sending transcription: what are you doing hi what (is_final: False)
2024-12-02 18:07:17,958 [DEBUG] app1.py:1214 - Speech recognizing: what are you doing hi what are you doing
2024-12-02 18:07:17,959 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8611ed2968984bd191d0936c5f6a9662, text="what are you doing hi what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:17,960 [DEBUG] app1.py:1104 - Sending transcription: what are you doing hi what are you doing (is_final: False)
2024-12-02 18:07:18,608 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 18:07:18,771 [INFO] app1.py:1205 - Speech recognized: What are you doing? Hi, what are you doing?
2024-12-02 18:07:18,772 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eb82948296944d3f8156621df32cb9b0, text="What are you doing? Hi, what are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:18,775 [DEBUG] app1.py:1104 - Sending transcription: What are you doing? Hi, what are you doing? (is_final: True)
2024-12-02 18:07:18,775 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 18:07:19,131 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 18:07:19,140 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:07:19,143 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:07:19,186 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 18:07:19,279 [INFO] app1.py:1240 - Audio stream started
2024-12-02 18:07:22,853 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:07:22,853 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3e0168d8caf64f24a7fc83068a3bdd39, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:22,854 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:07:23,056 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:07:23,057 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f16bb182b2854a07ac49fc406912190c, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:23,058 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:07:23,660 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 18:07:23,661 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a8e7602f48ba42f5b9b82fc11000e311, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:23,662 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 18:07:25,139 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:07:25,140 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2b2a72a006544800bd51bac432116fe6, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:25,141 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:07:25,636 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:07:25,637 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d5818f70141e485dad12ff2820a28890, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:25,637 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:07:26,943 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me can
2024-12-02 18:07:26,944 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e31609e1a2764a69ba1a65310de959f2, text="are you listening me can", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:26,944 [DEBUG] app1.py:1104 - Sending transcription: are you listening me can (is_final: False)
2024-12-02 18:07:27,034 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me can you hear me
2024-12-02 18:07:27,035 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=87caf1120ee64dfcaa68e11b09f22593, text="are you listening me can you hear me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:27,036 [DEBUG] app1.py:1104 - Sending transcription: are you listening me can you hear me (is_final: False)
2024-12-02 18:07:27,934 [INFO] app1.py:1205 - Speech recognized: Are you listening me? Can you hear me?
2024-12-02 18:07:27,935 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4656d44387794b0f95e766c82c396b5d, text="Are you listening me? Can you hear me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:27,937 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? Can you hear me? (is_final: True)
2024-12-02 18:07:29,023 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 18:07:29,024 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=afb0294bd63049928ccc67fb0a30bb5b, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:29,025 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 18:07:29,335 [DEBUG] app1.py:1214 - Speech recognizing: are you listen
2024-12-02 18:07:29,336 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=846f194bad134acbaa29831f588ebaa6, text="are you listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:29,337 [DEBUG] app1.py:1104 - Sending transcription: are you listen (is_final: False)
2024-12-02 18:07:29,427 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:07:29,428 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5a8a4aa3b2b2454c97c9ec40eedcc566, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:29,429 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:07:29,723 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:07:29,724 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b20c835a5473461d99e410cc8ffa1f74, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:29,725 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:07:30,566 [INFO] app1.py:1205 - Speech recognized: Are you listening me? Can you?
2024-12-02 18:07:30,567 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c829e1ff992647b392c86ebbda28cd17, text="Are you listening me? Can you?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:30,568 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? Can you? (is_final: True)
2024-12-02 18:07:33,221 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:07:33,926 [DEBUG] app1.py:1214 - Speech recognizing: uh i'm
2024-12-02 18:07:33,928 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6c538f1c785144238955872e26267d1d, text="uh i'm", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:33,929 [DEBUG] app1.py:1104 - Sending transcription: uh i'm (is_final: False)
2024-12-02 18:07:34,330 [DEBUG] app1.py:1214 - Speech recognizing: uh i'm here
2024-12-02 18:07:34,330 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5ff3f42583c14f49bd5ff72202b4d57b, text="uh i'm here", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:34,331 [DEBUG] app1.py:1104 - Sending transcription: uh i'm here (is_final: False)
2024-12-02 18:07:34,376 [INFO] app1.py:1205 - Speech recognized: Uh, I'm here.
2024-12-02 18:07:34,377 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0c801364be5f43acbc3fb8d0e6be518b, text="Uh, I'm here.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:34,378 [DEBUG] app1.py:1104 - Sending transcription: Uh, I'm here. (is_final: True)
2024-12-02 18:07:36,755 [DEBUG] app1.py:1214 - Speech recognizing: huh i'm here
2024-12-02 18:07:36,758 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=301e637b91634af385dffa2965d9d61a, text="huh i'm here", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:36,759 [DEBUG] app1.py:1104 - Sending transcription: huh i'm here (is_final: False)
2024-12-02 18:07:36,859 [INFO] app1.py:1205 - Speech recognized: Huh. I'm here.
2024-12-02 18:07:36,860 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=98df5ea0d6064e9a88620a23ebb184f2, text="Huh. I'm here.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:36,863 [DEBUG] app1.py:1104 - Sending transcription: Huh. I'm here. (is_final: True)
2024-12-02 18:07:39,251 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 18:07:39,252 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=225a93bdd63943bf839eac08abea73bd, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:39,252 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 18:07:39,455 [DEBUG] app1.py:1214 - Speech recognizing: are you listen
2024-12-02 18:07:39,455 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e86c022f0551409bb94464fbf7c0e3cf, text="are you listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:39,457 [DEBUG] app1.py:1104 - Sending transcription: are you listen (is_final: False)
2024-12-02 18:07:39,547 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:07:39,547 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8c1bdb07cb22451aafc53062db3ba213, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:39,548 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:07:39,844 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:07:39,845 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0b8ed858b6a047c393c98a55e4a5ccd9, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:39,846 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:07:40,172 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 18:07:40,173 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a89dadafeec64958b4ddaadfef124ec0, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:40,174 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 18:07:41,540 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:07:41,540 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1cec5de13cc746f49a926cb178b498d2, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:41,541 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:07:42,145 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:07:42,147 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=70431e071afe4de8800ad670fd9a4ac0, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:42,148 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:07:43,632 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me no
2024-12-02 18:07:43,632 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8be4dda9b14f409aab21429e2e016987, text="are you listening me no", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:43,634 [DEBUG] app1.py:1104 - Sending transcription: are you listening me no (is_final: False)
2024-12-02 18:07:43,976 [INFO] app1.py:1205 - Speech recognized: Are you listening me? No.
2024-12-02 18:07:43,977 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ac557181d03f4c2fa7e63f5de7783cb6, text="Are you listening me? No.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:43,979 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? No. (is_final: True)
2024-12-02 18:07:45,340 [DEBUG] app1.py:1214 - Speech recognizing: are you
2024-12-02 18:07:45,341 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=29601fdee26d466fbec9ca921d8d1a1e, text="are you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:45,341 [DEBUG] app1.py:1104 - Sending transcription: are you (is_final: False)
2024-12-02 18:07:45,650 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:07:45,650 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c56b708a343f42a4b9788a91efc9da10, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:45,652 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:07:45,851 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:07:45,852 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1f30fce01ebe46e6acaad0843af3d292, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:45,854 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:07:47,156 [INFO] app1.py:1205 - Speech recognized: Are you listening me? No.
2024-12-02 18:07:47,156 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6521ffc172ac475882b2ea299b4ad220, text="Are you listening me? No.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:47,157 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? No. (is_final: True)
2024-12-02 18:07:51,348 [DEBUG] app1.py:1214 - Speech recognizing: no
2024-12-02 18:07:51,349 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1b38d067b7004a8992e1501f2c338daa, text="no", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:51,351 [DEBUG] app1.py:1104 - Sending transcription: no (is_final: False)
2024-12-02 18:07:51,737 [DEBUG] app1.py:1214 - Speech recognizing: no why aren't
2024-12-02 18:07:51,737 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2273963c51bd47e8925a048bd16e28a2, text="no why aren't", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:51,738 [DEBUG] app1.py:1104 - Sending transcription: no why aren't (is_final: False)
2024-12-02 18:07:52,046 [DEBUG] app1.py:1214 - Speech recognizing: no why aren't you
2024-12-02 18:07:52,047 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9aed7d1323754ce9aa6884d01a1c0cf7, text="no why aren't you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:52,047 [DEBUG] app1.py:1104 - Sending transcription: no why aren't you (is_final: False)
2024-12-02 18:07:52,340 [DEBUG] app1.py:1214 - Speech recognizing: no why aren't you listening me
2024-12-02 18:07:52,341 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d0a2d82051fa4cac8cf430abf64e5d7e, text="no why aren't you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:52,341 [DEBUG] app1.py:1104 - Sending transcription: no why aren't you listening me (is_final: False)
2024-12-02 18:07:53,431 [INFO] app1.py:1205 - Speech recognized: No. Why aren't you listening me?
2024-12-02 18:07:53,432 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0474269c0ec24330b2eaefc67dbefbf8, text="No. Why aren't you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:53,433 [DEBUG] app1.py:1104 - Sending transcription: No. Why aren't you listening me? (is_final: True)
2024-12-02 18:07:54,826 [DEBUG] app1.py:1214 - Speech recognizing: no
2024-12-02 18:07:54,827 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ccce9e4bc3a0485eba749111ba56e82a, text="no", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:54,828 [DEBUG] app1.py:1104 - Sending transcription: no (is_final: False)
2024-12-02 18:07:55,733 [DEBUG] app1.py:1214 - Speech recognizing: no why
2024-12-02 18:07:55,733 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c383d583f58e4400994c1bff74bde531, text="no why", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:55,734 [DEBUG] app1.py:1104 - Sending transcription: no why (is_final: False)
2024-12-02 18:07:56,123 [DEBUG] app1.py:1214 - Speech recognizing: no why aren't
2024-12-02 18:07:56,125 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fe3be80ac3514456b4925fc6abb79568, text="no why aren't", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:56,126 [DEBUG] app1.py:1104 - Sending transcription: no why aren't (is_final: False)
2024-12-02 18:07:56,326 [DEBUG] app1.py:1214 - Speech recognizing: no why aren't you listening
2024-12-02 18:07:56,326 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8fc9e28c45a3432f9b3fae93e9796b1c, text="no why aren't you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:56,327 [DEBUG] app1.py:1104 - Sending transcription: no why aren't you listening (is_final: False)
2024-12-02 18:07:56,732 [DEBUG] app1.py:1214 - Speech recognizing: no why aren't you listening me
2024-12-02 18:07:56,733 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aacf35ce59e44b6991837b60959ecb4f, text="no why aren't you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:56,735 [DEBUG] app1.py:1104 - Sending transcription: no why aren't you listening me (is_final: False)
2024-12-02 18:07:57,572 [INFO] app1.py:1205 - Speech recognized: No. Why aren't you listening me?
2024-12-02 18:07:57,573 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=07d19b867dfc426e973d014f0268a776, text="No. Why aren't you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:07:57,574 [DEBUG] app1.py:1104 - Sending transcription: No. Why aren't you listening me? (is_final: True)
2024-12-02 18:07:59,313 [DEBUG] app1.py:1214 - Speech recognizing: please listen
2024-12-02 18:07:59,313 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2af6d720b75f45338b3d215b46704f51, text="please listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:59,314 [DEBUG] app1.py:1104 - Sending transcription: please listen (is_final: False)
2024-12-02 18:07:59,627 [DEBUG] app1.py:1214 - Speech recognizing: please listen me
2024-12-02 18:07:59,628 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a937ed3f93ee48d2aa8319581729ad34, text="please listen me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:07:59,629 [DEBUG] app1.py:1104 - Sending transcription: please listen me (is_final: False)
2024-12-02 18:08:00,267 [INFO] app1.py:1205 - Speech recognized: Please listen me.
2024-12-02 18:08:00,268 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8d762ec416744f21bb54ffa635b4a999, text="Please listen me.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:00,268 [DEBUG] app1.py:1104 - Sending transcription: Please listen me. (is_final: True)
2024-12-02 18:08:01,737 [DEBUG] app1.py:1214 - Speech recognizing: please listen
2024-12-02 18:08:01,738 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0c727657d9744058978a5ca832c47055, text="please listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:01,739 [DEBUG] app1.py:1104 - Sending transcription: please listen (is_final: False)
2024-12-02 18:08:02,237 [DEBUG] app1.py:1214 - Speech recognizing: please listen me
2024-12-02 18:08:02,237 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d6f7bd217f964e7ca45d53c9ab48acd2, text="please listen me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:02,237 [DEBUG] app1.py:1104 - Sending transcription: please listen me (is_final: False)
2024-12-02 18:08:03,223 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:08:03,319 [INFO] app1.py:1205 - Speech recognized: Please listen me.
2024-12-02 18:08:03,320 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d486412b67364c56bfe992c7ba28cbc0, text="Please listen me.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:03,321 [DEBUG] app1.py:1104 - Sending transcription: Please listen me. (is_final: True)
2024-12-02 18:08:13,833 [DEBUG] app1.py:1214 - Speech recognizing: please
2024-12-02 18:08:13,833 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0568469b11884780911e2b44060de91e, text="please", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:13,834 [DEBUG] app1.py:1104 - Sending transcription: please (is_final: False)
2024-12-02 18:08:14,128 [INFO] app1.py:1205 - Speech recognized: Please.
2024-12-02 18:08:14,128 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6e9b38439a65472fbfc82c24c147ec8f, text="Please.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:14,129 [DEBUG] app1.py:1104 - Sending transcription: Please. (is_final: True)
2024-12-02 18:08:15,937 [DEBUG] app1.py:1214 - Speech recognizing: please
2024-12-02 18:08:15,938 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2ecfb59d7c6d42a2be3c523876da748e, text="please", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:15,939 [DEBUG] app1.py:1104 - Sending transcription: please (is_final: False)
2024-12-02 18:08:16,765 [INFO] app1.py:1205 - Speech recognized: Please.
2024-12-02 18:08:16,766 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a69a1e3a456c42b7a3de0b06f26ecf27, text="Please.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:16,766 [DEBUG] app1.py:1104 - Sending transcription: Please. (is_final: True)
2024-12-02 18:08:18,638 [DEBUG] app1.py:1214 - Speech recognizing: please
2024-12-02 18:08:18,639 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=35af2a20ba1245caa04249e5584176af, text="please", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:18,640 [DEBUG] app1.py:1104 - Sending transcription: please (is_final: False)
2024-12-02 18:08:18,951 [DEBUG] app1.py:1214 - Speech recognizing: please listen
2024-12-02 18:08:18,952 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=07c4a7116a8546a2af902e2fb560df86, text="please listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:18,953 [DEBUG] app1.py:1104 - Sending transcription: please listen (is_final: False)
2024-12-02 18:08:19,152 [DEBUG] app1.py:1214 - Speech recognizing: please listen me
2024-12-02 18:08:19,153 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ce159f490c0c488ea6e3163fa52512e3, text="please listen me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:19,154 [DEBUG] app1.py:1104 - Sending transcription: please listen me (is_final: False)
2024-12-02 18:08:19,863 [INFO] app1.py:1205 - Speech recognized: Please listen me.
2024-12-02 18:08:19,863 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9c781bb7c295476aa513865382c0137c, text="Please listen me.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:19,863 [DEBUG] app1.py:1104 - Sending transcription: Please listen me. (is_final: True)
2024-12-02 18:08:21,529 [DEBUG] app1.py:1214 - Speech recognizing: please listen
2024-12-02 18:08:21,529 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bc7bde5ee75741ea8b3e02d76bed9c86, text="please listen", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:21,530 [DEBUG] app1.py:1104 - Sending transcription: please listen (is_final: False)
2024-12-02 18:08:21,824 [DEBUG] app1.py:1214 - Speech recognizing: please listen me
2024-12-02 18:08:21,824 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=28a34e4c0979468fb8123720f30f8a34, text="please listen me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:21,825 [DEBUG] app1.py:1104 - Sending transcription: please listen me (is_final: False)
2024-12-02 18:08:22,354 [INFO] app1.py:1205 - Speech recognized: Please listen me.
2024-12-02 18:08:22,368 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fab453279ad14334998b6468b5440610, text="Please listen me.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:22,369 [DEBUG] app1.py:1104 - Sending transcription: Please listen me. (is_final: True)
2024-12-02 18:08:32,429 [DEBUG] app1.py:1214 - Speech recognizing: please
2024-12-02 18:08:32,431 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=633301b8eb9347bda9392fcfcfb54392, text="please", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:32,433 [DEBUG] app1.py:1104 - Sending transcription: please (is_final: False)
2024-12-02 18:08:32,645 [INFO] app1.py:1205 - Speech recognized: Please.
2024-12-02 18:08:32,646 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5d6e3a05eef54a508824e05735342315, text="Please.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:32,647 [DEBUG] app1.py:1104 - Sending transcription: Please. (is_final: True)
2024-12-02 18:08:33,225 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:08:33,971 [DEBUG] app1.py:1214 - Speech recognizing: please
2024-12-02 18:08:33,972 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=821a3717714848fd97aa76b710e2f54c, text="please", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:08:33,973 [DEBUG] app1.py:1104 - Sending transcription: please (is_final: False)
2024-12-02 18:08:35,444 [INFO] app1.py:1205 - Speech recognized: Please.
2024-12-02 18:08:35,444 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fb47f6016a4c4aa995ae800117a00363, text="Please.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:35,446 [DEBUG] app1.py:1104 - Sending transcription: Please. (is_final: True)
2024-12-02 18:08:55,292 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:08:55,293 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4553007fd3484e0594e7e55f05fa4003, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:08:55,294 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:09:03,226 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:09:10,391 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:09:10,392 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=91f9760895e7486f973c766edbbbb79c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:09:10,392 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:09:14,606 [DEBUG] app1.py:1214 - Speech recognizing: like
2024-12-02 18:09:14,606 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b3caf6818b17425498c13bcc713f69af, text="like", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:14,607 [DEBUG] app1.py:1104 - Sending transcription: like (is_final: False)
2024-12-02 18:09:14,916 [DEBUG] app1.py:1214 - Speech recognizing: like mrs
2024-12-02 18:09:14,917 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ecc55063a0b245cebf86f6ec7e4f1ec0, text="like mrs", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:14,918 [DEBUG] app1.py:1104 - Sending transcription: like mrs (is_final: False)
2024-12-02 18:09:15,305 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yog
2024-12-02 18:09:15,306 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8ebc1e7c41254ad8aafd78d90126a2f7, text="like mrs yog", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:15,308 [DEBUG] app1.py:1104 - Sending transcription: like mrs yog (is_final: False)
2024-12-02 18:09:15,908 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga
2024-12-02 18:09:15,909 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=01517c4da22c487383466489aa4c50cb, text="like mrs yoga", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:15,911 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga (is_final: False)
2024-12-02 18:09:16,105 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga pajam
2024-12-02 18:09:16,105 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6cb1b87c6ee74aae843d397ba007e048, text="like mrs yoga pajam", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:16,105 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga pajam (is_final: False)
2024-12-02 18:09:16,806 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga
2024-12-02 18:09:16,806 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=972fda4833964eb9b36b060898f56e8e, text="like mrs yoga", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:16,806 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga (is_final: False)
2024-12-02 18:09:17,415 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga pajamas
2024-12-02 18:09:17,435 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a2f351fb766f49c7844d32949313f5d7, text="like mrs yoga pajamas", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:17,436 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga pajamas (is_final: False)
2024-12-02 18:09:17,820 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga essay nani
2024-12-02 18:09:17,821 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0209ed5c08004c518dd8db8e50a9880c, text="like mrs yoga essay nani", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:17,824 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga essay nani (is_final: False)
2024-12-02 18:09:18,102 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga essay nani yoga
2024-12-02 18:09:18,103 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=067b55f5a398432eaf67d79febd3ea43, text="like mrs yoga essay nani yoga", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:18,710 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga essay nani yoga tuchi
2024-12-02 18:09:18,710 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bfd304bcfdc845fcb0ab019f12162444, text="like mrs yoga essay nani yoga tuchi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:19,115 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga essay nani yoga kuchbi
2024-12-02 18:09:19,116 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bbfca7f61e0c428182c44b2b00d303cc, text="like mrs yoga essay nani yoga kuchbi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:09:21,026 [INFO] app1.py:1205 - Speech recognized: Like Mrs. yoga essay Nani yoga kuchi.
2024-12-02 18:09:21,027 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d4b37ad1080b45aaa86faf3d5509a9ed, text="Like Mrs. yoga essay Nani yoga kuchi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:09:33,228 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:09:41,145 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:09:41,148 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=453db5cb68804a8cb6af7c0a8f0ab63f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:09:56,190 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:09:56,191 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4f0eaf6715d941168605d68aa09f2e57, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:10:03,229 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:10:11,362 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:10:11,363 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=411e4e329fc6485ab9ee651bf5d447d1, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:10:26,412 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:10:26,413 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1f440ed879874b0d98cc45cb441ba17a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:10:33,231 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:10:41,569 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:10:41,570 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2b7f38126b274cb6a693c1c9cac00f71, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:10:56,621 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:10:56,621 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=76ab0470919d49c0a90f1fd4ad5031a5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:11:03,233 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:11:10,740 [DEBUG] app1.py:1214 - Speech recognizing: tamil
2024-12-02 18:11:10,740 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6d1181a7dca14d6c9452f124ef1e8f9c, text="tamil", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:11:11,031 [DEBUG] app1.py:1214 - Speech recognizing: tamil video
2024-12-02 18:11:11,032 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2c824a7f879847e2a502b3fbbcc70963, text="tamil video", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:11:11,841 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:11:11,841 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1aad734c92bf4ef294cf3671406e592a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:11:27,021 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:11:27,022 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=315daf656032413aaad08fe945938298, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:11:28,210 [DEBUG] app1.py:1214 - Speech recognizing: let me know
2024-12-02 18:11:28,210 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7e6b95f9dfb34c76bbdfeff9e815e9cd, text="let me know", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:11:29,298 [DEBUG] app1.py:1214 - Speech recognizing: let me know when you
2024-12-02 18:11:29,300 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=8368e56e92844f048183fabb59ab0ae5, text="let me know when you", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:11:29,331 [INFO] app1.py:1205 - Speech recognized: Let me know when you.
2024-12-02 18:11:29,331 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6552ec3bf48041d1b7e7fd87b1013d1f, text="Let me know when you.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:11:33,235 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:11:49,387 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:11:49,388 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9378c99e57a342cc892ecc5766d8f7f7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:12:03,237 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:12:04,449 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:12:04,451 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cddb8682921a4e1095af40297dede923, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:12:19,763 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:12:19,764 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ff735637af23427fb2d380d089eee4b4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:12:33,239 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:12:34,689 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:12:34,689 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5dffacae8ac34ed3b54b1251e6d75810, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:12:49,686 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:12:49,686 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=242fd0190d5146b0abba2c7b5e2c9b10, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:13:03,240 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:13:04,706 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:13:04,707 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=527a93d0c8864701a8ededcc9ba590e5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:13:19,697 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:13:19,698 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7af7001c65e0434a9f3ae850efc8606c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:13:33,241 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:13:34,685 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:13:34,686 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=81bdbd87e4d5437bb7b8c11ed27d6135, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:13:49,687 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:13:49,688 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=96a7031abd044282812a7bf44a7002a8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:14:03,243 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:14:04,784 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:14:04,785 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b1691120cd3a42f8b20e8dc6952aad17, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:14:20,029 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:14:20,030 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7757ae2de50e486088f6b92d600a956c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:14:33,245 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:14:34,985 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:14:34,986 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=770da6ad238d451fb1fd05746319772c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:14:49,983 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:14:49,984 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7c62608365cd44fbb7893ad2a4da31ce, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:15:03,248 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:15:05,269 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:15:05,270 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a37261af77494f38a320bf7dae4f5d3e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:15:20,243 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:15:20,244 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a039f59a73d7480196ab9f949e058998, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:15:33,250 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:15:35,479 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:15:35,482 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0c56859b6e604ee099fbb1c75c115c7e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:15:50,307 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:15:50,308 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5873eb0db7144e098d59cfd28c6fa4c2, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:16:03,252 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:16:05,288 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:16:05,289 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7d86a75ee2c64d4e8d126073e5649046, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:16:20,530 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:16:20,530 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=73b00db36dbf4f17aebbefd6da841da9, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:16:33,253 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:16:35,389 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:16:35,390 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=83fbc7f77eb24a74a272cba71b65a7f0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:16:50,667 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:16:50,667 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6baf01fe3310496bb7b443f114a2a597, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:17:03,255 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:17:05,603 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:17:05,603 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=d5f1def9e95948b6acf62cda3a829e83, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:17:20,698 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:17:20,699 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=031b860bc22b47a2b87ec9489967b84a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:17:33,259 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:17:35,687 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:17:35,688 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e157348e9ef04b029da3411f27c4efe7, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:17:50,831 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:17:50,831 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b2112dab18e145f5afc600910d9b4b64, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:18:03,262 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:18:05,881 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:18:05,881 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=191fab955def4554a7083012a4c1f462, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:18:20,871 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:18:20,872 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=62e1f4f96ea74f5aaed7ce045b8ceb2e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:18:33,263 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:18:35,887 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:18:35,888 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f3ff87cff7a744b99252ecebee83a316, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:18:50,883 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:18:50,885 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5d5bd54e539d4401b8769c4c5c71b5fc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:19:03,264 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:19:05,887 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:19:05,888 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf3185e0eb624d1aa84033609c612d06, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:19:20,893 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:19:20,894 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5e380fdb8273453ab63d0c7bd9254b28, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:19:31,203 [DEBUG] app1.py:1214 - Speech recognizing: hi hello
2024-12-02 18:19:31,204 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ec3bc4679c7d4026a1bb2801e5ef3c77, text="hi hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:32,700 [DEBUG] app1.py:1214 - Speech recognizing: hi hello what are
2024-12-02 18:19:32,701 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c41cd80f3efa4977ac1e74cb4dc87948, text="hi hello what are", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:33,101 [DEBUG] app1.py:1214 - Speech recognizing: hi hello what are you doing
2024-12-02 18:19:33,102 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9868a1a6026c45e0b4b453a1fecd26fa, text="hi hello what are you doing", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:33,265 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:19:33,940 [INFO] app1.py:1205 - Speech recognized: Hi, hello. What are you doing?
2024-12-02 18:19:33,941 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=25d6ba32b2df4fd0b6bf503bc85b1691, text="Hi, hello. What are you doing?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:19:34,997 [DEBUG] app1.py:1214 - Speech recognizing: are you listening
2024-12-02 18:19:34,998 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=88b098c4417c4926ab283bdc596870e8, text="are you listening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:35,307 [DEBUG] app1.py:1214 - Speech recognizing: are you listening me
2024-12-02 18:19:35,308 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9b05bdd2a21d400cbf57459c29c97b72, text="are you listening me", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:36,084 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:19:36,085 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:19:36,085 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga essay nani yoga (is_final: False)
2024-12-02 18:19:36,087 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga essay nani yoga tuchi (is_final: False)
2024-12-02 18:19:36,087 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga essay nani yoga kuchbi (is_final: False)
2024-12-02 18:19:36,088 [DEBUG] app1.py:1104 - Sending transcription: Like Mrs. yoga essay Nani yoga kuchi. (is_final: True)
2024-12-02 18:19:36,089 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,090 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,091 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,092 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,092 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,096 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,109 [DEBUG] app1.py:1104 - Sending transcription: tamil (is_final: False)
2024-12-02 18:19:36,109 [DEBUG] app1.py:1104 - Sending transcription: tamil video (is_final: False)
2024-12-02 18:19:36,111 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,111 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,113 [DEBUG] app1.py:1104 - Sending transcription: let me know (is_final: False)
2024-12-02 18:19:36,114 [DEBUG] app1.py:1104 - Sending transcription: let me know when you (is_final: False)
2024-12-02 18:19:36,114 [DEBUG] app1.py:1104 - Sending transcription: Let me know when you. (is_final: True)
2024-12-02 18:19:36,115 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,120 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,121 [INFO] app1.py:1205 - Speech recognized: Are you listening me?
2024-12-02 18:19:36,122 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,122 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e846f58beba2471b8ab75b579f0e5cae, text="Are you listening me?", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:19:36,124 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,129 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,130 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,132 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,139 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,141 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,142 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,144 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,145 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,147 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,148 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,153 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,156 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,157 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,157 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,158 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,158 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,160 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,160 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,161 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,161 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,163 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,163 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,164 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,169 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,171 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,172 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,174 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:19:36,177 [DEBUG] app1.py:1104 - Sending transcription: hi hello (is_final: False)
2024-12-02 18:19:36,177 [DEBUG] app1.py:1104 - Sending transcription: hi hello what are (is_final: False)
2024-12-02 18:19:36,181 [DEBUG] app1.py:1104 - Sending transcription: hi hello what are you doing (is_final: False)
2024-12-02 18:19:36,190 [DEBUG] app1.py:1104 - Sending transcription: Hi, hello. What are you doing? (is_final: True)
2024-12-02 18:19:36,192 [DEBUG] app1.py:1104 - Sending transcription: are you listening (is_final: False)
2024-12-02 18:19:36,193 [DEBUG] app1.py:1104 - Sending transcription: are you listening me (is_final: False)
2024-12-02 18:19:36,193 [DEBUG] app1.py:1104 - Sending transcription: Are you listening me? (is_final: True)
2024-12-02 18:19:37,507 [DEBUG] app1.py:1214 - Speech recognizing: like
2024-12-02 18:19:37,508 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=989a6e59ce7142e8b8924552b56b6d17, text="like", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:37,509 [DEBUG] app1.py:1104 - Sending transcription: like (is_final: False)
2024-12-02 18:19:37,930 [DEBUG] app1.py:1214 - Speech recognizing: like mrs
2024-12-02 18:19:37,931 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e061067b17de49369c47331f93bd38a0, text="like mrs", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:37,931 [DEBUG] app1.py:1104 - Sending transcription: like mrs (is_final: False)
2024-12-02 18:19:38,113 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yog
2024-12-02 18:19:38,113 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c68840a395b64c57bb4439b91006e549, text="like mrs yog", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:38,114 [DEBUG] app1.py:1104 - Sending transcription: like mrs yog (is_final: False)
2024-12-02 18:19:38,500 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga has
2024-12-02 18:19:38,501 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3d97a651c4bc4a1989b92565e2738b75, text="like mrs yoga has", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:38,503 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga has (is_final: False)
2024-12-02 18:19:38,701 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga has a
2024-12-02 18:19:38,703 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d2942e55096647ab97a913560baa9b8f, text="like mrs yoga has a", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:38,703 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga has a (is_final: False)
2024-12-02 18:19:38,810 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga has a nanny
2024-12-02 18:19:38,811 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=94a8b93740cb4b9d982f4e694ce77e65, text="like mrs yoga has a nanny", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:38,811 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga has a nanny (is_final: False)
2024-12-02 18:19:39,105 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga has a nanny yoga
2024-12-02 18:19:39,106 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e836493b854843f680a3144958ec7cab, text="like mrs yoga has a nanny yoga", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:39,108 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga has a nanny yoga (is_final: False)
2024-12-02 18:19:39,416 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga has a nanny you'll get
2024-12-02 18:19:39,417 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d0f2e6faf8c74647a62f56999d06ff8f, text="like mrs yoga has a nanny you'll get", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:39,419 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga has a nanny you'll get (is_final: False)
2024-12-02 18:19:39,802 [DEBUG] app1.py:1214 - Speech recognizing: like mrs yoga has a nanny yoga here
2024-12-02 18:19:39,803 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=158c62645f07470a85c4a3c7f929adae, text="like mrs yoga has a nanny yoga here", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:39,804 [DEBUG] app1.py:1104 - Sending transcription: like mrs yoga has a nanny yoga here (is_final: False)
2024-12-02 18:19:40,144 [INFO] app1.py:1205 - Speech recognized: Like Mrs. Yoga has a nanny Yoga here.
2024-12-02 18:19:40,145 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=84ff4b5518ba4eae924d78299bb3ba57, text="Like Mrs. Yoga has a nanny Yoga here.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:19:40,146 [DEBUG] app1.py:1104 - Sending transcription: Like Mrs. Yoga has a nanny Yoga here. (is_final: True)
2024-12-02 18:19:42,005 [INFO] app1.py:1250 - Stopping audio stream
2024-12-02 18:19:42,136 [DEBUG] app1.py:1214 - Speech recognizing: like this is
2024-12-02 18:19:42,136 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dccfdd1f4e294065ab68344819aa5d63, text="like this is", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:42,137 [DEBUG] app1.py:1104 - Sending transcription: like this is (is_final: False)
2024-12-02 18:19:42,198 [DEBUG] app1.py:1214 - Speech recognizing: like this is open as
2024-12-02 18:19:42,200 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2204d861b1ed4505888cc18fba6a9b6e, text="like this is open as", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:42,202 [DEBUG] app1.py:1104 - Sending transcription: like this is open as (is_final: False)
2024-12-02 18:19:42,212 [INFO] app1.py:1255 - Audio streaming stopped
2024-12-02 18:19:46,640 [INFO] app1.py:1192 - Initializing speech recognition
2024-12-02 18:19:46,648 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:19:46,649 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:19:46,692 [INFO] app1.py:1227 - Starting continuous recognition
2024-12-02 18:19:46,787 [INFO] app1.py:1240 - Audio stream started
2024-12-02 18:19:49,129 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 18:19:49,130 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ebde0e4fdae94fcd94513bb3deff935b, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:19:49,131 [DEBUG] app1.py:1104 - Sending transcription: hi (is_final: False)
2024-12-02 18:19:50,625 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 18:19:50,626 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=17a991c8277d49a0834067432ad23ce4, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:19:50,627 [DEBUG] app1.py:1104 - Sending transcription: Hi. (is_final: True)
2024-12-02 18:20:03,267 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:20:10,852 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:20:10,853 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=11ae334fa6644fc59dbafa85160854cb, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:20:10,853 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:20:25,415 [DEBUG] app1.py:1214 - Speech recognizing: phone
2024-12-02 18:20:25,415 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c7c9d8184f6a46acb697f92a0d827cab, text="phone", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:20:25,435 [DEBUG] app1.py:1104 - Sending transcription: phone (is_final: False)
2024-12-02 18:20:27,038 [INFO] app1.py:1205 - Speech recognized: Phone.
2024-12-02 18:20:27,039 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cc36b44663814871bc948928bb99995f, text="Phone.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:20:27,040 [DEBUG] app1.py:1104 - Sending transcription: Phone. (is_final: True)
2024-12-02 18:20:33,269 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:20:47,148 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:20:47,148 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c08e9ea25fa646bc9e63608bdb1a29c8, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:20:47,149 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:20:49,653 [DEBUG] app1.py:1214 - Speech recognizing: paper thing
2024-12-02 18:20:49,655 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5350517929274ed7b9dfd4c0d10254d7, text="paper thing", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:20:49,656 [DEBUG] app1.py:1104 - Sending transcription: paper thing (is_final: False)
2024-12-02 18:20:58,538 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:20:58,538 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fe49225fd2c743829cac6222979fe5ab, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:20:58,539 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:21:00,249 [INFO] app1.py:1205 - Speech recognized: Hello. Hello.
2024-12-02 18:21:00,250 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=00e959cfa2ea4abbac6d7c0f6d6afa37, text="Hello. Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:21:00,251 [DEBUG] app1.py:1104 - Sending transcription: Hello. Hello. (is_final: True)
2024-12-02 18:21:03,045 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:21:03,045 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=db1b2eb12d04415ab62a3eb8da101fd5, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:21:03,046 [DEBUG] app1.py:1104 - Sending transcription: hello (is_final: False)
2024-12-02 18:21:03,270 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:21:04,444 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:21:04,444 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=317ef696f7d04df5878d328a1c014347, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:21:04,446 [DEBUG] app1.py:1104 - Sending transcription: Hello. (is_final: True)
2024-12-02 18:21:24,765 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:21:24,768 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f4e784a8dd9d488fa81a6a752242104c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:21:24,769 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:21:26,215 [DEBUG] app1.py:1214 - Speech recognizing: deploying
2024-12-02 18:21:26,216 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d76a987aabd44a6292d53b8e742cb99b, text="deploying", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:21:26,216 [DEBUG] app1.py:1104 - Sending transcription: deploying (is_final: False)
2024-12-02 18:21:26,417 [DEBUG] app1.py:1214 - Speech recognizing: deploying us due
2024-12-02 18:21:26,417 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=39c86d6ac72046b991d75513267bb171, text="deploying us due", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:21:26,418 [DEBUG] app1.py:1104 - Sending transcription: deploying us due (is_final: False)
2024-12-02 18:21:26,819 [DEBUG] app1.py:1214 - Speech recognizing: deploying us due to some
2024-12-02 18:21:26,820 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=43a91830372a4baa8853effb22930787, text="deploying us due to some", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:21:26,821 [DEBUG] app1.py:1104 - Sending transcription: deploying us due to some (is_final: False)
2024-12-02 18:21:27,131 [DEBUG] app1.py:1214 - Speech recognizing: deploying us due to some reasons
2024-12-02 18:21:27,131 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9b3203ea6c914fa4a2c6aac5c8f5de5a, text="deploying us due to some reasons", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:21:27,134 [DEBUG] app1.py:1104 - Sending transcription: deploying us due to some reasons (is_final: False)
2024-12-02 18:21:28,984 [INFO] app1.py:1205 - Speech recognized: Deploying due to some reasons.
2024-12-02 18:21:28,984 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cb45355caf5f4814bca44e910cb49cd5, text="Deploying due to some reasons.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:21:28,986 [DEBUG] app1.py:1104 - Sending transcription: Deploying due to some reasons. (is_final: True)
2024-12-02 18:21:29,451 [DEBUG] app1.py:1214 - Speech recognizing: screens
2024-12-02 18:21:29,451 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=afbc8e8ad23a4a28a34dceecf3202d94, text="screens", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:21:29,452 [DEBUG] app1.py:1104 - Sending transcription: screens (is_final: False)
2024-12-02 18:21:29,651 [DEBUG] app1.py:1214 - Speech recognizing: screenshot
2024-12-02 18:21:29,652 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9036e294a05d4322939fbee3859db5c2, text="screenshot", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:21:29,652 [DEBUG] app1.py:1104 - Sending transcription: screenshot (is_final: False)
2024-12-02 18:21:31,554 [INFO] app1.py:1205 - Speech recognized: Screenshot.
2024-12-02 18:21:31,554 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8790a67f26714931835671c64f5abf82, text="Screenshot.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:21:31,555 [DEBUG] app1.py:1104 - Sending transcription: Screenshot. (is_final: True)
2024-12-02 18:21:33,271 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:21:43,348 [INFO] app1.py:1096 - New transcription stream connection established
2024-12-02 18:21:43,348 [DEBUG] app1.py:1098 - Starting transcription stream generator
2024-12-02 18:21:47,165 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:21:47,165 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ca51064627f84032b03e3185f852b869, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:21:47,166 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:22:03,273 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:22:06,747 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:22:06,748 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=740361402511423cbe7ed0742b995f4e, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:06,749 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:22:21,979 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:22:21,980 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4fe5a90a44e6414c8ad3edba5186aec3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:21,981 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:22:25,761 [DEBUG] app1.py:1214 - Speech recognizing: you know ethical
2024-12-02 18:22:25,761 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bcbf43f3d6244d85984e732fafe23ed3, text="you know ethical", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:25,782 [DEBUG] app1.py:1104 - Sending transcription: you know ethical (is_final: False)
2024-12-02 18:22:26,060 [DEBUG] app1.py:1214 - Speech recognizing: you know ethically
2024-12-02 18:22:26,061 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=44b6895fe4044f6492b91b4cd4e36887, text="you know ethically", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:26,062 [DEBUG] app1.py:1104 - Sending transcription: you know ethically (is_final: False)
2024-12-02 18:22:33,276 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:22:37,211 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:22:37,212 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=038bf95c180147f98c79a0db79780afc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:37,212 [DEBUG] app1.py:1104 - Sending transcription:  (is_final: True)
2024-12-02 18:22:42,939 [DEBUG] app1.py:1214 - Speech recognizing: copy paste
2024-12-02 18:22:42,939 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=16751d22afc847d08f008aa1a29d36f9, text="copy paste", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:42,940 [DEBUG] app1.py:1104 - Sending transcription: copy paste (is_final: False)
2024-12-02 18:22:43,484 [INFO] app1.py:1205 - Speech recognized: Copy paste.
2024-12-02 18:22:43,484 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1bfaecd632f54695820b6b2e4c8c8ecf, text="Copy paste.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:43,485 [DEBUG] app1.py:1104 - Sending transcription: Copy paste. (is_final: True)
2024-12-02 18:22:44,934 [DEBUG] app1.py:1214 - Speech recognizing: copy
2024-12-02 18:22:44,934 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9987727ed1034fff9dd1dcf17103588a, text="copy", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:44,935 [DEBUG] app1.py:1104 - Sending transcription: copy (is_final: False)
2024-12-02 18:22:45,228 [DEBUG] app1.py:1214 - Speech recognizing: copy paste
2024-12-02 18:22:45,230 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d4cb712408cd4191aafb85b2a2056220, text="copy paste", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:45,231 [DEBUG] app1.py:1104 - Sending transcription: copy paste (is_final: False)
2024-12-02 18:22:46,039 [INFO] app1.py:1205 - Speech recognized: Copy paste.
2024-12-02 18:22:46,040 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7a8b5ef0bf7d4fbfa1bb1fc295a47cff, text="Copy paste.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:46,040 [DEBUG] app1.py:1104 - Sending transcription: Copy paste. (is_final: True)
2024-12-02 18:22:48,421 [DEBUG] app1.py:1214 - Speech recognizing: good evening
2024-12-02 18:22:48,422 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=953b611499424c14888b35a61676493f, text="good evening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:48,422 [DEBUG] app1.py:1104 - Sending transcription: good evening (is_final: False)
2024-12-02 18:22:49,370 [DEBUG] app1.py:1214 - Speech recognizing: good evening sir
2024-12-02 18:22:49,372 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=800cbc90111e4471b4d57bc816f0c194, text="good evening sir", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:49,373 [DEBUG] app1.py:1104 - Sending transcription: good evening sir (is_final: False)
2024-12-02 18:22:49,375 [INFO] app1.py:1205 - Speech recognized: Good evening, Sir.
2024-12-02 18:22:49,381 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=43b9391a16f44207a4bb136e3ffc2266, text="Good evening, Sir.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:49,382 [DEBUG] app1.py:1104 - Sending transcription: Good evening, Sir. (is_final: True)
2024-12-02 18:22:51,638 [DEBUG] app1.py:1214 - Speech recognizing: good evening
2024-12-02 18:22:51,639 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=45703aed732f4750be569a271a72c6d1, text="good evening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:51,639 [DEBUG] app1.py:1104 - Sending transcription: good evening (is_final: False)
2024-12-02 18:22:52,043 [DEBUG] app1.py:1214 - Speech recognizing: good evening sir
2024-12-02 18:22:52,043 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a01f90041d914007a7db38ec2b2603c3, text="good evening sir", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:52,046 [DEBUG] app1.py:1104 - Sending transcription: good evening sir (is_final: False)
2024-12-02 18:22:53,840 [INFO] app1.py:1205 - Speech recognized: Good evening, Sir.
2024-12-02 18:22:53,841 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e71e0f4830ad43de91934c1cb260090f, text="Good evening, Sir.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:53,841 [DEBUG] app1.py:1104 - Sending transcription: Good evening, Sir. (is_final: True)
2024-12-02 18:22:57,132 [DEBUG] app1.py:1214 - Speech recognizing: status report
2024-12-02 18:22:57,133 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b1818084b2974da3903e53d7b938939f, text="status report", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:57,133 [DEBUG] app1.py:1104 - Sending transcription: status report (is_final: False)
2024-12-02 18:22:57,445 [INFO] app1.py:1205 - Speech recognized: Status Report.
2024-12-02 18:22:57,446 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2023a84dfcdd4cdabf47987fb6d8edc0, text="Status Report.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:57,448 [DEBUG] app1.py:1104 - Sending transcription: Status Report. (is_final: True)
2024-12-02 18:22:59,137 [DEBUG] app1.py:1214 - Speech recognizing: status
2024-12-02 18:22:59,137 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b9c0ad55eab94d4ab401ed3bec5cbd36, text="status", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:59,138 [DEBUG] app1.py:1104 - Sending transcription: status (is_final: False)
2024-12-02 18:22:59,744 [DEBUG] app1.py:1214 - Speech recognizing: status report
2024-12-02 18:22:59,744 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=cf3ae36857f64ec6adb2966b5a2c832c, text="status report", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:22:59,745 [DEBUG] app1.py:1104 - Sending transcription: status report (is_final: False)
2024-12-02 18:22:59,963 [INFO] app1.py:1205 - Speech recognized: Status Report.
2024-12-02 18:22:59,964 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=38a77f5a2a1c4be58a961056a032c68b, text="Status Report.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:22:59,966 [DEBUG] app1.py:1104 - Sending transcription: Status Report. (is_final: True)
2024-12-02 18:23:03,278 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:23:12,596 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 18:23:12,597 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c373a95b3de440b3be59202097d908da, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:23:12,597 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 18:23:13,965 [DEBUG] app1.py:1214 - Speech recognizing: play
2024-12-02 18:23:13,966 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=835381f46d824c3a8ce2e94fae0bee6d, text="play", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:13,966 [DEBUG] app1.py:1104 - Sending transcription: play (is_final: False)
2024-12-02 18:23:14,137 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 18:23:14,138 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eb0d930d72e0471bb3dc0552f47c14bf, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:23:14,146 [DEBUG] app1.py:1104 - Sending transcription: Play. (is_final: True)
2024-12-02 18:23:33,280 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:23:34,096 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:23:34,097 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=85f74c6afd6b42428f9676434fb5aa36, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:23:38,016 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 18:23:38,017 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e5292dc7fd1e4fd28a2c71d672187db5, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:38,931 [DEBUG] app1.py:1214 - Speech recognizing: hi i
2024-12-02 18:23:38,931 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=373e0d5e322f417cb563be4f3598c675, text="hi i", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:39,227 [DEBUG] app1.py:1214 - Speech recognizing: hi i started report
2024-12-02 18:23:39,228 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=39161c1515894f67852ccef4bcbee662, text="hi i started report", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:39,320 [DEBUG] app1.py:1214 - Speech recognizing: hi i started reporting
2024-12-02 18:23:39,320 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=131bb703df14498882602cb9ea435e70, text="hi i started reporting", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:39,942 [INFO] app1.py:1205 - Speech recognized: Hi, I started reporting well.
2024-12-02 18:23:39,943 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=68d21e00ec0f42159ab98d3a3aeaa5f1, text="Hi, I started reporting well.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:23:48,020 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatam
2024-12-02 18:23:48,020 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=718c286016e24c05ba10e0677f1afd1f, text="gopi khatam", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:48,421 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari
2024-12-02 18:23:48,422 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d4b942e41c5c424c93819a04a34d3f70, text="gopi khatamari", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:48,621 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and
2024-12-02 18:23:48,621 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ba167f5def39440b9b19ebe98ea8f6f6, text="gopi khatamari and", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:49,022 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and muj
2024-12-02 18:23:49,023 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e538e881096046fc822e3c4776aec9b8, text="gopi khatamari and muj", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:49,225 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and mazhya
2024-12-02 18:23:49,226 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4a7e224e77b540ec89a5361efe1942d0, text="gopi khatamari and mazhya", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:49,940 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and mujhe ki milan
2024-12-02 18:23:49,941 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=698d5922e84440cfa7fd16b00988d458, text="gopi khatamari and mujhe ki milan", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:50,328 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and mujhe ki milani to
2024-12-02 18:23:50,329 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=49f529109e69478ea6179a58839156b1, text="gopi khatamari and mujhe ki milani to", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:50,826 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and mujhe ki milani to kat
2024-12-02 18:23:50,827 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1305cd65a3cb4249a2b3a6c1ae0b6f51, text="gopi khatamari and mujhe ki milani to kat", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:50,937 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and mujhe ki milani to katni
2024-12-02 18:23:50,938 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=74bd990bcfd14bfa9c15a22d4c7b545d, text="gopi khatamari and mujhe ki milani to katni", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:51,633 [DEBUG] app1.py:1214 - Speech recognizing: gopi khatamari and mujhe ki milani to katani khadang
2024-12-02 18:23:51,634 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6c34fb0ebf38416797f2547a431ce100, text="gopi khatamari and mujhe ki milani to katani khadang", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:53,491 [INFO] app1.py:1205 - Speech recognized: Gopi Khatamari and Mujhe Ki Milani to Katani.
2024-12-02 18:23:53,493 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=64a00279b28d44a787fa1cb203d10e55, text="Gopi Khatamari and Mujhe Ki Milani to Katani.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:23:59,217 [DEBUG] app1.py:1214 - Speech recognizing: nair
2024-12-02 18:23:59,219 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=905021683b8744b98bb4bb04ab1126d2, text="nair", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:59,609 [DEBUG] app1.py:1214 - Speech recognizing: nair bhas
2024-12-02 18:23:59,610 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=dc72ba96298f4fcfa89f4fea074d6adc, text="nair bhas", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:23:59,923 [DEBUG] app1.py:1214 - Speech recognizing: nair bhasaraudu
2024-12-02 18:23:59,923 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9d4428221cad49ad9552bac2d0e252ac, text="nair bhasaraudu", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:00,262 [INFO] app1.py:1205 - Speech recognized: Near bars Arora.
2024-12-02 18:24:00,263 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e9f59eb32a86448b9fa3dc29048b80ee, text="Near bars Arora.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:24:03,284 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:24:19,127 [DEBUG] app1.py:1214 - Speech recognizing: i
2024-12-02 18:24:19,128 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=416b6540e2e045bf8c843e198e65d4cd, text="i", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:20,321 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:24:20,322 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fd13705a455441cfbeda85614f06f588, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:24:23,726 [DEBUG] app1.py:1214 - Speech recognizing: arsu stunja
2024-12-02 18:24:23,727 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c7a42ef39a354e9db55a73e3fe740d19, text="arsu stunja", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:23,927 [DEBUG] app1.py:1214 - Speech recognizing: arsu tonja
2024-12-02 18:24:23,928 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=61066185e2bf493cb52fe634be0ce173, text="arsu tonja", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:24,625 [DEBUG] app1.py:1214 - Speech recognizing: arsu tonja habi
2024-12-02 18:24:24,626 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e82a4279771e4088808c128657237d61, text="arsu tonja habi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:25,124 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri
2024-12-02 18:24:25,125 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a2f0eac94c24479ab67fdf7df80379a8, text="arsu stun JA habi cheri", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:25,230 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri ke
2024-12-02 18:24:25,231 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f920cd24c26e465091938e13343a437d, text="arsu stun JA habi cheri ke", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:25,524 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri ke bai
2024-12-02 18:24:25,524 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=86c28592d0ce4c568b15c5dc1d8bd570, text="arsu stun JA habi cheri ke bai", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:25,819 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri ke baiment
2024-12-02 18:24:25,820 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=04985463fe614ab796e0073ce54c5b88, text="arsu stun JA habi cheri ke baiment", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:26,520 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri ke baimenta
2024-12-02 18:24:26,521 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=278e93d65391497899a917afc69775d7, text="arsu stun JA habi cheri ke baimenta", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:26,936 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri ke baiment which
2024-12-02 18:24:26,937 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=813c505e79664369bd21ed57bbe76801, text="arsu stun JA habi cheri ke baiment which", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:27,120 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri ke baiment which layer
2024-12-02 18:24:27,122 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=acc88b7b1ebc4c20907f688919d29d2b, text="arsu stun JA habi cheri ke baiment which layer", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:29,026 [DEBUG] app1.py:1214 - Speech recognizing: arsu stun JA habi cheri ke baiment which layer very good
2024-12-02 18:24:29,027 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b24df2e8f5054acab1122174b3c8369e, text="arsu stun JA habi cheri ke baiment which layer very good", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:29,387 [INFO] app1.py:1205 - Speech recognized: Arsu tonja habi Cheri ke baiment.
2024-12-02 18:24:29,389 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7014256ec6b3470cbf84ad0eff48ed5c, text="Arsu tonja habi Cheri ke baiment.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:24:33,305 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:24:37,724 [DEBUG] app1.py:1214 - Speech recognizing: assistant
2024-12-02 18:24:37,724 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a164f458486d453e9bcf048ff8fd847d, text="assistant", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:38,765 [DEBUG] app1.py:1214 - Speech recognizing: assistant job
2024-12-02 18:24:38,765 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=96801f433bbe4f178dc78e7200b92573, text="assistant job", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:38,780 [INFO] app1.py:1205 - Speech recognized: Assistant job.
2024-12-02 18:24:38,781 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8124e0b6671d485784a20e41e87bd0d1, text="Assistant job.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:24:52,720 [DEBUG] app1.py:1214 - Speech recognizing: dososo sanity
2024-12-02 18:24:52,720 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1e50b08ba85644b694cbc711c0ca9136, text="dososo sanity", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:24:54,029 [INFO] app1.py:1205 - Speech recognized: Go to Sanity.
2024-12-02 18:24:54,029 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=21b0815aa35348e2ae7f97da7dedb094, text="Go to Sanity.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:25:03,307 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:25:13,030 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:25:13,030 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=881257a5149348ac9745d076e16473b6, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:25:20,065 [INFO] app1.py:1205 - Speech recognized: Play.
2024-12-02 18:25:20,066 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=63f57919ea644c31b605c5a5c3982377, text="Play.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:25:27,760 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 18:25:27,762 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2391a97727f3483788e40e3ef0833ef4, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:25:33,309 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:25:47,844 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:25:47,844 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=dde871e4fb034700b361ff78fab12d30, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:25:57,146 [INFO] app1.py:1205 - Speech recognized: I.
2024-12-02 18:25:57,148 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4fc71e19487240a9a61fbe3c5a759f23, text="I.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:26:03,311 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:26:17,090 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:26:17,091 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3fb62265f14d4faeb47dba3096ba8d42, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:26:22,853 [INFO] app1.py:1205 - Speech recognized: And.
2024-12-02 18:26:22,853 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4465bb141abc4b0cb70e446819cd5411, text="And.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:26:33,316 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:26:42,795 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:26:42,796 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0031fdebca7f462481feef9adaedd96c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:26:57,948 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:26:57,948 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c10df0da1b7d48039f5ca3ddd7cb8d30, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:27:03,332 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:27:12,240 [DEBUG] app1.py:1214 - Speech recognizing: hi hello
2024-12-02 18:27:12,241 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5a7cd731bec24a09bcd824ada3860f66, text="hi hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:13,254 [INFO] app1.py:1205 - Speech recognized: Hi. Hello.
2024-12-02 18:27:13,254 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=aca037b22a644cd791aec9e87e271b9c, text="Hi. Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:27:14,730 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:27:14,731 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=44a55e16769a49d285c0c58445abe05a, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:15,821 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:27:15,822 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c900173b660542be8288b35386f897e9, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:27:18,142 [DEBUG] app1.py:1214 - Speech recognizing: hello
2024-12-02 18:27:18,144 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aadf03348e5143a3910eecf4bb8427e0, text="hello", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:18,421 [INFO] app1.py:1205 - Speech recognized: Hello.
2024-12-02 18:27:18,422 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bf3c726ebc0347cc9e85f9f9c94091dd, text="Hello.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:27:23,665 [DEBUG] app1.py:1214 - Speech recognizing: hi
2024-12-02 18:27:23,666 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9c39f0a91a5f4f3a99c4bf833d79c4bf, text="hi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:23,682 [INFO] app1.py:1205 - Speech recognized: Hi.
2024-12-02 18:27:23,683 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=51fae47dea9746cd99708e4740b8656f, text="Hi.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:27:31,956 [INFO] app1.py:1205 - Speech recognized: Nicholas.
2024-12-02 18:27:31,958 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=38534774b92b4ae39dbf250965bf892f, text="Nicholas.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:27:33,333 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:27:46,935 [DEBUG] app1.py:1214 - Speech recognizing: sexy boy
2024-12-02 18:27:46,936 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=29b2c7bf632e4e7ca3f89c52e848a9a3, text="sexy boy", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:47,759 [INFO] app1.py:1205 - Speech recognized: Sexy boy.
2024-12-02 18:27:47,760 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=390462974fe54d6faf857d19e1e15027, text="Sexy boy.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:27:56,333 [DEBUG] app1.py:1214 - Speech recognizing: kawhi
2024-12-02 18:27:56,335 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d3916598d99045238192290c9e147c5f, text="kawhi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:57,066 [DEBUG] app1.py:1214 - Speech recognizing: kawhi put
2024-12-02 18:27:57,067 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=138d55841e5942a3a41ea32d01668b1a, text="kawhi put", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:57,442 [DEBUG] app1.py:1214 - Speech recognizing: kawhi put yella
2024-12-02 18:27:57,442 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=99f0a4694c3e4f17ac91d6c57bf493ca, text="kawhi put yella", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:27:57,475 [INFO] app1.py:1205 - Speech recognized: Kawhi put yellow.
2024-12-02 18:27:57,475 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=a660119fe0b14488823ac679f0087cd1, text="Kawhi put yellow.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:28:03,335 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:28:17,666 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:28:17,667 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e88f992023274c9288c353b5b23ed2cc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:28:21,433 [DEBUG] app1.py:1214 - Speech recognizing: good
2024-12-02 18:28:21,435 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=1cdbcb067aac46f387bbd984bd2f0589, text="good", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:28:21,742 [DEBUG] app1.py:1214 - Speech recognizing: good morning
2024-12-02 18:28:21,743 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=86befc0ac8ad4bc9ac90c6f5e6e0f115, text="good morning", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:28:22,654 [INFO] app1.py:1205 - Speech recognized: Good morning.
2024-12-02 18:28:22,654 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=eaa00b5c8da3404098968940e90155df, text="Good morning.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:28:23,339 [DEBUG] app1.py:1214 - Speech recognizing: good evening
2024-12-02 18:28:23,340 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=98b809d18cfe4a20ab0731e4d9ef5cb9, text="good evening", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:28:24,551 [DEBUG] app1.py:1214 - Speech recognizing: good evening and
2024-12-02 18:28:24,553 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=6317675c765a418eb0c0505e0d73fd73, text="good evening and", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:28:25,827 [DEBUG] app1.py:1214 - Speech recognizing: good evening and morning
2024-12-02 18:28:25,828 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=df073a62d40e409bb1a2c65dbe11056d, text="good evening and morning", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:28:27,476 [INFO] app1.py:1205 - Speech recognized: Good evening and good evening and morning.
2024-12-02 18:28:27,477 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=85d66d40c48748deb5577fedb835fffc, text="Good evening and good evening and morning.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:28:33,337 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:28:34,341 [INFO] app1.py:1205 - Speech recognized: Evening.
2024-12-02 18:28:34,342 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=2fc2ed023631415a8c0f753019099bda, text="Evening.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:28:54,294 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:28:54,295 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0ea22c939ba24da2910f4fbcc6daf04a, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:29:03,339 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:29:09,551 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:29:09,552 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ddd0212a91964f3eb30edd7c41f22846, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:29:24,740 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:29:24,741 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=9d57bcafb55c4c94b9f43fe367fa09b4, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:29:33,341 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:29:39,861 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:29:39,862 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=491d21f3d9364e1c9243b63f07e81f45, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:29:42,920 [DEBUG] app1.py:1214 - Speech recognizing: with this sidewalk
2024-12-02 18:29:42,921 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3007cbce2cbb44dbb8277b3f4feec31c, text="with this sidewalk", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:29:44,739 [INFO] app1.py:1205 - Speech recognized: With this sidewalk.
2024-12-02 18:29:44,743 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=3555dd28abab4978876fba6a30b2b736, text="With this sidewalk.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:29:47,443 [DEBUG] app1.py:1214 - Speech recognizing: design
2024-12-02 18:29:47,443 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d0f657228648482488fa2020821ee9fa, text="design", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:29:47,941 [DEBUG] app1.py:1214 - Speech recognizing: design sidewalk
2024-12-02 18:29:47,942 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7afc7cbad47b4cfb9c5f47fb880e9a54, text="design sidewalk", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:29:49,269 [INFO] app1.py:1205 - Speech recognized: Designer.
2024-12-02 18:29:49,282 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=48b66a50e23041cd848ae1a3b18860fe, text="Designer.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:29:55,822 [DEBUG] app1.py:1214 - Speech recognizing: good morning
2024-12-02 18:29:55,823 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5678551dd32741e39bb2629354dd5dab, text="good morning", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:30:03,343 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:30:09,293 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:30:09,294 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=5cae7370608d4a84a373a3ea4ef40931, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:30:24,295 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:30:24,296 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=90b6235661784df3b8f26a0af9f45eb5, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:30:33,345 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:30:39,294 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:30:39,294 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e55cfa1ab69544098bad28be47a7afc0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:30:54,640 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:30:54,642 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=88befa21200c408aa24e7b43dd7cabae, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:31:03,347 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:31:09,634 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:31:09,635 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=6d3e19da93754260baedb6184b5bdb18, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:31:24,695 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:31:24,695 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=1f06c2f81dd94495b47476d1a37e6da3, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:31:33,348 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:31:36,826 [DEBUG] app1.py:1214 - Speech recognizing: church
2024-12-02 18:31:36,827 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=47940580540845d38ad481204f07169f, text="church", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:31:37,126 [DEBUG] app1.py:1214 - Speech recognizing: search translator
2024-12-02 18:31:37,126 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=df5cb8b4daff4f579035471776def92a, text="search translator", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:31:37,434 [DEBUG] app1.py:1214 - Speech recognizing: church translator app
2024-12-02 18:31:37,434 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=34e7f803afcb40468f44d2f98aa23a3e, text="church translator app", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:31:38,335 [INFO] app1.py:1205 - Speech recognized: Search translator app.
2024-12-02 18:31:38,335 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b1bc69f487de403997cbe10f0cec6464, text="Search translator app.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:31:42,422 [DEBUG] app1.py:1214 - Speech recognizing: eh mmm
2024-12-02 18:31:42,423 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c32617d73bf147aeae3aeaa2bef5d4c3, text="eh mmm", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:31:42,622 [DEBUG] app1.py:1214 - Speech recognizing: eh mmm church
2024-12-02 18:31:42,623 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d57a0c271d584832aa623e85e7d7a6e3, text="eh mmm church", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:31:43,026 [DEBUG] app1.py:1214 - Speech recognizing: eh mmm church translator
2024-12-02 18:31:43,026 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f7e723eb9be84d8287820ed8d1060782, text="eh mmm church translator", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:31:43,133 [DEBUG] app1.py:1214 - Speech recognizing: eh mmm church translator app
2024-12-02 18:31:43,134 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3e891835c8664eba8080b618a8398dd5, text="eh mmm church translator app", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:31:43,541 [INFO] app1.py:1205 - Speech recognized: Eh MMM, church translator app.
2024-12-02 18:31:43,542 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0ee131c43fcd4600a85736c3c44fb8f9, text="Eh MMM, church translator app.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:31:48,130 [INFO] app1.py:1205 - Speech recognized: MMM.
2024-12-02 18:31:48,132 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=bdc0ef60f89b430185f1076b5f08eb6c, text="MMM.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:31:59,636 [DEBUG] app1.py:1214 - Speech recognizing: message
2024-12-02 18:31:59,637 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4a1f05c5241243a38c70c6375d6134fc, text="message", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:32:00,042 [DEBUG] app1.py:1214 - Speech recognizing: message limit
2024-12-02 18:32:00,043 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=88d0236b322544e4973f05bf9654454e, text="message limit", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:32:00,229 [DEBUG] app1.py:1214 - Speech recognizing: message limit reach
2024-12-02 18:32:00,229 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ac2a16a330394a73ac73c08bbc564ab8, text="message limit reach", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:32:00,338 [DEBUG] app1.py:1214 - Speech recognizing: message limit reached
2024-12-02 18:32:00,339 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2f9e4644a8ed4077a2e99b67dbf5e44d, text="message limit reached", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:32:01,627 [DEBUG] app1.py:1214 - Speech recognizing: message limit reached santiag
2024-12-02 18:32:01,627 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=3b028648f3be48889fcc705254270b2e, text="message limit reached santiag", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:32:02,346 [INFO] app1.py:1205 - Speech recognized: Message limit reached Santiago.
2024-12-02 18:32:02,346 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=76abf50f99e448bfb1f67438971f5089, text="Message limit reached Santiago.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:32:03,349 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:32:17,635 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:32:17,635 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=fa0caefc74d444c39fad02c4438c10b0, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:32:33,351 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:32:37,447 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:32:37,447 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=8da07a4cd35445aa8624464d794a0c2d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:32:52,534 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:32:52,534 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=ca3e1d6fd0964ab2ba0d83ac458df46b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:33:03,380 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:33:07,738 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:33:07,739 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4d9c391a69ab4394834842f11f895a6d, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:33:21,337 [DEBUG] app1.py:1214 - Speech recognizing: sakshi
2024-12-02 18:33:21,338 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=4716959d60e747e290f0db81460aede6, text="sakshi", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:21,739 [DEBUG] app1.py:1214 - Speech recognizing: sakshi naman
2024-12-02 18:33:21,739 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=b275d30c1d40427b9a0b444032c6085e, text="sakshi naman", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:21,940 [DEBUG] app1.py:1214 - Speech recognizing: sakshi naman of
2024-12-02 18:33:21,941 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f14cee3260fe4a1ca31116da2e9dc046, text="sakshi naman of", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:23,000 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:33:23,000 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=16d835a09986454694b0c6706fb6072c, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:33:33,386 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:33:38,052 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:33:38,052 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e988fb1034994968b9fcc1af8cd387dc, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:33:41,627 [DEBUG] app1.py:1214 - Speech recognizing: designer
2024-12-02 18:33:41,628 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e07d840266984b8ca256e3510719911a, text="designer", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:41,940 [DEBUG] app1.py:1214 - Speech recognizing: designer implement
2024-12-02 18:33:41,941 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=e440a9f5e9a94936976911580d57b6c1, text="designer implement", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:42,329 [DEBUG] app1.py:1214 - Speech recognizing: designer implemented
2024-12-02 18:33:42,331 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=47398dfb18b44b32bf97a1af85af5388, text="designer implemented", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:42,528 [DEBUG] app1.py:1214 - Speech recognizing: designer implemented side
2024-12-02 18:33:42,529 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=600b134b98ac41a0a6445f32d146fd15, text="designer implemented side", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:42,935 [DEBUG] app1.py:1214 - Speech recognizing: designer implemented sidebar
2024-12-02 18:33:42,937 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=d2ac2a5a6a684393b819ffcdc23aba84, text="designer implemented sidebar", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:43,745 [DEBUG] app1.py:1214 - Speech recognizing: designer implemented sidebar comp
2024-12-02 18:33:43,746 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=f7b79fb3628a47499e14f3f40b4730e9, text="designer implemented sidebar comp", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:43,835 [DEBUG] app1.py:1214 - Speech recognizing: designer implemented sidebar component
2024-12-02 18:33:43,836 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=5ddaeaf62f2049c9aa4818eec1051112, text="designer implemented sidebar component", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:44,192 [INFO] app1.py:1205 - Speech recognized: Designer implemented sidebar component.
2024-12-02 18:33:44,192 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0c39eae946ba486093018b67e0afda7b, text="Designer implemented sidebar component.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:33:47,953 [DEBUG] app1.py:1214 - Speech recognizing: 80
2024-12-02 18:33:47,954 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=2725f448127347d2837539600e9f58f4, text="80", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:48,852 [DEBUG] app1.py:1214 - Speech recognizing: 80% comple
2024-12-02 18:33:48,852 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=554cc3976d7348518baad83ad16cd407, text="80% comple", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:48,963 [DEBUG] app1.py:1214 - Speech recognizing: 80% complete
2024-12-02 18:33:48,963 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=ff3a38ccd1374313bc1772cd5c489759, text="80% complete", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:33:50,785 [INFO] app1.py:1205 - Speech recognized: 80% complete.
2024-12-02 18:33:50,786 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=942b4247062549c6a30de69407ffbecb, text="80% complete.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:34:03,388 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:34:09,019 [DEBUG] app1.py:1214 - Speech recognizing: church
2024-12-02 18:34:09,019 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=250f85804fad4c9598c286f846f3126c, text="church", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:34:09,035 [INFO] app1.py:1205 - Speech recognized: Church.
2024-12-02 18:34:09,036 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cde1ef1ce0fb4bfd911ab2a34eb94ac3, text="Church.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:34:20,549 [DEBUG] app1.py:1214 - Speech recognizing: we
2024-12-02 18:34:20,550 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=aef585077d2e41c09bfd531ac2e54c29, text="we", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:34:20,951 [DEBUG] app1.py:1214 - Speech recognizing: we implemented
2024-12-02 18:34:20,952 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=c91d22ece1e64be5a87b3191b99cf04f, text="we implemented", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:34:22,770 [INFO] app1.py:1205 - Speech recognized: We implemented.
2024-12-02 18:34:22,770 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=31cf4de10dfd4e98a35ef2522a3240e0, text="We implemented.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:34:23,746 [DEBUG] app1.py:1214 - Speech recognizing: we implemented
2024-12-02 18:34:23,746 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bc202125baec422aa372d3c5cc5cff9a, text="we implemented", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:34:25,676 [INFO] app1.py:1205 - Speech recognized: We implemented.
2024-12-02 18:34:25,677 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=7b8dcdd41efc448fa711d64dc3d849a2, text="We implemented.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:34:33,389 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:34:35,272 [INFO] app1.py:1205 - Speech recognized: Some of the.
2024-12-02 18:34:35,272 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0db9e04fa144447f808fec9af2ee4852, text="Some of the.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:34:43,056 [INFO] app1.py:1205 - Speech recognized: Balika Vadhu.
2024-12-02 18:34:43,056 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=0e230f86f98c464fa04ef669ea1cbee4, text="Balika Vadhu.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:35:03,166 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:35:03,167 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=674fc07e80db4616887530c4715cfc23, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:35:03,390 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:35:08,129 [DEBUG] app1.py:1214 - Speech recognizing: united church
2024-12-02 18:35:08,130 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=bd77dc7cb53f45a2ac4ca6cdee301eec, text="united church", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:35:10,044 [INFO] app1.py:1205 - Speech recognized: United Church.
2024-12-02 18:35:10,045 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=37663179a26f418099546742bf188c40, text="United Church.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:35:30,264 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:35:30,265 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cdef98b9cd6843dfa9c43b206741fe6f, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:35:31,427 [DEBUG] app1.py:1214 - Speech recognizing: report
2024-12-02 18:35:31,428 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7b23d18158384d568c484c6f9184145c, text="report", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:35:32,730 [DEBUG] app1.py:1214 - Speech recognizing: hey cortana
2024-12-02 18:35:32,731 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=9de86e0f29ef46af9c7230e7a70449f4, text="hey cortana", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:35:33,391 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:35:34,364 [INFO] app1.py:1205 - Speech recognized: Hey, Cortana.
2024-12-02 18:35:34,364 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=e370f9aa27bf44b4b04a4047608c1474, text="Hey, Cortana.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:35:53,727 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:35:53,728 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=499b8af7776d49248c67c6f39b4f5c1b, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:36:03,392 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:36:09,345 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:36:09,346 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=c0cd32e43cdd4389a6e2d9656a987374, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:36:15,924 [DEBUG] app1.py:1214 - Speech recognizing: the last
2024-12-02 18:36:15,926 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=a5761dff7e654ffb980d2f3276b328cf, text="the last", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:36:16,221 [DEBUG] app1.py:1214 - Speech recognizing: the last name
2024-12-02 18:36:16,222 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=7799cf0250ca4ae5a15804bc7ffb58f2, text="the last name", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:36:16,822 [DEBUG] app1.py:1214 - Speech recognizing: the last name which is
2024-12-02 18:36:16,823 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=fc54d2e1767142d38b827cbce70f4082, text="the last name which is", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:36:17,226 [DEBUG] app1.py:1214 - Speech recognizing: the last name which is repairing
2024-12-02 18:36:17,227 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=151ec68606fc40d18fdd55d7913aa561, text="the last name which is repairing", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:36:19,050 [INFO] app1.py:1205 - Speech recognized: The last name.
2024-12-02 18:36:19,051 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=cbd31c28aa6a43b186b562736f0170d1, text="The last name.", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:36:25,815 [DEBUG] app1.py:1214 - Speech recognizing: right
2024-12-02 18:36:25,815 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=58052a61602d467f9a77c7a5baaa5cea, text="right", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:36:28,021 [DEBUG] app1.py:1214 - Speech recognizing: add
2024-12-02 18:36:28,022 [DEBUG] app1.py:1215 - Recognition interim details: SpeechRecognitionResult(result_id=0b068f29448f416e83ff132375031bc0, text="add", reason=ResultReason.RecognizingSpeech)
2024-12-02 18:36:33,395 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:36:39,132 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:36:39,133 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=4d8f2bcfcdc4412f9d6817c65f53e711, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:36:54,337 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:36:54,337 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=b370b6672dc5471da1464ad1692f7082, text="", reason=ResultReason.RecognizedSpeech)
2024-12-02 18:37:03,396 [INFO] app1.py:898 - Active clients: ['d5f39e3f-1590-4632-8331-dd14565d65a0', '65e638b0-1041-4202-aed0-ae5b89ca2da2', 'ab2ee750-7736-495c-bd4f-3077d2402fea']
2024-12-02 18:37:09,449 [INFO] app1.py:1205 - Speech recognized: 
2024-12-02 18:37:09,450 [DEBUG] app1.py:1206 - Recognition result details: SpeechRecognitionResult(result_id=f40fb1eacfb14c72b1e4e47aa060f0d9, text="", reason=ResultReason.RecognizedSpeech)
